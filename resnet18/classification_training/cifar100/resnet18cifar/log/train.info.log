2022-07-17 08:27:28 - network: resnet18cifar
2022-07-17 08:27:28 - num_classes: 100
2022-07-17 08:27:28 - input_image_size: 32
2022-07-17 08:27:28 - trained_model_path: 
2022-07-17 08:27:28 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-17 08:27:28 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2022-07-17 08:27:28 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fac1047e4f0>
2022-07-17 08:27:28 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fac1047e7f0>
2022-07-17 08:27:28 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fac1047e8e0>
2022-07-17 08:27:28 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fac1047e910>
2022-07-17 08:27:28 - seed: 0
2022-07-17 08:27:28 - batch_size: 128
2022-07-17 08:27:28 - num_workers: 16
2022-07-17 08:27:28 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2022-07-17 08:27:28 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2022-07-17 08:27:28 - epochs: 200
2022-07-17 08:27:28 - print_interval: 50
2022-07-17 08:27:28 - accumulation_steps: 1
2022-07-17 08:27:28 - sync_bn: False
2022-07-17 08:27:28 - apex: True
2022-07-17 08:27:28 - use_ema_model: False
2022-07-17 08:27:28 - ema_model_decay: 0.9999
2022-07-17 08:27:28 - gpus_type: NVIDIA RTX A5000
2022-07-17 08:27:28 - gpus_num: 1
2022-07-17 08:27:28 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fac1047be70>
2022-07-17 08:27:28 - --------------------parameters--------------------
2022-07-17 08:27:28 - name: conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.0.weight, grad: True
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.1.weight, grad: True
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.1.bias, grad: True
2022-07-17 08:27:28 - name: fc.weight, grad: True
2022-07-17 08:27:28 - name: fc.bias, grad: True
2022-07-17 08:27:28 - --------------------buffers--------------------
2022-07-17 08:27:28 - name: conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.1.running_var, grad: False
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2022-07-17 08:27:28 - -----------no weight decay layers--------------
2022-07-17 08:27:28 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2022-07-17 08:27:28 - -------------weight decay layers---------------
2022-07-17 08:27:28 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2022-07-17 08:27:28 - epoch 001 lr: 0.100000
2022-07-17 08:27:33 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.0946
2022-07-17 08:27:35 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.1176
2022-07-17 08:27:37 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9192
2022-07-17 08:27:38 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7903
2022-07-17 08:27:40 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.7842
2022-07-17 08:27:42 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.6062
2022-07-17 08:27:44 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.5315
2022-07-17 08:27:45 - train: epoch 001, train_loss: 3.8988
2022-07-17 08:27:49 - eval: epoch: 001, acc1: 15.970%, acc5: 40.500%, test_loss: 3.6042, per_image_load_time: 0.261ms, per_image_inference_time: 0.047ms
2022-07-17 08:27:49 - until epoch: 001, best_acc1: 15.970%
2022-07-17 08:27:49 - epoch 002 lr: 0.100000
2022-07-17 08:27:54 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.3951
2022-07-17 08:27:56 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.1676
2022-07-17 08:27:58 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.2101
2022-07-17 08:28:00 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 3.3584
2022-07-17 08:28:02 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 2.9135
2022-07-17 08:28:04 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.1373
2022-07-17 08:28:06 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 2.5915
2022-07-17 08:28:07 - train: epoch 002, train_loss: 3.1402
2022-07-17 08:28:10 - eval: epoch: 002, acc1: 23.900%, acc5: 56.090%, test_loss: 3.0364, per_image_load_time: 0.219ms, per_image_inference_time: 0.042ms
2022-07-17 08:28:11 - until epoch: 002, best_acc1: 23.900%
2022-07-17 08:28:11 - epoch 003 lr: 0.100000
2022-07-17 08:28:15 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 2.8312
2022-07-17 08:28:17 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 2.5900
2022-07-17 08:28:18 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 2.5919
2022-07-17 08:28:20 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 2.4195
2022-07-17 08:28:22 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 2.5072
2022-07-17 08:28:24 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 2.6807
2022-07-17 08:28:26 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 2.3684
2022-07-17 08:28:28 - train: epoch 003, train_loss: 2.5574
2022-07-17 08:28:31 - eval: epoch: 003, acc1: 37.260%, acc5: 69.910%, test_loss: 2.3618, per_image_load_time: 0.263ms, per_image_inference_time: 0.044ms
2022-07-17 08:28:31 - until epoch: 003, best_acc1: 37.260%
2022-07-17 08:28:32 - epoch 004 lr: 0.100000
2022-07-17 08:28:36 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 2.1585
2022-07-17 08:28:38 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 2.5503
2022-07-17 08:28:40 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 2.1875
2022-07-17 08:28:42 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 2.5135
2022-07-17 08:28:44 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 2.0785
2022-07-17 08:28:46 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 2.1616
2022-07-17 08:28:47 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 1.8388
2022-07-17 08:28:49 - train: epoch 004, train_loss: 2.1961
2022-07-17 08:28:52 - eval: epoch: 004, acc1: 43.130%, acc5: 75.890%, test_loss: 2.1047, per_image_load_time: 0.232ms, per_image_inference_time: 0.043ms
2022-07-17 08:28:52 - until epoch: 004, best_acc1: 43.130%
2022-07-17 08:28:52 - epoch 005 lr: 0.100000
2022-07-17 08:28:57 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 1.9916
2022-07-17 08:28:59 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 2.0321
2022-07-17 08:29:01 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 1.8705
2022-07-17 08:29:03 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 2.1658
2022-07-17 08:29:05 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 1.7693
2022-07-17 08:29:07 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 1.7150
2022-07-17 08:29:09 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 1.6035
2022-07-17 08:29:11 - train: epoch 005, train_loss: 1.9599
2022-07-17 08:29:14 - eval: epoch: 005, acc1: 43.460%, acc5: 75.790%, test_loss: 2.1491, per_image_load_time: 0.228ms, per_image_inference_time: 0.046ms
2022-07-17 08:29:14 - until epoch: 005, best_acc1: 43.460%
2022-07-17 08:29:14 - epoch 006 lr: 0.100000
2022-07-17 08:29:18 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 1.7650
2022-07-17 08:29:20 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 1.6754
2022-07-17 08:29:22 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 1.8606
2022-07-17 08:29:24 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 1.7309
2022-07-17 08:29:25 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 1.7019
2022-07-17 08:29:27 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 1.5949
2022-07-17 08:29:29 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 1.6088
2022-07-17 08:29:31 - train: epoch 006, train_loss: 1.7824
2022-07-17 08:29:34 - eval: epoch: 006, acc1: 45.750%, acc5: 78.470%, test_loss: 2.0216, per_image_load_time: 0.230ms, per_image_inference_time: 0.043ms
2022-07-17 08:29:34 - until epoch: 006, best_acc1: 45.750%
2022-07-17 08:29:34 - epoch 007 lr: 0.100000
2022-07-17 08:29:39 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 1.8220
2022-07-17 08:29:41 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 1.6399
2022-07-17 08:29:43 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 1.6685
2022-07-17 08:29:45 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 1.5184
2022-07-17 08:29:47 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 1.5972
2022-07-17 08:29:49 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 1.2836
2022-07-17 08:29:51 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 1.5783
2022-07-17 08:29:52 - train: epoch 007, train_loss: 1.6693
2022-07-17 08:29:55 - eval: epoch: 007, acc1: 50.010%, acc5: 81.410%, test_loss: 1.8353, per_image_load_time: 0.247ms, per_image_inference_time: 0.041ms
2022-07-17 08:29:56 - until epoch: 007, best_acc1: 50.010%
2022-07-17 08:29:56 - epoch 008 lr: 0.100000
2022-07-17 08:30:00 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 1.5729
2022-07-17 08:30:02 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 1.4219
2022-07-17 08:30:04 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 1.4585
2022-07-17 08:30:06 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 1.4328
2022-07-17 08:30:08 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 1.2921
2022-07-17 08:30:10 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 1.5226
2022-07-17 08:30:12 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 1.5024
2022-07-17 08:30:13 - train: epoch 008, train_loss: 1.5456
2022-07-17 08:30:17 - eval: epoch: 008, acc1: 52.740%, acc5: 81.870%, test_loss: 1.7580, per_image_load_time: 0.282ms, per_image_inference_time: 0.047ms
2022-07-17 08:30:17 - until epoch: 008, best_acc1: 52.740%
2022-07-17 08:30:17 - epoch 009 lr: 0.100000
2022-07-17 08:30:22 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 1.3722
2022-07-17 08:30:24 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 1.5923
2022-07-17 08:30:26 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 1.4805
2022-07-17 08:30:28 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 1.4988
2022-07-17 08:30:29 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 1.4961
2022-07-17 08:30:31 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 1.2254
2022-07-17 08:30:32 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 1.5765
2022-07-17 08:30:34 - train: epoch 009, train_loss: 1.4661
2022-07-17 08:30:37 - eval: epoch: 009, acc1: 52.690%, acc5: 83.270%, test_loss: 1.7082, per_image_load_time: 0.305ms, per_image_inference_time: 0.042ms
2022-07-17 08:30:38 - until epoch: 009, best_acc1: 52.740%
2022-07-17 08:30:38 - epoch 010 lr: 0.100000
2022-07-17 08:30:42 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 1.5711
2022-07-17 08:30:44 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 1.2630
2022-07-17 08:30:46 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 1.3968
2022-07-17 08:30:48 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 1.3827
2022-07-17 08:30:50 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 1.4742
2022-07-17 08:30:52 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 1.2790
2022-07-17 08:30:54 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 1.2483
2022-07-17 08:30:56 - train: epoch 010, train_loss: 1.3961
2022-07-17 08:30:59 - eval: epoch: 010, acc1: 54.140%, acc5: 84.410%, test_loss: 1.6435, per_image_load_time: 0.286ms, per_image_inference_time: 0.045ms
2022-07-17 08:30:59 - until epoch: 010, best_acc1: 54.140%
2022-07-17 08:30:59 - epoch 011 lr: 0.100000
2022-07-17 08:31:04 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 1.3879
2022-07-17 08:31:05 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 1.1547
2022-07-17 08:31:07 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 1.6447
2022-07-17 08:31:08 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 1.3246
2022-07-17 08:31:10 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 1.3897
2022-07-17 08:31:12 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 1.1575
2022-07-17 08:31:13 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 1.2876
2022-07-17 08:31:15 - train: epoch 011, train_loss: 1.3426
2022-07-17 08:31:18 - eval: epoch: 011, acc1: 52.050%, acc5: 82.930%, test_loss: 1.7877, per_image_load_time: 0.225ms, per_image_inference_time: 0.042ms
2022-07-17 08:31:18 - until epoch: 011, best_acc1: 54.140%
2022-07-17 08:31:18 - epoch 012 lr: 0.100000
2022-07-17 08:31:22 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 1.1585
2022-07-17 08:31:24 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 1.4804
2022-07-17 08:31:26 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 1.3840
2022-07-17 08:31:28 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 1.5717
2022-07-17 08:31:30 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 1.1778
2022-07-17 08:31:32 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 1.3544
2022-07-17 08:31:34 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 1.1323
2022-07-17 08:31:36 - train: epoch 012, train_loss: 1.3064
2022-07-17 08:31:40 - eval: epoch: 012, acc1: 58.240%, acc5: 85.800%, test_loss: 1.5281, per_image_load_time: 0.263ms, per_image_inference_time: 0.045ms
2022-07-17 08:31:40 - until epoch: 012, best_acc1: 58.240%
2022-07-17 08:31:40 - epoch 013 lr: 0.100000
2022-07-17 08:31:44 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 1.2074
2022-07-17 08:31:46 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 1.1760
2022-07-17 08:31:47 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 1.5003
2022-07-17 08:31:49 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 1.0917
2022-07-17 08:31:50 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 1.4271
2022-07-17 08:31:52 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 1.1281
2022-07-17 08:31:54 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 1.0813
2022-07-17 08:31:56 - train: epoch 013, train_loss: 1.2625
2022-07-17 08:31:59 - eval: epoch: 013, acc1: 55.210%, acc5: 84.520%, test_loss: 1.6236, per_image_load_time: 0.220ms, per_image_inference_time: 0.043ms
2022-07-17 08:31:59 - until epoch: 013, best_acc1: 58.240%
2022-07-17 08:31:59 - epoch 014 lr: 0.100000
2022-07-17 08:32:04 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 1.0346
2022-07-17 08:32:06 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 1.0581
2022-07-17 08:32:08 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 1.1730
2022-07-17 08:32:10 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 1.2320
2022-07-17 08:32:12 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 1.1307
2022-07-17 08:32:14 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 1.2684
2022-07-17 08:32:16 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 1.1701
2022-07-17 08:32:17 - train: epoch 014, train_loss: 1.2199
2022-07-17 08:32:21 - eval: epoch: 014, acc1: 54.990%, acc5: 83.950%, test_loss: 1.6748, per_image_load_time: 0.266ms, per_image_inference_time: 0.042ms
2022-07-17 08:32:21 - until epoch: 014, best_acc1: 58.240%
2022-07-17 08:32:21 - epoch 015 lr: 0.100000
2022-07-17 08:32:25 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 0.8936
2022-07-17 08:32:27 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 1.5314
2022-07-17 08:32:29 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 1.3240
2022-07-17 08:32:31 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 1.3615
2022-07-17 08:32:33 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.3372
2022-07-17 08:32:35 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 1.0341
2022-07-17 08:32:37 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 1.1990
2022-07-17 08:32:39 - train: epoch 015, train_loss: 1.1922
2022-07-17 08:32:42 - eval: epoch: 015, acc1: 59.050%, acc5: 85.780%, test_loss: 1.5123, per_image_load_time: 0.237ms, per_image_inference_time: 0.042ms
2022-07-17 08:32:42 - until epoch: 015, best_acc1: 59.050%
2022-07-17 08:32:42 - epoch 016 lr: 0.100000
2022-07-17 08:32:46 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 1.2284
2022-07-17 08:32:48 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 1.1359
2022-07-17 08:32:51 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 1.2643
2022-07-17 08:32:52 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 1.3798
2022-07-17 08:32:54 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 1.0477
2022-07-17 08:32:56 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 1.2915
2022-07-17 08:32:57 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 1.1119
2022-07-17 08:32:59 - train: epoch 016, train_loss: 1.1592
2022-07-17 08:33:02 - eval: epoch: 016, acc1: 58.990%, acc5: 86.890%, test_loss: 1.5073, per_image_load_time: 0.280ms, per_image_inference_time: 0.045ms
2022-07-17 08:33:02 - until epoch: 016, best_acc1: 59.050%
2022-07-17 08:33:02 - epoch 017 lr: 0.100000
2022-07-17 08:33:07 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 0.9234
2022-07-17 08:33:09 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 1.1099
2022-07-17 08:33:11 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 0.8280
2022-07-17 08:33:13 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 1.1070
2022-07-17 08:33:15 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 1.2406
2022-07-17 08:33:17 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 1.3892
2022-07-17 08:33:19 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 0.8751
2022-07-17 08:33:20 - train: epoch 017, train_loss: 1.1457
2022-07-17 08:33:24 - eval: epoch: 017, acc1: 58.360%, acc5: 86.340%, test_loss: 1.5577, per_image_load_time: 0.264ms, per_image_inference_time: 0.044ms
2022-07-17 08:33:24 - until epoch: 017, best_acc1: 59.050%
2022-07-17 08:33:24 - epoch 018 lr: 0.100000
2022-07-17 08:33:28 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 0.9272
2022-07-17 08:33:30 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 0.9650
2022-07-17 08:33:32 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.3485
2022-07-17 08:33:33 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 1.1280
2022-07-17 08:33:35 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 1.1081
2022-07-17 08:33:36 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 0.9238
2022-07-17 08:33:38 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 1.3029
2022-07-17 08:33:40 - train: epoch 018, train_loss: 1.1137
2022-07-17 08:33:43 - eval: epoch: 018, acc1: 58.270%, acc5: 86.320%, test_loss: 1.5439, per_image_load_time: 0.246ms, per_image_inference_time: 0.050ms
2022-07-17 08:33:43 - until epoch: 018, best_acc1: 59.050%
2022-07-17 08:33:43 - epoch 019 lr: 0.100000
2022-07-17 08:33:48 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 0.9643
2022-07-17 08:33:50 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 1.0351
2022-07-17 08:33:52 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 1.3373
2022-07-17 08:33:54 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 1.2809
2022-07-17 08:33:56 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 1.3021
2022-07-17 08:33:58 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 1.0874
2022-07-17 08:34:00 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 1.0540
2022-07-17 08:34:02 - train: epoch 019, train_loss: 1.0846
2022-07-17 08:34:06 - eval: epoch: 019, acc1: 58.960%, acc5: 87.040%, test_loss: 1.4704, per_image_load_time: 0.309ms, per_image_inference_time: 0.042ms
2022-07-17 08:34:06 - until epoch: 019, best_acc1: 59.050%
2022-07-17 08:34:06 - epoch 020 lr: 0.100000
2022-07-17 08:34:11 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 1.1854
2022-07-17 08:34:12 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 0.9573
2022-07-17 08:34:14 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 1.2231
2022-07-17 08:34:15 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 1.2421
2022-07-17 08:34:17 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 0.9801
2022-07-17 08:34:19 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 1.0452
2022-07-17 08:34:21 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 1.0795
2022-07-17 08:34:23 - train: epoch 020, train_loss: 1.0741
2022-07-17 08:34:26 - eval: epoch: 020, acc1: 59.190%, acc5: 86.890%, test_loss: 1.4875, per_image_load_time: 0.234ms, per_image_inference_time: 0.043ms
2022-07-17 08:34:26 - until epoch: 020, best_acc1: 59.190%
2022-07-17 08:34:26 - epoch 021 lr: 0.100000
2022-07-17 08:34:31 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 0.9991
2022-07-17 08:34:33 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.2158
2022-07-17 08:34:35 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 1.2616
2022-07-17 08:34:37 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.1281
2022-07-17 08:34:39 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 1.1027
2022-07-17 08:34:41 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 1.1812
2022-07-17 08:34:43 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 1.0874
2022-07-17 08:34:44 - train: epoch 021, train_loss: 1.0607
2022-07-17 08:34:48 - eval: epoch: 021, acc1: 58.610%, acc5: 87.350%, test_loss: 1.5529, per_image_load_time: 0.317ms, per_image_inference_time: 0.046ms
2022-07-17 08:34:48 - until epoch: 021, best_acc1: 59.190%
2022-07-17 08:34:48 - epoch 022 lr: 0.100000
2022-07-17 08:34:52 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 1.0555
2022-07-17 08:34:54 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 1.0973
2022-07-17 08:34:56 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 1.0064
2022-07-17 08:34:58 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 1.4885
2022-07-17 08:35:00 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 1.1501
2022-07-17 08:35:02 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 1.1608
2022-07-17 08:35:04 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.0885
2022-07-17 08:35:06 - train: epoch 022, train_loss: 1.0502
2022-07-17 08:35:09 - eval: epoch: 022, acc1: 59.190%, acc5: 86.540%, test_loss: 1.5364, per_image_load_time: 0.252ms, per_image_inference_time: 0.043ms
2022-07-17 08:35:09 - until epoch: 022, best_acc1: 59.190%
2022-07-17 08:35:09 - epoch 023 lr: 0.100000
2022-07-17 08:35:14 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 0.8941
2022-07-17 08:35:16 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 0.9158
2022-07-17 08:35:18 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 1.0566
2022-07-17 08:35:19 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.2669
2022-07-17 08:35:21 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 1.0477
2022-07-17 08:35:23 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 1.0971
2022-07-17 08:35:25 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 0.9859
2022-07-17 08:35:26 - train: epoch 023, train_loss: 1.0312
2022-07-17 08:35:30 - eval: epoch: 023, acc1: 59.610%, acc5: 86.700%, test_loss: 1.5098, per_image_load_time: 0.290ms, per_image_inference_time: 0.052ms
2022-07-17 08:35:30 - until epoch: 023, best_acc1: 59.610%
2022-07-17 08:35:30 - epoch 024 lr: 0.100000
2022-07-17 08:35:34 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 0.7987
2022-07-17 08:35:36 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 0.8833
2022-07-17 08:35:38 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 1.0404
2022-07-17 08:35:40 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 1.3090
2022-07-17 08:35:42 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 0.9959
2022-07-17 08:35:44 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.1011
2022-07-17 08:35:46 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 1.2259
2022-07-17 08:35:48 - train: epoch 024, train_loss: 1.0165
2022-07-17 08:35:51 - eval: epoch: 024, acc1: 61.550%, acc5: 87.610%, test_loss: 1.4169, per_image_load_time: 0.238ms, per_image_inference_time: 0.045ms
2022-07-17 08:35:52 - until epoch: 024, best_acc1: 61.550%
2022-07-17 08:35:52 - epoch 025 lr: 0.100000
2022-07-17 08:35:56 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 0.9937
2022-07-17 08:35:57 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 0.9701
2022-07-17 08:35:59 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.2535
2022-07-17 08:36:01 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 1.1109
2022-07-17 08:36:02 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 0.8704
2022-07-17 08:36:04 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 1.1056
2022-07-17 08:36:06 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 1.1035
2022-07-17 08:36:08 - train: epoch 025, train_loss: 1.0040
2022-07-17 08:36:11 - eval: epoch: 025, acc1: 58.940%, acc5: 86.820%, test_loss: 1.5155, per_image_load_time: 0.216ms, per_image_inference_time: 0.042ms
2022-07-17 08:36:11 - until epoch: 025, best_acc1: 61.550%
2022-07-17 08:36:11 - epoch 026 lr: 0.100000
2022-07-17 08:36:15 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 0.8402
2022-07-17 08:36:17 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 0.8327
2022-07-17 08:36:19 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 1.0955
2022-07-17 08:36:21 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 1.1026
2022-07-17 08:36:23 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 0.7731
2022-07-17 08:36:25 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.1042
2022-07-17 08:36:27 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.2001
2022-07-17 08:36:29 - train: epoch 026, train_loss: 0.9826
2022-07-17 08:36:32 - eval: epoch: 026, acc1: 60.310%, acc5: 87.470%, test_loss: 1.4646, per_image_load_time: 0.246ms, per_image_inference_time: 0.047ms
2022-07-17 08:36:32 - until epoch: 026, best_acc1: 61.550%
2022-07-17 08:36:32 - epoch 027 lr: 0.100000
2022-07-17 08:36:37 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 0.9127
2022-07-17 08:36:39 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 1.0149
2022-07-17 08:36:40 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 0.8347
2022-07-17 08:36:43 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 1.3348
2022-07-17 08:36:45 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 1.1715
2022-07-17 08:36:47 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 1.1559
2022-07-17 08:36:49 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 1.1501
2022-07-17 08:36:51 - train: epoch 027, train_loss: 0.9774
2022-07-17 08:36:54 - eval: epoch: 027, acc1: 61.790%, acc5: 88.650%, test_loss: 1.3903, per_image_load_time: 0.261ms, per_image_inference_time: 0.044ms
2022-07-17 08:36:54 - until epoch: 027, best_acc1: 61.790%
2022-07-17 08:36:54 - epoch 028 lr: 0.100000
2022-07-17 08:36:58 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 1.0536
2022-07-17 08:37:00 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 1.0370
2022-07-17 08:37:02 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 0.9516
2022-07-17 08:37:04 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 0.9986
2022-07-17 08:37:06 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 1.0972
2022-07-17 08:37:08 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 0.8353
2022-07-17 08:37:09 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 1.2112
2022-07-17 08:37:11 - train: epoch 028, train_loss: 0.9738
2022-07-17 08:37:14 - eval: epoch: 028, acc1: 60.020%, acc5: 86.910%, test_loss: 1.5436, per_image_load_time: 0.246ms, per_image_inference_time: 0.046ms
2022-07-17 08:37:14 - until epoch: 028, best_acc1: 61.790%
2022-07-17 08:37:14 - epoch 029 lr: 0.100000
2022-07-17 08:37:19 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 1.0387
2022-07-17 08:37:21 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 1.0208
2022-07-17 08:37:24 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 1.0062
2022-07-17 08:37:26 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 0.9095
2022-07-17 08:37:28 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 0.9408
2022-07-17 08:37:30 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 0.8967
2022-07-17 08:37:32 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 0.9257
2022-07-17 08:37:33 - train: epoch 029, train_loss: 0.9582
2022-07-17 08:37:36 - eval: epoch: 029, acc1: 59.970%, acc5: 86.710%, test_loss: 1.5058, per_image_load_time: 0.236ms, per_image_inference_time: 0.042ms
2022-07-17 08:37:37 - until epoch: 029, best_acc1: 61.790%
2022-07-17 08:37:37 - epoch 030 lr: 0.100000
2022-07-17 08:37:41 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 0.9377
2022-07-17 08:37:43 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 0.8646
2022-07-17 08:37:44 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 0.8528
2022-07-17 08:37:46 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 0.7660
2022-07-17 08:37:47 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 0.9953
2022-07-17 08:37:49 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 0.8465
2022-07-17 08:37:50 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 1.0247
2022-07-17 08:37:52 - train: epoch 030, train_loss: 0.9512
2022-07-17 08:37:56 - eval: epoch: 030, acc1: 59.760%, acc5: 86.480%, test_loss: 1.5156, per_image_load_time: 0.346ms, per_image_inference_time: 0.054ms
2022-07-17 08:37:56 - until epoch: 030, best_acc1: 61.790%
2022-07-17 08:37:56 - epoch 031 lr: 0.100000
2022-07-17 08:38:01 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 1.0324
2022-07-17 08:38:03 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 0.9213
2022-07-17 08:38:05 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 1.1017
2022-07-17 08:38:07 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 1.0520
2022-07-17 08:38:09 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 0.8689
2022-07-17 08:38:11 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 1.0909
2022-07-17 08:38:13 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 0.9507
2022-07-17 08:38:15 - train: epoch 031, train_loss: 0.9481
2022-07-17 08:38:18 - eval: epoch: 031, acc1: 61.250%, acc5: 87.360%, test_loss: 1.4572, per_image_load_time: 0.234ms, per_image_inference_time: 0.046ms
2022-07-17 08:38:18 - until epoch: 031, best_acc1: 61.790%
2022-07-17 08:38:18 - epoch 032 lr: 0.100000
2022-07-17 08:38:22 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 0.9903
2022-07-17 08:38:23 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 0.8830
2022-07-17 08:38:25 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 0.8665
2022-07-17 08:38:27 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 0.9106
2022-07-17 08:38:28 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 1.0497
2022-07-17 08:38:30 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 0.8577
2022-07-17 08:38:32 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 0.8091
2022-07-17 08:38:33 - train: epoch 032, train_loss: 0.9487
2022-07-17 08:38:37 - eval: epoch: 032, acc1: 61.680%, acc5: 87.640%, test_loss: 1.4681, per_image_load_time: 0.276ms, per_image_inference_time: 0.044ms
2022-07-17 08:38:37 - until epoch: 032, best_acc1: 61.790%
2022-07-17 08:38:37 - epoch 033 lr: 0.100000
2022-07-17 08:38:42 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 0.8512
2022-07-17 08:38:44 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 0.7294
2022-07-17 08:38:46 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 1.0163
2022-07-17 08:38:48 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 1.0585
2022-07-17 08:38:50 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 0.9513
2022-07-17 08:38:52 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 1.1613
2022-07-17 08:38:54 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 1.0733
2022-07-17 08:38:55 - train: epoch 033, train_loss: 0.9404
2022-07-17 08:38:59 - eval: epoch: 033, acc1: 62.220%, acc5: 87.880%, test_loss: 1.4206, per_image_load_time: 0.286ms, per_image_inference_time: 0.043ms
2022-07-17 08:38:59 - until epoch: 033, best_acc1: 62.220%
2022-07-17 08:38:59 - epoch 034 lr: 0.100000
2022-07-17 08:39:03 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 0.9018
2022-07-17 08:39:05 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 0.7119
2022-07-17 08:39:06 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 1.2364
2022-07-17 08:39:08 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 0.7691
2022-07-17 08:39:10 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 0.9947
2022-07-17 08:39:12 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 1.1039
2022-07-17 08:39:14 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 1.1009
2022-07-17 08:39:16 - train: epoch 034, train_loss: 0.9344
2022-07-17 08:39:20 - eval: epoch: 034, acc1: 60.860%, acc5: 86.810%, test_loss: 1.4787, per_image_load_time: 0.270ms, per_image_inference_time: 0.044ms
2022-07-17 08:39:20 - until epoch: 034, best_acc1: 62.220%
2022-07-17 08:39:20 - epoch 035 lr: 0.100000
2022-07-17 08:39:24 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 0.6437
2022-07-17 08:39:26 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 0.8452
2022-07-17 08:39:28 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 0.8734
2022-07-17 08:39:30 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 0.8842
2022-07-17 08:39:32 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 0.7647
2022-07-17 08:39:33 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 0.8854
2022-07-17 08:39:35 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 1.1874
2022-07-17 08:39:36 - train: epoch 035, train_loss: 0.9240
2022-07-17 08:39:39 - eval: epoch: 035, acc1: 60.550%, acc5: 86.370%, test_loss: 1.5097, per_image_load_time: 0.236ms, per_image_inference_time: 0.041ms
2022-07-17 08:39:39 - until epoch: 035, best_acc1: 62.220%
2022-07-17 08:39:39 - epoch 036 lr: 0.100000
2022-07-17 08:39:44 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 1.0227
2022-07-17 08:39:46 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 0.9410
2022-07-17 08:39:48 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 0.8632
2022-07-17 08:39:50 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 0.8010
2022-07-17 08:39:52 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 0.8787
2022-07-17 08:39:54 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 0.7477
2022-07-17 08:39:56 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 1.1212
2022-07-17 08:39:58 - train: epoch 036, train_loss: 0.9170
2022-07-17 08:40:01 - eval: epoch: 036, acc1: 59.700%, acc5: 87.070%, test_loss: 1.6031, per_image_load_time: 0.255ms, per_image_inference_time: 0.043ms
2022-07-17 08:40:01 - until epoch: 036, best_acc1: 62.220%
2022-07-17 08:40:01 - epoch 037 lr: 0.100000
2022-07-17 08:40:06 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 0.8154
2022-07-17 08:40:08 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 0.9626
2022-07-17 08:40:09 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 0.9113
2022-07-17 08:40:11 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 1.4034
2022-07-17 08:40:12 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 0.9578
2022-07-17 08:40:14 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 1.2552
2022-07-17 08:40:15 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 1.0128
2022-07-17 08:40:17 - train: epoch 037, train_loss: 0.9139
2022-07-17 08:40:20 - eval: epoch: 037, acc1: 63.600%, acc5: 89.390%, test_loss: 1.3499, per_image_load_time: 0.255ms, per_image_inference_time: 0.043ms
2022-07-17 08:40:20 - until epoch: 037, best_acc1: 63.600%
2022-07-17 08:40:20 - epoch 038 lr: 0.100000
2022-07-17 08:40:25 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 0.6664
2022-07-17 08:40:26 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 0.6867
2022-07-17 08:40:28 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 0.9389
2022-07-17 08:40:31 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 0.6818
2022-07-17 08:40:33 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 0.8215
2022-07-17 08:40:35 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 1.0841
2022-07-17 08:40:37 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 1.1187
2022-07-17 08:40:39 - train: epoch 038, train_loss: 0.9005
2022-07-17 08:40:42 - eval: epoch: 038, acc1: 63.790%, acc5: 89.070%, test_loss: 1.3662, per_image_load_time: 0.256ms, per_image_inference_time: 0.043ms
2022-07-17 08:40:42 - until epoch: 038, best_acc1: 63.790%
2022-07-17 08:40:42 - epoch 039 lr: 0.100000
2022-07-17 08:40:46 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 1.1122
2022-07-17 08:40:48 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 0.8230
2022-07-17 08:40:49 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 1.0835
2022-07-17 08:40:51 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 1.0043
2022-07-17 08:40:52 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 0.8036
2022-07-17 08:40:54 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 0.7287
2022-07-17 08:40:56 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 1.0790
2022-07-17 08:40:58 - train: epoch 039, train_loss: 0.9032
2022-07-17 08:41:01 - eval: epoch: 039, acc1: 62.230%, acc5: 88.160%, test_loss: 1.4035, per_image_load_time: 0.232ms, per_image_inference_time: 0.043ms
2022-07-17 08:41:01 - until epoch: 039, best_acc1: 63.790%
2022-07-17 08:41:01 - epoch 040 lr: 0.100000
2022-07-17 08:41:05 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 0.8127
2022-07-17 08:41:07 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 0.5820
2022-07-17 08:41:10 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 0.9357
2022-07-17 08:41:12 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 1.0890
2022-07-17 08:41:14 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 1.2186
2022-07-17 08:41:16 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 0.8993
2022-07-17 08:41:18 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 1.1881
2022-07-17 08:41:19 - train: epoch 040, train_loss: 0.9053
2022-07-17 08:41:23 - eval: epoch: 040, acc1: 60.010%, acc5: 87.530%, test_loss: 1.4839, per_image_load_time: 0.273ms, per_image_inference_time: 0.042ms
2022-07-17 08:41:23 - until epoch: 040, best_acc1: 63.790%
2022-07-17 08:41:23 - epoch 041 lr: 0.100000
2022-07-17 08:41:27 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 0.6507
2022-07-17 08:41:29 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 0.6557
2022-07-17 08:41:30 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 1.0409
2022-07-17 08:41:32 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 0.8055
2022-07-17 08:41:34 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 1.2623
2022-07-17 08:41:36 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 0.9536
2022-07-17 08:41:38 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 1.1644
2022-07-17 08:41:40 - train: epoch 041, train_loss: 0.8974
2022-07-17 08:41:43 - eval: epoch: 041, acc1: 63.810%, acc5: 89.580%, test_loss: 1.3357, per_image_load_time: 0.237ms, per_image_inference_time: 0.043ms
2022-07-17 08:41:43 - until epoch: 041, best_acc1: 63.810%
2022-07-17 08:41:43 - epoch 042 lr: 0.100000
2022-07-17 08:41:48 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 0.5671
2022-07-17 08:41:50 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 0.8756
2022-07-17 08:41:52 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 0.7229
2022-07-17 08:41:54 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 0.8406
2022-07-17 08:41:56 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 1.1423
2022-07-17 08:41:58 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 0.8528
2022-07-17 08:41:59 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 0.7409
2022-07-17 08:42:01 - train: epoch 042, train_loss: 0.8888
2022-07-17 08:42:04 - eval: epoch: 042, acc1: 63.560%, acc5: 89.590%, test_loss: 1.3364, per_image_load_time: 0.279ms, per_image_inference_time: 0.042ms
2022-07-17 08:42:05 - until epoch: 042, best_acc1: 63.810%
2022-07-17 08:42:05 - epoch 043 lr: 0.100000
2022-07-17 08:42:09 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 0.8469
2022-07-17 08:42:11 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 0.9453
2022-07-17 08:42:13 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 0.9138
2022-07-17 08:42:15 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 1.1346
2022-07-17 08:42:17 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 1.0077
2022-07-17 08:42:19 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 0.9932
2022-07-17 08:42:21 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 0.8034
2022-07-17 08:42:23 - train: epoch 043, train_loss: 0.8999
2022-07-17 08:42:27 - eval: epoch: 043, acc1: 62.380%, acc5: 88.580%, test_loss: 1.4202, per_image_load_time: 0.262ms, per_image_inference_time: 0.062ms
2022-07-17 08:42:27 - until epoch: 043, best_acc1: 63.810%
2022-07-17 08:42:27 - epoch 044 lr: 0.100000
2022-07-17 08:42:32 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 0.8925
2022-07-17 08:42:33 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 1.0906
2022-07-17 08:42:35 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 0.8064
2022-07-17 08:42:37 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 0.8776
2022-07-17 08:42:38 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 1.0257
2022-07-17 08:42:40 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 0.7510
2022-07-17 08:42:42 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 0.8034
2022-07-17 08:42:43 - train: epoch 044, train_loss: 0.8826
2022-07-17 08:42:46 - eval: epoch: 044, acc1: 60.590%, acc5: 86.850%, test_loss: 1.5777, per_image_load_time: 0.264ms, per_image_inference_time: 0.042ms
2022-07-17 08:42:47 - until epoch: 044, best_acc1: 63.810%
2022-07-17 08:42:47 - epoch 045 lr: 0.100000
2022-07-17 08:42:51 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 0.9166
2022-07-17 08:42:53 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 0.7846
2022-07-17 08:42:55 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 0.7844
2022-07-17 08:42:57 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 0.8502
2022-07-17 08:42:59 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 0.8585
2022-07-17 08:43:01 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 0.9135
2022-07-17 08:43:03 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 1.0042
2022-07-17 08:43:05 - train: epoch 045, train_loss: 0.8787
2022-07-17 08:43:09 - eval: epoch: 045, acc1: 63.540%, acc5: 88.840%, test_loss: 1.3676, per_image_load_time: 0.298ms, per_image_inference_time: 0.048ms
2022-07-17 08:43:09 - until epoch: 045, best_acc1: 63.810%
2022-07-17 08:43:09 - epoch 046 lr: 0.100000
2022-07-17 08:43:13 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 0.6771
2022-07-17 08:43:15 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 0.7385
2022-07-17 08:43:17 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 0.6721
2022-07-17 08:43:18 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 0.9578
2022-07-17 08:43:20 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 0.9500
2022-07-17 08:43:22 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 0.6380
2022-07-17 08:43:24 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 0.8712
2022-07-17 08:43:26 - train: epoch 046, train_loss: 0.8707
2022-07-17 08:43:29 - eval: epoch: 046, acc1: 60.180%, acc5: 86.930%, test_loss: 1.4900, per_image_load_time: 0.246ms, per_image_inference_time: 0.041ms
2022-07-17 08:43:29 - until epoch: 046, best_acc1: 63.810%
2022-07-17 08:43:29 - epoch 047 lr: 0.100000
2022-07-17 08:43:34 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 0.6631
2022-07-17 08:43:36 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 0.7307
2022-07-17 08:43:38 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 0.8955
2022-07-17 08:43:40 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 0.8740
2022-07-17 08:43:42 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 0.9062
2022-07-17 08:43:44 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 0.8518
2022-07-17 08:43:46 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 0.8532
2022-07-17 08:43:48 - train: epoch 047, train_loss: 0.8768
2022-07-17 08:43:51 - eval: epoch: 047, acc1: 62.760%, acc5: 88.470%, test_loss: 1.4265, per_image_load_time: 0.301ms, per_image_inference_time: 0.047ms
2022-07-17 08:43:52 - until epoch: 047, best_acc1: 63.810%
2022-07-17 08:43:52 - epoch 048 lr: 0.100000
2022-07-17 08:43:56 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 0.8790
2022-07-17 08:43:58 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 0.7130
2022-07-17 08:44:00 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 0.8762
2022-07-17 08:44:02 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 0.8454
2022-07-17 08:44:04 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 0.9923
2022-07-17 08:44:06 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 0.7333
2022-07-17 08:44:08 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 0.9177
2022-07-17 08:44:10 - train: epoch 048, train_loss: 0.8823
2022-07-17 08:44:13 - eval: epoch: 048, acc1: 64.240%, acc5: 89.000%, test_loss: 1.3629, per_image_load_time: 0.259ms, per_image_inference_time: 0.046ms
2022-07-17 08:44:13 - until epoch: 048, best_acc1: 64.240%
2022-07-17 08:44:13 - epoch 049 lr: 0.100000
2022-07-17 08:44:18 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 1.0483
2022-07-17 08:44:20 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 0.6848
2022-07-17 08:44:22 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 0.8611
2022-07-17 08:44:23 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 1.0484
2022-07-17 08:44:25 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 0.9278
2022-07-17 08:44:27 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 0.9126
2022-07-17 08:44:29 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 0.9716
2022-07-17 08:44:30 - train: epoch 049, train_loss: 0.8690
2022-07-17 08:44:34 - eval: epoch: 049, acc1: 61.120%, acc5: 87.910%, test_loss: 1.4897, per_image_load_time: 0.345ms, per_image_inference_time: 0.049ms
2022-07-17 08:44:35 - until epoch: 049, best_acc1: 64.240%
2022-07-17 08:44:35 - epoch 050 lr: 0.100000
2022-07-17 08:44:39 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 0.7228
2022-07-17 08:44:41 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 0.5870
2022-07-17 08:44:43 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 0.8829
2022-07-17 08:44:45 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 0.7908
2022-07-17 08:44:47 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 0.9135
2022-07-17 08:44:49 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 0.8969
2022-07-17 08:44:51 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 0.9961
2022-07-17 08:44:53 - train: epoch 050, train_loss: 0.8597
2022-07-17 08:44:56 - eval: epoch: 050, acc1: 63.980%, acc5: 88.750%, test_loss: 1.4033, per_image_load_time: 0.255ms, per_image_inference_time: 0.041ms
2022-07-17 08:44:56 - until epoch: 050, best_acc1: 64.240%
2022-07-17 08:44:56 - epoch 051 lr: 0.100000
2022-07-17 08:45:00 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 0.7729
2022-07-17 08:45:02 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 0.8324
2022-07-17 08:45:03 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 0.9038
2022-07-17 08:45:05 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 0.9538
2022-07-17 08:45:07 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 0.9770
2022-07-17 08:45:08 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 0.8570
2022-07-17 08:45:11 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 0.7177
2022-07-17 08:45:12 - train: epoch 051, train_loss: 0.8761
2022-07-17 08:45:16 - eval: epoch: 051, acc1: 61.590%, acc5: 87.560%, test_loss: 1.4632, per_image_load_time: 0.263ms, per_image_inference_time: 0.044ms
2022-07-17 08:45:16 - until epoch: 051, best_acc1: 64.240%
2022-07-17 08:45:16 - epoch 052 lr: 0.100000
2022-07-17 08:45:20 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 0.8331
2022-07-17 08:45:22 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 0.9492
2022-07-17 08:45:24 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 0.8883
2022-07-17 08:45:26 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 0.9349
2022-07-17 08:45:28 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 0.8479
2022-07-17 08:45:30 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 0.7296
2022-07-17 08:45:32 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 0.9069
2022-07-17 08:45:34 - train: epoch 052, train_loss: 0.8615
2022-07-17 08:45:38 - eval: epoch: 052, acc1: 62.900%, acc5: 88.670%, test_loss: 1.3937, per_image_load_time: 0.335ms, per_image_inference_time: 0.050ms
2022-07-17 08:45:38 - until epoch: 052, best_acc1: 64.240%
2022-07-17 08:45:38 - epoch 053 lr: 0.100000
2022-07-17 08:45:42 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 0.6445
2022-07-17 08:45:44 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 0.8137
2022-07-17 08:45:46 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 0.7201
2022-07-17 08:45:48 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 0.8773
2022-07-17 08:45:50 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 0.9066
2022-07-17 08:45:52 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 0.6204
2022-07-17 08:45:54 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 0.8455
2022-07-17 08:45:55 - train: epoch 053, train_loss: 0.8531
2022-07-17 08:45:59 - eval: epoch: 053, acc1: 62.230%, acc5: 88.520%, test_loss: 1.4566, per_image_load_time: 0.254ms, per_image_inference_time: 0.042ms
2022-07-17 08:45:59 - until epoch: 053, best_acc1: 64.240%
2022-07-17 08:45:59 - epoch 054 lr: 0.100000
2022-07-17 08:46:03 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 0.8435
2022-07-17 08:46:05 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 0.8512
2022-07-17 08:46:07 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 0.5891
2022-07-17 08:46:09 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 1.1761
2022-07-17 08:46:11 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 0.8219
2022-07-17 08:46:13 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 0.9821
2022-07-17 08:46:15 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 0.8357
2022-07-17 08:46:16 - train: epoch 054, train_loss: 0.8499
2022-07-17 08:46:19 - eval: epoch: 054, acc1: 61.410%, acc5: 87.980%, test_loss: 1.4954, per_image_load_time: 0.259ms, per_image_inference_time: 0.044ms
2022-07-17 08:46:19 - until epoch: 054, best_acc1: 64.240%
2022-07-17 08:46:19 - epoch 055 lr: 0.100000
2022-07-17 08:46:24 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 0.8699
2022-07-17 08:46:26 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 0.8058
2022-07-17 08:46:28 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 0.8138
2022-07-17 08:46:30 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 1.0393
2022-07-17 08:46:32 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 0.9235
2022-07-17 08:46:34 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 0.7552
2022-07-17 08:46:36 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 0.7459
2022-07-17 08:46:38 - train: epoch 055, train_loss: 0.8522
2022-07-17 08:46:42 - eval: epoch: 055, acc1: 64.140%, acc5: 88.860%, test_loss: 1.3845, per_image_load_time: 0.261ms, per_image_inference_time: 0.043ms
2022-07-17 08:46:42 - until epoch: 055, best_acc1: 64.240%
2022-07-17 08:46:42 - epoch 056 lr: 0.100000
2022-07-17 08:46:46 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 0.8462
2022-07-17 08:46:48 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 0.7385
2022-07-17 08:46:50 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 0.8637
2022-07-17 08:46:51 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 0.8350
2022-07-17 08:46:53 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 0.7675
2022-07-17 08:46:54 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 1.2112
2022-07-17 08:46:56 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 0.7856
2022-07-17 08:46:57 - train: epoch 056, train_loss: 0.8545
2022-07-17 08:47:01 - eval: epoch: 056, acc1: 63.750%, acc5: 89.420%, test_loss: 1.3549, per_image_load_time: 0.277ms, per_image_inference_time: 0.050ms
2022-07-17 08:47:01 - until epoch: 056, best_acc1: 64.240%
2022-07-17 08:47:01 - epoch 057 lr: 0.100000
2022-07-17 08:47:06 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 0.7139
2022-07-17 08:47:08 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 0.8404
2022-07-17 08:47:10 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 0.7436
2022-07-17 08:47:12 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 0.8993
2022-07-17 08:47:14 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 0.7861
2022-07-17 08:47:16 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 1.0399
2022-07-17 08:47:18 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 0.9424
2022-07-17 08:47:20 - train: epoch 057, train_loss: 0.8523
2022-07-17 08:47:23 - eval: epoch: 057, acc1: 61.560%, acc5: 87.370%, test_loss: 1.4776, per_image_load_time: 0.256ms, per_image_inference_time: 0.041ms
2022-07-17 08:47:23 - until epoch: 057, best_acc1: 64.240%
2022-07-17 08:47:23 - epoch 058 lr: 0.100000
2022-07-17 08:47:27 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 0.8094
2022-07-17 08:47:28 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 0.6151
2022-07-17 08:47:30 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 0.7641
2022-07-17 08:47:32 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 0.8362
2022-07-17 08:47:33 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 0.7598
2022-07-17 08:47:35 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 1.1876
2022-07-17 08:47:36 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 1.0265
2022-07-17 08:47:38 - train: epoch 058, train_loss: 0.8395
2022-07-17 08:47:42 - eval: epoch: 058, acc1: 61.940%, acc5: 88.120%, test_loss: 1.4577, per_image_load_time: 0.276ms, per_image_inference_time: 0.044ms
2022-07-17 08:47:42 - until epoch: 058, best_acc1: 64.240%
2022-07-17 08:47:42 - epoch 059 lr: 0.100000
2022-07-17 08:47:47 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 0.7796
2022-07-17 08:47:49 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 0.7266
2022-07-17 08:47:51 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 0.8033
2022-07-17 08:47:53 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 0.9402
2022-07-17 08:47:55 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 0.9561
2022-07-17 08:47:57 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 0.9228
2022-07-17 08:47:59 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 1.1578
2022-07-17 08:48:01 - train: epoch 059, train_loss: 0.8494
2022-07-17 08:48:05 - eval: epoch: 059, acc1: 61.530%, acc5: 87.600%, test_loss: 1.4659, per_image_load_time: 0.306ms, per_image_inference_time: 0.045ms
2022-07-17 08:48:05 - until epoch: 059, best_acc1: 64.240%
2022-07-17 08:48:05 - epoch 060 lr: 0.100000
2022-07-17 08:48:09 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 0.7220
2022-07-17 08:48:11 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 1.0172
2022-07-17 08:48:12 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 0.7404
2022-07-17 08:48:14 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 0.7837
2022-07-17 08:48:16 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 0.9648
2022-07-17 08:48:18 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 0.8474
2022-07-17 08:48:20 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 0.8484
2022-07-17 08:48:22 - train: epoch 060, train_loss: 0.8410
2022-07-17 08:48:26 - eval: epoch: 060, acc1: 63.260%, acc5: 88.990%, test_loss: 1.4015, per_image_load_time: 0.267ms, per_image_inference_time: 0.043ms
2022-07-17 08:48:26 - until epoch: 060, best_acc1: 64.240%
2022-07-17 08:48:26 - epoch 061 lr: 0.020000
2022-07-17 08:48:30 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 0.3946
2022-07-17 08:48:33 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 0.4000
2022-07-17 08:48:35 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 0.4153
2022-07-17 08:48:37 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 0.5244
2022-07-17 08:48:38 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 0.2731
2022-07-17 08:48:40 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 0.3473
2022-07-17 08:48:42 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 0.3190
2022-07-17 08:48:43 - train: epoch 061, train_loss: 0.4222
2022-07-17 08:48:46 - eval: epoch: 061, acc1: 74.410%, acc5: 93.700%, test_loss: 0.9361, per_image_load_time: 0.262ms, per_image_inference_time: 0.043ms
2022-07-17 08:48:46 - until epoch: 061, best_acc1: 74.410%
2022-07-17 08:48:46 - epoch 062 lr: 0.020000
2022-07-17 08:48:51 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 0.1690
2022-07-17 08:48:53 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 0.2722
2022-07-17 08:48:55 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 0.3820
2022-07-17 08:48:57 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 0.1608
2022-07-17 08:48:59 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 0.3000
2022-07-17 08:49:01 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 0.1743
2022-07-17 08:49:03 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 0.3163
2022-07-17 08:49:05 - train: epoch 062, train_loss: 0.2780
2022-07-17 08:49:09 - eval: epoch: 062, acc1: 75.070%, acc5: 93.900%, test_loss: 0.9391, per_image_load_time: 0.297ms, per_image_inference_time: 0.049ms
2022-07-17 08:49:09 - until epoch: 062, best_acc1: 75.070%
2022-07-17 08:49:09 - epoch 063 lr: 0.020000
2022-07-17 08:49:13 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 0.2258
2022-07-17 08:49:15 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 0.2387
2022-07-17 08:49:17 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 0.1386
2022-07-17 08:49:18 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 0.2085
2022-07-17 08:49:20 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 0.2076
2022-07-17 08:49:21 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 0.2729
2022-07-17 08:49:23 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 0.2011
2022-07-17 08:49:25 - train: epoch 063, train_loss: 0.2155
2022-07-17 08:49:28 - eval: epoch: 063, acc1: 75.120%, acc5: 93.880%, test_loss: 0.9619, per_image_load_time: 0.265ms, per_image_inference_time: 0.042ms
2022-07-17 08:49:28 - until epoch: 063, best_acc1: 75.120%
2022-07-17 08:49:28 - epoch 064 lr: 0.020000
2022-07-17 08:49:32 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 0.1272
2022-07-17 08:49:34 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 0.1534
2022-07-17 08:49:36 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 0.2019
2022-07-17 08:49:38 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 0.1825
2022-07-17 08:49:40 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 0.1866
2022-07-17 08:49:42 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 0.2116
2022-07-17 08:49:44 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 0.1654
2022-07-17 08:49:46 - train: epoch 064, train_loss: 0.1807
2022-07-17 08:49:50 - eval: epoch: 064, acc1: 75.250%, acc5: 94.100%, test_loss: 0.9602, per_image_load_time: 0.276ms, per_image_inference_time: 0.041ms
2022-07-17 08:49:50 - until epoch: 064, best_acc1: 75.250%
2022-07-17 08:49:50 - epoch 065 lr: 0.020000
2022-07-17 08:49:54 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 0.1318
2022-07-17 08:49:56 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 0.1976
2022-07-17 08:49:58 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 0.1657
2022-07-17 08:49:59 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 0.2126
2022-07-17 08:50:01 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 0.1838
2022-07-17 08:50:02 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 0.1823
2022-07-17 08:50:04 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 0.1929
2022-07-17 08:50:06 - train: epoch 065, train_loss: 0.1513
2022-07-17 08:50:09 - eval: epoch: 065, acc1: 74.770%, acc5: 93.720%, test_loss: 0.9979, per_image_load_time: 0.276ms, per_image_inference_time: 0.042ms
2022-07-17 08:50:10 - until epoch: 065, best_acc1: 75.250%
2022-07-17 08:50:10 - epoch 066 lr: 0.020000
2022-07-17 08:50:14 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 0.1029
2022-07-17 08:50:16 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 0.1038
2022-07-17 08:50:18 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 0.0915
2022-07-17 08:50:20 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 0.0824
2022-07-17 08:50:22 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 0.1509
2022-07-17 08:50:24 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 0.1242
2022-07-17 08:50:26 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 0.0891
2022-07-17 08:50:28 - train: epoch 066, train_loss: 0.1301
2022-07-17 08:50:31 - eval: epoch: 066, acc1: 74.860%, acc5: 93.840%, test_loss: 1.0193, per_image_load_time: 0.276ms, per_image_inference_time: 0.046ms
2022-07-17 08:50:32 - until epoch: 066, best_acc1: 75.250%
2022-07-17 08:50:32 - epoch 067 lr: 0.020000
2022-07-17 08:50:36 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 0.1540
2022-07-17 08:50:37 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 0.0921
2022-07-17 08:50:39 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 0.0574
2022-07-17 08:50:41 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 0.1037
2022-07-17 08:50:43 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 0.1451
2022-07-17 08:50:45 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 0.0991
2022-07-17 08:50:47 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 0.1955
2022-07-17 08:50:49 - train: epoch 067, train_loss: 0.1166
2022-07-17 08:50:52 - eval: epoch: 067, acc1: 74.790%, acc5: 93.600%, test_loss: 1.0238, per_image_load_time: 0.220ms, per_image_inference_time: 0.044ms
2022-07-17 08:50:52 - until epoch: 067, best_acc1: 75.250%
2022-07-17 08:50:52 - epoch 068 lr: 0.020000
2022-07-17 08:50:56 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 0.1622
2022-07-17 08:50:58 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 0.0570
2022-07-17 08:51:00 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 0.0931
2022-07-17 08:51:03 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 0.1333
2022-07-17 08:51:04 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 0.1025
2022-07-17 08:51:06 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 0.0589
2022-07-17 08:51:08 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 0.1203
2022-07-17 08:51:09 - train: epoch 068, train_loss: 0.1031
2022-07-17 08:51:13 - eval: epoch: 068, acc1: 74.300%, acc5: 93.400%, test_loss: 1.0593, per_image_load_time: 0.280ms, per_image_inference_time: 0.043ms
2022-07-17 08:51:13 - until epoch: 068, best_acc1: 75.250%
2022-07-17 08:51:13 - epoch 069 lr: 0.020000
2022-07-17 08:51:17 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 0.1078
2022-07-17 08:51:19 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 0.0983
2022-07-17 08:51:21 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 0.0750
2022-07-17 08:51:23 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 0.1091
2022-07-17 08:51:25 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 0.1231
2022-07-17 08:51:27 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 0.1032
2022-07-17 08:51:29 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 0.0763
2022-07-17 08:51:31 - train: epoch 069, train_loss: 0.0994
2022-07-17 08:51:34 - eval: epoch: 069, acc1: 74.740%, acc5: 93.570%, test_loss: 1.0741, per_image_load_time: 0.254ms, per_image_inference_time: 0.047ms
2022-07-17 08:51:35 - until epoch: 069, best_acc1: 75.250%
2022-07-17 08:51:35 - epoch 070 lr: 0.020000
2022-07-17 08:51:39 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 0.0424
2022-07-17 08:51:41 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 0.0576
2022-07-17 08:51:43 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 0.1222
2022-07-17 08:51:45 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 0.1094
2022-07-17 08:51:47 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 0.1060
2022-07-17 08:51:48 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 0.1663
2022-07-17 08:51:50 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 0.1195
2022-07-17 08:51:51 - train: epoch 070, train_loss: 0.0959
2022-07-17 08:51:55 - eval: epoch: 070, acc1: 73.980%, acc5: 93.120%, test_loss: 1.1062, per_image_load_time: 0.284ms, per_image_inference_time: 0.042ms
2022-07-17 08:51:55 - until epoch: 070, best_acc1: 75.250%
2022-07-17 08:51:55 - epoch 071 lr: 0.020000
2022-07-17 08:51:59 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 0.0729
2022-07-17 08:52:01 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 0.0747
2022-07-17 08:52:03 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 0.0560
2022-07-17 08:52:05 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 0.0930
2022-07-17 08:52:07 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 0.1068
2022-07-17 08:52:10 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 0.1922
2022-07-17 08:52:11 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 0.1058
2022-07-17 08:52:13 - train: epoch 071, train_loss: 0.0989
2022-07-17 08:52:17 - eval: epoch: 071, acc1: 73.580%, acc5: 93.200%, test_loss: 1.1111, per_image_load_time: 0.257ms, per_image_inference_time: 0.045ms
2022-07-17 08:52:17 - until epoch: 071, best_acc1: 75.250%
2022-07-17 08:52:17 - epoch 072 lr: 0.020000
2022-07-17 08:52:22 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 0.1318
2022-07-17 08:52:23 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 0.1126
2022-07-17 08:52:25 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 0.0757
2022-07-17 08:52:27 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 0.0882
2022-07-17 08:52:29 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 0.0882
2022-07-17 08:52:31 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 0.0907
2022-07-17 08:52:33 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 0.1117
2022-07-17 08:52:35 - train: epoch 072, train_loss: 0.1019
2022-07-17 08:52:38 - eval: epoch: 072, acc1: 73.990%, acc5: 93.010%, test_loss: 1.1167, per_image_load_time: 0.286ms, per_image_inference_time: 0.042ms
2022-07-17 08:52:38 - until epoch: 072, best_acc1: 75.250%
2022-07-17 08:52:38 - epoch 073 lr: 0.020000
2022-07-17 08:52:43 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 0.1003
2022-07-17 08:52:45 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 0.0857
2022-07-17 08:52:47 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 0.0801
2022-07-17 08:52:49 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 0.1226
2022-07-17 08:52:51 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 0.1325
2022-07-17 08:52:53 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 0.1297
2022-07-17 08:52:54 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 0.1128
2022-07-17 08:52:56 - train: epoch 073, train_loss: 0.1119
2022-07-17 08:52:59 - eval: epoch: 073, acc1: 73.730%, acc5: 92.910%, test_loss: 1.1481, per_image_load_time: 0.280ms, per_image_inference_time: 0.048ms
2022-07-17 08:52:59 - until epoch: 073, best_acc1: 75.250%
2022-07-17 08:52:59 - epoch 074 lr: 0.020000
2022-07-17 08:53:04 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 0.1784
2022-07-17 08:53:06 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 0.0600
2022-07-17 08:53:08 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 0.1161
2022-07-17 08:53:10 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 0.1050
2022-07-17 08:53:12 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 0.1011
2022-07-17 08:53:14 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 0.1466
2022-07-17 08:53:16 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 0.1572
2022-07-17 08:53:18 - train: epoch 074, train_loss: 0.1278
2022-07-17 08:53:21 - eval: epoch: 074, acc1: 72.840%, acc5: 92.760%, test_loss: 1.1678, per_image_load_time: 0.259ms, per_image_inference_time: 0.043ms
2022-07-17 08:53:21 - until epoch: 074, best_acc1: 75.250%
2022-07-17 08:53:21 - epoch 075 lr: 0.020000
2022-07-17 08:53:26 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 0.1287
2022-07-17 08:53:28 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 0.0686
2022-07-17 08:53:30 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 0.0943
2022-07-17 08:53:31 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 0.2032
2022-07-17 08:53:33 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 0.1785
2022-07-17 08:53:34 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 0.1661
2022-07-17 08:53:36 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 0.1870
2022-07-17 08:53:38 - train: epoch 075, train_loss: 0.1398
2022-07-17 08:53:42 - eval: epoch: 075, acc1: 72.170%, acc5: 92.290%, test_loss: 1.2209, per_image_load_time: 0.337ms, per_image_inference_time: 0.052ms
2022-07-17 08:53:42 - until epoch: 075, best_acc1: 75.250%
2022-07-17 08:53:42 - epoch 076 lr: 0.020000
2022-07-17 08:53:47 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 0.1041
2022-07-17 08:53:49 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 0.2374
2022-07-17 08:53:51 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 0.1326
2022-07-17 08:53:53 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 0.0918
2022-07-17 08:53:55 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 0.2639
2022-07-17 08:53:57 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 0.1779
2022-07-17 08:53:59 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 0.2327
2022-07-17 08:54:01 - train: epoch 076, train_loss: 0.1512
2022-07-17 08:54:04 - eval: epoch: 076, acc1: 71.820%, acc5: 91.960%, test_loss: 1.2442, per_image_load_time: 0.262ms, per_image_inference_time: 0.044ms
2022-07-17 08:54:04 - until epoch: 076, best_acc1: 75.250%
2022-07-17 08:54:04 - epoch 077 lr: 0.020000
2022-07-17 08:54:08 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 0.0952
2022-07-17 08:54:10 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 0.2022
2022-07-17 08:54:11 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 0.1812
2022-07-17 08:54:13 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 0.1689
2022-07-17 08:54:14 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 0.1536
2022-07-17 08:54:16 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 0.1939
2022-07-17 08:54:18 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 0.1663
2022-07-17 08:54:20 - train: epoch 077, train_loss: 0.1597
2022-07-17 08:54:24 - eval: epoch: 077, acc1: 71.190%, acc5: 91.890%, test_loss: 1.2387, per_image_load_time: 0.304ms, per_image_inference_time: 0.044ms
2022-07-17 08:54:24 - until epoch: 077, best_acc1: 75.250%
2022-07-17 08:54:24 - epoch 078 lr: 0.020000
2022-07-17 08:54:28 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 0.1480
2022-07-17 08:54:30 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 0.1531
2022-07-17 08:54:32 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 0.2032
2022-07-17 08:54:35 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 0.1757
2022-07-17 08:54:37 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 0.1471
2022-07-17 08:54:38 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 0.1528
2022-07-17 08:54:40 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 0.1986
2022-07-17 08:54:42 - train: epoch 078, train_loss: 0.1604
2022-07-17 08:54:46 - eval: epoch: 078, acc1: 71.040%, acc5: 91.810%, test_loss: 1.2641, per_image_load_time: 0.289ms, per_image_inference_time: 0.045ms
2022-07-17 08:54:46 - until epoch: 078, best_acc1: 75.250%
2022-07-17 08:54:46 - epoch 079 lr: 0.020000
2022-07-17 08:54:50 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 0.1320
2022-07-17 08:54:51 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 0.1071
2022-07-17 08:54:53 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 0.1947
2022-07-17 08:54:55 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 0.1503
2022-07-17 08:54:57 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 0.2226
2022-07-17 08:54:59 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 0.2170
2022-07-17 08:55:01 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 0.2319
2022-07-17 08:55:03 - train: epoch 079, train_loss: 0.1747
2022-07-17 08:55:07 - eval: epoch: 079, acc1: 70.810%, acc5: 91.580%, test_loss: 1.2704, per_image_load_time: 0.292ms, per_image_inference_time: 0.043ms
2022-07-17 08:55:07 - until epoch: 079, best_acc1: 75.250%
2022-07-17 08:55:07 - epoch 080 lr: 0.020000
2022-07-17 08:55:11 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 0.1358
2022-07-17 08:55:13 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 0.2004
2022-07-17 08:55:15 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 0.2103
2022-07-17 08:55:17 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 0.2449
2022-07-17 08:55:19 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 0.1697
2022-07-17 08:55:20 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 0.2200
2022-07-17 08:55:22 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 0.2447
2022-07-17 08:55:23 - train: epoch 080, train_loss: 0.1772
2022-07-17 08:55:27 - eval: epoch: 080, acc1: 70.940%, acc5: 91.740%, test_loss: 1.2576, per_image_load_time: 0.278ms, per_image_inference_time: 0.041ms
2022-07-17 08:55:27 - until epoch: 080, best_acc1: 75.250%
2022-07-17 08:55:27 - epoch 081 lr: 0.020000
2022-07-17 08:55:32 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 0.1568
2022-07-17 08:55:34 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 0.1142
2022-07-17 08:55:36 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 0.1857
2022-07-17 08:55:38 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 0.1829
2022-07-17 08:55:40 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 0.1671
2022-07-17 08:55:42 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 0.2095
2022-07-17 08:55:44 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 0.1477
2022-07-17 08:55:46 - train: epoch 081, train_loss: 0.1731
2022-07-17 08:55:49 - eval: epoch: 081, acc1: 70.330%, acc5: 91.250%, test_loss: 1.3255, per_image_load_time: 0.248ms, per_image_inference_time: 0.044ms
2022-07-17 08:55:49 - until epoch: 081, best_acc1: 75.250%
2022-07-17 08:55:49 - epoch 082 lr: 0.020000
2022-07-17 08:55:54 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 0.1840
2022-07-17 08:55:55 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 0.1662
2022-07-17 08:55:57 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 0.1178
2022-07-17 08:55:59 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 0.1946
2022-07-17 08:56:00 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 0.1461
2022-07-17 08:56:02 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 0.2220
2022-07-17 08:56:04 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 0.2528
2022-07-17 08:56:05 - train: epoch 082, train_loss: 0.1789
2022-07-17 08:56:08 - eval: epoch: 082, acc1: 70.370%, acc5: 91.510%, test_loss: 1.2961, per_image_load_time: 0.262ms, per_image_inference_time: 0.043ms
2022-07-17 08:56:09 - until epoch: 082, best_acc1: 75.250%
2022-07-17 08:56:09 - epoch 083 lr: 0.020000
2022-07-17 08:56:13 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 0.1506
2022-07-17 08:56:15 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 0.1766
2022-07-17 08:56:17 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 0.0702
2022-07-17 08:56:19 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 0.1413
2022-07-17 08:56:21 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 0.1521
2022-07-17 08:56:23 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 0.2223
2022-07-17 08:56:25 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 0.1823
2022-07-17 08:56:27 - train: epoch 083, train_loss: 0.1793
2022-07-17 08:56:30 - eval: epoch: 083, acc1: 70.110%, acc5: 91.820%, test_loss: 1.2993, per_image_load_time: 0.255ms, per_image_inference_time: 0.051ms
2022-07-17 08:56:31 - until epoch: 083, best_acc1: 75.250%
2022-07-17 08:56:31 - epoch 084 lr: 0.020000
2022-07-17 08:56:35 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 0.1867
2022-07-17 08:56:36 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 0.1212
2022-07-17 08:56:38 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 0.1421
2022-07-17 08:56:39 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 0.1696
2022-07-17 08:56:41 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 0.2238
2022-07-17 08:56:43 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 0.3062
2022-07-17 08:56:45 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 0.2086
2022-07-17 08:56:47 - train: epoch 084, train_loss: 0.1822
2022-07-17 08:56:50 - eval: epoch: 084, acc1: 71.520%, acc5: 91.790%, test_loss: 1.2530, per_image_load_time: 0.241ms, per_image_inference_time: 0.043ms
2022-07-17 08:56:51 - until epoch: 084, best_acc1: 75.250%
2022-07-17 08:56:51 - epoch 085 lr: 0.020000
2022-07-17 08:56:55 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 0.1503
2022-07-17 08:56:57 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 0.1453
2022-07-17 08:56:59 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 0.1742
2022-07-17 08:57:01 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 0.1555
2022-07-17 08:57:03 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 0.1814
2022-07-17 08:57:05 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 0.2006
2022-07-17 08:57:06 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 0.3970
2022-07-17 08:57:08 - train: epoch 085, train_loss: 0.1738
2022-07-17 08:57:11 - eval: epoch: 085, acc1: 70.050%, acc5: 91.350%, test_loss: 1.3182, per_image_load_time: 0.282ms, per_image_inference_time: 0.045ms
2022-07-17 08:57:12 - until epoch: 085, best_acc1: 75.250%
2022-07-17 08:57:12 - epoch 086 lr: 0.020000
2022-07-17 08:57:16 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 0.0998
2022-07-17 08:57:18 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 0.0730
2022-07-17 08:57:20 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 0.1632
2022-07-17 08:57:22 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 0.2527
2022-07-17 08:57:24 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 0.1824
2022-07-17 08:57:26 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 0.1554
2022-07-17 08:57:28 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 0.2185
2022-07-17 08:57:29 - train: epoch 086, train_loss: 0.1812
2022-07-17 08:57:33 - eval: epoch: 086, acc1: 71.090%, acc5: 91.510%, test_loss: 1.2749, per_image_load_time: 0.250ms, per_image_inference_time: 0.044ms
2022-07-17 08:57:33 - until epoch: 086, best_acc1: 75.250%
2022-07-17 08:57:33 - epoch 087 lr: 0.020000
2022-07-17 08:57:37 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 0.1461
2022-07-17 08:57:40 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 0.1421
2022-07-17 08:57:42 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 0.1155
2022-07-17 08:57:43 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 0.1916
2022-07-17 08:57:45 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 0.2254
2022-07-17 08:57:46 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 0.1782
2022-07-17 08:57:48 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 0.2637
2022-07-17 08:57:49 - train: epoch 087, train_loss: 0.1764
2022-07-17 08:57:53 - eval: epoch: 087, acc1: 70.910%, acc5: 90.970%, test_loss: 1.3273, per_image_load_time: 0.307ms, per_image_inference_time: 0.048ms
2022-07-17 08:57:53 - until epoch: 087, best_acc1: 75.250%
2022-07-17 08:57:53 - epoch 088 lr: 0.020000
2022-07-17 08:57:58 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 0.1804
2022-07-17 08:58:00 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 0.2060
2022-07-17 08:58:02 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 0.2196
2022-07-17 08:58:04 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 0.1917
2022-07-17 08:58:06 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 0.1141
2022-07-17 08:58:08 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 0.2329
2022-07-17 08:58:10 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 0.2085
2022-07-17 08:58:12 - train: epoch 088, train_loss: 0.1808
2022-07-17 08:58:16 - eval: epoch: 088, acc1: 69.980%, acc5: 91.310%, test_loss: 1.3306, per_image_load_time: 0.324ms, per_image_inference_time: 0.044ms
2022-07-17 08:58:16 - until epoch: 088, best_acc1: 75.250%
2022-07-17 08:58:16 - epoch 089 lr: 0.020000
2022-07-17 08:58:20 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 0.1648
2022-07-17 08:58:22 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 0.0895
2022-07-17 08:58:23 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 0.1043
2022-07-17 08:58:25 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 0.1667
2022-07-17 08:58:27 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 0.1478
2022-07-17 08:58:28 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 0.1372
2022-07-17 08:58:30 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 0.1979
2022-07-17 08:58:32 - train: epoch 089, train_loss: 0.1822
2022-07-17 08:58:35 - eval: epoch: 089, acc1: 69.800%, acc5: 91.200%, test_loss: 1.3500, per_image_load_time: 0.268ms, per_image_inference_time: 0.041ms
2022-07-17 08:58:35 - until epoch: 089, best_acc1: 75.250%
2022-07-17 08:58:35 - epoch 090 lr: 0.020000
2022-07-17 08:58:40 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 0.1203
2022-07-17 08:58:42 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 0.1404
2022-07-17 08:58:44 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 0.1275
2022-07-17 08:58:46 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 0.1970
2022-07-17 08:58:48 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 0.2026
2022-07-17 08:58:50 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 0.1710
2022-07-17 08:58:52 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 0.2351
2022-07-17 08:58:54 - train: epoch 090, train_loss: 0.1818
2022-07-17 08:58:58 - eval: epoch: 090, acc1: 70.480%, acc5: 91.700%, test_loss: 1.3186, per_image_load_time: 0.316ms, per_image_inference_time: 0.044ms
2022-07-17 08:58:58 - until epoch: 090, best_acc1: 75.250%
2022-07-17 08:58:58 - epoch 091 lr: 0.020000
2022-07-17 08:59:03 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 0.1489
2022-07-17 08:59:04 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 0.1445
2022-07-17 08:59:06 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 0.0749
2022-07-17 08:59:07 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 0.1431
2022-07-17 08:59:09 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 0.1690
2022-07-17 08:59:11 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 0.1032
2022-07-17 08:59:13 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 0.1288
2022-07-17 08:59:15 - train: epoch 091, train_loss: 0.1725
2022-07-17 08:59:19 - eval: epoch: 091, acc1: 70.940%, acc5: 91.640%, test_loss: 1.2658, per_image_load_time: 0.288ms, per_image_inference_time: 0.042ms
2022-07-17 08:59:19 - until epoch: 091, best_acc1: 75.250%
2022-07-17 08:59:19 - epoch 092 lr: 0.020000
2022-07-17 08:59:23 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 0.1385
2022-07-17 08:59:25 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 0.1143
2022-07-17 08:59:27 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 0.1174
2022-07-17 08:59:29 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 0.0819
2022-07-17 08:59:31 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 0.1243
2022-07-17 08:59:33 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 0.1679
2022-07-17 08:59:35 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 0.1561
2022-07-17 08:59:36 - train: epoch 092, train_loss: 0.1674
2022-07-17 08:59:41 - eval: epoch: 092, acc1: 70.640%, acc5: 91.620%, test_loss: 1.2955, per_image_load_time: 0.358ms, per_image_inference_time: 0.044ms
2022-07-17 08:59:41 - until epoch: 092, best_acc1: 75.250%
2022-07-17 08:59:41 - epoch 093 lr: 0.020000
2022-07-17 08:59:46 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 0.1313
2022-07-17 08:59:48 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 0.1369
2022-07-17 08:59:50 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 0.1721
2022-07-17 08:59:52 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 0.1471
2022-07-17 08:59:54 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 0.1906
2022-07-17 08:59:56 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 0.1577
2022-07-17 08:59:58 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 0.1617
2022-07-17 09:00:00 - train: epoch 093, train_loss: 0.1646
2022-07-17 09:00:03 - eval: epoch: 093, acc1: 70.290%, acc5: 91.550%, test_loss: 1.3011, per_image_load_time: 0.272ms, per_image_inference_time: 0.045ms
2022-07-17 09:00:03 - until epoch: 093, best_acc1: 75.250%
2022-07-17 09:00:03 - epoch 094 lr: 0.020000
2022-07-17 09:00:08 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 0.1575
2022-07-17 09:00:10 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 0.2855
2022-07-17 09:00:11 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 0.1529
2022-07-17 09:00:13 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 0.1638
2022-07-17 09:00:15 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 0.1425
2022-07-17 09:00:17 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 0.1559
2022-07-17 09:00:19 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 0.1987
2022-07-17 09:00:21 - train: epoch 094, train_loss: 0.1731
2022-07-17 09:00:24 - eval: epoch: 094, acc1: 70.360%, acc5: 91.270%, test_loss: 1.3024, per_image_load_time: 0.256ms, per_image_inference_time: 0.043ms
2022-07-17 09:00:24 - until epoch: 094, best_acc1: 75.250%
2022-07-17 09:00:24 - epoch 095 lr: 0.020000
2022-07-17 09:00:28 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 0.2135
2022-07-17 09:00:30 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 0.2178
2022-07-17 09:00:32 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 0.1121
2022-07-17 09:00:34 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 0.1918
2022-07-17 09:00:36 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 0.2235
2022-07-17 09:00:38 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 0.1533
2022-07-17 09:00:40 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 0.2090
2022-07-17 09:00:42 - train: epoch 095, train_loss: 0.1833
2022-07-17 09:00:45 - eval: epoch: 095, acc1: 70.250%, acc5: 91.300%, test_loss: 1.3512, per_image_load_time: 0.275ms, per_image_inference_time: 0.041ms
2022-07-17 09:00:46 - until epoch: 095, best_acc1: 75.250%
2022-07-17 09:00:46 - epoch 096 lr: 0.020000
2022-07-17 09:00:50 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 0.1773
2022-07-17 09:00:52 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 0.0799
2022-07-17 09:00:54 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 0.1316
2022-07-17 09:00:56 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 0.1774
2022-07-17 09:00:58 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 0.1187
2022-07-17 09:01:00 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 0.2520
2022-07-17 09:01:02 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 0.2032
2022-07-17 09:01:04 - train: epoch 096, train_loss: 0.1655
2022-07-17 09:01:07 - eval: epoch: 096, acc1: 70.260%, acc5: 91.390%, test_loss: 1.3343, per_image_load_time: 0.248ms, per_image_inference_time: 0.042ms
2022-07-17 09:01:07 - until epoch: 096, best_acc1: 75.250%
2022-07-17 09:01:07 - epoch 097 lr: 0.020000
2022-07-17 09:01:11 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 0.1993
2022-07-17 09:01:13 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 0.1739
2022-07-17 09:01:15 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 0.1185
2022-07-17 09:01:17 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 0.0997
2022-07-17 09:01:19 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 0.0935
2022-07-17 09:01:21 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 0.1365
2022-07-17 09:01:22 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 0.3065
2022-07-17 09:01:24 - train: epoch 097, train_loss: 0.1672
2022-07-17 09:01:28 - eval: epoch: 097, acc1: 69.920%, acc5: 91.070%, test_loss: 1.3635, per_image_load_time: 0.280ms, per_image_inference_time: 0.086ms
2022-07-17 09:01:28 - until epoch: 097, best_acc1: 75.250%
2022-07-17 09:01:28 - epoch 098 lr: 0.020000
2022-07-17 09:01:44 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 0.1160
2022-07-17 09:01:54 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 0.1634
2022-07-17 09:02:04 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 0.1485
2022-07-17 09:02:14 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 0.2182
2022-07-17 09:02:23 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 0.1475
2022-07-17 09:02:32 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 0.2273
2022-07-17 09:02:42 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 0.3810
2022-07-17 09:02:50 - train: epoch 098, train_loss: 0.1879
2022-07-17 09:02:54 - eval: epoch: 098, acc1: 70.280%, acc5: 91.410%, test_loss: 1.3520, per_image_load_time: 0.273ms, per_image_inference_time: 0.050ms
2022-07-17 09:02:54 - until epoch: 098, best_acc1: 75.250%
2022-07-17 09:02:54 - epoch 099 lr: 0.020000
2022-07-17 09:02:59 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 0.1519
2022-07-17 09:03:01 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 0.1817
2022-07-17 09:03:03 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 0.0859
2022-07-17 09:03:05 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 0.1328
2022-07-17 09:03:06 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 0.1370
2022-07-17 09:03:08 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 0.1522
2022-07-17 09:03:10 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 0.1398
2022-07-17 09:03:11 - train: epoch 099, train_loss: 0.1670
2022-07-17 09:03:15 - eval: epoch: 099, acc1: 70.620%, acc5: 91.510%, test_loss: 1.3543, per_image_load_time: 0.296ms, per_image_inference_time: 0.043ms
2022-07-17 09:03:15 - until epoch: 099, best_acc1: 75.250%
2022-07-17 09:03:15 - epoch 100 lr: 0.020000
2022-07-17 09:03:19 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 0.1345
2022-07-17 09:03:21 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 0.1769
2022-07-17 09:03:23 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 0.1980
2022-07-17 09:03:25 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 0.1329
2022-07-17 09:03:27 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 0.1195
2022-07-17 09:03:29 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 0.1695
2022-07-17 09:03:31 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 0.2028
2022-07-17 09:03:33 - train: epoch 100, train_loss: 0.1618
2022-07-17 09:03:37 - eval: epoch: 100, acc1: 69.930%, acc5: 91.280%, test_loss: 1.3722, per_image_load_time: 0.312ms, per_image_inference_time: 0.045ms
2022-07-17 09:03:37 - until epoch: 100, best_acc1: 75.250%
2022-07-17 09:03:37 - epoch 101 lr: 0.020000
2022-07-17 09:03:42 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 0.1803
2022-07-17 09:03:43 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 0.1467
2022-07-17 09:03:45 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 0.1876
2022-07-17 09:03:47 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 0.2582
2022-07-17 09:03:48 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 0.1679
2022-07-17 09:03:50 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 0.1584
2022-07-17 09:03:52 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 0.1111
2022-07-17 09:03:54 - train: epoch 101, train_loss: 0.1687
2022-07-17 09:03:56 - eval: epoch: 101, acc1: 70.470%, acc5: 91.330%, test_loss: 1.3480, per_image_load_time: 0.222ms, per_image_inference_time: 0.044ms
2022-07-17 09:03:57 - until epoch: 101, best_acc1: 75.250%
2022-07-17 09:03:57 - epoch 102 lr: 0.020000
2022-07-17 09:04:01 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 0.1243
2022-07-17 09:04:03 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 0.1684
2022-07-17 09:04:05 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 0.1543
2022-07-17 09:04:07 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 0.1510
2022-07-17 09:04:09 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 0.1685
2022-07-17 09:04:12 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 0.0824
2022-07-17 09:04:14 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 0.1944
2022-07-17 09:04:15 - train: epoch 102, train_loss: 0.1624
2022-07-17 09:04:19 - eval: epoch: 102, acc1: 69.770%, acc5: 90.980%, test_loss: 1.3899, per_image_load_time: 0.306ms, per_image_inference_time: 0.047ms
2022-07-17 09:04:19 - until epoch: 102, best_acc1: 75.250%
2022-07-17 09:04:19 - epoch 103 lr: 0.020000
2022-07-17 09:04:24 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 0.1480
2022-07-17 09:04:26 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 0.1728
2022-07-17 09:04:28 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 0.1822
2022-07-17 09:04:30 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 0.2079
2022-07-17 09:04:32 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 0.1752
2022-07-17 09:04:34 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 0.2358
2022-07-17 09:04:36 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 0.1239
2022-07-17 09:04:38 - train: epoch 103, train_loss: 0.1701
2022-07-17 09:04:41 - eval: epoch: 103, acc1: 70.720%, acc5: 91.340%, test_loss: 1.3207, per_image_load_time: 0.261ms, per_image_inference_time: 0.043ms
2022-07-17 09:04:41 - until epoch: 103, best_acc1: 75.250%
2022-07-17 09:04:41 - epoch 104 lr: 0.020000
2022-07-17 09:04:46 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 0.1615
2022-07-17 09:04:48 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 0.1062
2022-07-17 09:04:50 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 0.2047
2022-07-17 09:04:52 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 0.2052
2022-07-17 09:04:53 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 0.1830
2022-07-17 09:04:55 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 0.1467
2022-07-17 09:04:57 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 0.2437
2022-07-17 09:04:59 - train: epoch 104, train_loss: 0.1673
2022-07-17 09:05:03 - eval: epoch: 104, acc1: 69.670%, acc5: 90.920%, test_loss: 1.3917, per_image_load_time: 0.348ms, per_image_inference_time: 0.048ms
2022-07-17 09:05:03 - until epoch: 104, best_acc1: 75.250%
2022-07-17 09:05:03 - epoch 105 lr: 0.020000
2022-07-17 09:05:07 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 0.2122
2022-07-17 09:05:09 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 0.1493
2022-07-17 09:05:12 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 0.1368
2022-07-17 09:05:14 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 0.1622
2022-07-17 09:05:16 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 0.1557
2022-07-17 09:05:18 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 0.1439
2022-07-17 09:05:20 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 0.1136
2022-07-17 09:05:21 - train: epoch 105, train_loss: 0.1784
2022-07-17 09:05:25 - eval: epoch: 105, acc1: 69.550%, acc5: 90.920%, test_loss: 1.3804, per_image_load_time: 0.261ms, per_image_inference_time: 0.044ms
2022-07-17 09:05:25 - until epoch: 105, best_acc1: 75.250%
2022-07-17 09:05:25 - epoch 106 lr: 0.020000
2022-07-17 09:05:29 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 0.1641
2022-07-17 09:05:30 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 0.1252
2022-07-17 09:05:32 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 0.2672
2022-07-17 09:05:34 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 0.1242
2022-07-17 09:05:36 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 0.2224
2022-07-17 09:05:37 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 0.2006
2022-07-17 09:05:39 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 0.2070
2022-07-17 09:05:41 - train: epoch 106, train_loss: 0.1743
2022-07-17 09:05:44 - eval: epoch: 106, acc1: 70.010%, acc5: 90.970%, test_loss: 1.3549, per_image_load_time: 0.241ms, per_image_inference_time: 0.043ms
2022-07-17 09:05:44 - until epoch: 106, best_acc1: 75.250%
2022-07-17 09:05:44 - epoch 107 lr: 0.020000
2022-07-17 09:05:49 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 0.2696
2022-07-17 09:05:51 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 0.1918
2022-07-17 09:05:53 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 0.2812
2022-07-17 09:05:55 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 0.1445
2022-07-17 09:05:57 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 0.2527
2022-07-17 09:05:59 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 0.2472
2022-07-17 09:06:01 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 0.1884
2022-07-17 09:06:03 - train: epoch 107, train_loss: 0.1696
2022-07-17 09:06:07 - eval: epoch: 107, acc1: 69.750%, acc5: 90.770%, test_loss: 1.4024, per_image_load_time: 0.303ms, per_image_inference_time: 0.043ms
2022-07-17 09:06:07 - until epoch: 107, best_acc1: 75.250%
2022-07-17 09:06:07 - epoch 108 lr: 0.020000
2022-07-17 09:06:11 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 0.1707
2022-07-17 09:06:12 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 0.1553
2022-07-17 09:06:14 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 0.1960
2022-07-17 09:06:16 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 0.1102
2022-07-17 09:06:18 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 0.1938
2022-07-17 09:06:20 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 0.1503
2022-07-17 09:06:22 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 0.2108
2022-07-17 09:06:24 - train: epoch 108, train_loss: 0.1645
2022-07-17 09:06:27 - eval: epoch: 108, acc1: 70.430%, acc5: 91.330%, test_loss: 1.3482, per_image_load_time: 0.269ms, per_image_inference_time: 0.043ms
2022-07-17 09:06:28 - until epoch: 108, best_acc1: 75.250%
2022-07-17 09:06:28 - epoch 109 lr: 0.020000
2022-07-17 09:06:32 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 0.1327
2022-07-17 09:06:34 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 0.1378
2022-07-17 09:06:36 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 0.0895
2022-07-17 09:06:38 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 0.1501
2022-07-17 09:06:40 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 0.2026
2022-07-17 09:06:41 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 0.1459
2022-07-17 09:06:43 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 0.1257
2022-07-17 09:06:45 - train: epoch 109, train_loss: 0.1630
2022-07-17 09:06:48 - eval: epoch: 109, acc1: 69.940%, acc5: 91.170%, test_loss: 1.3802, per_image_load_time: 0.283ms, per_image_inference_time: 0.042ms
2022-07-17 09:06:48 - until epoch: 109, best_acc1: 75.250%
2022-07-17 09:06:48 - epoch 110 lr: 0.020000
2022-07-17 09:06:54 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 0.1297
2022-07-17 09:06:56 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 0.2415
2022-07-17 09:06:58 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 0.2318
2022-07-17 09:07:00 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 0.1623
2022-07-17 09:07:02 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 0.1102
2022-07-17 09:07:04 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 0.2518
2022-07-17 09:07:06 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 0.1630
2022-07-17 09:07:08 - train: epoch 110, train_loss: 0.1662
2022-07-17 09:07:11 - eval: epoch: 110, acc1: 70.430%, acc5: 91.090%, test_loss: 1.3533, per_image_load_time: 0.219ms, per_image_inference_time: 0.045ms
2022-07-17 09:07:11 - until epoch: 110, best_acc1: 75.250%
2022-07-17 09:07:11 - epoch 111 lr: 0.020000
2022-07-17 09:07:15 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 0.0472
2022-07-17 09:07:17 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 0.2226
2022-07-17 09:07:18 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 0.1125
2022-07-17 09:07:20 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 0.1785
2022-07-17 09:07:22 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 0.2571
2022-07-17 09:07:23 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 0.1889
2022-07-17 09:07:25 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 0.1136
2022-07-17 09:07:26 - train: epoch 111, train_loss: 0.1506
2022-07-17 09:07:30 - eval: epoch: 111, acc1: 69.950%, acc5: 90.820%, test_loss: 1.3989, per_image_load_time: 0.280ms, per_image_inference_time: 0.043ms
2022-07-17 09:07:30 - until epoch: 111, best_acc1: 75.250%
2022-07-17 09:07:30 - epoch 112 lr: 0.020000
2022-07-17 09:07:35 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 0.0488
2022-07-17 09:07:37 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 0.0871
2022-07-17 09:07:39 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 0.1065
2022-07-17 09:07:40 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 0.0708
2022-07-17 09:07:42 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 0.2274
2022-07-17 09:07:44 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 0.2508
2022-07-17 09:07:46 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 0.2509
2022-07-17 09:07:48 - train: epoch 112, train_loss: 0.1560
2022-07-17 09:07:52 - eval: epoch: 112, acc1: 69.540%, acc5: 90.720%, test_loss: 1.4026, per_image_load_time: 0.269ms, per_image_inference_time: 0.041ms
2022-07-17 09:07:52 - until epoch: 112, best_acc1: 75.250%
2022-07-17 09:07:52 - epoch 113 lr: 0.020000
2022-07-17 09:07:56 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 0.1889
2022-07-17 09:07:58 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 0.1211
2022-07-17 09:07:59 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 0.1454
2022-07-17 09:08:01 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 0.2168
2022-07-17 09:08:03 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 0.1044
2022-07-17 09:08:05 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 0.1328
2022-07-17 09:08:07 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 0.1822
2022-07-17 09:08:09 - train: epoch 113, train_loss: 0.1636
2022-07-17 09:08:12 - eval: epoch: 113, acc1: 70.140%, acc5: 90.970%, test_loss: 1.3647, per_image_load_time: 0.276ms, per_image_inference_time: 0.045ms
2022-07-17 09:08:12 - until epoch: 113, best_acc1: 75.250%
2022-07-17 09:08:12 - epoch 114 lr: 0.020000
2022-07-17 09:08:17 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 0.0996
2022-07-17 09:08:19 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 0.0903
2022-07-17 09:08:21 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 0.1667
2022-07-17 09:08:23 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 0.1654
2022-07-17 09:08:25 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 0.2642
2022-07-17 09:08:27 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 0.2639
2022-07-17 09:08:28 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 0.1118
2022-07-17 09:08:30 - train: epoch 114, train_loss: 0.1596
2022-07-17 09:08:33 - eval: epoch: 114, acc1: 70.020%, acc5: 90.740%, test_loss: 1.4170, per_image_load_time: 0.271ms, per_image_inference_time: 0.045ms
2022-07-17 09:08:33 - until epoch: 114, best_acc1: 75.250%
2022-07-17 09:08:33 - epoch 115 lr: 0.020000
2022-07-17 09:08:38 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 0.0790
2022-07-17 09:08:39 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 0.2090
2022-07-17 09:08:41 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 0.1322
2022-07-17 09:08:43 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 0.2027
2022-07-17 09:08:45 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 0.0778
2022-07-17 09:08:48 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 0.1162
2022-07-17 09:08:50 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 0.2238
2022-07-17 09:08:51 - train: epoch 115, train_loss: 0.1583
2022-07-17 09:08:55 - eval: epoch: 115, acc1: 70.680%, acc5: 90.970%, test_loss: 1.3909, per_image_load_time: 0.291ms, per_image_inference_time: 0.042ms
2022-07-17 09:08:55 - until epoch: 115, best_acc1: 75.250%
2022-07-17 09:08:55 - epoch 116 lr: 0.020000
2022-07-17 09:09:00 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 0.1044
2022-07-17 09:09:02 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 0.1147
2022-07-17 09:09:04 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 0.2067
2022-07-17 09:09:05 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 0.1771
2022-07-17 09:09:06 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 0.1511
2022-07-17 09:09:08 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 0.2427
2022-07-17 09:09:10 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 0.1798
2022-07-17 09:09:11 - train: epoch 116, train_loss: 0.1717
2022-07-17 09:09:15 - eval: epoch: 116, acc1: 69.560%, acc5: 90.460%, test_loss: 1.4501, per_image_load_time: 0.273ms, per_image_inference_time: 0.042ms
2022-07-17 09:09:15 - until epoch: 116, best_acc1: 75.250%
2022-07-17 09:09:15 - epoch 117 lr: 0.020000
2022-07-17 09:09:19 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 0.1947
2022-07-17 09:09:21 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 0.2119
2022-07-17 09:09:23 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 0.1072
2022-07-17 09:09:25 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 0.2793
2022-07-17 09:09:27 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 0.1056
2022-07-17 09:09:29 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 0.1895
2022-07-17 09:09:31 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 0.1806
2022-07-17 09:09:33 - train: epoch 117, train_loss: 0.1712
2022-07-17 09:09:36 - eval: epoch: 117, acc1: 69.980%, acc5: 90.670%, test_loss: 1.4038, per_image_load_time: 0.252ms, per_image_inference_time: 0.043ms
2022-07-17 09:09:36 - until epoch: 117, best_acc1: 75.250%
2022-07-17 09:09:36 - epoch 118 lr: 0.020000
2022-07-17 09:09:40 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 0.1498
2022-07-17 09:09:42 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 0.1396
2022-07-17 09:09:44 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 0.1236
2022-07-17 09:09:45 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 0.1765
2022-07-17 09:09:47 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 0.1911
2022-07-17 09:09:48 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 0.1087
2022-07-17 09:09:50 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 0.1546
2022-07-17 09:09:52 - train: epoch 118, train_loss: 0.1645
2022-07-17 09:09:55 - eval: epoch: 118, acc1: 69.590%, acc5: 91.010%, test_loss: 1.4446, per_image_load_time: 0.246ms, per_image_inference_time: 0.042ms
2022-07-17 09:09:55 - until epoch: 118, best_acc1: 75.250%
2022-07-17 09:09:55 - epoch 119 lr: 0.020000
2022-07-17 09:09:59 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 0.1048
2022-07-17 09:10:02 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 0.0830
2022-07-17 09:10:04 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 0.1126
2022-07-17 09:10:06 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 0.2060
2022-07-17 09:10:08 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 0.1552
2022-07-17 09:10:10 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 0.1673
2022-07-17 09:10:12 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 0.1207
2022-07-17 09:10:14 - train: epoch 119, train_loss: 0.1698
2022-07-17 09:10:17 - eval: epoch: 119, acc1: 69.670%, acc5: 91.150%, test_loss: 1.3946, per_image_load_time: 0.280ms, per_image_inference_time: 0.048ms
2022-07-17 09:10:17 - until epoch: 119, best_acc1: 75.250%
2022-07-17 09:10:17 - epoch 120 lr: 0.020000
2022-07-17 09:10:21 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 0.1253
2022-07-17 09:10:23 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 0.0926
2022-07-17 09:10:24 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 0.1237
2022-07-17 09:10:26 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 0.1600
2022-07-17 09:10:28 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 0.2313
2022-07-17 09:10:30 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 0.1593
2022-07-17 09:10:32 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 0.1725
2022-07-17 09:10:34 - train: epoch 120, train_loss: 0.1529
2022-07-17 09:10:37 - eval: epoch: 120, acc1: 70.650%, acc5: 91.510%, test_loss: 1.3556, per_image_load_time: 0.228ms, per_image_inference_time: 0.045ms
2022-07-17 09:10:37 - until epoch: 120, best_acc1: 75.250%
2022-07-17 09:10:37 - epoch 121 lr: 0.004000
2022-07-17 09:10:42 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 0.0767
2022-07-17 09:10:44 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 0.0356
2022-07-17 09:10:46 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 0.0966
2022-07-17 09:10:48 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 0.0642
2022-07-17 09:10:50 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 0.0564
2022-07-17 09:10:51 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 0.0282
2022-07-17 09:10:53 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 0.0410
2022-07-17 09:10:54 - train: epoch 121, train_loss: 0.0672
2022-07-17 09:10:58 - eval: epoch: 121, acc1: 74.370%, acc5: 93.080%, test_loss: 1.1478, per_image_load_time: 0.277ms, per_image_inference_time: 0.043ms
2022-07-17 09:10:58 - until epoch: 121, best_acc1: 75.250%
2022-07-17 09:10:58 - epoch 122 lr: 0.004000
2022-07-17 09:11:03 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 0.0221
2022-07-17 09:11:05 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 0.0327
2022-07-17 09:11:07 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 0.0438
2022-07-17 09:11:09 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 0.0366
2022-07-17 09:11:11 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 0.0397
2022-07-17 09:11:13 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 0.0274
2022-07-17 09:11:15 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 0.0359
2022-07-17 09:11:17 - train: epoch 122, train_loss: 0.0352
2022-07-17 09:11:20 - eval: epoch: 122, acc1: 74.450%, acc5: 93.350%, test_loss: 1.1407, per_image_load_time: 0.258ms, per_image_inference_time: 0.046ms
2022-07-17 09:11:21 - until epoch: 122, best_acc1: 75.250%
2022-07-17 09:11:21 - epoch 123 lr: 0.004000
2022-07-17 09:11:25 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 0.0244
2022-07-17 09:11:27 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 0.0185
2022-07-17 09:11:29 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 0.0243
2022-07-17 09:11:31 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 0.0319
2022-07-17 09:11:32 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 0.0190
2022-07-17 09:11:34 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.0257
2022-07-17 09:11:35 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 0.0161
2022-07-17 09:11:37 - train: epoch 123, train_loss: 0.0258
2022-07-17 09:11:40 - eval: epoch: 123, acc1: 75.010%, acc5: 93.280%, test_loss: 1.1284, per_image_load_time: 0.253ms, per_image_inference_time: 0.042ms
2022-07-17 09:11:40 - until epoch: 123, best_acc1: 75.250%
2022-07-17 09:11:40 - epoch 124 lr: 0.004000
2022-07-17 09:11:44 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.0169
2022-07-17 09:11:46 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 0.0140
2022-07-17 09:11:49 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 0.0755
2022-07-17 09:11:51 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 0.0482
2022-07-17 09:11:53 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 0.0149
2022-07-17 09:11:55 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 0.0325
2022-07-17 09:11:57 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 0.0100
2022-07-17 09:11:58 - train: epoch 124, train_loss: 0.0204
2022-07-17 09:12:02 - eval: epoch: 124, acc1: 75.290%, acc5: 93.440%, test_loss: 1.1193, per_image_load_time: 0.268ms, per_image_inference_time: 0.043ms
2022-07-17 09:12:02 - until epoch: 124, best_acc1: 75.290%
2022-07-17 09:12:02 - epoch 125 lr: 0.004000
2022-07-17 09:12:07 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.0361
2022-07-17 09:12:08 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.0225
2022-07-17 09:12:10 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 0.0063
2022-07-17 09:12:12 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 0.0324
2022-07-17 09:12:13 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 0.0363
2022-07-17 09:12:15 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 0.0450
2022-07-17 09:12:17 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 0.0101
2022-07-17 09:12:19 - train: epoch 125, train_loss: 0.0171
2022-07-17 09:12:22 - eval: epoch: 125, acc1: 75.360%, acc5: 93.340%, test_loss: 1.1270, per_image_load_time: 0.244ms, per_image_inference_time: 0.042ms
2022-07-17 09:12:22 - until epoch: 125, best_acc1: 75.360%
2022-07-17 09:12:22 - epoch 126 lr: 0.004000
2022-07-17 09:12:26 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.0120
2022-07-17 09:12:28 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 0.0193
2022-07-17 09:12:30 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 0.0109
2022-07-17 09:12:32 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 0.0084
2022-07-17 09:12:34 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 0.0085
2022-07-17 09:12:36 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 0.0275
2022-07-17 09:12:38 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 0.0091
2022-07-17 09:12:40 - train: epoch 126, train_loss: 0.0157
2022-07-17 09:12:44 - eval: epoch: 126, acc1: 75.400%, acc5: 93.230%, test_loss: 1.1251, per_image_load_time: 0.323ms, per_image_inference_time: 0.052ms
2022-07-17 09:12:44 - until epoch: 126, best_acc1: 75.400%
2022-07-17 09:12:44 - epoch 127 lr: 0.004000
2022-07-17 09:12:49 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.0173
2022-07-17 09:12:50 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 0.0183
2022-07-17 09:12:52 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.0077
2022-07-17 09:12:54 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.0101
2022-07-17 09:12:57 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.0132
2022-07-17 09:12:59 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 09:13:01 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 0.0379
2022-07-17 09:13:02 - train: epoch 127, train_loss: 0.0140
2022-07-17 09:13:06 - eval: epoch: 127, acc1: 75.250%, acc5: 93.410%, test_loss: 1.1256, per_image_load_time: 0.279ms, per_image_inference_time: 0.043ms
2022-07-17 09:13:06 - until epoch: 127, best_acc1: 75.400%
2022-07-17 09:13:06 - epoch 128 lr: 0.004000
2022-07-17 09:13:11 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 0.0091
2022-07-17 09:13:13 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.0103
2022-07-17 09:13:15 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 0.0079
2022-07-17 09:13:16 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.0281
2022-07-17 09:13:18 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 0.0171
2022-07-17 09:13:20 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 0.0044
2022-07-17 09:13:22 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 0.0086
2022-07-17 09:13:23 - train: epoch 128, train_loss: 0.0116
2022-07-17 09:13:27 - eval: epoch: 128, acc1: 75.510%, acc5: 93.520%, test_loss: 1.1185, per_image_load_time: 0.301ms, per_image_inference_time: 0.052ms
2022-07-17 09:13:27 - until epoch: 128, best_acc1: 75.510%
2022-07-17 09:13:27 - epoch 129 lr: 0.004000
2022-07-17 09:13:32 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 0.0072
2022-07-17 09:13:34 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 0.0094
2022-07-17 09:13:36 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 09:13:38 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 0.0083
2022-07-17 09:13:40 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 0.0159
2022-07-17 09:13:42 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 0.0110
2022-07-17 09:13:44 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 09:13:46 - train: epoch 129, train_loss: 0.0112
2022-07-17 09:13:49 - eval: epoch: 129, acc1: 75.810%, acc5: 93.430%, test_loss: 1.1097, per_image_load_time: 0.231ms, per_image_inference_time: 0.045ms
2022-07-17 09:13:49 - until epoch: 129, best_acc1: 75.810%
2022-07-17 09:13:49 - epoch 130 lr: 0.004000
2022-07-17 09:13:53 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 0.0090
2022-07-17 09:13:55 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 0.0080
2022-07-17 09:13:57 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 09:13:58 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 0.0176
2022-07-17 09:14:00 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.0066
2022-07-17 09:14:02 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 0.0099
2022-07-17 09:14:04 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 0.0071
2022-07-17 09:14:06 - train: epoch 130, train_loss: 0.0107
2022-07-17 09:14:09 - eval: epoch: 130, acc1: 75.480%, acc5: 93.460%, test_loss: 1.1183, per_image_load_time: 0.230ms, per_image_inference_time: 0.043ms
2022-07-17 09:14:09 - until epoch: 130, best_acc1: 75.810%
2022-07-17 09:14:09 - epoch 131 lr: 0.004000
2022-07-17 09:14:13 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 09:14:15 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 0.0177
2022-07-17 09:14:17 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 0.0125
2022-07-17 09:14:19 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 0.0047
2022-07-17 09:14:21 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 0.0087
2022-07-17 09:14:23 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 0.0057
2022-07-17 09:14:25 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 09:14:26 - train: epoch 131, train_loss: 0.0101
2022-07-17 09:14:30 - eval: epoch: 131, acc1: 75.560%, acc5: 93.510%, test_loss: 1.1149, per_image_load_time: 0.276ms, per_image_inference_time: 0.041ms
2022-07-17 09:14:30 - until epoch: 131, best_acc1: 75.810%
2022-07-17 09:14:30 - epoch 132 lr: 0.004000
2022-07-17 09:14:35 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.0140
2022-07-17 09:14:37 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:14:39 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 0.0248
2022-07-17 09:14:41 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 09:14:43 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 0.0052
2022-07-17 09:14:45 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 0.0090
2022-07-17 09:14:47 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.0052
2022-07-17 09:14:48 - train: epoch 132, train_loss: 0.0092
2022-07-17 09:14:52 - eval: epoch: 132, acc1: 75.650%, acc5: 93.480%, test_loss: 1.1153, per_image_load_time: 0.248ms, per_image_inference_time: 0.042ms
2022-07-17 09:14:52 - until epoch: 132, best_acc1: 75.810%
2022-07-17 09:14:52 - epoch 133 lr: 0.004000
2022-07-17 09:14:56 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.0157
2022-07-17 09:14:58 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.0094
2022-07-17 09:15:00 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.0099
2022-07-17 09:15:02 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 0.0067
2022-07-17 09:15:04 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 0.0057
2022-07-17 09:15:05 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 0.0076
2022-07-17 09:15:07 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.0063
2022-07-17 09:15:08 - train: epoch 133, train_loss: 0.0087
2022-07-17 09:15:12 - eval: epoch: 133, acc1: 75.810%, acc5: 93.580%, test_loss: 1.1025, per_image_load_time: 0.303ms, per_image_inference_time: 0.050ms
2022-07-17 09:15:12 - until epoch: 133, best_acc1: 75.810%
2022-07-17 09:15:12 - epoch 134 lr: 0.004000
2022-07-17 09:15:18 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 0.0149
2022-07-17 09:15:20 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:15:22 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 0.0052
2022-07-17 09:15:24 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.0070
2022-07-17 09:15:26 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 0.0044
2022-07-17 09:15:28 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.0116
2022-07-17 09:15:30 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 0.0063
2022-07-17 09:15:31 - train: epoch 134, train_loss: 0.0089
2022-07-17 09:15:35 - eval: epoch: 134, acc1: 75.850%, acc5: 93.490%, test_loss: 1.1051, per_image_load_time: 0.253ms, per_image_inference_time: 0.042ms
2022-07-17 09:15:35 - until epoch: 134, best_acc1: 75.850%
2022-07-17 09:15:35 - epoch 135 lr: 0.004000
2022-07-17 09:15:39 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 0.0057
2022-07-17 09:15:41 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.0421
2022-07-17 09:15:42 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 0.0047
2022-07-17 09:15:44 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 0.0315
2022-07-17 09:15:46 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 0.0090
2022-07-17 09:15:47 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:15:49 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 0.0080
2022-07-17 09:15:50 - train: epoch 135, train_loss: 0.0081
2022-07-17 09:15:54 - eval: epoch: 135, acc1: 75.580%, acc5: 93.610%, test_loss: 1.1059, per_image_load_time: 0.271ms, per_image_inference_time: 0.043ms
2022-07-17 09:15:54 - until epoch: 135, best_acc1: 75.850%
2022-07-17 09:15:54 - epoch 136 lr: 0.004000
2022-07-17 09:15:59 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 09:16:01 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.0082
2022-07-17 09:16:03 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.0037
2022-07-17 09:16:05 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 0.0055
2022-07-17 09:16:07 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.0139
2022-07-17 09:16:09 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 0.0073
2022-07-17 09:16:11 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 0.0071
2022-07-17 09:16:13 - train: epoch 136, train_loss: 0.0079
2022-07-17 09:16:15 - eval: epoch: 136, acc1: 75.730%, acc5: 93.550%, test_loss: 1.1029, per_image_load_time: 0.218ms, per_image_inference_time: 0.042ms
2022-07-17 09:16:16 - until epoch: 136, best_acc1: 75.850%
2022-07-17 09:16:16 - epoch 137 lr: 0.004000
2022-07-17 09:16:20 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 09:16:21 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:16:23 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.0043
2022-07-17 09:16:25 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 0.0079
2022-07-17 09:16:26 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 0.0079
2022-07-17 09:16:28 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 0.0034
2022-07-17 09:16:30 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.0088
2022-07-17 09:16:32 - train: epoch 137, train_loss: 0.0072
2022-07-17 09:16:36 - eval: epoch: 137, acc1: 75.970%, acc5: 93.550%, test_loss: 1.0969, per_image_load_time: 0.281ms, per_image_inference_time: 0.044ms
2022-07-17 09:16:36 - until epoch: 137, best_acc1: 75.970%
2022-07-17 09:16:36 - epoch 138 lr: 0.004000
2022-07-17 09:16:40 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 0.0048
2022-07-17 09:16:42 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 0.0033
2022-07-17 09:16:44 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:16:46 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 0.0660
2022-07-17 09:16:48 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.0119
2022-07-17 09:16:50 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.0076
2022-07-17 09:16:52 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 09:16:54 - train: epoch 138, train_loss: 0.0074
2022-07-17 09:16:57 - eval: epoch: 138, acc1: 75.870%, acc5: 93.530%, test_loss: 1.0980, per_image_load_time: 0.273ms, per_image_inference_time: 0.043ms
2022-07-17 09:16:57 - until epoch: 138, best_acc1: 75.970%
2022-07-17 09:16:57 - epoch 139 lr: 0.004000
2022-07-17 09:17:02 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 0.0060
2022-07-17 09:17:03 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 0.0125
2022-07-17 09:17:05 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 0.0284
2022-07-17 09:17:07 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.0057
2022-07-17 09:17:09 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 0.0067
2022-07-17 09:17:11 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 09:17:14 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 0.0058
2022-07-17 09:17:15 - train: epoch 139, train_loss: 0.0075
2022-07-17 09:17:19 - eval: epoch: 139, acc1: 76.020%, acc5: 93.460%, test_loss: 1.0936, per_image_load_time: 0.259ms, per_image_inference_time: 0.043ms
2022-07-17 09:17:19 - until epoch: 139, best_acc1: 76.020%
2022-07-17 09:17:19 - epoch 140 lr: 0.004000
2022-07-17 09:17:23 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 0.0088
2022-07-17 09:17:25 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 0.0053
2022-07-17 09:17:27 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 0.0079
2022-07-17 09:17:29 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.0085
2022-07-17 09:17:31 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 0.0043
2022-07-17 09:17:32 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.0102
2022-07-17 09:17:34 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 0.0060
2022-07-17 09:17:35 - train: epoch 140, train_loss: 0.0067
2022-07-17 09:17:39 - eval: epoch: 140, acc1: 76.000%, acc5: 93.540%, test_loss: 1.0881, per_image_load_time: 0.303ms, per_image_inference_time: 0.042ms
2022-07-17 09:17:39 - until epoch: 140, best_acc1: 76.020%
2022-07-17 09:17:39 - epoch 141 lr: 0.004000
2022-07-17 09:17:43 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.0069
2022-07-17 09:17:45 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 09:17:47 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 09:17:49 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 09:17:51 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 0.0088
2022-07-17 09:17:53 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 09:17:55 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.0192
2022-07-17 09:17:57 - train: epoch 141, train_loss: 0.0064
2022-07-17 09:18:00 - eval: epoch: 141, acc1: 75.980%, acc5: 93.460%, test_loss: 1.0929, per_image_load_time: 0.231ms, per_image_inference_time: 0.043ms
2022-07-17 09:18:00 - until epoch: 141, best_acc1: 76.020%
2022-07-17 09:18:00 - epoch 142 lr: 0.004000
2022-07-17 09:18:05 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 09:18:06 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.0090
2022-07-17 09:18:08 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.0049
2022-07-17 09:18:09 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 0.0078
2022-07-17 09:18:11 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 09:18:12 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 0.0044
2022-07-17 09:18:14 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 0.0035
2022-07-17 09:18:16 - train: epoch 142, train_loss: 0.0066
2022-07-17 09:18:19 - eval: epoch: 142, acc1: 76.090%, acc5: 93.380%, test_loss: 1.0885, per_image_load_time: 0.234ms, per_image_inference_time: 0.044ms
2022-07-17 09:18:19 - until epoch: 142, best_acc1: 76.090%
2022-07-17 09:18:19 - epoch 143 lr: 0.004000
2022-07-17 09:18:23 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 09:18:25 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 0.0125
2022-07-17 09:18:27 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 0.0063
2022-07-17 09:18:29 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 09:18:31 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 0.0037
2022-07-17 09:18:33 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 09:18:35 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.0067
2022-07-17 09:18:37 - train: epoch 143, train_loss: 0.0064
2022-07-17 09:18:40 - eval: epoch: 143, acc1: 76.140%, acc5: 93.560%, test_loss: 1.0827, per_image_load_time: 0.249ms, per_image_inference_time: 0.040ms
2022-07-17 09:18:41 - until epoch: 143, best_acc1: 76.140%
2022-07-17 09:18:41 - epoch 144 lr: 0.004000
2022-07-17 09:18:45 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.0068
2022-07-17 09:18:47 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 09:18:48 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 0.0165
2022-07-17 09:18:50 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 0.0066
2022-07-17 09:18:51 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 0.0409
2022-07-17 09:18:53 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.0087
2022-07-17 09:18:55 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 0.0043
2022-07-17 09:18:57 - train: epoch 144, train_loss: 0.0061
2022-07-17 09:19:01 - eval: epoch: 144, acc1: 76.140%, acc5: 93.440%, test_loss: 1.0830, per_image_load_time: 0.283ms, per_image_inference_time: 0.043ms
2022-07-17 09:19:01 - until epoch: 144, best_acc1: 76.140%
2022-07-17 09:19:01 - epoch 145 lr: 0.004000
2022-07-17 09:19:06 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.0044
2022-07-17 09:19:08 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 0.0033
2022-07-17 09:19:10 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.0049
2022-07-17 09:19:12 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 0.0066
2022-07-17 09:19:14 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.0029
2022-07-17 09:19:16 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.0061
2022-07-17 09:19:18 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:19:19 - train: epoch 145, train_loss: 0.0065
2022-07-17 09:19:23 - eval: epoch: 145, acc1: 76.060%, acc5: 93.610%, test_loss: 1.0775, per_image_load_time: 0.300ms, per_image_inference_time: 0.044ms
2022-07-17 09:19:23 - until epoch: 145, best_acc1: 76.140%
2022-07-17 09:19:23 - epoch 146 lr: 0.004000
2022-07-17 09:19:27 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.0113
2022-07-17 09:19:29 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:19:31 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 09:19:33 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 0.0030
2022-07-17 09:19:35 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 09:19:37 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 0.0012
2022-07-17 09:19:39 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:19:41 - train: epoch 146, train_loss: 0.0061
2022-07-17 09:19:45 - eval: epoch: 146, acc1: 76.030%, acc5: 93.480%, test_loss: 1.0778, per_image_load_time: 0.251ms, per_image_inference_time: 0.044ms
2022-07-17 09:19:45 - until epoch: 146, best_acc1: 76.140%
2022-07-17 09:19:45 - epoch 147 lr: 0.004000
2022-07-17 09:19:49 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 0.0045
2022-07-17 09:19:52 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 09:19:53 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 0.0076
2022-07-17 09:19:55 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 09:19:56 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:19:58 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 0.0113
2022-07-17 09:19:59 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 0.0058
2022-07-17 09:20:01 - train: epoch 147, train_loss: 0.0054
2022-07-17 09:20:04 - eval: epoch: 147, acc1: 76.070%, acc5: 93.520%, test_loss: 1.0734, per_image_load_time: 0.250ms, per_image_inference_time: 0.045ms
2022-07-17 09:20:04 - until epoch: 147, best_acc1: 76.140%
2022-07-17 09:20:04 - epoch 148 lr: 0.004000
2022-07-17 09:20:09 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 0.0041
2022-07-17 09:20:11 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 09:20:13 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:20:15 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 0.0020
2022-07-17 09:20:17 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 0.0047
2022-07-17 09:20:19 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 0.0048
2022-07-17 09:20:21 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 0.0060
2022-07-17 09:20:23 - train: epoch 148, train_loss: 0.0056
2022-07-17 09:20:26 - eval: epoch: 148, acc1: 75.890%, acc5: 93.560%, test_loss: 1.0721, per_image_load_time: 0.303ms, per_image_inference_time: 0.049ms
2022-07-17 09:20:27 - until epoch: 148, best_acc1: 76.140%
2022-07-17 09:20:27 - epoch 149 lr: 0.004000
2022-07-17 09:20:31 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 0.0041
2022-07-17 09:20:32 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 0.0075
2022-07-17 09:20:34 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.0073
2022-07-17 09:20:35 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 0.0077
2022-07-17 09:20:37 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.0049
2022-07-17 09:20:39 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 0.0044
2022-07-17 09:20:41 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 09:20:42 - train: epoch 149, train_loss: 0.0057
2022-07-17 09:20:46 - eval: epoch: 149, acc1: 75.930%, acc5: 93.500%, test_loss: 1.0731, per_image_load_time: 0.253ms, per_image_inference_time: 0.042ms
2022-07-17 09:20:46 - until epoch: 149, best_acc1: 76.140%
2022-07-17 09:20:46 - epoch 150 lr: 0.004000
2022-07-17 09:20:50 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.0049
2022-07-17 09:20:52 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.0045
2022-07-17 09:20:54 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.0033
2022-07-17 09:20:56 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 0.0035
2022-07-17 09:20:58 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 0.0104
2022-07-17 09:21:00 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 0.0023
2022-07-17 09:21:03 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 0.0048
2022-07-17 09:21:04 - train: epoch 150, train_loss: 0.0057
2022-07-17 09:21:08 - eval: epoch: 150, acc1: 76.090%, acc5: 93.470%, test_loss: 1.0779, per_image_load_time: 0.273ms, per_image_inference_time: 0.042ms
2022-07-17 09:21:08 - until epoch: 150, best_acc1: 76.140%
2022-07-17 09:21:08 - epoch 151 lr: 0.004000
2022-07-17 09:21:12 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 0.0069
2022-07-17 09:21:14 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 0.0064
2022-07-17 09:21:16 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 0.0081
2022-07-17 09:21:18 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 0.0255
2022-07-17 09:21:20 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 0.0054
2022-07-17 09:21:22 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.0034
2022-07-17 09:21:24 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.0016
2022-07-17 09:21:25 - train: epoch 151, train_loss: 0.0055
2022-07-17 09:21:28 - eval: epoch: 151, acc1: 76.230%, acc5: 93.450%, test_loss: 1.0712, per_image_load_time: 0.227ms, per_image_inference_time: 0.042ms
2022-07-17 09:21:29 - until epoch: 151, best_acc1: 76.230%
2022-07-17 09:21:29 - epoch 152 lr: 0.004000
2022-07-17 09:21:33 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 0.0025
2022-07-17 09:21:35 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 09:21:37 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.0049
2022-07-17 09:21:39 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.0031
2022-07-17 09:21:41 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:21:42 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 0.0035
2022-07-17 09:21:44 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 0.0047
2022-07-17 09:21:46 - train: epoch 152, train_loss: 0.0054
2022-07-17 09:21:49 - eval: epoch: 152, acc1: 76.210%, acc5: 93.480%, test_loss: 1.0730, per_image_load_time: 0.282ms, per_image_inference_time: 0.043ms
2022-07-17 09:21:49 - until epoch: 152, best_acc1: 76.230%
2022-07-17 09:21:49 - epoch 153 lr: 0.004000
2022-07-17 09:21:54 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 09:21:56 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 0.0033
2022-07-17 09:21:58 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 09:22:00 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 0.0027
2022-07-17 09:22:02 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 0.0055
2022-07-17 09:22:04 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:22:06 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 09:22:08 - train: epoch 153, train_loss: 0.0052
2022-07-17 09:22:11 - eval: epoch: 153, acc1: 76.150%, acc5: 93.550%, test_loss: 1.0713, per_image_load_time: 0.279ms, per_image_inference_time: 0.042ms
2022-07-17 09:22:12 - until epoch: 153, best_acc1: 76.230%
2022-07-17 09:22:12 - epoch 154 lr: 0.004000
2022-07-17 09:22:16 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:22:18 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 09:22:20 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 0.0100
2022-07-17 09:22:21 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 0.0070
2022-07-17 09:22:23 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 0.0036
2022-07-17 09:22:25 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 09:22:26 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 09:22:28 - train: epoch 154, train_loss: 0.0056
2022-07-17 09:22:31 - eval: epoch: 154, acc1: 76.000%, acc5: 93.470%, test_loss: 1.0633, per_image_load_time: 0.231ms, per_image_inference_time: 0.042ms
2022-07-17 09:22:31 - until epoch: 154, best_acc1: 76.230%
2022-07-17 09:22:31 - epoch 155 lr: 0.004000
2022-07-17 09:22:36 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 09:22:38 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 0.0041
2022-07-17 09:22:39 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 0.0103
2022-07-17 09:22:41 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 0.0060
2022-07-17 09:22:43 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 09:22:45 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 09:22:47 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 0.0059
2022-07-17 09:22:49 - train: epoch 155, train_loss: 0.0050
2022-07-17 09:22:53 - eval: epoch: 155, acc1: 76.040%, acc5: 93.430%, test_loss: 1.0644, per_image_load_time: 0.308ms, per_image_inference_time: 0.053ms
2022-07-17 09:22:53 - until epoch: 155, best_acc1: 76.230%
2022-07-17 09:22:53 - epoch 156 lr: 0.004000
2022-07-17 09:22:58 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 09:23:00 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 0.0028
2022-07-17 09:23:02 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 0.0038
2022-07-17 09:23:04 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.0021
2022-07-17 09:23:06 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.0222
2022-07-17 09:23:08 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 09:23:10 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 09:23:12 - train: epoch 156, train_loss: 0.0055
2022-07-17 09:23:15 - eval: epoch: 156, acc1: 76.280%, acc5: 93.460%, test_loss: 1.0661, per_image_load_time: 0.254ms, per_image_inference_time: 0.042ms
2022-07-17 09:23:15 - until epoch: 156, best_acc1: 76.280%
2022-07-17 09:23:15 - epoch 157 lr: 0.004000
2022-07-17 09:23:19 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 0.0165
2022-07-17 09:23:21 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.0227
2022-07-17 09:23:23 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 0.0062
2022-07-17 09:23:25 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 0.0040
2022-07-17 09:23:27 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 0.0039
2022-07-17 09:23:29 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.0056
2022-07-17 09:23:31 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 0.0062
2022-07-17 09:23:32 - train: epoch 157, train_loss: 0.0050
2022-07-17 09:23:36 - eval: epoch: 157, acc1: 76.310%, acc5: 93.470%, test_loss: 1.0520, per_image_load_time: 0.270ms, per_image_inference_time: 0.049ms
2022-07-17 09:23:36 - until epoch: 157, best_acc1: 76.310%
2022-07-17 09:23:36 - epoch 158 lr: 0.004000
2022-07-17 09:23:41 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.0044
2022-07-17 09:23:43 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 0.0034
2022-07-17 09:23:45 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 0.0026
2022-07-17 09:23:47 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 0.0060
2022-07-17 09:23:49 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 0.0035
2022-07-17 09:23:51 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 09:23:53 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 09:23:55 - train: epoch 158, train_loss: 0.0051
2022-07-17 09:23:58 - eval: epoch: 158, acc1: 76.350%, acc5: 93.560%, test_loss: 1.0522, per_image_load_time: 0.233ms, per_image_inference_time: 0.044ms
2022-07-17 09:23:58 - until epoch: 158, best_acc1: 76.350%
2022-07-17 09:23:58 - epoch 159 lr: 0.004000
2022-07-17 09:24:03 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 0.0033
2022-07-17 09:24:05 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:24:06 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.0045
2022-07-17 09:24:08 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:24:09 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 0.0048
2022-07-17 09:24:11 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 0.0046
2022-07-17 09:24:13 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.0024
2022-07-17 09:24:15 - train: epoch 159, train_loss: 0.0052
2022-07-17 09:24:19 - eval: epoch: 159, acc1: 76.310%, acc5: 93.530%, test_loss: 1.0532, per_image_load_time: 0.341ms, per_image_inference_time: 0.049ms
2022-07-17 09:24:19 - until epoch: 159, best_acc1: 76.350%
2022-07-17 09:24:19 - epoch 160 lr: 0.004000
2022-07-17 09:24:23 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 0.0079
2022-07-17 09:24:25 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 0.0050
2022-07-17 09:24:27 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 0.0022
2022-07-17 09:24:29 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 0.0042
2022-07-17 09:24:31 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 0.0037
2022-07-17 09:24:33 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 0.0062
2022-07-17 09:24:35 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.0032
2022-07-17 09:24:37 - train: epoch 160, train_loss: 0.0049
2022-07-17 09:24:40 - eval: epoch: 160, acc1: 76.360%, acc5: 93.580%, test_loss: 1.0565, per_image_load_time: 0.237ms, per_image_inference_time: 0.044ms
2022-07-17 09:24:40 - until epoch: 160, best_acc1: 76.360%
2022-07-17 09:24:40 - epoch 161 lr: 0.000800
2022-07-17 09:24:45 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 0.0052
2022-07-17 09:24:46 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.0054
2022-07-17 09:24:48 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.0045
2022-07-17 09:24:50 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 0.0056
2022-07-17 09:24:52 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 09:24:54 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 0.0064
2022-07-17 09:24:56 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 0.0107
2022-07-17 09:24:58 - train: epoch 161, train_loss: 0.0049
2022-07-17 09:25:01 - eval: epoch: 161, acc1: 76.230%, acc5: 93.580%, test_loss: 1.0496, per_image_load_time: 0.228ms, per_image_inference_time: 0.042ms
2022-07-17 09:25:01 - until epoch: 161, best_acc1: 76.360%
2022-07-17 09:25:01 - epoch 162 lr: 0.000800
2022-07-17 09:25:05 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 0.0043
2022-07-17 09:25:07 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 0.0053
2022-07-17 09:25:09 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:25:11 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:25:13 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:25:15 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 0.0043
2022-07-17 09:25:17 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:25:19 - train: epoch 162, train_loss: 0.0045
2022-07-17 09:25:23 - eval: epoch: 162, acc1: 76.470%, acc5: 93.650%, test_loss: 1.0468, per_image_load_time: 0.303ms, per_image_inference_time: 0.044ms
2022-07-17 09:25:23 - until epoch: 162, best_acc1: 76.470%
2022-07-17 09:25:23 - epoch 163 lr: 0.000800
2022-07-17 09:25:27 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 0.0064
2022-07-17 09:25:29 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 09:25:30 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 09:25:32 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 0.0059
2022-07-17 09:25:34 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 0.0045
2022-07-17 09:25:36 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:25:38 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 0.0093
2022-07-17 09:25:40 - train: epoch 163, train_loss: 0.0044
2022-07-17 09:25:44 - eval: epoch: 163, acc1: 76.380%, acc5: 93.700%, test_loss: 1.0444, per_image_load_time: 0.246ms, per_image_inference_time: 0.042ms
2022-07-17 09:25:44 - until epoch: 163, best_acc1: 76.470%
2022-07-17 09:25:44 - epoch 164 lr: 0.000800
2022-07-17 09:25:48 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 09:25:50 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:25:52 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:25:54 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 09:25:56 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 09:25:57 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:25:59 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:26:00 - train: epoch 164, train_loss: 0.0045
2022-07-17 09:26:03 - eval: epoch: 164, acc1: 76.460%, acc5: 93.740%, test_loss: 1.0420, per_image_load_time: 0.245ms, per_image_inference_time: 0.042ms
2022-07-17 09:26:03 - until epoch: 164, best_acc1: 76.470%
2022-07-17 09:26:03 - epoch 165 lr: 0.000800
2022-07-17 09:26:08 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.0051
2022-07-17 09:26:10 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:26:12 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 0.0091
2022-07-17 09:26:15 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 09:26:17 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 0.0037
2022-07-17 09:26:19 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.0057
2022-07-17 09:26:21 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:26:22 - train: epoch 165, train_loss: 0.0043
2022-07-17 09:26:26 - eval: epoch: 165, acc1: 76.400%, acc5: 93.560%, test_loss: 1.0439, per_image_load_time: 0.233ms, per_image_inference_time: 0.049ms
2022-07-17 09:26:26 - until epoch: 165, best_acc1: 76.470%
2022-07-17 09:26:26 - epoch 166 lr: 0.000800
2022-07-17 09:26:30 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 09:26:32 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 09:26:34 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 0.0120
2022-07-17 09:26:35 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 09:26:37 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:26:38 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 0.0042
2022-07-17 09:26:40 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:26:41 - train: epoch 166, train_loss: 0.0044
2022-07-17 09:26:45 - eval: epoch: 166, acc1: 76.310%, acc5: 93.620%, test_loss: 1.0443, per_image_load_time: 0.280ms, per_image_inference_time: 0.045ms
2022-07-17 09:26:45 - until epoch: 166, best_acc1: 76.470%
2022-07-17 09:26:45 - epoch 167 lr: 0.000800
2022-07-17 09:26:51 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:26:53 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 09:26:55 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 09:26:56 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 09:26:58 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 0.0040
2022-07-17 09:27:00 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.0061
2022-07-17 09:27:02 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:27:04 - train: epoch 167, train_loss: 0.0043
2022-07-17 09:27:08 - eval: epoch: 167, acc1: 76.420%, acc5: 93.730%, test_loss: 1.0407, per_image_load_time: 0.300ms, per_image_inference_time: 0.042ms
2022-07-17 09:27:08 - until epoch: 167, best_acc1: 76.470%
2022-07-17 09:27:08 - epoch 168 lr: 0.000800
2022-07-17 09:27:12 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:27:14 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 0.0041
2022-07-17 09:27:16 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 0.0048
2022-07-17 09:27:17 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:27:19 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 09:27:21 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:27:23 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 0.0047
2022-07-17 09:27:25 - train: epoch 168, train_loss: 0.0040
2022-07-17 09:27:28 - eval: epoch: 168, acc1: 76.460%, acc5: 93.680%, test_loss: 1.0415, per_image_load_time: 0.260ms, per_image_inference_time: 0.049ms
2022-07-17 09:27:28 - until epoch: 168, best_acc1: 76.470%
2022-07-17 09:27:28 - epoch 169 lr: 0.000800
2022-07-17 09:27:33 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:27:35 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 0.0038
2022-07-17 09:27:37 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 0.0053
2022-07-17 09:27:39 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:27:41 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.0037
2022-07-17 09:27:43 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:27:45 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:27:46 - train: epoch 169, train_loss: 0.0041
2022-07-17 09:27:50 - eval: epoch: 169, acc1: 76.530%, acc5: 93.700%, test_loss: 1.0407, per_image_load_time: 0.270ms, per_image_inference_time: 0.042ms
2022-07-17 09:27:50 - until epoch: 169, best_acc1: 76.530%
2022-07-17 09:27:50 - epoch 170 lr: 0.000800
2022-07-17 09:27:54 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:27:56 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 0.0089
2022-07-17 09:27:58 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:28:00 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 09:28:02 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 0.0049
2022-07-17 09:28:04 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 0.0037
2022-07-17 09:28:06 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.0055
2022-07-17 09:28:08 - train: epoch 170, train_loss: 0.0042
2022-07-17 09:28:11 - eval: epoch: 170, acc1: 76.490%, acc5: 93.580%, test_loss: 1.0368, per_image_load_time: 0.289ms, per_image_inference_time: 0.046ms
2022-07-17 09:28:11 - until epoch: 170, best_acc1: 76.530%
2022-07-17 09:28:11 - epoch 171 lr: 0.000800
2022-07-17 09:28:16 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 09:28:18 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:28:20 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.0119
2022-07-17 09:28:21 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.0044
2022-07-17 09:28:23 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 09:28:25 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:28:26 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:28:28 - train: epoch 171, train_loss: 0.0043
2022-07-17 09:28:31 - eval: epoch: 171, acc1: 76.480%, acc5: 93.620%, test_loss: 1.0437, per_image_load_time: 0.266ms, per_image_inference_time: 0.043ms
2022-07-17 09:28:31 - until epoch: 171, best_acc1: 76.530%
2022-07-17 09:28:31 - epoch 172 lr: 0.000800
2022-07-17 09:28:36 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:28:38 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.0184
2022-07-17 09:28:40 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 0.0040
2022-07-17 09:28:42 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:28:44 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.0045
2022-07-17 09:28:46 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 0.0073
2022-07-17 09:28:48 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:28:50 - train: epoch 172, train_loss: 0.0042
2022-07-17 09:28:54 - eval: epoch: 172, acc1: 76.510%, acc5: 93.600%, test_loss: 1.0420, per_image_load_time: 0.304ms, per_image_inference_time: 0.044ms
2022-07-17 09:28:54 - until epoch: 172, best_acc1: 76.530%
2022-07-17 09:28:54 - epoch 173 lr: 0.000800
2022-07-17 09:28:58 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 09:29:00 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.0038
2022-07-17 09:29:01 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 09:29:03 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:29:04 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:29:06 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:29:08 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:29:09 - train: epoch 173, train_loss: 0.0039
2022-07-17 09:29:13 - eval: epoch: 173, acc1: 76.550%, acc5: 93.590%, test_loss: 1.0400, per_image_load_time: 0.279ms, per_image_inference_time: 0.041ms
2022-07-17 09:29:13 - until epoch: 173, best_acc1: 76.550%
2022-07-17 09:29:13 - epoch 174 lr: 0.000800
2022-07-17 09:29:18 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 09:29:20 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:29:22 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:29:24 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:29:26 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 0.0047
2022-07-17 09:29:28 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 09:29:30 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 09:29:32 - train: epoch 174, train_loss: 0.0040
2022-07-17 09:29:36 - eval: epoch: 174, acc1: 76.650%, acc5: 93.620%, test_loss: 1.0409, per_image_load_time: 0.270ms, per_image_inference_time: 0.043ms
2022-07-17 09:29:36 - until epoch: 174, best_acc1: 76.650%
2022-07-17 09:29:36 - epoch 175 lr: 0.000800
2022-07-17 09:29:40 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 09:29:42 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 0.0077
2022-07-17 09:29:43 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 09:29:45 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.0055
2022-07-17 09:29:47 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 0.0093
2022-07-17 09:29:49 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 0.0051
2022-07-17 09:29:51 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 09:29:53 - train: epoch 175, train_loss: 0.0041
2022-07-17 09:29:57 - eval: epoch: 175, acc1: 76.590%, acc5: 93.680%, test_loss: 1.0379, per_image_load_time: 0.315ms, per_image_inference_time: 0.042ms
2022-07-17 09:29:57 - until epoch: 175, best_acc1: 76.650%
2022-07-17 09:29:57 - epoch 176 lr: 0.000800
2022-07-17 09:30:02 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 0.0053
2022-07-17 09:30:04 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 0.0109
2022-07-17 09:30:06 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 0.0029
2022-07-17 09:30:08 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:30:10 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:30:11 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 0.0064
2022-07-17 09:30:13 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:30:14 - train: epoch 176, train_loss: 0.0039
2022-07-17 09:30:18 - eval: epoch: 176, acc1: 76.370%, acc5: 93.610%, test_loss: 1.0423, per_image_load_time: 0.263ms, per_image_inference_time: 0.041ms
2022-07-17 09:30:18 - until epoch: 176, best_acc1: 76.650%
2022-07-17 09:30:18 - epoch 177 lr: 0.000800
2022-07-17 09:30:22 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:30:24 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:30:26 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:30:28 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:30:30 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.0075
2022-07-17 09:30:32 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 0.0052
2022-07-17 09:30:34 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.0057
2022-07-17 09:30:36 - train: epoch 177, train_loss: 0.0039
2022-07-17 09:30:39 - eval: epoch: 177, acc1: 76.590%, acc5: 93.700%, test_loss: 1.0402, per_image_load_time: 0.260ms, per_image_inference_time: 0.044ms
2022-07-17 09:30:39 - until epoch: 177, best_acc1: 76.650%
2022-07-17 09:30:39 - epoch 178 lr: 0.000800
2022-07-17 09:30:44 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.0040
2022-07-17 09:30:46 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 0.0044
2022-07-17 09:30:47 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 0.0037
2022-07-17 09:30:49 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:30:50 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.0053
2022-07-17 09:30:52 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 0.0040
2022-07-17 09:30:54 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:30:55 - train: epoch 178, train_loss: 0.0040
2022-07-17 09:30:58 - eval: epoch: 178, acc1: 76.440%, acc5: 93.670%, test_loss: 1.0394, per_image_load_time: 0.230ms, per_image_inference_time: 0.043ms
2022-07-17 09:30:58 - until epoch: 178, best_acc1: 76.650%
2022-07-17 09:30:58 - epoch 179 lr: 0.000800
2022-07-17 09:31:03 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:31:05 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.0038
2022-07-17 09:31:07 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 0.0098
2022-07-17 09:31:09 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 0.0050
2022-07-17 09:31:11 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:31:13 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.0086
2022-07-17 09:31:15 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:31:17 - train: epoch 179, train_loss: 0.0040
2022-07-17 09:31:20 - eval: epoch: 179, acc1: 76.390%, acc5: 93.650%, test_loss: 1.0360, per_image_load_time: 0.267ms, per_image_inference_time: 0.051ms
2022-07-17 09:31:20 - until epoch: 179, best_acc1: 76.650%
2022-07-17 09:31:20 - epoch 180 lr: 0.000800
2022-07-17 09:31:25 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:31:27 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.0052
2022-07-17 09:31:28 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:31:30 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 09:31:32 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:31:34 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 0.0073
2022-07-17 09:31:36 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.0056
2022-07-17 09:31:38 - train: epoch 180, train_loss: 0.0040
2022-07-17 09:31:41 - eval: epoch: 180, acc1: 76.450%, acc5: 93.590%, test_loss: 1.0363, per_image_load_time: 0.237ms, per_image_inference_time: 0.042ms
2022-07-17 09:31:42 - until epoch: 180, best_acc1: 76.650%
2022-07-17 09:31:42 - epoch 181 lr: 0.000800
2022-07-17 09:31:46 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 0.0094
2022-07-17 09:31:48 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:31:50 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 09:31:52 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:31:54 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 09:31:56 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:31:57 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:31:59 - train: epoch 181, train_loss: 0.0038
2022-07-17 09:32:03 - eval: epoch: 181, acc1: 76.530%, acc5: 93.600%, test_loss: 1.0379, per_image_load_time: 0.311ms, per_image_inference_time: 0.044ms
2022-07-17 09:32:03 - until epoch: 181, best_acc1: 76.650%
2022-07-17 09:32:03 - epoch 182 lr: 0.000800
2022-07-17 09:32:08 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 09:32:10 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:32:12 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 0.0038
2022-07-17 09:32:14 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:32:16 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:32:18 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 0.0070
2022-07-17 09:32:20 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:32:21 - train: epoch 182, train_loss: 0.0039
2022-07-17 09:32:25 - eval: epoch: 182, acc1: 76.510%, acc5: 93.610%, test_loss: 1.0367, per_image_load_time: 0.234ms, per_image_inference_time: 0.044ms
2022-07-17 09:32:25 - until epoch: 182, best_acc1: 76.650%
2022-07-17 09:32:25 - epoch 183 lr: 0.000800
2022-07-17 09:32:29 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.0065
2022-07-17 09:32:31 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 09:32:33 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 09:32:34 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 0.0048
2022-07-17 09:32:36 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:32:38 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 0.0041
2022-07-17 09:32:39 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 0.0050
2022-07-17 09:32:41 - train: epoch 183, train_loss: 0.0039
2022-07-17 09:32:44 - eval: epoch: 183, acc1: 76.460%, acc5: 93.590%, test_loss: 1.0368, per_image_load_time: 0.270ms, per_image_inference_time: 0.042ms
2022-07-17 09:32:44 - until epoch: 183, best_acc1: 76.650%
2022-07-17 09:32:44 - epoch 184 lr: 0.000800
2022-07-17 09:32:49 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 0.0044
2022-07-17 09:32:51 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:32:53 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:32:55 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 0.0041
2022-07-17 09:32:56 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:32:58 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 09:33:00 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:33:02 - train: epoch 184, train_loss: 0.0041
2022-07-17 09:33:05 - eval: epoch: 184, acc1: 76.750%, acc5: 93.680%, test_loss: 1.0369, per_image_load_time: 0.235ms, per_image_inference_time: 0.042ms
2022-07-17 09:33:06 - until epoch: 184, best_acc1: 76.750%
2022-07-17 09:33:06 - epoch 185 lr: 0.000800
2022-07-17 09:33:10 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 09:33:12 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 0.0098
2022-07-17 09:33:13 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:33:15 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:33:17 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 09:33:18 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:33:20 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 0.0050
2022-07-17 09:33:22 - train: epoch 185, train_loss: 0.0039
2022-07-17 09:33:25 - eval: epoch: 185, acc1: 76.390%, acc5: 93.550%, test_loss: 1.0369, per_image_load_time: 0.236ms, per_image_inference_time: 0.043ms
2022-07-17 09:33:25 - until epoch: 185, best_acc1: 76.750%
2022-07-17 09:33:25 - epoch 186 lr: 0.000800
2022-07-17 09:33:30 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 09:33:32 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 09:33:34 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 0.0121
2022-07-17 09:33:36 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 09:33:38 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 0.0037
2022-07-17 09:33:40 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 0.0043
2022-07-17 09:33:42 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 0.0042
2022-07-17 09:33:44 - train: epoch 186, train_loss: 0.0037
2022-07-17 09:33:47 - eval: epoch: 186, acc1: 76.650%, acc5: 93.690%, test_loss: 1.0333, per_image_load_time: 0.255ms, per_image_inference_time: 0.046ms
2022-07-17 09:33:47 - until epoch: 186, best_acc1: 76.750%
2022-07-17 09:33:47 - epoch 187 lr: 0.000800
2022-07-17 09:33:52 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 09:33:53 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 09:33:55 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 0.0046
2022-07-17 09:33:57 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 0.0040
2022-07-17 09:33:59 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.0037
2022-07-17 09:34:01 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:34:03 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 09:34:05 - train: epoch 187, train_loss: 0.0037
2022-07-17 09:34:08 - eval: epoch: 187, acc1: 76.350%, acc5: 93.610%, test_loss: 1.0387, per_image_load_time: 0.225ms, per_image_inference_time: 0.043ms
2022-07-17 09:34:08 - until epoch: 187, best_acc1: 76.750%
2022-07-17 09:34:08 - epoch 188 lr: 0.000800
2022-07-17 09:34:12 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:34:14 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:34:16 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:34:18 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 0.0042
2022-07-17 09:34:20 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 0.0048
2022-07-17 09:34:22 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 0.0048
2022-07-17 09:34:23 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:34:25 - train: epoch 188, train_loss: 0.0038
2022-07-17 09:34:28 - eval: epoch: 188, acc1: 76.510%, acc5: 93.750%, test_loss: 1.0353, per_image_load_time: 0.261ms, per_image_inference_time: 0.042ms
2022-07-17 09:34:28 - until epoch: 188, best_acc1: 76.750%
2022-07-17 09:34:28 - epoch 189 lr: 0.000800
2022-07-17 09:34:33 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:34:35 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:34:37 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:34:39 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 0.0029
2022-07-17 09:34:41 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 0.0051
2022-07-17 09:34:43 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 0.0044
2022-07-17 09:34:45 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:34:47 - train: epoch 189, train_loss: 0.0039
2022-07-17 09:34:51 - eval: epoch: 189, acc1: 76.520%, acc5: 93.790%, test_loss: 1.0340, per_image_load_time: 0.248ms, per_image_inference_time: 0.042ms
2022-07-17 09:34:51 - until epoch: 189, best_acc1: 76.750%
2022-07-17 09:34:51 - epoch 190 lr: 0.000800
2022-07-17 09:34:55 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 09:34:57 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:34:58 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 0.0055
2022-07-17 09:35:00 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:35:01 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 0.0077
2022-07-17 09:35:03 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:35:05 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 0.0014
2022-07-17 09:35:06 - train: epoch 190, train_loss: 0.0037
2022-07-17 09:35:09 - eval: epoch: 190, acc1: 76.520%, acc5: 93.710%, test_loss: 1.0340, per_image_load_time: 0.250ms, per_image_inference_time: 0.042ms
2022-07-17 09:35:10 - until epoch: 190, best_acc1: 76.750%
2022-07-17 09:35:10 - epoch 191 lr: 0.000800
2022-07-17 09:35:14 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.0029
2022-07-17 09:35:16 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 0.0012
2022-07-17 09:35:18 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.0038
2022-07-17 09:35:20 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:35:22 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 09:35:24 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 09:35:26 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:35:28 - train: epoch 191, train_loss: 0.0039
2022-07-17 09:35:32 - eval: epoch: 191, acc1: 76.510%, acc5: 93.670%, test_loss: 1.0357, per_image_load_time: 0.295ms, per_image_inference_time: 0.044ms
2022-07-17 09:35:32 - until epoch: 191, best_acc1: 76.750%
2022-07-17 09:35:32 - epoch 192 lr: 0.000800
2022-07-17 09:35:36 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:35:38 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 09:35:40 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:35:41 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:35:43 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 09:35:44 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 0.0026
2022-07-17 09:35:46 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:35:47 - train: epoch 192, train_loss: 0.0037
2022-07-17 09:35:50 - eval: epoch: 192, acc1: 76.490%, acc5: 93.670%, test_loss: 1.0325, per_image_load_time: 0.228ms, per_image_inference_time: 0.041ms
2022-07-17 09:35:50 - until epoch: 192, best_acc1: 76.750%
2022-07-17 09:35:50 - epoch 193 lr: 0.000800
2022-07-17 09:35:55 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 09:35:56 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:35:58 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:35:59 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:36:01 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.0057
2022-07-17 09:36:02 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 0.0017
2022-07-17 09:36:04 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 0.0052
2022-07-17 09:36:06 - train: epoch 193, train_loss: 0.0039
2022-07-17 09:36:09 - eval: epoch: 193, acc1: 76.430%, acc5: 93.750%, test_loss: 1.0358, per_image_load_time: 0.262ms, per_image_inference_time: 0.043ms
2022-07-17 09:36:09 - until epoch: 193, best_acc1: 76.750%
2022-07-17 09:36:09 - epoch 194 lr: 0.000800
2022-07-17 09:36:13 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:36:15 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 0.0047
2022-07-17 09:36:16 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.0101
2022-07-17 09:36:18 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 09:36:19 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 09:36:21 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.0097
2022-07-17 09:36:22 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:36:24 - train: epoch 194, train_loss: 0.0037
2022-07-17 09:36:27 - eval: epoch: 194, acc1: 76.630%, acc5: 93.700%, test_loss: 1.0354, per_image_load_time: 0.280ms, per_image_inference_time: 0.046ms
2022-07-17 09:36:28 - until epoch: 194, best_acc1: 76.750%
2022-07-17 09:36:28 - epoch 195 lr: 0.000800
2022-07-17 09:36:32 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 09:36:34 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:36:35 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.0027
2022-07-17 09:36:37 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2022-07-17 09:36:38 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 0.0047
2022-07-17 09:36:40 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:36:41 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:36:43 - train: epoch 195, train_loss: 0.0039
2022-07-17 09:36:46 - eval: epoch: 195, acc1: 76.380%, acc5: 93.710%, test_loss: 1.0332, per_image_load_time: 0.242ms, per_image_inference_time: 0.042ms
2022-07-17 09:36:46 - until epoch: 195, best_acc1: 76.750%
2022-07-17 09:36:46 - epoch 196 lr: 0.000800
2022-07-17 09:36:50 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 09:36:52 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.0044
2022-07-17 09:36:53 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 0.0085
2022-07-17 09:36:55 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 09:36:56 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.0022
2022-07-17 09:36:58 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.0029
2022-07-17 09:36:59 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 09:37:01 - train: epoch 196, train_loss: 0.0039
2022-07-17 09:37:04 - eval: epoch: 196, acc1: 76.590%, acc5: 93.650%, test_loss: 1.0304, per_image_load_time: 0.244ms, per_image_inference_time: 0.044ms
2022-07-17 09:37:04 - until epoch: 196, best_acc1: 76.750%
2022-07-17 09:37:04 - epoch 197 lr: 0.000800
2022-07-17 09:37:08 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.0032
2022-07-17 09:37:10 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 09:37:11 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:37:13 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 0.0028
2022-07-17 09:37:14 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:37:16 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 0.0035
2022-07-17 09:37:17 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 0.0046
2022-07-17 09:37:19 - train: epoch 197, train_loss: 0.0038
2022-07-17 09:37:22 - eval: epoch: 197, acc1: 76.470%, acc5: 93.630%, test_loss: 1.0335, per_image_load_time: 0.235ms, per_image_inference_time: 0.044ms
2022-07-17 09:37:22 - until epoch: 197, best_acc1: 76.750%
2022-07-17 09:37:22 - epoch 198 lr: 0.000800
2022-07-17 09:37:26 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 0.0030
2022-07-17 09:37:27 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.0072
2022-07-17 09:37:29 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.0021
2022-07-17 09:37:30 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 0.0081
2022-07-17 09:37:32 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 0.0023
2022-07-17 09:37:33 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:37:35 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.0034
2022-07-17 09:37:36 - train: epoch 198, train_loss: 0.0036
2022-07-17 09:37:39 - eval: epoch: 198, acc1: 76.570%, acc5: 93.670%, test_loss: 1.0308, per_image_load_time: 0.243ms, per_image_inference_time: 0.041ms
2022-07-17 09:37:40 - until epoch: 198, best_acc1: 76.750%
2022-07-17 09:37:40 - epoch 199 lr: 0.000800
2022-07-17 09:37:44 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.0020
2022-07-17 09:37:45 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.0044
2022-07-17 09:37:47 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 0.0031
2022-07-17 09:37:48 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.0019
2022-07-17 09:37:50 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 0.0127
2022-07-17 09:37:51 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 0.0165
2022-07-17 09:37:53 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.0024
2022-07-17 09:37:54 - train: epoch 199, train_loss: 0.0038
2022-07-17 09:37:57 - eval: epoch: 199, acc1: 76.710%, acc5: 93.630%, test_loss: 1.0338, per_image_load_time: 0.237ms, per_image_inference_time: 0.040ms
2022-07-17 09:37:57 - until epoch: 199, best_acc1: 76.750%
2022-07-17 09:37:57 - epoch 200 lr: 0.000800
2022-07-17 09:38:01 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 0.0037
2022-07-17 09:38:03 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.0033
2022-07-17 09:38:04 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 0.0069
2022-07-17 09:38:06 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.0016
2022-07-17 09:38:07 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 0.0036
2022-07-17 09:38:09 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 0.0025
2022-07-17 09:38:10 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 0.0056
2022-07-17 09:38:12 - train: epoch 200, train_loss: 0.0037
2022-07-17 09:38:14 - eval: epoch: 200, acc1: 76.600%, acc5: 93.730%, test_loss: 1.0288, per_image_load_time: 0.208ms, per_image_inference_time: 0.040ms
2022-07-17 09:38:15 - until epoch: 200, best_acc1: 76.750%
2022-07-17 09:38:15 - train done. model: resnet18cifar, train time: 1.172 hours, best_acc1: 76.750%
2023-05-31 00:53:12 - network: resnet18cifar
2023-05-31 00:53:12 - num_classes: 100
2023-05-31 00:53:12 - input_image_size: 32
2023-05-31 00:53:12 - trained_model_path: 
2023-05-31 00:53:12 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 00:53:12 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 00:53:12 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fde0a667d00>
2023-05-31 00:53:12 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fde0a667a30>
2023-05-31 00:53:12 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fde0a667a00>
2023-05-31 00:53:12 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fde0a667970>
2023-05-31 00:53:12 - seed: 0
2023-05-31 00:53:12 - batch_size: 128
2023-05-31 00:53:12 - num_workers: 16
2023-05-31 00:53:12 - accumulation_steps: 1
2023-05-31 00:53:12 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 00:53:12 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 00:53:12 - epochs: 200
2023-05-31 00:53:12 - print_interval: 50
2023-05-31 00:53:12 - sync_bn: False
2023-05-31 00:53:12 - apex: True
2023-05-31 00:53:12 - use_ema_model: False
2023-05-31 00:53:12 - ema_model_decay: 0.9999
2023-05-31 00:53:12 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 00:53:12 - gpus_num: 1
2023-05-31 00:53:12 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fde0a7454f0>
2023-05-31 00:53:12 - --------------------parameters--------------------
2023-05-31 00:53:12 - name: conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 00:53:12 - name: fc.weight, grad: True
2023-05-31 00:53:12 - name: fc.bias, grad: True
2023-05-31 00:53:12 - --------------------buffers--------------------
2023-05-31 00:53:12 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 00:53:12 - -----------no weight decay layers--------------
2023-05-31 00:53:12 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 00:53:12 - -------------weight decay layers---------------
2023-05-31 00:53:12 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 00:53:12 - epoch 001 lr: 0.100000
2023-05-31 00:53:19 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.0865
2023-05-31 00:53:21 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.0503
2023-05-31 00:53:22 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9884
2023-05-31 00:53:23 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7567
2023-05-31 00:53:24 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.8468
2023-05-31 00:53:26 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.6083
2023-05-31 00:53:27 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.6004
2023-05-31 00:53:28 - train: epoch 001, train_loss: 3.8827
2023-05-31 00:53:29 - eval: epoch: 001, acc1: 17.350%, acc5: 42.570%, test_loss: 3.4736, per_image_load_time: 0.062ms, per_image_inference_time: 0.046ms
2023-05-31 00:53:30 - until epoch: 001, best_acc1: 17.350%
2023-05-31 00:53:30 - epoch 002 lr: 0.100000
2023-05-31 00:53:32 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.4635
2023-05-31 00:53:33 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.2598
2023-05-31 00:53:34 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.2792
2023-05-31 00:53:36 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 3.3293
2023-05-31 00:53:37 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 2.8233
2023-05-31 00:53:38 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.1790
2023-05-31 00:53:39 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 2.6892
2023-05-31 00:53:41 - train: epoch 002, train_loss: 3.1485
2023-05-31 00:53:42 - eval: epoch: 002, acc1: 26.990%, acc5: 59.440%, test_loss: 2.8551, per_image_load_time: 0.066ms, per_image_inference_time: 0.044ms
2023-05-31 00:53:42 - until epoch: 002, best_acc1: 26.990%
2023-05-31 00:53:42 - epoch 003 lr: 0.100000
2023-05-31 00:53:45 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 2.8511
2023-05-31 00:53:46 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 2.6427
2023-05-31 00:53:47 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 2.5983
2023-05-31 00:53:48 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 2.4748
2023-05-31 00:53:50 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 2.5576
2023-05-31 00:53:51 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 2.6627
2023-05-31 00:53:52 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 2.3642
2023-05-31 00:53:53 - train: epoch 003, train_loss: 2.5735
2023-05-31 00:53:55 - eval: epoch: 003, acc1: 37.740%, acc5: 71.190%, test_loss: 2.3254, per_image_load_time: 0.077ms, per_image_inference_time: 0.048ms
2023-05-31 00:53:55 - until epoch: 003, best_acc1: 37.740%
2023-05-31 00:53:55 - epoch 004 lr: 0.100000
2023-05-31 00:53:57 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 2.2412
2023-05-31 00:53:59 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 2.3972
2023-05-31 00:54:00 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 2.3021
2023-05-31 00:54:01 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 2.4645
2023-05-31 00:54:02 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 1.9989
2023-05-31 00:54:04 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 2.2340
2023-05-31 00:54:05 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 1.9498
2023-05-31 00:54:06 - train: epoch 004, train_loss: 2.2081
2023-05-31 00:54:07 - eval: epoch: 004, acc1: 41.380%, acc5: 72.880%, test_loss: 2.2283, per_image_load_time: 0.067ms, per_image_inference_time: 0.043ms
2023-05-31 00:54:08 - until epoch: 004, best_acc1: 41.380%
2023-05-31 00:54:08 - epoch 005 lr: 0.100000
2023-05-31 00:54:10 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 2.0031
2023-05-31 00:54:11 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 2.0340
2023-05-31 00:54:12 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 1.8222
2023-05-31 00:54:14 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 2.1616
2023-05-31 00:54:15 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 1.8374
2023-05-31 00:54:16 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 1.8206
2023-05-31 00:54:18 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 1.5894
2023-05-31 00:54:19 - train: epoch 005, train_loss: 1.9713
2023-05-31 00:54:20 - eval: epoch: 005, acc1: 42.310%, acc5: 74.980%, test_loss: 2.1990, per_image_load_time: 0.066ms, per_image_inference_time: 0.043ms
2023-05-31 00:54:20 - until epoch: 005, best_acc1: 42.310%
2023-05-31 00:54:20 - epoch 006 lr: 0.100000
2023-05-31 00:54:22 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 1.8465
2023-05-31 00:54:24 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 1.7557
2023-05-31 00:54:25 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 1.8326
2023-05-31 00:54:26 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 1.8280
2023-05-31 00:54:28 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 1.6003
2023-05-31 00:54:29 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 1.5479
2023-05-31 00:54:30 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 1.5406
2023-05-31 00:54:31 - train: epoch 006, train_loss: 1.7819
2023-05-31 00:54:33 - eval: epoch: 006, acc1: 46.600%, acc5: 78.860%, test_loss: 1.9708, per_image_load_time: 0.066ms, per_image_inference_time: 0.045ms
2023-05-31 00:54:33 - until epoch: 006, best_acc1: 46.600%
2023-05-31 00:54:33 - epoch 007 lr: 0.100000
2023-05-31 00:54:35 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 1.8243
2023-05-31 00:54:36 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 1.6655
2023-05-31 00:54:38 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 1.7501
2023-05-31 00:54:39 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 1.4978
2023-05-31 00:54:40 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 1.5274
2023-05-31 00:54:41 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 1.2929
2023-05-31 00:54:43 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 1.6254
2023-05-31 00:54:44 - train: epoch 007, train_loss: 1.6729
2023-05-31 00:54:45 - eval: epoch: 007, acc1: 47.920%, acc5: 79.470%, test_loss: 1.9391, per_image_load_time: 0.071ms, per_image_inference_time: 0.044ms
2023-05-31 00:54:46 - until epoch: 007, best_acc1: 47.920%
2023-05-31 00:54:46 - epoch 008 lr: 0.100000
2023-05-31 00:54:48 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 1.6351
2023-05-31 00:54:49 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 1.3211
2023-05-31 00:54:50 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 1.4559
2023-05-31 00:54:52 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 1.2936
2023-05-31 00:54:53 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 1.2500
2023-05-31 00:54:54 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 1.5592
2023-05-31 00:54:56 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 1.5199
2023-05-31 00:54:57 - train: epoch 008, train_loss: 1.5543
2023-05-31 00:54:58 - eval: epoch: 008, acc1: 50.560%, acc5: 81.260%, test_loss: 1.8413, per_image_load_time: 0.064ms, per_image_inference_time: 0.045ms
2023-05-31 00:54:58 - until epoch: 008, best_acc1: 50.560%
2023-05-31 00:54:58 - epoch 009 lr: 0.100000
2023-05-31 00:55:00 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 1.3814
2023-05-31 00:55:02 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 1.4926
2023-05-31 00:55:03 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 1.4517
2023-05-31 00:55:04 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 1.4495
2023-05-31 00:55:06 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 1.5683
2023-05-31 00:55:07 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 1.2326
2023-05-31 00:55:08 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 1.5170
2023-05-31 00:55:09 - train: epoch 009, train_loss: 1.4728
2023-05-31 00:55:10 - eval: epoch: 009, acc1: 53.320%, acc5: 83.630%, test_loss: 1.6833, per_image_load_time: 0.065ms, per_image_inference_time: 0.044ms
2023-05-31 00:55:11 - until epoch: 009, best_acc1: 53.320%
2023-05-31 00:55:11 - epoch 010 lr: 0.100000
2023-05-31 00:55:13 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 1.5568
2023-05-31 00:55:14 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 1.2830
2023-05-31 00:55:15 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 1.3767
2023-05-31 00:55:17 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 1.4159
2023-05-31 00:55:18 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 1.4661
2023-05-31 00:55:19 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 1.3207
2023-05-31 00:55:21 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 1.3113
2023-05-31 00:55:22 - train: epoch 010, train_loss: 1.3957
2023-05-31 00:55:23 - eval: epoch: 010, acc1: 54.770%, acc5: 84.610%, test_loss: 1.6225, per_image_load_time: 0.080ms, per_image_inference_time: 0.044ms
2023-05-31 00:55:24 - until epoch: 010, best_acc1: 54.770%
2023-05-31 00:55:24 - epoch 011 lr: 0.100000
2023-05-31 00:55:26 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 1.4689
2023-05-31 00:55:27 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 1.0826
2023-05-31 00:55:28 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 1.5991
2023-05-31 00:55:30 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 1.3629
2023-05-31 00:55:31 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 1.3188
2023-05-31 00:55:32 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 1.1372
2023-05-31 00:55:34 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 1.3602
2023-05-31 00:55:35 - train: epoch 011, train_loss: 1.3393
2023-05-31 00:55:36 - eval: epoch: 011, acc1: 56.680%, acc5: 85.290%, test_loss: 1.5727, per_image_load_time: 0.064ms, per_image_inference_time: 0.044ms
2023-05-31 00:55:36 - until epoch: 011, best_acc1: 56.680%
2023-05-31 00:55:36 - epoch 012 lr: 0.100000
2023-05-31 00:55:38 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 1.1122
2023-05-31 00:55:40 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 1.4913
2023-05-31 00:55:41 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 1.2899
2023-05-31 00:55:42 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 1.6355
2023-05-31 00:55:44 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 1.2308
2023-05-31 00:55:45 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 1.4755
2023-05-31 00:55:46 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 1.2109
2023-05-31 00:55:47 - train: epoch 012, train_loss: 1.3016
2023-05-31 00:55:49 - eval: epoch: 012, acc1: 54.280%, acc5: 82.130%, test_loss: 1.7517, per_image_load_time: 0.067ms, per_image_inference_time: 0.045ms
2023-05-31 00:55:49 - until epoch: 012, best_acc1: 56.680%
2023-05-31 00:55:49 - epoch 013 lr: 0.100000
2023-05-31 00:55:51 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 1.2304
2023-05-31 00:55:52 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 1.2049
2023-05-31 00:55:53 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 1.5722
2023-05-31 00:55:55 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 1.1673
2023-05-31 00:55:56 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 1.3523
2023-05-31 00:55:57 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 1.2524
2023-05-31 00:55:59 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 1.0852
2023-05-31 00:56:00 - train: epoch 013, train_loss: 1.2533
2023-05-31 00:56:01 - eval: epoch: 013, acc1: 55.020%, acc5: 83.520%, test_loss: 1.6725, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 00:56:01 - until epoch: 013, best_acc1: 56.680%
2023-05-31 00:56:01 - epoch 014 lr: 0.100000
2023-05-31 00:56:03 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 1.0250
2023-05-31 00:56:05 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 1.0355
2023-05-31 00:56:06 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 1.1700
2023-05-31 00:56:07 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 1.2364
2023-05-31 00:56:08 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 1.1296
2023-05-31 00:56:10 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 1.2197
2023-05-31 00:56:11 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 1.2050
2023-05-31 00:56:12 - train: epoch 014, train_loss: 1.2175
2023-05-31 00:56:13 - eval: epoch: 014, acc1: 57.450%, acc5: 85.380%, test_loss: 1.5712, per_image_load_time: 0.067ms, per_image_inference_time: 0.046ms
2023-05-31 00:56:14 - until epoch: 014, best_acc1: 57.450%
2023-05-31 00:56:14 - epoch 015 lr: 0.100000
2023-05-31 00:56:16 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 0.8722
2023-05-31 00:56:17 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 1.4800
2023-05-31 00:56:18 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 1.4041
2023-05-31 00:56:20 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 1.2361
2023-05-31 00:56:21 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.2650
2023-05-31 00:56:22 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 1.0628
2023-05-31 00:56:24 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 1.2177
2023-05-31 00:56:25 - train: epoch 015, train_loss: 1.1838
2023-05-31 00:56:26 - eval: epoch: 015, acc1: 57.340%, acc5: 85.370%, test_loss: 1.5745, per_image_load_time: 0.067ms, per_image_inference_time: 0.045ms
2023-05-31 00:56:26 - until epoch: 015, best_acc1: 57.450%
2023-05-31 00:56:26 - epoch 016 lr: 0.100000
2023-05-31 00:56:28 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 1.1887
2023-05-31 00:56:29 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 1.2171
2023-05-31 00:56:31 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 1.1760
2023-05-31 00:56:32 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 1.2891
2023-05-31 00:56:33 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 1.0908
2023-05-31 00:56:35 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 1.2181
2023-05-31 00:56:36 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 1.1210
2023-05-31 00:56:37 - train: epoch 016, train_loss: 1.1580
2023-05-31 00:56:38 - eval: epoch: 016, acc1: 59.520%, acc5: 87.190%, test_loss: 1.4734, per_image_load_time: 0.066ms, per_image_inference_time: 0.044ms
2023-05-31 00:56:39 - until epoch: 016, best_acc1: 59.520%
2023-05-31 00:56:39 - epoch 017 lr: 0.100000
2023-05-31 00:56:41 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 0.9541
2023-05-31 00:56:42 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 1.1775
2023-05-31 00:56:43 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 0.8403
2023-05-31 00:56:44 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 0.9776
2023-05-31 00:56:46 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 1.1355
2023-05-31 00:56:47 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 1.4043
2023-05-31 00:56:48 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 0.8421
2023-05-31 00:56:49 - train: epoch 017, train_loss: 1.1370
2023-05-31 00:56:51 - eval: epoch: 017, acc1: 59.340%, acc5: 86.740%, test_loss: 1.4704, per_image_load_time: 0.069ms, per_image_inference_time: 0.047ms
2023-05-31 00:56:51 - until epoch: 017, best_acc1: 59.520%
2023-05-31 00:56:51 - epoch 018 lr: 0.100000
2023-05-31 00:56:53 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 1.0424
2023-05-31 00:56:54 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 0.8622
2023-05-31 00:56:56 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.3831
2023-05-31 00:56:57 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 1.1281
2023-05-31 00:56:58 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 1.1348
2023-05-31 00:56:59 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 0.9617
2023-05-31 00:57:01 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 1.2581
2023-05-31 00:57:02 - train: epoch 018, train_loss: 1.1047
2023-05-31 00:57:03 - eval: epoch: 018, acc1: 61.170%, acc5: 87.140%, test_loss: 1.4378, per_image_load_time: 0.067ms, per_image_inference_time: 0.047ms
2023-05-31 00:57:03 - until epoch: 018, best_acc1: 61.170%
2023-05-31 00:57:03 - epoch 019 lr: 0.100000
2023-05-31 00:57:06 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 0.9552
2023-05-31 00:57:07 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 1.1369
2023-05-31 00:57:08 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 1.3264
2023-05-31 00:57:09 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 1.2267
2023-05-31 00:57:11 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 1.1020
2023-05-31 00:57:12 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 1.2336
2023-05-31 00:57:13 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 0.9793
2023-05-31 00:57:14 - train: epoch 019, train_loss: 1.0832
2023-05-31 00:57:16 - eval: epoch: 019, acc1: 58.360%, acc5: 86.920%, test_loss: 1.4908, per_image_load_time: 0.069ms, per_image_inference_time: 0.050ms
2023-05-31 00:57:16 - until epoch: 019, best_acc1: 61.170%
2023-05-31 00:57:16 - epoch 020 lr: 0.100000
2023-05-31 00:57:18 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 1.0992
2023-05-31 00:57:19 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 1.0073
2023-05-31 00:57:21 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 1.1740
2023-05-31 00:57:22 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 1.1011
2023-05-31 00:57:23 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 1.0075
2023-05-31 00:57:24 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 1.0227
2023-05-31 00:57:26 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 1.1056
2023-05-31 00:57:27 - train: epoch 020, train_loss: 1.0742
2023-05-31 00:57:28 - eval: epoch: 020, acc1: 57.810%, acc5: 85.940%, test_loss: 1.5531, per_image_load_time: 0.069ms, per_image_inference_time: 0.044ms
2023-05-31 00:57:28 - until epoch: 020, best_acc1: 61.170%
2023-05-31 00:57:28 - epoch 021 lr: 0.100000
2023-05-31 00:57:30 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 0.8695
2023-05-31 00:57:32 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.1119
2023-05-31 00:57:33 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 1.2981
2023-05-31 00:57:34 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.2024
2023-05-31 00:57:36 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 1.1186
2023-05-31 00:57:37 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 1.1471
2023-05-31 00:57:38 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 1.0923
2023-05-31 00:57:39 - train: epoch 021, train_loss: 1.0604
2023-05-31 00:57:41 - eval: epoch: 021, acc1: 59.550%, acc5: 86.790%, test_loss: 1.4941, per_image_load_time: 0.066ms, per_image_inference_time: 0.045ms
2023-05-31 00:57:41 - until epoch: 021, best_acc1: 61.170%
2023-05-31 00:57:41 - epoch 022 lr: 0.100000
2023-05-31 00:57:43 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 0.9730
2023-05-31 00:57:44 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 1.0381
2023-05-31 00:57:45 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 0.9741
2023-05-31 00:57:47 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 1.3571
2023-05-31 00:57:48 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 1.1250
2023-05-31 00:57:49 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 1.1783
2023-05-31 00:57:50 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.0745
2023-05-31 00:57:52 - train: epoch 022, train_loss: 1.0440
2023-05-31 00:57:53 - eval: epoch: 022, acc1: 60.580%, acc5: 87.010%, test_loss: 1.4546, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 00:57:53 - until epoch: 022, best_acc1: 61.170%
2023-05-31 00:57:53 - epoch 023 lr: 0.100000
2023-05-31 00:57:55 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 0.7703
2023-05-31 00:57:57 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 1.0529
2023-05-31 00:57:58 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 1.0683
2023-05-31 00:57:59 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.2901
2023-05-31 00:58:00 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 1.1760
2023-05-31 00:58:02 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 1.0963
2023-05-31 00:58:03 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 0.9002
2023-05-31 00:58:04 - train: epoch 023, train_loss: 1.0282
2023-05-31 00:58:05 - eval: epoch: 023, acc1: 61.360%, acc5: 87.160%, test_loss: 1.4489, per_image_load_time: 0.068ms, per_image_inference_time: 0.043ms
2023-05-31 00:58:06 - until epoch: 023, best_acc1: 61.360%
2023-05-31 00:58:06 - epoch 024 lr: 0.100000
2023-05-31 00:58:08 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 0.8181
2023-05-31 00:58:09 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 0.9078
2023-05-31 00:58:10 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 0.9969
2023-05-31 00:58:12 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 1.2445
2023-05-31 00:58:13 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 1.1074
2023-05-31 00:58:14 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.0228
2023-05-31 00:58:16 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 1.0548
2023-05-31 00:58:17 - train: epoch 024, train_loss: 1.0144
2023-05-31 00:58:18 - eval: epoch: 024, acc1: 59.320%, acc5: 86.510%, test_loss: 1.5328, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 00:58:18 - until epoch: 024, best_acc1: 61.360%
2023-05-31 00:58:18 - epoch 025 lr: 0.100000
2023-05-31 00:58:20 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 0.8259
2023-05-31 00:58:22 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 0.9394
2023-05-31 00:58:23 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.1868
2023-05-31 00:58:24 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 1.0259
2023-05-31 00:58:25 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 0.9795
2023-05-31 00:58:27 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 1.1124
2023-05-31 00:58:28 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 1.0799
2023-05-31 00:58:29 - train: epoch 025, train_loss: 0.9940
2023-05-31 00:58:30 - eval: epoch: 025, acc1: 57.560%, acc5: 86.130%, test_loss: 1.6323, per_image_load_time: 0.070ms, per_image_inference_time: 0.046ms
2023-05-31 00:58:31 - until epoch: 025, best_acc1: 61.360%
2023-05-31 00:58:31 - epoch 026 lr: 0.100000
2023-05-31 00:58:33 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 0.7979
2023-05-31 00:58:34 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 0.6827
2023-05-31 00:58:35 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 0.9752
2023-05-31 00:58:37 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 1.0724
2023-05-31 00:58:38 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 0.7309
2023-05-31 00:58:39 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.0903
2023-05-31 00:58:40 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.1801
2023-05-31 00:58:42 - train: epoch 026, train_loss: 0.9885
2023-05-31 00:58:43 - eval: epoch: 026, acc1: 60.120%, acc5: 87.280%, test_loss: 1.4922, per_image_load_time: 0.069ms, per_image_inference_time: 0.046ms
2023-05-31 00:58:43 - until epoch: 026, best_acc1: 61.360%
2023-05-31 00:58:43 - epoch 027 lr: 0.100000
2023-05-31 00:58:45 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 0.9678
2023-05-31 00:58:46 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 1.0704
2023-05-31 00:58:48 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 0.6927
2023-05-31 00:58:49 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 1.0216
2023-05-31 00:58:50 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 1.1781
2023-05-31 00:58:52 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 1.0119
2023-05-31 00:58:53 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 1.2337
2023-05-31 00:58:54 - train: epoch 027, train_loss: 0.9680
2023-05-31 00:58:55 - eval: epoch: 027, acc1: 61.290%, acc5: 88.070%, test_loss: 1.4003, per_image_load_time: 0.070ms, per_image_inference_time: 0.046ms
2023-05-31 00:58:56 - until epoch: 027, best_acc1: 61.360%
2023-05-31 00:58:56 - epoch 028 lr: 0.100000
2023-05-31 00:58:58 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 1.0513
2023-05-31 00:58:59 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 0.8947
2023-05-31 00:59:00 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 0.9432
2023-05-31 00:59:02 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 1.0436
2023-05-31 00:59:03 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 1.1181
2023-05-31 00:59:04 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 0.9197
2023-05-31 00:59:05 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 1.1011
2023-05-31 00:59:07 - train: epoch 028, train_loss: 0.9757
2023-05-31 00:59:08 - eval: epoch: 028, acc1: 61.170%, acc5: 87.830%, test_loss: 1.4418, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 00:59:08 - until epoch: 028, best_acc1: 61.360%
2023-05-31 00:59:08 - epoch 029 lr: 0.100000
2023-05-31 00:59:10 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 0.9043
2023-05-31 00:59:11 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 1.0379
2023-05-31 00:59:13 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 0.9639
2023-05-31 00:59:14 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 1.0355
2023-05-31 00:59:15 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 0.9660
2023-05-31 00:59:17 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 1.1021
2023-05-31 00:59:18 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 0.7923
2023-05-31 00:59:19 - train: epoch 029, train_loss: 0.9633
2023-05-31 00:59:20 - eval: epoch: 029, acc1: 59.490%, acc5: 86.810%, test_loss: 1.4986, per_image_load_time: 0.066ms, per_image_inference_time: 0.046ms
2023-05-31 00:59:20 - until epoch: 029, best_acc1: 61.360%
2023-05-31 00:59:20 - epoch 030 lr: 0.100000
2023-05-31 00:59:23 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 0.9491
2023-05-31 00:59:24 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 0.7309
2023-05-31 00:59:25 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 0.9745
2023-05-31 00:59:26 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 0.8053
2023-05-31 00:59:28 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 1.0444
2023-05-31 00:59:29 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 0.8979
2023-05-31 00:59:30 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 1.0897
2023-05-31 00:59:31 - train: epoch 030, train_loss: 0.9489
2023-05-31 00:59:33 - eval: epoch: 030, acc1: 61.140%, acc5: 88.220%, test_loss: 1.4326, per_image_load_time: 0.066ms, per_image_inference_time: 0.047ms
2023-05-31 00:59:33 - until epoch: 030, best_acc1: 61.360%
2023-05-31 00:59:33 - epoch 031 lr: 0.100000
2023-05-31 00:59:35 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 0.9529
2023-05-31 00:59:36 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 0.9345
2023-05-31 00:59:37 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 1.0891
2023-05-31 00:59:39 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 1.0062
2023-05-31 00:59:40 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 0.9556
2023-05-31 00:59:41 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 1.1096
2023-05-31 00:59:43 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 1.0693
2023-05-31 00:59:44 - train: epoch 031, train_loss: 0.9560
2023-05-31 00:59:45 - eval: epoch: 031, acc1: 62.190%, acc5: 88.160%, test_loss: 1.4224, per_image_load_time: 0.071ms, per_image_inference_time: 0.046ms
2023-05-31 00:59:45 - until epoch: 031, best_acc1: 62.190%
2023-05-31 00:59:45 - epoch 032 lr: 0.100000
2023-05-31 00:59:47 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 0.9391
2023-05-31 00:59:49 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 0.9191
2023-05-31 00:59:50 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 0.9290
2023-05-31 00:59:51 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 0.7808
2023-05-31 00:59:53 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 1.0457
2023-05-31 00:59:54 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 0.9138
2023-05-31 00:59:55 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 0.8435
2023-05-31 00:59:56 - train: epoch 032, train_loss: 0.9449
2023-05-31 00:59:58 - eval: epoch: 032, acc1: 60.000%, acc5: 86.890%, test_loss: 1.5037, per_image_load_time: 0.066ms, per_image_inference_time: 0.043ms
2023-05-31 00:59:58 - until epoch: 032, best_acc1: 62.190%
2023-05-31 00:59:58 - epoch 033 lr: 0.100000
2023-05-31 01:00:00 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 0.8246
2023-05-31 01:00:01 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 0.8623
2023-05-31 01:00:03 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 0.9274
2023-05-31 01:00:04 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 0.9558
2023-05-31 01:00:05 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 0.9052
2023-05-31 01:00:07 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 1.0673
2023-05-31 01:00:08 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 0.9646
2023-05-31 01:00:09 - train: epoch 033, train_loss: 0.9316
2023-05-31 01:00:10 - eval: epoch: 033, acc1: 62.350%, acc5: 88.330%, test_loss: 1.3928, per_image_load_time: 0.068ms, per_image_inference_time: 0.046ms
2023-05-31 01:00:11 - until epoch: 033, best_acc1: 62.350%
2023-05-31 01:00:11 - epoch 034 lr: 0.100000
2023-05-31 01:00:13 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 0.9583
2023-05-31 01:00:14 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 1.0192
2023-05-31 01:00:16 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 0.9907
2023-05-31 01:00:17 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 0.7925
2023-05-31 01:00:18 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 0.9192
2023-05-31 01:00:20 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 1.0010
2023-05-31 01:00:21 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 1.0701
2023-05-31 01:00:22 - train: epoch 034, train_loss: 0.9276
2023-05-31 01:00:23 - eval: epoch: 034, acc1: 61.070%, acc5: 87.830%, test_loss: 1.4658, per_image_load_time: 0.071ms, per_image_inference_time: 0.046ms
2023-05-31 01:00:24 - until epoch: 034, best_acc1: 62.350%
2023-05-31 01:00:24 - epoch 035 lr: 0.100000
2023-05-31 01:00:26 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 0.5497
2023-05-31 01:00:27 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 0.9395
2023-05-31 01:00:28 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 0.8364
2023-05-31 01:00:30 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 0.7667
2023-05-31 01:00:31 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 0.9635
2023-05-31 01:00:32 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 0.9587
2023-05-31 01:00:34 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 1.0499
2023-05-31 01:00:35 - train: epoch 035, train_loss: 0.9197
2023-05-31 01:00:36 - eval: epoch: 035, acc1: 61.680%, acc5: 87.600%, test_loss: 1.4450, per_image_load_time: 0.068ms, per_image_inference_time: 0.047ms
2023-05-31 01:00:36 - until epoch: 035, best_acc1: 62.350%
2023-05-31 01:00:36 - epoch 036 lr: 0.100000
2023-05-31 01:00:38 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 0.8933
2023-05-31 01:00:40 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 0.8288
2023-05-31 01:00:41 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 0.8328
2023-05-31 01:00:42 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 0.7876
2023-05-31 01:00:44 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 0.8417
2023-05-31 01:00:45 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 0.8617
2023-05-31 01:00:46 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 1.0550
2023-05-31 01:00:47 - train: epoch 036, train_loss: 0.9126
2023-05-31 01:00:48 - eval: epoch: 036, acc1: 61.330%, acc5: 88.140%, test_loss: 1.4441, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:00:49 - until epoch: 036, best_acc1: 62.350%
2023-05-31 01:00:49 - epoch 037 lr: 0.100000
2023-05-31 01:00:51 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 0.7523
2023-05-31 01:00:52 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 0.8929
2023-05-31 01:00:54 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 0.6966
2023-05-31 01:00:55 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 1.1470
2023-05-31 01:00:56 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 0.9589
2023-05-31 01:00:57 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 1.3270
2023-05-31 01:00:59 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 0.9652
2023-05-31 01:01:00 - train: epoch 037, train_loss: 0.9166
2023-05-31 01:01:01 - eval: epoch: 037, acc1: 61.430%, acc5: 88.170%, test_loss: 1.4638, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:01:01 - until epoch: 037, best_acc1: 62.350%
2023-05-31 01:01:01 - epoch 038 lr: 0.100000
2023-05-31 01:01:04 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 0.7500
2023-05-31 01:01:05 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 0.7094
2023-05-31 01:01:06 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 1.0543
2023-05-31 01:01:07 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 0.8087
2023-05-31 01:01:09 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 0.9032
2023-05-31 01:01:10 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 1.1528
2023-05-31 01:01:11 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 1.1864
2023-05-31 01:01:12 - train: epoch 038, train_loss: 0.9044
2023-05-31 01:01:14 - eval: epoch: 038, acc1: 62.610%, acc5: 89.070%, test_loss: 1.3595, per_image_load_time: 0.070ms, per_image_inference_time: 0.048ms
2023-05-31 01:01:14 - until epoch: 038, best_acc1: 62.610%
2023-05-31 01:01:14 - epoch 039 lr: 0.100000
2023-05-31 01:01:16 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 0.8092
2023-05-31 01:01:17 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 1.0355
2023-05-31 01:01:19 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 0.8459
2023-05-31 01:01:20 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 0.8685
2023-05-31 01:01:21 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 0.7448
2023-05-31 01:01:23 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 1.0373
2023-05-31 01:01:24 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 0.9447
2023-05-31 01:01:25 - train: epoch 039, train_loss: 0.9031
2023-05-31 01:01:26 - eval: epoch: 039, acc1: 62.850%, acc5: 88.400%, test_loss: 1.3772, per_image_load_time: 0.073ms, per_image_inference_time: 0.044ms
2023-05-31 01:01:27 - until epoch: 039, best_acc1: 62.850%
2023-05-31 01:01:27 - epoch 040 lr: 0.100000
2023-05-31 01:01:29 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 0.8636
2023-05-31 01:01:30 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 0.5537
2023-05-31 01:01:31 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 0.9008
2023-05-31 01:01:33 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 0.9723
2023-05-31 01:01:34 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 1.1279
2023-05-31 01:01:35 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 0.7647
2023-05-31 01:01:37 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 1.0344
2023-05-31 01:01:38 - train: epoch 040, train_loss: 0.8986
2023-05-31 01:01:39 - eval: epoch: 040, acc1: 62.140%, acc5: 87.530%, test_loss: 1.4375, per_image_load_time: 0.066ms, per_image_inference_time: 0.047ms
2023-05-31 01:01:39 - until epoch: 040, best_acc1: 62.850%
2023-05-31 01:01:39 - epoch 041 lr: 0.100000
2023-05-31 01:01:41 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 0.7287
2023-05-31 01:01:42 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 0.7434
2023-05-31 01:01:44 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 0.9756
2023-05-31 01:01:45 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 0.8449
2023-05-31 01:01:46 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 1.0831
2023-05-31 01:01:47 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 1.0795
2023-05-31 01:01:49 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 0.8937
2023-05-31 01:01:50 - train: epoch 041, train_loss: 0.8880
2023-05-31 01:01:51 - eval: epoch: 041, acc1: 62.550%, acc5: 87.930%, test_loss: 1.4300, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 01:01:51 - until epoch: 041, best_acc1: 62.850%
2023-05-31 01:01:51 - epoch 042 lr: 0.100000
2023-05-31 01:01:53 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 0.6077
2023-05-31 01:01:55 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 0.8341
2023-05-31 01:01:56 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 0.8061
2023-05-31 01:01:57 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 0.7884
2023-05-31 01:01:59 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 1.1216
2023-05-31 01:02:00 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 0.8273
2023-05-31 01:02:01 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 0.8730
2023-05-31 01:02:02 - train: epoch 042, train_loss: 0.8836
2023-05-31 01:02:04 - eval: epoch: 042, acc1: 61.980%, acc5: 88.170%, test_loss: 1.4328, per_image_load_time: 0.064ms, per_image_inference_time: 0.042ms
2023-05-31 01:02:04 - until epoch: 042, best_acc1: 62.850%
2023-05-31 01:02:04 - epoch 043 lr: 0.100000
2023-05-31 01:02:06 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 0.7506
2023-05-31 01:02:07 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 0.9111
2023-05-31 01:02:09 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 0.9420
2023-05-31 01:02:10 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 0.9879
2023-05-31 01:02:11 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 0.9103
2023-05-31 01:02:12 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 0.9639
2023-05-31 01:02:14 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 0.8738
2023-05-31 01:02:15 - train: epoch 043, train_loss: 0.8821
2023-05-31 01:02:16 - eval: epoch: 043, acc1: 60.060%, acc5: 87.610%, test_loss: 1.5247, per_image_load_time: 0.071ms, per_image_inference_time: 0.047ms
2023-05-31 01:02:16 - until epoch: 043, best_acc1: 62.850%
2023-05-31 01:02:16 - epoch 044 lr: 0.100000
2023-05-31 01:02:19 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 0.8511
2023-05-31 01:02:20 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 1.0719
2023-05-31 01:02:21 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 0.8588
2023-05-31 01:02:22 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 0.8607
2023-05-31 01:02:24 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 1.1378
2023-05-31 01:02:25 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 0.7740
2023-05-31 01:02:26 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 0.7655
2023-05-31 01:02:27 - train: epoch 044, train_loss: 0.8828
2023-05-31 01:02:29 - eval: epoch: 044, acc1: 63.390%, acc5: 88.780%, test_loss: 1.4139, per_image_load_time: 0.065ms, per_image_inference_time: 0.045ms
2023-05-31 01:02:29 - until epoch: 044, best_acc1: 63.390%
2023-05-31 01:02:29 - epoch 045 lr: 0.100000
2023-05-31 01:02:31 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 0.7627
2023-05-31 01:02:32 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 0.7331
2023-05-31 01:02:34 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 0.7626
2023-05-31 01:02:35 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 0.7958
2023-05-31 01:02:36 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 0.7625
2023-05-31 01:02:38 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 0.8496
2023-05-31 01:02:39 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 1.1544
2023-05-31 01:02:40 - train: epoch 045, train_loss: 0.8806
2023-05-31 01:02:41 - eval: epoch: 045, acc1: 60.360%, acc5: 86.930%, test_loss: 1.5260, per_image_load_time: 0.071ms, per_image_inference_time: 0.044ms
2023-05-31 01:02:41 - until epoch: 045, best_acc1: 63.390%
2023-05-31 01:02:41 - epoch 046 lr: 0.100000
2023-05-31 01:02:44 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 0.7038
2023-05-31 01:02:45 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 0.7243
2023-05-31 01:02:46 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 0.7117
2023-05-31 01:02:48 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 0.9368
2023-05-31 01:02:49 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 0.8540
2023-05-31 01:02:50 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 0.7387
2023-05-31 01:02:52 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 0.8647
2023-05-31 01:02:53 - train: epoch 046, train_loss: 0.8732
2023-05-31 01:02:54 - eval: epoch: 046, acc1: 60.450%, acc5: 86.700%, test_loss: 1.5150, per_image_load_time: 0.075ms, per_image_inference_time: 0.048ms
2023-05-31 01:02:54 - until epoch: 046, best_acc1: 63.390%
2023-05-31 01:02:54 - epoch 047 lr: 0.100000
2023-05-31 01:02:57 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 0.8291
2023-05-31 01:02:58 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 0.6070
2023-05-31 01:02:59 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 0.7880
2023-05-31 01:03:01 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 0.8488
2023-05-31 01:03:02 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 0.8109
2023-05-31 01:03:03 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 0.7959
2023-05-31 01:03:04 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 0.9614
2023-05-31 01:03:06 - train: epoch 047, train_loss: 0.8725
2023-05-31 01:03:07 - eval: epoch: 047, acc1: 62.090%, acc5: 88.090%, test_loss: 1.4276, per_image_load_time: 0.070ms, per_image_inference_time: 0.048ms
2023-05-31 01:03:07 - until epoch: 047, best_acc1: 63.390%
2023-05-31 01:03:07 - epoch 048 lr: 0.100000
2023-05-31 01:03:09 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 0.8321
2023-05-31 01:03:11 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 0.6024
2023-05-31 01:03:12 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 0.9234
2023-05-31 01:03:13 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 0.9820
2023-05-31 01:03:15 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 0.7866
2023-05-31 01:03:16 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 0.8707
2023-05-31 01:03:17 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 0.9105
2023-05-31 01:03:18 - train: epoch 048, train_loss: 0.8664
2023-05-31 01:03:20 - eval: epoch: 048, acc1: 62.830%, acc5: 88.190%, test_loss: 1.4427, per_image_load_time: 0.072ms, per_image_inference_time: 0.045ms
2023-05-31 01:03:20 - until epoch: 048, best_acc1: 63.390%
2023-05-31 01:03:20 - epoch 049 lr: 0.100000
2023-05-31 01:03:22 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 1.0212
2023-05-31 01:03:23 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 0.7977
2023-05-31 01:03:25 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 0.9477
2023-05-31 01:03:26 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 0.8246
2023-05-31 01:03:28 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 0.8701
2023-05-31 01:03:29 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 0.9554
2023-05-31 01:03:30 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 0.9267
2023-05-31 01:03:31 - train: epoch 049, train_loss: 0.8610
2023-05-31 01:03:33 - eval: epoch: 049, acc1: 62.530%, acc5: 88.370%, test_loss: 1.4540, per_image_load_time: 0.068ms, per_image_inference_time: 0.048ms
2023-05-31 01:03:33 - until epoch: 049, best_acc1: 63.390%
2023-05-31 01:03:33 - epoch 050 lr: 0.100000
2023-05-31 01:03:35 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 0.7643
2023-05-31 01:03:36 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 0.7364
2023-05-31 01:03:38 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 0.7423
2023-05-31 01:03:39 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 0.8611
2023-05-31 01:03:40 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 0.8145
2023-05-31 01:03:42 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 0.7984
2023-05-31 01:03:43 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 1.0216
2023-05-31 01:03:44 - train: epoch 050, train_loss: 0.8705
2023-05-31 01:03:46 - eval: epoch: 050, acc1: 61.390%, acc5: 87.100%, test_loss: 1.4886, per_image_load_time: 0.075ms, per_image_inference_time: 0.045ms
2023-05-31 01:03:46 - until epoch: 050, best_acc1: 63.390%
2023-05-31 01:03:46 - epoch 051 lr: 0.100000
2023-05-31 01:03:48 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 0.7820
2023-05-31 01:03:49 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 0.7919
2023-05-31 01:03:51 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 0.8024
2023-05-31 01:03:52 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 0.9196
2023-05-31 01:03:53 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 0.9822
2023-05-31 01:03:55 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 0.7447
2023-05-31 01:03:56 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 0.7238
2023-05-31 01:03:57 - train: epoch 051, train_loss: 0.8675
2023-05-31 01:03:58 - eval: epoch: 051, acc1: 63.380%, acc5: 88.620%, test_loss: 1.3824, per_image_load_time: 0.067ms, per_image_inference_time: 0.048ms
2023-05-31 01:03:59 - until epoch: 051, best_acc1: 63.390%
2023-05-31 01:03:59 - epoch 052 lr: 0.100000
2023-05-31 01:04:01 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 0.8834
2023-05-31 01:04:02 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 0.7872
2023-05-31 01:04:03 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 0.7692
2023-05-31 01:04:04 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 0.7423
2023-05-31 01:04:06 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 0.7678
2023-05-31 01:04:07 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 0.8729
2023-05-31 01:04:08 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 0.9272
2023-05-31 01:04:09 - train: epoch 052, train_loss: 0.8582
2023-05-31 01:04:11 - eval: epoch: 052, acc1: 63.320%, acc5: 88.710%, test_loss: 1.4002, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:04:11 - until epoch: 052, best_acc1: 63.390%
2023-05-31 01:04:11 - epoch 053 lr: 0.100000
2023-05-31 01:04:13 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 0.7009
2023-05-31 01:04:14 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 0.7216
2023-05-31 01:04:16 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 0.7575
2023-05-31 01:04:17 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 0.7974
2023-05-31 01:04:18 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 0.9078
2023-05-31 01:04:19 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 0.6266
2023-05-31 01:04:21 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 0.8648
2023-05-31 01:04:22 - train: epoch 053, train_loss: 0.8517
2023-05-31 01:04:23 - eval: epoch: 053, acc1: 62.610%, acc5: 88.810%, test_loss: 1.4478, per_image_load_time: 0.072ms, per_image_inference_time: 0.046ms
2023-05-31 01:04:23 - until epoch: 053, best_acc1: 63.390%
2023-05-31 01:04:23 - epoch 054 lr: 0.100000
2023-05-31 01:04:25 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 0.5962
2023-05-31 01:04:27 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 0.8558
2023-05-31 01:04:28 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 0.6381
2023-05-31 01:04:29 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 0.9891
2023-05-31 01:04:31 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 0.8401
2023-05-31 01:04:32 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 0.9460
2023-05-31 01:04:33 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 0.8366
2023-05-31 01:04:34 - train: epoch 054, train_loss: 0.8469
2023-05-31 01:04:35 - eval: epoch: 054, acc1: 62.870%, acc5: 88.710%, test_loss: 1.4303, per_image_load_time: 0.068ms, per_image_inference_time: 0.046ms
2023-05-31 01:04:36 - until epoch: 054, best_acc1: 63.390%
2023-05-31 01:04:36 - epoch 055 lr: 0.100000
2023-05-31 01:04:38 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 0.9177
2023-05-31 01:04:39 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 0.9195
2023-05-31 01:04:41 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 0.7186
2023-05-31 01:04:42 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 0.8242
2023-05-31 01:04:43 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 0.9064
2023-05-31 01:04:44 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 0.7070
2023-05-31 01:04:46 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 0.6902
2023-05-31 01:04:47 - train: epoch 055, train_loss: 0.8589
2023-05-31 01:04:48 - eval: epoch: 055, acc1: 64.240%, acc5: 88.860%, test_loss: 1.3567, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:04:49 - until epoch: 055, best_acc1: 64.240%
2023-05-31 01:04:49 - epoch 056 lr: 0.100000
2023-05-31 01:04:51 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 0.8735
2023-05-31 01:04:52 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 0.7958
2023-05-31 01:04:53 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 0.8755
2023-05-31 01:04:55 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 1.0943
2023-05-31 01:04:56 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 0.7456
2023-05-31 01:04:57 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 1.1043
2023-05-31 01:04:59 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 0.8913
2023-05-31 01:05:00 - train: epoch 056, train_loss: 0.8448
2023-05-31 01:05:01 - eval: epoch: 056, acc1: 61.890%, acc5: 88.320%, test_loss: 1.4578, per_image_load_time: 0.069ms, per_image_inference_time: 0.046ms
2023-05-31 01:05:01 - until epoch: 056, best_acc1: 64.240%
2023-05-31 01:05:01 - epoch 057 lr: 0.100000
2023-05-31 01:05:03 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 0.7945
2023-05-31 01:05:05 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 0.7780
2023-05-31 01:05:06 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 0.7196
2023-05-31 01:05:07 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 0.9475
2023-05-31 01:05:09 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 0.6865
2023-05-31 01:05:10 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 0.8701
2023-05-31 01:05:11 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 0.8705
2023-05-31 01:05:12 - train: epoch 057, train_loss: 0.8448
2023-05-31 01:05:14 - eval: epoch: 057, acc1: 58.580%, acc5: 85.250%, test_loss: 1.6398, per_image_load_time: 0.069ms, per_image_inference_time: 0.046ms
2023-05-31 01:05:14 - until epoch: 057, best_acc1: 64.240%
2023-05-31 01:05:14 - epoch 058 lr: 0.100000
2023-05-31 01:05:16 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 0.7953
2023-05-31 01:05:17 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 0.7324
2023-05-31 01:05:18 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 0.7083
2023-05-31 01:05:20 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 1.0099
2023-05-31 01:05:21 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 0.9824
2023-05-31 01:05:22 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 1.0457
2023-05-31 01:05:24 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 0.9407
2023-05-31 01:05:25 - train: epoch 058, train_loss: 0.8485
2023-05-31 01:05:26 - eval: epoch: 058, acc1: 63.600%, acc5: 87.970%, test_loss: 1.3896, per_image_load_time: 0.067ms, per_image_inference_time: 0.052ms
2023-05-31 01:05:26 - until epoch: 058, best_acc1: 64.240%
2023-05-31 01:05:26 - epoch 059 lr: 0.100000
2023-05-31 01:05:29 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 0.7842
2023-05-31 01:05:30 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 0.7457
2023-05-31 01:05:31 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 0.7144
2023-05-31 01:05:32 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 1.0948
2023-05-31 01:05:34 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 1.1193
2023-05-31 01:05:35 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 0.7882
2023-05-31 01:05:36 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 1.1120
2023-05-31 01:05:37 - train: epoch 059, train_loss: 0.8332
2023-05-31 01:05:39 - eval: epoch: 059, acc1: 60.670%, acc5: 86.690%, test_loss: 1.4831, per_image_load_time: 0.066ms, per_image_inference_time: 0.045ms
2023-05-31 01:05:39 - until epoch: 059, best_acc1: 64.240%
2023-05-31 01:05:39 - epoch 060 lr: 0.100000
2023-05-31 01:05:41 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 0.6995
2023-05-31 01:05:42 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 1.0227
2023-05-31 01:05:44 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 0.7184
2023-05-31 01:05:45 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 0.6499
2023-05-31 01:05:46 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 0.9645
2023-05-31 01:05:48 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 0.7652
2023-05-31 01:05:49 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 0.9206
2023-05-31 01:05:50 - train: epoch 060, train_loss: 0.8372
2023-05-31 01:05:51 - eval: epoch: 060, acc1: 61.550%, acc5: 87.610%, test_loss: 1.4691, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 01:05:51 - until epoch: 060, best_acc1: 64.240%
2023-05-31 01:05:51 - epoch 061 lr: 0.020000
2023-05-31 01:05:53 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 0.4090
2023-05-31 01:05:55 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 0.4339
2023-05-31 01:05:56 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 0.3566
2023-05-31 01:05:57 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 0.4765
2023-05-31 01:05:59 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 0.3232
2023-05-31 01:06:00 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 0.2811
2023-05-31 01:06:01 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 0.3837
2023-05-31 01:06:02 - train: epoch 061, train_loss: 0.4239
2023-05-31 01:06:03 - eval: epoch: 061, acc1: 73.960%, acc5: 93.510%, test_loss: 0.9430, per_image_load_time: 0.069ms, per_image_inference_time: 0.050ms
2023-05-31 01:06:04 - until epoch: 061, best_acc1: 73.960%
2023-05-31 01:06:04 - epoch 062 lr: 0.020000
2023-05-31 01:06:06 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 0.2370
2023-05-31 01:06:07 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 0.2943
2023-05-31 01:06:09 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 0.2970
2023-05-31 01:06:10 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 0.2373
2023-05-31 01:06:11 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 0.2578
2023-05-31 01:06:13 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 0.1525
2023-05-31 01:06:14 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 0.2278
2023-05-31 01:06:15 - train: epoch 062, train_loss: 0.2740
2023-05-31 01:06:16 - eval: epoch: 062, acc1: 74.930%, acc5: 93.750%, test_loss: 0.9480, per_image_load_time: 0.065ms, per_image_inference_time: 0.046ms
2023-05-31 01:06:17 - until epoch: 062, best_acc1: 74.930%
2023-05-31 01:06:17 - epoch 063 lr: 0.020000
2023-05-31 01:06:19 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 0.2291
2023-05-31 01:06:20 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 0.1894
2023-05-31 01:06:21 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 0.1229
2023-05-31 01:06:23 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 0.2228
2023-05-31 01:06:24 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 0.3074
2023-05-31 01:06:25 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 0.1942
2023-05-31 01:06:26 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 0.2158
2023-05-31 01:06:27 - train: epoch 063, train_loss: 0.2117
2023-05-31 01:06:29 - eval: epoch: 063, acc1: 74.900%, acc5: 93.510%, test_loss: 0.9585, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:06:29 - until epoch: 063, best_acc1: 74.930%
2023-05-31 01:06:29 - epoch 064 lr: 0.020000
2023-05-31 01:06:31 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 0.1306
2023-05-31 01:06:32 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 0.2266
2023-05-31 01:06:34 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 0.1793
2023-05-31 01:06:35 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 0.2174
2023-05-31 01:06:36 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 0.1804
2023-05-31 01:06:38 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 0.2180
2023-05-31 01:06:39 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 0.2035
2023-05-31 01:06:40 - train: epoch 064, train_loss: 0.1751
2023-05-31 01:06:41 - eval: epoch: 064, acc1: 74.870%, acc5: 93.760%, test_loss: 0.9812, per_image_load_time: 0.070ms, per_image_inference_time: 0.050ms
2023-05-31 01:06:42 - until epoch: 064, best_acc1: 74.930%
2023-05-31 01:06:42 - epoch 065 lr: 0.020000
2023-05-31 01:06:44 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 0.0869
2023-05-31 01:06:45 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 0.2174
2023-05-31 01:06:46 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 0.1576
2023-05-31 01:06:48 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 0.1874
2023-05-31 01:06:49 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 0.1706
2023-05-31 01:06:50 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 0.1352
2023-05-31 01:06:52 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 0.1957
2023-05-31 01:06:53 - train: epoch 065, train_loss: 0.1481
2023-05-31 01:06:54 - eval: epoch: 065, acc1: 75.010%, acc5: 93.450%, test_loss: 1.0012, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 01:06:54 - until epoch: 065, best_acc1: 75.010%
2023-05-31 01:06:54 - epoch 066 lr: 0.020000
2023-05-31 01:06:56 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 0.0985
2023-05-31 01:06:58 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 0.0701
2023-05-31 01:06:59 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 0.1147
2023-05-31 01:07:00 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 0.1285
2023-05-31 01:07:02 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 0.2168
2023-05-31 01:07:03 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 0.1109
2023-05-31 01:07:04 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 0.1269
2023-05-31 01:07:05 - train: epoch 066, train_loss: 0.1244
2023-05-31 01:07:07 - eval: epoch: 066, acc1: 74.970%, acc5: 93.580%, test_loss: 1.0156, per_image_load_time: 0.069ms, per_image_inference_time: 0.043ms
2023-05-31 01:07:07 - until epoch: 066, best_acc1: 75.010%
2023-05-31 01:07:07 - epoch 067 lr: 0.020000
2023-05-31 01:07:09 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 0.1442
2023-05-31 01:07:10 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 0.0669
2023-05-31 01:07:12 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 0.1030
2023-05-31 01:07:13 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 0.0910
2023-05-31 01:07:14 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 0.1074
2023-05-31 01:07:15 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 0.1189
2023-05-31 01:07:17 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 0.1023
2023-05-31 01:07:18 - train: epoch 067, train_loss: 0.1158
2023-05-31 01:07:19 - eval: epoch: 067, acc1: 74.160%, acc5: 93.250%, test_loss: 1.0501, per_image_load_time: 0.069ms, per_image_inference_time: 0.044ms
2023-05-31 01:07:19 - until epoch: 067, best_acc1: 75.010%
2023-05-31 01:07:19 - epoch 068 lr: 0.020000
2023-05-31 01:07:21 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 0.1072
2023-05-31 01:07:23 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 0.0716
2023-05-31 01:07:24 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 0.0836
2023-05-31 01:07:25 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 0.1360
2023-05-31 01:07:26 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 0.0717
2023-05-31 01:07:28 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 0.1326
2023-05-31 01:07:29 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 0.1123
2023-05-31 01:07:30 - train: epoch 068, train_loss: 0.1024
2023-05-31 01:07:31 - eval: epoch: 068, acc1: 74.330%, acc5: 93.380%, test_loss: 1.0515, per_image_load_time: 0.065ms, per_image_inference_time: 0.044ms
2023-05-31 01:07:31 - until epoch: 068, best_acc1: 75.010%
2023-05-31 01:07:31 - epoch 069 lr: 0.020000
2023-05-31 01:07:34 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 0.0765
2023-05-31 01:07:35 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 0.0738
2023-05-31 01:07:36 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 0.1220
2023-05-31 01:07:37 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 0.0660
2023-05-31 01:07:39 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 0.1597
2023-05-31 01:07:40 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 0.0707
2023-05-31 01:07:41 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 0.1036
2023-05-31 01:07:42 - train: epoch 069, train_loss: 0.0951
2023-05-31 01:07:44 - eval: epoch: 069, acc1: 73.970%, acc5: 92.890%, test_loss: 1.0973, per_image_load_time: 0.078ms, per_image_inference_time: 0.043ms
2023-05-31 01:07:44 - until epoch: 069, best_acc1: 75.010%
2023-05-31 01:07:44 - epoch 070 lr: 0.020000
2023-05-31 01:07:46 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 0.0566
2023-05-31 01:07:47 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 0.0603
2023-05-31 01:07:49 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 0.0940
2023-05-31 01:07:50 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 0.0860
2023-05-31 01:07:51 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 0.0865
2023-05-31 01:07:53 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 0.0772
2023-05-31 01:07:54 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 0.0972
2023-05-31 01:07:55 - train: epoch 070, train_loss: 0.0915
2023-05-31 01:07:56 - eval: epoch: 070, acc1: 74.540%, acc5: 93.070%, test_loss: 1.0795, per_image_load_time: 0.072ms, per_image_inference_time: 0.045ms
2023-05-31 01:07:57 - until epoch: 070, best_acc1: 75.010%
2023-05-31 01:07:57 - epoch 071 lr: 0.020000
2023-05-31 01:07:59 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 0.1335
2023-05-31 01:08:00 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 0.0799
2023-05-31 01:08:01 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 0.0414
2023-05-31 01:08:02 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 0.1013
2023-05-31 01:08:04 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 0.1119
2023-05-31 01:08:05 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 0.1172
2023-05-31 01:08:06 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 0.0961
2023-05-31 01:08:07 - train: epoch 071, train_loss: 0.0973
2023-05-31 01:08:09 - eval: epoch: 071, acc1: 73.590%, acc5: 92.810%, test_loss: 1.1309, per_image_load_time: 0.078ms, per_image_inference_time: 0.044ms
2023-05-31 01:08:09 - until epoch: 071, best_acc1: 75.010%
2023-05-31 01:08:09 - epoch 072 lr: 0.020000
2023-05-31 01:08:11 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 0.0605
2023-05-31 01:08:12 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 0.1077
2023-05-31 01:08:14 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 0.0814
2023-05-31 01:08:15 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 0.1674
2023-05-31 01:08:16 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 0.0779
2023-05-31 01:08:18 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 0.0747
2023-05-31 01:08:19 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 0.0612
2023-05-31 01:08:20 - train: epoch 072, train_loss: 0.0994
2023-05-31 01:08:21 - eval: epoch: 072, acc1: 73.460%, acc5: 92.510%, test_loss: 1.1342, per_image_load_time: 0.065ms, per_image_inference_time: 0.046ms
2023-05-31 01:08:21 - until epoch: 072, best_acc1: 75.010%
2023-05-31 01:08:21 - epoch 073 lr: 0.020000
2023-05-31 01:08:23 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 0.0627
2023-05-31 01:08:25 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 0.0805
2023-05-31 01:08:26 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 0.0581
2023-05-31 01:08:27 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 0.2103
2023-05-31 01:08:29 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 0.1143
2023-05-31 01:08:30 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 0.1144
2023-05-31 01:08:31 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 0.1146
2023-05-31 01:08:32 - train: epoch 073, train_loss: 0.1094
2023-05-31 01:08:33 - eval: epoch: 073, acc1: 73.150%, acc5: 92.530%, test_loss: 1.1618, per_image_load_time: 0.064ms, per_image_inference_time: 0.046ms
2023-05-31 01:08:34 - until epoch: 073, best_acc1: 75.010%
2023-05-31 01:08:34 - epoch 074 lr: 0.020000
2023-05-31 01:08:36 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 0.2034
2023-05-31 01:08:38 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 0.0670
2023-05-31 01:08:39 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 0.1897
2023-05-31 01:08:40 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 0.0602
2023-05-31 01:08:41 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 0.0689
2023-05-31 01:08:43 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 0.1362
2023-05-31 01:08:44 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 0.1772
2023-05-31 01:08:45 - train: epoch 074, train_loss: 0.1192
2023-05-31 01:08:46 - eval: epoch: 074, acc1: 72.800%, acc5: 92.820%, test_loss: 1.1712, per_image_load_time: 0.070ms, per_image_inference_time: 0.043ms
2023-05-31 01:08:47 - until epoch: 074, best_acc1: 75.010%
2023-05-31 01:08:47 - epoch 075 lr: 0.020000
2023-05-31 01:08:49 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 0.1396
2023-05-31 01:08:50 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 0.0758
2023-05-31 01:08:51 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 0.1122
2023-05-31 01:08:53 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 0.1344
2023-05-31 01:08:54 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 0.1614
2023-05-31 01:08:55 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 0.1286
2023-05-31 01:08:56 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 0.1583
2023-05-31 01:08:57 - train: epoch 075, train_loss: 0.1260
2023-05-31 01:08:59 - eval: epoch: 075, acc1: 72.530%, acc5: 92.560%, test_loss: 1.1734, per_image_load_time: 0.064ms, per_image_inference_time: 0.043ms
2023-05-31 01:08:59 - until epoch: 075, best_acc1: 75.010%
2023-05-31 01:08:59 - epoch 076 lr: 0.020000
2023-05-31 01:09:01 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 0.1053
2023-05-31 01:09:02 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 0.1165
2023-05-31 01:09:04 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 0.1646
2023-05-31 01:09:05 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 0.0818
2023-05-31 01:09:06 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 0.1904
2023-05-31 01:09:07 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 0.1049
2023-05-31 01:09:09 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 0.1442
2023-05-31 01:09:10 - train: epoch 076, train_loss: 0.1392
2023-05-31 01:09:11 - eval: epoch: 076, acc1: 71.730%, acc5: 91.530%, test_loss: 1.2417, per_image_load_time: 0.075ms, per_image_inference_time: 0.045ms
2023-05-31 01:09:11 - until epoch: 076, best_acc1: 75.010%
2023-05-31 01:09:11 - epoch 077 lr: 0.020000
2023-05-31 01:09:13 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 0.1386
2023-05-31 01:09:15 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 0.1214
2023-05-31 01:09:16 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 0.1903
2023-05-31 01:09:17 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 0.1832
2023-05-31 01:09:19 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 0.2246
2023-05-31 01:09:20 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 0.2132
2023-05-31 01:09:21 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 0.1667
2023-05-31 01:09:22 - train: epoch 077, train_loss: 0.1488
2023-05-31 01:09:24 - eval: epoch: 077, acc1: 71.660%, acc5: 91.510%, test_loss: 1.2508, per_image_load_time: 0.062ms, per_image_inference_time: 0.044ms
2023-05-31 01:09:24 - until epoch: 077, best_acc1: 75.010%
2023-05-31 01:09:24 - epoch 078 lr: 0.020000
2023-05-31 01:09:26 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 0.1735
2023-05-31 01:09:27 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 0.0743
2023-05-31 01:09:28 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 0.1454
2023-05-31 01:09:30 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 0.0821
2023-05-31 01:09:31 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 0.1535
2023-05-31 01:09:32 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 0.1965
2023-05-31 01:09:33 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 0.1443
2023-05-31 01:09:35 - train: epoch 078, train_loss: 0.1690
2023-05-31 01:09:36 - eval: epoch: 078, acc1: 71.330%, acc5: 91.880%, test_loss: 1.2327, per_image_load_time: 0.070ms, per_image_inference_time: 0.046ms
2023-05-31 01:09:36 - until epoch: 078, best_acc1: 75.010%
2023-05-31 01:09:36 - epoch 079 lr: 0.020000
2023-05-31 01:09:38 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 0.1412
2023-05-31 01:09:40 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 0.1164
2023-05-31 01:09:41 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 0.1922
2023-05-31 01:09:42 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 0.1289
2023-05-31 01:09:43 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 0.1522
2023-05-31 01:09:45 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 0.2230
2023-05-31 01:09:46 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 0.2317
2023-05-31 01:09:47 - train: epoch 079, train_loss: 0.1722
2023-05-31 01:09:48 - eval: epoch: 079, acc1: 70.120%, acc5: 91.510%, test_loss: 1.2863, per_image_load_time: 0.064ms, per_image_inference_time: 0.044ms
2023-05-31 01:09:49 - until epoch: 079, best_acc1: 75.010%
2023-05-31 01:09:49 - epoch 080 lr: 0.020000
2023-05-31 01:09:51 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 0.1417
2023-05-31 01:09:52 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 0.1719
2023-05-31 01:09:53 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 0.1780
2023-05-31 01:09:55 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 0.2191
2023-05-31 01:09:56 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 0.2506
2023-05-31 01:09:57 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 0.2614
2023-05-31 01:09:58 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 0.2295
2023-05-31 01:09:59 - train: epoch 080, train_loss: 0.1743
2023-05-31 01:10:01 - eval: epoch: 080, acc1: 71.270%, acc5: 91.420%, test_loss: 1.2804, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:10:01 - until epoch: 080, best_acc1: 75.010%
2023-05-31 01:10:01 - epoch 081 lr: 0.020000
2023-05-31 01:10:03 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 0.1632
2023-05-31 01:10:04 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 0.1541
2023-05-31 01:10:06 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 0.1654
2023-05-31 01:10:07 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 0.2231
2023-05-31 01:10:08 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 0.1266
2023-05-31 01:10:10 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 0.1965
2023-05-31 01:10:11 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 0.1230
2023-05-31 01:10:12 - train: epoch 081, train_loss: 0.1828
2023-05-31 01:10:13 - eval: epoch: 081, acc1: 70.610%, acc5: 91.260%, test_loss: 1.2953, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:10:13 - until epoch: 081, best_acc1: 75.010%
2023-05-31 01:10:13 - epoch 082 lr: 0.020000
2023-05-31 01:10:16 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 0.2178
2023-05-31 01:10:17 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 0.1594
2023-05-31 01:10:18 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 0.1053
2023-05-31 01:10:19 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 0.1753
2023-05-31 01:10:21 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 0.1345
2023-05-31 01:10:22 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 0.2307
2023-05-31 01:10:23 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 0.1410
2023-05-31 01:10:24 - train: epoch 082, train_loss: 0.1749
2023-05-31 01:10:26 - eval: epoch: 082, acc1: 70.990%, acc5: 91.540%, test_loss: 1.2640, per_image_load_time: 0.071ms, per_image_inference_time: 0.047ms
2023-05-31 01:10:26 - until epoch: 082, best_acc1: 75.010%
2023-05-31 01:10:26 - epoch 083 lr: 0.020000
2023-05-31 01:10:28 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 0.2571
2023-05-31 01:10:29 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 0.1504
2023-05-31 01:10:30 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 0.1781
2023-05-31 01:10:32 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 0.1024
2023-05-31 01:10:33 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 0.1473
2023-05-31 01:10:34 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 0.2144
2023-05-31 01:10:36 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 0.2759
2023-05-31 01:10:37 - train: epoch 083, train_loss: 0.1863
2023-05-31 01:10:38 - eval: epoch: 083, acc1: 70.680%, acc5: 91.260%, test_loss: 1.2748, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 01:10:38 - until epoch: 083, best_acc1: 75.010%
2023-05-31 01:10:38 - epoch 084 lr: 0.020000
2023-05-31 01:10:40 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 0.2301
2023-05-31 01:10:42 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 0.1259
2023-05-31 01:10:43 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 0.1064
2023-05-31 01:10:44 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 0.1609
2023-05-31 01:10:46 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 0.1653
2023-05-31 01:10:47 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 0.1734
2023-05-31 01:10:48 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 0.1736
2023-05-31 01:10:49 - train: epoch 084, train_loss: 0.1687
2023-05-31 01:10:50 - eval: epoch: 084, acc1: 70.860%, acc5: 91.070%, test_loss: 1.3209, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:10:51 - until epoch: 084, best_acc1: 75.010%
2023-05-31 01:10:51 - epoch 085 lr: 0.020000
2023-05-31 01:10:53 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 0.0930
2023-05-31 01:10:54 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 0.1084
2023-05-31 01:10:55 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 0.1209
2023-05-31 01:10:57 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 0.0961
2023-05-31 01:10:58 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 0.2012
2023-05-31 01:10:59 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 0.1750
2023-05-31 01:11:00 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 0.2181
2023-05-31 01:11:02 - train: epoch 085, train_loss: 0.1653
2023-05-31 01:11:03 - eval: epoch: 085, acc1: 71.050%, acc5: 91.190%, test_loss: 1.3019, per_image_load_time: 0.076ms, per_image_inference_time: 0.044ms
2023-05-31 01:11:03 - until epoch: 085, best_acc1: 75.010%
2023-05-31 01:11:03 - epoch 086 lr: 0.020000
2023-05-31 01:11:05 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 0.1350
2023-05-31 01:11:06 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 0.1151
2023-05-31 01:11:08 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 0.1491
2023-05-31 01:11:09 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 0.1952
2023-05-31 01:11:10 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 0.1577
2023-05-31 01:11:12 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 0.1955
2023-05-31 01:11:13 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 0.2500
2023-05-31 01:11:14 - train: epoch 086, train_loss: 0.1773
2023-05-31 01:11:15 - eval: epoch: 086, acc1: 71.600%, acc5: 91.450%, test_loss: 1.3204, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:11:15 - until epoch: 086, best_acc1: 75.010%
2023-05-31 01:11:15 - epoch 087 lr: 0.020000
2023-05-31 01:11:18 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 0.1488
2023-05-31 01:11:19 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 0.1856
2023-05-31 01:11:20 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 0.1199
2023-05-31 01:11:21 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 0.1773
2023-05-31 01:11:23 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 0.2147
2023-05-31 01:11:24 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 0.1845
2023-05-31 01:11:25 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 0.2108
2023-05-31 01:11:26 - train: epoch 087, train_loss: 0.1774
2023-05-31 01:11:28 - eval: epoch: 087, acc1: 69.380%, acc5: 90.510%, test_loss: 1.3698, per_image_load_time: 0.070ms, per_image_inference_time: 0.042ms
2023-05-31 01:11:28 - until epoch: 087, best_acc1: 75.010%
2023-05-31 01:11:28 - epoch 088 lr: 0.020000
2023-05-31 01:11:30 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 0.1261
2023-05-31 01:11:31 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 0.2103
2023-05-31 01:11:32 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 0.1930
2023-05-31 01:11:34 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 0.2407
2023-05-31 01:11:35 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 0.1498
2023-05-31 01:11:36 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 0.1796
2023-05-31 01:11:38 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 0.2505
2023-05-31 01:11:39 - train: epoch 088, train_loss: 0.1847
2023-05-31 01:11:40 - eval: epoch: 088, acc1: 70.270%, acc5: 91.650%, test_loss: 1.3043, per_image_load_time: 0.074ms, per_image_inference_time: 0.044ms
2023-05-31 01:11:40 - until epoch: 088, best_acc1: 75.010%
2023-05-31 01:11:40 - epoch 089 lr: 0.020000
2023-05-31 01:11:42 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 0.1482
2023-05-31 01:11:44 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 0.2265
2023-05-31 01:11:45 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 0.1072
2023-05-31 01:11:46 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 0.1035
2023-05-31 01:11:47 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 0.2395
2023-05-31 01:11:49 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 0.1574
2023-05-31 01:11:50 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 0.2088
2023-05-31 01:11:51 - train: epoch 089, train_loss: 0.1692
2023-05-31 01:11:52 - eval: epoch: 089, acc1: 70.780%, acc5: 91.800%, test_loss: 1.2671, per_image_load_time: 0.070ms, per_image_inference_time: 0.052ms
2023-05-31 01:11:53 - until epoch: 089, best_acc1: 75.010%
2023-05-31 01:11:53 - epoch 090 lr: 0.020000
2023-05-31 01:11:55 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 0.0801
2023-05-31 01:11:56 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 0.1607
2023-05-31 01:11:57 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 0.0755
2023-05-31 01:11:59 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 0.1495
2023-05-31 01:12:00 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 0.1547
2023-05-31 01:12:01 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 0.1993
2023-05-31 01:12:02 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 0.1355
2023-05-31 01:12:04 - train: epoch 090, train_loss: 0.1706
2023-05-31 01:12:05 - eval: epoch: 090, acc1: 69.950%, acc5: 90.970%, test_loss: 1.3479, per_image_load_time: 0.068ms, per_image_inference_time: 0.043ms
2023-05-31 01:12:05 - until epoch: 090, best_acc1: 75.010%
2023-05-31 01:12:05 - epoch 091 lr: 0.020000
2023-05-31 01:12:07 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 0.1290
2023-05-31 01:12:08 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 0.1941
2023-05-31 01:12:10 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 0.1323
2023-05-31 01:12:11 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 0.1816
2023-05-31 01:12:12 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 0.1544
2023-05-31 01:12:14 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 0.1985
2023-05-31 01:12:15 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 0.1320
2023-05-31 01:12:16 - train: epoch 091, train_loss: 0.1776
2023-05-31 01:12:17 - eval: epoch: 091, acc1: 70.340%, acc5: 91.360%, test_loss: 1.3082, per_image_load_time: 0.067ms, per_image_inference_time: 0.043ms
2023-05-31 01:12:17 - until epoch: 091, best_acc1: 75.010%
2023-05-31 01:12:17 - epoch 092 lr: 0.020000
2023-05-31 01:12:19 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 0.1391
2023-05-31 01:12:21 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 0.1786
2023-05-31 01:12:22 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 0.2396
2023-05-31 01:12:23 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 0.0998
2023-05-31 01:12:25 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 0.1461
2023-05-31 01:12:26 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 0.1768
2023-05-31 01:12:27 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 0.3216
2023-05-31 01:12:28 - train: epoch 092, train_loss: 0.1679
2023-05-31 01:12:30 - eval: epoch: 092, acc1: 71.010%, acc5: 91.420%, test_loss: 1.3052, per_image_load_time: 0.071ms, per_image_inference_time: 0.044ms
2023-05-31 01:12:30 - until epoch: 092, best_acc1: 75.010%
2023-05-31 01:12:30 - epoch 093 lr: 0.020000
2023-05-31 01:12:32 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 0.1065
2023-05-31 01:12:33 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 0.1302
2023-05-31 01:12:35 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 0.2319
2023-05-31 01:12:36 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 0.2023
2023-05-31 01:12:37 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 0.2090
2023-05-31 01:12:38 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 0.1130
2023-05-31 01:12:40 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 0.1701
2023-05-31 01:12:41 - train: epoch 093, train_loss: 0.1676
2023-05-31 01:12:42 - eval: epoch: 093, acc1: 70.580%, acc5: 91.100%, test_loss: 1.3159, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:12:42 - until epoch: 093, best_acc1: 75.010%
2023-05-31 01:12:42 - epoch 094 lr: 0.020000
2023-05-31 01:12:44 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 0.1199
2023-05-31 01:12:46 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 0.1758
2023-05-31 01:12:47 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 0.2115
2023-05-31 01:12:48 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 0.1117
2023-05-31 01:12:49 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 0.1181
2023-05-31 01:12:51 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 0.2276
2023-05-31 01:12:52 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 0.2065
2023-05-31 01:12:53 - train: epoch 094, train_loss: 0.1780
2023-05-31 01:12:54 - eval: epoch: 094, acc1: 70.860%, acc5: 92.050%, test_loss: 1.2843, per_image_load_time: 0.066ms, per_image_inference_time: 0.045ms
2023-05-31 01:12:55 - until epoch: 094, best_acc1: 75.010%
2023-05-31 01:12:55 - epoch 095 lr: 0.020000
2023-05-31 01:12:57 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 0.1322
2023-05-31 01:12:58 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 0.1592
2023-05-31 01:12:59 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 0.1846
2023-05-31 01:13:00 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 0.2006
2023-05-31 01:13:02 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 0.1574
2023-05-31 01:13:03 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 0.1243
2023-05-31 01:13:04 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 0.2079
2023-05-31 01:13:05 - train: epoch 095, train_loss: 0.1764
2023-05-31 01:13:07 - eval: epoch: 095, acc1: 69.940%, acc5: 91.000%, test_loss: 1.3610, per_image_load_time: 0.077ms, per_image_inference_time: 0.044ms
2023-05-31 01:13:07 - until epoch: 095, best_acc1: 75.010%
2023-05-31 01:13:07 - epoch 096 lr: 0.020000
2023-05-31 01:13:09 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 0.1521
2023-05-31 01:13:10 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 0.1491
2023-05-31 01:13:12 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 0.1387
2023-05-31 01:13:13 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 0.2041
2023-05-31 01:13:14 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 0.1092
2023-05-31 01:13:15 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 0.1600
2023-05-31 01:13:17 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 0.2003
2023-05-31 01:13:18 - train: epoch 096, train_loss: 0.1643
2023-05-31 01:13:19 - eval: epoch: 096, acc1: 70.270%, acc5: 91.070%, test_loss: 1.3602, per_image_load_time: 0.071ms, per_image_inference_time: 0.048ms
2023-05-31 01:13:20 - until epoch: 096, best_acc1: 75.010%
2023-05-31 01:13:20 - epoch 097 lr: 0.020000
2023-05-31 01:13:22 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 0.1622
2023-05-31 01:13:23 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 0.1159
2023-05-31 01:13:24 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 0.1127
2023-05-31 01:13:26 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 0.1405
2023-05-31 01:13:27 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 0.1424
2023-05-31 01:13:28 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 0.2457
2023-05-31 01:13:30 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 0.1327
2023-05-31 01:13:31 - train: epoch 097, train_loss: 0.1718
2023-05-31 01:13:32 - eval: epoch: 097, acc1: 70.390%, acc5: 91.200%, test_loss: 1.3491, per_image_load_time: 0.069ms, per_image_inference_time: 0.047ms
2023-05-31 01:13:32 - until epoch: 097, best_acc1: 75.010%
2023-05-31 01:13:32 - epoch 098 lr: 0.020000
2023-05-31 01:13:34 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 0.1051
2023-05-31 01:13:36 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 0.1248
2023-05-31 01:13:37 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 0.1600
2023-05-31 01:13:38 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 0.2285
2023-05-31 01:13:39 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 0.1720
2023-05-31 01:13:41 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 0.2342
2023-05-31 01:13:42 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 0.2934
2023-05-31 01:13:43 - train: epoch 098, train_loss: 0.1714
2023-05-31 01:13:44 - eval: epoch: 098, acc1: 70.880%, acc5: 91.430%, test_loss: 1.3194, per_image_load_time: 0.065ms, per_image_inference_time: 0.044ms
2023-05-31 01:13:45 - until epoch: 098, best_acc1: 75.010%
2023-05-31 01:13:45 - epoch 099 lr: 0.020000
2023-05-31 01:13:47 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 0.1414
2023-05-31 01:13:48 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 0.1006
2023-05-31 01:13:49 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 0.1135
2023-05-31 01:13:51 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 0.1363
2023-05-31 01:13:52 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 0.1778
2023-05-31 01:13:53 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 0.2300
2023-05-31 01:13:55 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 0.1542
2023-05-31 01:13:56 - train: epoch 099, train_loss: 0.1589
2023-05-31 01:13:57 - eval: epoch: 099, acc1: 70.940%, acc5: 91.410%, test_loss: 1.3312, per_image_load_time: 0.069ms, per_image_inference_time: 0.046ms
2023-05-31 01:13:57 - until epoch: 099, best_acc1: 75.010%
2023-05-31 01:13:57 - epoch 100 lr: 0.020000
2023-05-31 01:13:59 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 0.1055
2023-05-31 01:14:01 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 0.1603
2023-05-31 01:14:02 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 0.1782
2023-05-31 01:14:03 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 0.2100
2023-05-31 01:14:04 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 0.1110
2023-05-31 01:14:06 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 0.2163
2023-05-31 01:14:07 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 0.1827
2023-05-31 01:14:08 - train: epoch 100, train_loss: 0.1607
2023-05-31 01:14:09 - eval: epoch: 100, acc1: 70.110%, acc5: 91.180%, test_loss: 1.3689, per_image_load_time: 0.084ms, per_image_inference_time: 0.044ms
2023-05-31 01:14:10 - until epoch: 100, best_acc1: 75.010%
2023-05-31 01:14:10 - epoch 101 lr: 0.020000
2023-05-31 01:14:12 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 0.1556
2023-05-31 01:14:13 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 0.1501
2023-05-31 01:14:14 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 0.1452
2023-05-31 01:14:16 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 0.1710
2023-05-31 01:14:17 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 0.1527
2023-05-31 01:14:18 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 0.2144
2023-05-31 01:14:20 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 0.1426
2023-05-31 01:14:21 - train: epoch 101, train_loss: 0.1737
2023-05-31 01:14:22 - eval: epoch: 101, acc1: 70.290%, acc5: 91.030%, test_loss: 1.3323, per_image_load_time: 0.076ms, per_image_inference_time: 0.045ms
2023-05-31 01:14:22 - until epoch: 101, best_acc1: 75.010%
2023-05-31 01:14:22 - epoch 102 lr: 0.020000
2023-05-31 01:14:24 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 0.1100
2023-05-31 01:14:26 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 0.1312
2023-05-31 01:14:27 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 0.1449
2023-05-31 01:14:28 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 0.0905
2023-05-31 01:14:30 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 0.2208
2023-05-31 01:14:31 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 0.1145
2023-05-31 01:14:32 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 0.3690
2023-05-31 01:14:33 - train: epoch 102, train_loss: 0.1595
2023-05-31 01:14:35 - eval: epoch: 102, acc1: 69.260%, acc5: 90.900%, test_loss: 1.4002, per_image_load_time: 0.067ms, per_image_inference_time: 0.046ms
2023-05-31 01:14:35 - until epoch: 102, best_acc1: 75.010%
2023-05-31 01:14:35 - epoch 103 lr: 0.020000
2023-05-31 01:14:37 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 0.1918
2023-05-31 01:14:38 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 0.1174
2023-05-31 01:14:40 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 0.2284
2023-05-31 01:14:41 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 0.2638
2023-05-31 01:14:42 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 0.1471
2023-05-31 01:14:43 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 0.1875
2023-05-31 01:14:45 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 0.1806
2023-05-31 01:14:46 - train: epoch 103, train_loss: 0.1751
2023-05-31 01:14:47 - eval: epoch: 103, acc1: 69.120%, acc5: 90.580%, test_loss: 1.4424, per_image_load_time: 0.073ms, per_image_inference_time: 0.044ms
2023-05-31 01:14:47 - until epoch: 103, best_acc1: 75.010%
2023-05-31 01:14:47 - epoch 104 lr: 0.020000
2023-05-31 01:14:50 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 0.0740
2023-05-31 01:14:51 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 0.2449
2023-05-31 01:14:52 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 0.2279
2023-05-31 01:14:53 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 0.2817
2023-05-31 01:14:55 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 0.1982
2023-05-31 01:14:56 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 0.1364
2023-05-31 01:14:57 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 0.3988
2023-05-31 01:14:58 - train: epoch 104, train_loss: 0.1725
2023-05-31 01:15:00 - eval: epoch: 104, acc1: 70.360%, acc5: 91.010%, test_loss: 1.3353, per_image_load_time: 0.075ms, per_image_inference_time: 0.047ms
2023-05-31 01:15:00 - until epoch: 104, best_acc1: 75.010%
2023-05-31 01:15:00 - epoch 105 lr: 0.020000
2023-05-31 01:15:02 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 0.1349
2023-05-31 01:15:03 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 0.1114
2023-05-31 01:15:05 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 0.0808
2023-05-31 01:15:06 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 0.1297
2023-05-31 01:15:07 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 0.1518
2023-05-31 01:15:08 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 0.1200
2023-05-31 01:15:10 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 0.2016
2023-05-31 01:15:11 - train: epoch 105, train_loss: 0.1697
2023-05-31 01:15:12 - eval: epoch: 105, acc1: 70.160%, acc5: 90.760%, test_loss: 1.3897, per_image_load_time: 0.066ms, per_image_inference_time: 0.048ms
2023-05-31 01:15:12 - until epoch: 105, best_acc1: 75.010%
2023-05-31 01:15:12 - epoch 106 lr: 0.020000
2023-05-31 01:15:14 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 0.1849
2023-05-31 01:15:16 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 0.1444
2023-05-31 01:15:17 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 0.1302
2023-05-31 01:15:18 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 0.1475
2023-05-31 01:15:20 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 0.1638
2023-05-31 01:15:21 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 0.2490
2023-05-31 01:15:22 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 0.1754
2023-05-31 01:15:23 - train: epoch 106, train_loss: 0.1621
2023-05-31 01:15:25 - eval: epoch: 106, acc1: 70.000%, acc5: 90.670%, test_loss: 1.3796, per_image_load_time: 0.074ms, per_image_inference_time: 0.047ms
2023-05-31 01:15:25 - until epoch: 106, best_acc1: 75.010%
2023-05-31 01:15:25 - epoch 107 lr: 0.020000
2023-05-31 01:15:27 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 0.1702
2023-05-31 01:15:28 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 0.0785
2023-05-31 01:15:30 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 0.1221
2023-05-31 01:15:31 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 0.0904
2023-05-31 01:15:32 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 0.1696
2023-05-31 01:15:34 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 0.2685
2023-05-31 01:15:35 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 0.1872
2023-05-31 01:15:36 - train: epoch 107, train_loss: 0.1595
2023-05-31 01:15:37 - eval: epoch: 107, acc1: 69.020%, acc5: 90.330%, test_loss: 1.4450, per_image_load_time: 0.067ms, per_image_inference_time: 0.046ms
2023-05-31 01:15:38 - until epoch: 107, best_acc1: 75.010%
2023-05-31 01:15:38 - epoch 108 lr: 0.020000
2023-05-31 01:15:40 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 0.1582
2023-05-31 01:15:41 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 0.0663
2023-05-31 01:15:42 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 0.1725
2023-05-31 01:15:44 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 0.1905
2023-05-31 01:15:45 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 0.2088
2023-05-31 01:15:46 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 0.1247
2023-05-31 01:15:47 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 0.1765
2023-05-31 01:15:48 - train: epoch 108, train_loss: 0.1660
2023-05-31 01:15:50 - eval: epoch: 108, acc1: 70.120%, acc5: 90.580%, test_loss: 1.3981, per_image_load_time: 0.066ms, per_image_inference_time: 0.044ms
2023-05-31 01:15:50 - until epoch: 108, best_acc1: 75.010%
2023-05-31 01:15:50 - epoch 109 lr: 0.020000
2023-05-31 01:15:52 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 0.1541
2023-05-31 01:15:53 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 0.0824
2023-05-31 01:15:55 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 0.1044
2023-05-31 01:15:56 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 0.1418
2023-05-31 01:15:57 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 0.1872
2023-05-31 01:15:59 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 0.1576
2023-05-31 01:16:00 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 0.1755
2023-05-31 01:16:01 - train: epoch 109, train_loss: 0.1701
2023-05-31 01:16:02 - eval: epoch: 109, acc1: 69.720%, acc5: 91.180%, test_loss: 1.4053, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:16:03 - until epoch: 109, best_acc1: 75.010%
2023-05-31 01:16:03 - epoch 110 lr: 0.020000
2023-05-31 01:16:05 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 0.1463
2023-05-31 01:16:06 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 0.1758
2023-05-31 01:16:07 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 0.1687
2023-05-31 01:16:08 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 0.2130
2023-05-31 01:16:10 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 0.1769
2023-05-31 01:16:11 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 0.2177
2023-05-31 01:16:12 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 0.1428
2023-05-31 01:16:13 - train: epoch 110, train_loss: 0.1584
2023-05-31 01:16:14 - eval: epoch: 110, acc1: 70.980%, acc5: 90.990%, test_loss: 1.3199, per_image_load_time: 0.067ms, per_image_inference_time: 0.047ms
2023-05-31 01:16:15 - until epoch: 110, best_acc1: 75.010%
2023-05-31 01:16:15 - epoch 111 lr: 0.020000
2023-05-31 01:16:17 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 0.1703
2023-05-31 01:16:18 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 0.1326
2023-05-31 01:16:19 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 0.1952
2023-05-31 01:16:21 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 0.2019
2023-05-31 01:16:22 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 0.1625
2023-05-31 01:16:23 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 0.1442
2023-05-31 01:16:25 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 0.1849
2023-05-31 01:16:26 - train: epoch 111, train_loss: 0.1594
2023-05-31 01:16:27 - eval: epoch: 111, acc1: 69.960%, acc5: 90.900%, test_loss: 1.4122, per_image_load_time: 0.066ms, per_image_inference_time: 0.044ms
2023-05-31 01:16:27 - until epoch: 111, best_acc1: 75.010%
2023-05-31 01:16:27 - epoch 112 lr: 0.020000
2023-05-31 01:16:29 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 0.0732
2023-05-31 01:16:30 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 0.1618
2023-05-31 01:16:32 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 0.3018
2023-05-31 01:16:33 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 0.2902
2023-05-31 01:16:34 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 0.2296
2023-05-31 01:16:36 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 0.2382
2023-05-31 01:16:37 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 0.1640
2023-05-31 01:16:38 - train: epoch 112, train_loss: 0.1583
2023-05-31 01:16:39 - eval: epoch: 112, acc1: 70.050%, acc5: 90.720%, test_loss: 1.3934, per_image_load_time: 0.071ms, per_image_inference_time: 0.044ms
2023-05-31 01:16:40 - until epoch: 112, best_acc1: 75.010%
2023-05-31 01:16:40 - epoch 113 lr: 0.020000
2023-05-31 01:16:42 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 0.1440
2023-05-31 01:16:43 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 0.2128
2023-05-31 01:16:45 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 0.1623
2023-05-31 01:16:46 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 0.1461
2023-05-31 01:16:47 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 0.1297
2023-05-31 01:16:48 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 0.1001
2023-05-31 01:16:50 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 0.1805
2023-05-31 01:16:51 - train: epoch 113, train_loss: 0.1775
2023-05-31 01:16:52 - eval: epoch: 113, acc1: 69.330%, acc5: 90.490%, test_loss: 1.4202, per_image_load_time: 0.065ms, per_image_inference_time: 0.043ms
2023-05-31 01:16:52 - until epoch: 113, best_acc1: 75.010%
2023-05-31 01:16:52 - epoch 114 lr: 0.020000
2023-05-31 01:16:54 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 0.1318
2023-05-31 01:16:56 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 0.2137
2023-05-31 01:16:57 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 0.0997
2023-05-31 01:16:58 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 0.2360
2023-05-31 01:16:59 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 0.2123
2023-05-31 01:17:01 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 0.1962
2023-05-31 01:17:02 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 0.2249
2023-05-31 01:17:03 - train: epoch 114, train_loss: 0.1585
2023-05-31 01:17:04 - eval: epoch: 114, acc1: 68.660%, acc5: 90.590%, test_loss: 1.4678, per_image_load_time: 0.067ms, per_image_inference_time: 0.045ms
2023-05-31 01:17:05 - until epoch: 114, best_acc1: 75.010%
2023-05-31 01:17:05 - epoch 115 lr: 0.020000
2023-05-31 01:17:07 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 0.1244
2023-05-31 01:17:08 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 0.1459
2023-05-31 01:17:09 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 0.2659
2023-05-31 01:17:11 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 0.1211
2023-05-31 01:17:12 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 0.1132
2023-05-31 01:17:13 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 0.2360
2023-05-31 01:17:15 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 0.1224
2023-05-31 01:17:16 - train: epoch 115, train_loss: 0.1507
2023-05-31 01:17:17 - eval: epoch: 115, acc1: 69.990%, acc5: 91.020%, test_loss: 1.3771, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:17:17 - until epoch: 115, best_acc1: 75.010%
2023-05-31 01:17:17 - epoch 116 lr: 0.020000
2023-05-31 01:17:19 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 0.2131
2023-05-31 01:17:21 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 0.1331
2023-05-31 01:17:22 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 0.1698
2023-05-31 01:17:23 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 0.1620
2023-05-31 01:17:25 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 0.1360
2023-05-31 01:17:26 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 0.1794
2023-05-31 01:17:27 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 0.2244
2023-05-31 01:17:28 - train: epoch 116, train_loss: 0.1617
2023-05-31 01:17:29 - eval: epoch: 116, acc1: 69.910%, acc5: 90.640%, test_loss: 1.4291, per_image_load_time: 0.071ms, per_image_inference_time: 0.043ms
2023-05-31 01:17:30 - until epoch: 116, best_acc1: 75.010%
2023-05-31 01:17:30 - epoch 117 lr: 0.020000
2023-05-31 01:17:32 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 0.1474
2023-05-31 01:17:33 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 0.1115
2023-05-31 01:17:34 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 0.1672
2023-05-31 01:17:36 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 0.2208
2023-05-31 01:17:37 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 0.1596
2023-05-31 01:17:38 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 0.2288
2023-05-31 01:17:40 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 0.1973
2023-05-31 01:17:41 - train: epoch 117, train_loss: 0.1799
2023-05-31 01:17:42 - eval: epoch: 117, acc1: 69.990%, acc5: 91.170%, test_loss: 1.3732, per_image_load_time: 0.070ms, per_image_inference_time: 0.045ms
2023-05-31 01:17:42 - until epoch: 117, best_acc1: 75.010%
2023-05-31 01:17:42 - epoch 118 lr: 0.020000
2023-05-31 01:17:44 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 0.1851
2023-05-31 01:17:46 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 0.1011
2023-05-31 01:17:47 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 0.0924
2023-05-31 01:17:48 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 0.2743
2023-05-31 01:17:49 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 0.1488
2023-05-31 01:17:51 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 0.2039
2023-05-31 01:17:52 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 0.1606
2023-05-31 01:17:53 - train: epoch 118, train_loss: 0.1592
2023-05-31 01:17:54 - eval: epoch: 118, acc1: 70.120%, acc5: 91.660%, test_loss: 1.3573, per_image_load_time: 0.066ms, per_image_inference_time: 0.043ms
2023-05-31 01:17:55 - until epoch: 118, best_acc1: 75.010%
2023-05-31 01:17:55 - epoch 119 lr: 0.020000
2023-05-31 01:17:57 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 0.0706
2023-05-31 01:17:58 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 0.1541
2023-05-31 01:17:59 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 0.1509
2023-05-31 01:18:00 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 0.1342
2023-05-31 01:18:02 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 0.1861
2023-05-31 01:18:03 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 0.2330
2023-05-31 01:18:04 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 0.2120
2023-05-31 01:18:05 - train: epoch 119, train_loss: 0.1581
2023-05-31 01:18:07 - eval: epoch: 119, acc1: 69.750%, acc5: 90.580%, test_loss: 1.4020, per_image_load_time: 0.073ms, per_image_inference_time: 0.045ms
2023-05-31 01:18:07 - until epoch: 119, best_acc1: 75.010%
2023-05-31 01:18:07 - epoch 120 lr: 0.020000
2023-05-31 01:18:09 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 0.1297
2023-05-31 01:18:10 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 0.1681
2023-05-31 01:18:12 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 0.1219
2023-05-31 01:18:13 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 0.1073
2023-05-31 01:18:14 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 0.2199
2023-05-31 01:18:15 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 0.2302
2023-05-31 01:18:17 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 0.1764
2023-05-31 01:18:18 - train: epoch 120, train_loss: 0.1619
2023-05-31 01:18:19 - eval: epoch: 120, acc1: 68.860%, acc5: 90.960%, test_loss: 1.4398, per_image_load_time: 0.065ms, per_image_inference_time: 0.044ms
2023-05-31 01:18:19 - until epoch: 120, best_acc1: 75.010%
2023-05-31 01:18:19 - epoch 121 lr: 0.004000
2023-05-31 01:18:21 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 0.1006
2023-05-31 01:18:23 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 0.0757
2023-05-31 01:18:24 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 0.0750
2023-05-31 01:18:25 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 0.0539
2023-05-31 01:18:27 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 0.0863
2023-05-31 01:18:28 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 0.0310
2023-05-31 01:18:29 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 0.0487
2023-05-31 01:18:30 - train: epoch 121, train_loss: 0.0710
2023-05-31 01:18:32 - eval: epoch: 121, acc1: 74.350%, acc5: 92.930%, test_loss: 1.1544, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:18:32 - until epoch: 121, best_acc1: 75.010%
2023-05-31 01:18:32 - epoch 122 lr: 0.004000
2023-05-31 01:18:34 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 0.0293
2023-05-31 01:18:35 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 0.0318
2023-05-31 01:18:37 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 0.0199
2023-05-31 01:18:38 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 0.0273
2023-05-31 01:18:39 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 0.0255
2023-05-31 01:18:40 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 0.0186
2023-05-31 01:18:42 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 0.0548
2023-05-31 01:18:43 - train: epoch 122, train_loss: 0.0333
2023-05-31 01:18:44 - eval: epoch: 122, acc1: 74.940%, acc5: 92.970%, test_loss: 1.1430, per_image_load_time: 0.065ms, per_image_inference_time: 0.043ms
2023-05-31 01:18:44 - until epoch: 122, best_acc1: 75.010%
2023-05-31 01:18:44 - epoch 123 lr: 0.004000
2023-05-31 01:18:46 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 0.0280
2023-05-31 01:18:48 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 0.0423
2023-05-31 01:18:49 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 0.0142
2023-05-31 01:18:50 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 0.0356
2023-05-31 01:18:51 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 0.0217
2023-05-31 01:18:53 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.0357
2023-05-31 01:18:54 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 0.0059
2023-05-31 01:18:55 - train: epoch 123, train_loss: 0.0258
2023-05-31 01:18:56 - eval: epoch: 123, acc1: 75.180%, acc5: 93.070%, test_loss: 1.1339, per_image_load_time: 0.073ms, per_image_inference_time: 0.045ms
2023-05-31 01:18:57 - until epoch: 123, best_acc1: 75.180%
2023-05-31 01:18:57 - epoch 124 lr: 0.004000
2023-05-31 01:18:59 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.0313
2023-05-31 01:19:00 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 0.0224
2023-05-31 01:19:02 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 0.0235
2023-05-31 01:19:03 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 0.0303
2023-05-31 01:19:04 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 0.0209
2023-05-31 01:19:05 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 0.0329
2023-05-31 01:19:07 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 0.0199
2023-05-31 01:19:08 - train: epoch 124, train_loss: 0.0201
2023-05-31 01:19:09 - eval: epoch: 124, acc1: 75.430%, acc5: 93.320%, test_loss: 1.1286, per_image_load_time: 0.069ms, per_image_inference_time: 0.044ms
2023-05-31 01:19:10 - until epoch: 124, best_acc1: 75.430%
2023-05-31 01:19:10 - epoch 125 lr: 0.004000
2023-05-31 01:19:12 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.0201
2023-05-31 01:19:13 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.0101
2023-05-31 01:19:14 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 0.0169
2023-05-31 01:19:16 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 0.0149
2023-05-31 01:19:17 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 0.0118
2023-05-31 01:19:18 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 0.0114
2023-05-31 01:19:19 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 0.0076
2023-05-31 01:19:21 - train: epoch 125, train_loss: 0.0168
2023-05-31 01:19:22 - eval: epoch: 125, acc1: 75.330%, acc5: 93.310%, test_loss: 1.1214, per_image_load_time: 0.069ms, per_image_inference_time: 0.044ms
2023-05-31 01:19:22 - until epoch: 125, best_acc1: 75.430%
2023-05-31 01:19:22 - epoch 126 lr: 0.004000
2023-05-31 01:19:24 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.0122
2023-05-31 01:19:25 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 0.0053
2023-05-31 01:19:27 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 0.0133
2023-05-31 01:19:28 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 0.0117
2023-05-31 01:19:29 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 0.0252
2023-05-31 01:19:31 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 0.0266
2023-05-31 01:19:32 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 0.0260
2023-05-31 01:19:33 - train: epoch 126, train_loss: 0.0149
2023-05-31 01:19:34 - eval: epoch: 126, acc1: 75.490%, acc5: 93.220%, test_loss: 1.1180, per_image_load_time: 0.066ms, per_image_inference_time: 0.045ms
2023-05-31 01:19:34 - until epoch: 126, best_acc1: 75.490%
2023-05-31 01:19:34 - epoch 127 lr: 0.004000
2023-05-31 01:19:36 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.0083
2023-05-31 01:19:38 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 0.0133
2023-05-31 01:19:39 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.0185
2023-05-31 01:19:40 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.0043
2023-05-31 01:19:42 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.0113
2023-05-31 01:19:43 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 0.0100
2023-05-31 01:19:44 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 0.0132
2023-05-31 01:19:45 - train: epoch 127, train_loss: 0.0139
2023-05-31 01:19:47 - eval: epoch: 127, acc1: 75.420%, acc5: 93.330%, test_loss: 1.1218, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:19:47 - until epoch: 127, best_acc1: 75.490%
2023-05-31 01:19:47 - epoch 128 lr: 0.004000
2023-05-31 01:19:49 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 0.0112
2023-05-31 01:19:50 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.0073
2023-05-31 01:19:52 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 0.0065
2023-05-31 01:19:53 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.0220
2023-05-31 01:19:54 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 0.0290
2023-05-31 01:19:55 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 0.0105
2023-05-31 01:19:57 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 0.0215
2023-05-31 01:19:58 - train: epoch 128, train_loss: 0.0126
2023-05-31 01:19:59 - eval: epoch: 128, acc1: 75.440%, acc5: 93.310%, test_loss: 1.1256, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 01:19:59 - until epoch: 128, best_acc1: 75.490%
2023-05-31 01:19:59 - epoch 129 lr: 0.004000
2023-05-31 01:20:01 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 0.0075
2023-05-31 01:20:03 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 0.0088
2023-05-31 01:20:04 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 0.0078
2023-05-31 01:20:05 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 0.0066
2023-05-31 01:20:06 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 0.0076
2023-05-31 01:20:08 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 0.0072
2023-05-31 01:20:09 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.0049
2023-05-31 01:20:10 - train: epoch 129, train_loss: 0.0112
2023-05-31 01:20:11 - eval: epoch: 129, acc1: 75.550%, acc5: 93.320%, test_loss: 1.1155, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:20:12 - until epoch: 129, best_acc1: 75.550%
2023-05-31 01:20:12 - epoch 130 lr: 0.004000
2023-05-31 01:20:15 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 0.0120
2023-05-31 01:20:16 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 0.0097
2023-05-31 01:20:17 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 0.0099
2023-05-31 01:20:18 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 0.0089
2023-05-31 01:20:20 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.0168
2023-05-31 01:20:21 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 0.0138
2023-05-31 01:20:22 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 0.0067
2023-05-31 01:20:23 - train: epoch 130, train_loss: 0.0110
2023-05-31 01:20:25 - eval: epoch: 130, acc1: 75.530%, acc5: 93.410%, test_loss: 1.1154, per_image_load_time: 0.065ms, per_image_inference_time: 0.047ms
2023-05-31 01:20:25 - until epoch: 130, best_acc1: 75.550%
2023-05-31 01:20:25 - epoch 131 lr: 0.004000
2023-05-31 01:20:27 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 0.0099
2023-05-31 01:20:28 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 0.0038
2023-05-31 01:20:30 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 0.0165
2023-05-31 01:20:31 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 0.0138
2023-05-31 01:20:32 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 0.0085
2023-05-31 01:20:33 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 0.0038
2023-05-31 01:20:35 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 0.0101
2023-05-31 01:20:36 - train: epoch 131, train_loss: 0.0099
2023-05-31 01:20:37 - eval: epoch: 131, acc1: 75.830%, acc5: 93.470%, test_loss: 1.1111, per_image_load_time: 0.068ms, per_image_inference_time: 0.043ms
2023-05-31 01:20:37 - until epoch: 131, best_acc1: 75.830%
2023-05-31 01:20:37 - epoch 132 lr: 0.004000
2023-05-31 01:20:40 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.0078
2023-05-31 01:20:41 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 0.0060
2023-05-31 01:20:42 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 0.0083
2023-05-31 01:20:43 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 0.0084
2023-05-31 01:20:45 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 0.0063
2023-05-31 01:20:46 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 0.0114
2023-05-31 01:20:47 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.0158
2023-05-31 01:20:48 - train: epoch 132, train_loss: 0.0088
2023-05-31 01:20:50 - eval: epoch: 132, acc1: 75.910%, acc5: 93.330%, test_loss: 1.1163, per_image_load_time: 0.066ms, per_image_inference_time: 0.043ms
2023-05-31 01:20:50 - until epoch: 132, best_acc1: 75.910%
2023-05-31 01:20:50 - epoch 133 lr: 0.004000
2023-05-31 01:20:52 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.0178
2023-05-31 01:20:53 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.0071
2023-05-31 01:20:55 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.0068
2023-05-31 01:20:56 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 0.0099
2023-05-31 01:20:57 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:20:58 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 0.0087
2023-05-31 01:21:00 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.0076
2023-05-31 01:21:01 - train: epoch 133, train_loss: 0.0090
2023-05-31 01:21:02 - eval: epoch: 133, acc1: 75.920%, acc5: 93.430%, test_loss: 1.1043, per_image_load_time: 0.071ms, per_image_inference_time: 0.047ms
2023-05-31 01:21:03 - until epoch: 133, best_acc1: 75.920%
2023-05-31 01:21:03 - epoch 134 lr: 0.004000
2023-05-31 01:21:05 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 0.0052
2023-05-31 01:21:06 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 0.0054
2023-05-31 01:21:07 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 0.0034
2023-05-31 01:21:08 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.0096
2023-05-31 01:21:10 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:21:11 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.0116
2023-05-31 01:21:12 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 0.0126
2023-05-31 01:21:13 - train: epoch 134, train_loss: 0.0090
2023-05-31 01:21:15 - eval: epoch: 134, acc1: 75.780%, acc5: 93.410%, test_loss: 1.1048, per_image_load_time: 0.066ms, per_image_inference_time: 0.046ms
2023-05-31 01:21:15 - until epoch: 134, best_acc1: 75.920%
2023-05-31 01:21:15 - epoch 135 lr: 0.004000
2023-05-31 01:21:17 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 0.0048
2023-05-31 01:21:18 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.0353
2023-05-31 01:21:20 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 0.0045
2023-05-31 01:21:21 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 0.0232
2023-05-31 01:21:22 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 0.0272
2023-05-31 01:21:24 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 0.0060
2023-05-31 01:21:25 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 0.0084
2023-05-31 01:21:26 - train: epoch 135, train_loss: 0.0081
2023-05-31 01:21:27 - eval: epoch: 135, acc1: 75.660%, acc5: 93.480%, test_loss: 1.0998, per_image_load_time: 0.065ms, per_image_inference_time: 0.044ms
2023-05-31 01:21:28 - until epoch: 135, best_acc1: 75.920%
2023-05-31 01:21:28 - epoch 136 lr: 0.004000
2023-05-31 01:21:30 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.0036
2023-05-31 01:21:31 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.0076
2023-05-31 01:21:32 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.0074
2023-05-31 01:21:34 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 0.0039
2023-05-31 01:21:35 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.0160
2023-05-31 01:21:36 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 0.0063
2023-05-31 01:21:37 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 0.0039
2023-05-31 01:21:38 - train: epoch 136, train_loss: 0.0079
2023-05-31 01:21:40 - eval: epoch: 136, acc1: 75.810%, acc5: 93.530%, test_loss: 1.1013, per_image_load_time: 0.065ms, per_image_inference_time: 0.045ms
2023-05-31 01:21:40 - until epoch: 136, best_acc1: 75.920%
2023-05-31 01:21:40 - epoch 137 lr: 0.004000
2023-05-31 01:21:42 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 0.0027
2023-05-31 01:21:43 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 0.0057
2023-05-31 01:21:44 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.0066
2023-05-31 01:21:46 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 0.0096
2023-05-31 01:21:47 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 0.0050
2023-05-31 01:21:48 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 0.0023
2023-05-31 01:21:50 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.0081
2023-05-31 01:21:51 - train: epoch 137, train_loss: 0.0072
2023-05-31 01:21:52 - eval: epoch: 137, acc1: 75.950%, acc5: 93.570%, test_loss: 1.0965, per_image_load_time: 0.064ms, per_image_inference_time: 0.044ms
2023-05-31 01:21:52 - until epoch: 137, best_acc1: 75.950%
2023-05-31 01:21:52 - epoch 138 lr: 0.004000
2023-05-31 01:21:54 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 0.0101
2023-05-31 01:21:56 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 0.0036
2023-05-31 01:21:57 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 0.0059
2023-05-31 01:21:58 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 0.0292
2023-05-31 01:22:00 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.0055
2023-05-31 01:22:01 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.0085
2023-05-31 01:22:02 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 0.0041
2023-05-31 01:22:03 - train: epoch 138, train_loss: 0.0072
2023-05-31 01:22:04 - eval: epoch: 138, acc1: 75.970%, acc5: 93.540%, test_loss: 1.0994, per_image_load_time: 0.064ms, per_image_inference_time: 0.044ms
2023-05-31 01:22:05 - until epoch: 138, best_acc1: 75.970%
2023-05-31 01:22:05 - epoch 139 lr: 0.004000
2023-05-31 01:22:07 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 0.0051
2023-05-31 01:22:08 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 0.0198
2023-05-31 01:22:10 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 0.0149
2023-05-31 01:22:11 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.0062
2023-05-31 01:22:12 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 0.0066
2023-05-31 01:22:13 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 0.0066
2023-05-31 01:22:15 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 0.0054
2023-05-31 01:22:16 - train: epoch 139, train_loss: 0.0073
2023-05-31 01:22:17 - eval: epoch: 139, acc1: 75.850%, acc5: 93.340%, test_loss: 1.0961, per_image_load_time: 0.064ms, per_image_inference_time: 0.044ms
2023-05-31 01:22:17 - until epoch: 139, best_acc1: 75.970%
2023-05-31 01:22:17 - epoch 140 lr: 0.004000
2023-05-31 01:22:19 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 0.0050
2023-05-31 01:22:21 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 0.0045
2023-05-31 01:22:22 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 0.0169
2023-05-31 01:22:23 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.0033
2023-05-31 01:22:25 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 0.0064
2023-05-31 01:22:26 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.0037
2023-05-31 01:22:27 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 0.0068
2023-05-31 01:22:28 - train: epoch 140, train_loss: 0.0066
2023-05-31 01:22:30 - eval: epoch: 140, acc1: 76.030%, acc5: 93.390%, test_loss: 1.0939, per_image_load_time: 0.070ms, per_image_inference_time: 0.045ms
2023-05-31 01:22:30 - until epoch: 140, best_acc1: 76.030%
2023-05-31 01:22:30 - epoch 141 lr: 0.004000
2023-05-31 01:22:32 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.0074
2023-05-31 01:22:33 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 0.0029
2023-05-31 01:22:35 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.0208
2023-05-31 01:22:36 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 0.0117
2023-05-31 01:22:37 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 0.0094
2023-05-31 01:22:39 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 0.0043
2023-05-31 01:22:40 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.0044
2023-05-31 01:22:41 - train: epoch 141, train_loss: 0.0065
2023-05-31 01:22:42 - eval: epoch: 141, acc1: 76.040%, acc5: 93.680%, test_loss: 1.0964, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:22:43 - until epoch: 141, best_acc1: 76.040%
2023-05-31 01:22:43 - epoch 142 lr: 0.004000
2023-05-31 01:22:45 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 0.0035
2023-05-31 01:22:46 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.0061
2023-05-31 01:22:47 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.0045
2023-05-31 01:22:48 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 0.0047
2023-05-31 01:22:50 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 0.0083
2023-05-31 01:22:51 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:22:52 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 0.0036
2023-05-31 01:22:53 - train: epoch 142, train_loss: 0.0064
2023-05-31 01:22:55 - eval: epoch: 142, acc1: 76.250%, acc5: 93.550%, test_loss: 1.0838, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:22:55 - until epoch: 142, best_acc1: 76.250%
2023-05-31 01:22:55 - epoch 143 lr: 0.004000
2023-05-31 01:22:57 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 0.0035
2023-05-31 01:22:58 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 0.0079
2023-05-31 01:23:00 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 0.0075
2023-05-31 01:23:01 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 0.0109
2023-05-31 01:23:02 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:23:04 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 0.0077
2023-05-31 01:23:05 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.0043
2023-05-31 01:23:06 - train: epoch 143, train_loss: 0.0059
2023-05-31 01:23:07 - eval: epoch: 143, acc1: 76.100%, acc5: 93.600%, test_loss: 1.0780, per_image_load_time: 0.063ms, per_image_inference_time: 0.044ms
2023-05-31 01:23:08 - until epoch: 143, best_acc1: 76.250%
2023-05-31 01:23:08 - epoch 144 lr: 0.004000
2023-05-31 01:23:10 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.0037
2023-05-31 01:23:11 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:23:12 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 0.0063
2023-05-31 01:23:14 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 0.0076
2023-05-31 01:23:15 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 0.0310
2023-05-31 01:23:16 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.0035
2023-05-31 01:23:18 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 0.0030
2023-05-31 01:23:19 - train: epoch 144, train_loss: 0.0063
2023-05-31 01:23:20 - eval: epoch: 144, acc1: 76.210%, acc5: 93.610%, test_loss: 1.0765, per_image_load_time: 0.069ms, per_image_inference_time: 0.047ms
2023-05-31 01:23:20 - until epoch: 144, best_acc1: 76.250%
2023-05-31 01:23:20 - epoch 145 lr: 0.004000
2023-05-31 01:23:22 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.0084
2023-05-31 01:23:24 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 0.0129
2023-05-31 01:23:25 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.0031
2023-05-31 01:23:26 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 0.0048
2023-05-31 01:23:27 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.0033
2023-05-31 01:23:29 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.0039
2023-05-31 01:23:30 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.0052
2023-05-31 01:23:31 - train: epoch 145, train_loss: 0.0059
2023-05-31 01:23:32 - eval: epoch: 145, acc1: 76.080%, acc5: 93.570%, test_loss: 1.0740, per_image_load_time: 0.070ms, per_image_inference_time: 0.045ms
2023-05-31 01:23:33 - until epoch: 145, best_acc1: 76.250%
2023-05-31 01:23:33 - epoch 146 lr: 0.004000
2023-05-31 01:23:35 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.0086
2023-05-31 01:23:36 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 0.0025
2023-05-31 01:23:37 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 0.0088
2023-05-31 01:23:39 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 0.0052
2023-05-31 01:23:40 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 0.0061
2023-05-31 01:23:41 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 0.0036
2023-05-31 01:23:43 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.0030
2023-05-31 01:23:44 - train: epoch 146, train_loss: 0.0060
2023-05-31 01:23:45 - eval: epoch: 146, acc1: 76.220%, acc5: 93.610%, test_loss: 1.0735, per_image_load_time: 0.070ms, per_image_inference_time: 0.049ms
2023-05-31 01:23:45 - until epoch: 146, best_acc1: 76.250%
2023-05-31 01:23:45 - epoch 147 lr: 0.004000
2023-05-31 01:23:47 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 0.0041
2023-05-31 01:23:49 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 0.0036
2023-05-31 01:23:50 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 0.0073
2023-05-31 01:23:51 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 0.0059
2023-05-31 01:23:53 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 0.0071
2023-05-31 01:23:54 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 0.0055
2023-05-31 01:23:55 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 0.0054
2023-05-31 01:23:56 - train: epoch 147, train_loss: 0.0055
2023-05-31 01:23:58 - eval: epoch: 147, acc1: 76.280%, acc5: 93.560%, test_loss: 1.0740, per_image_load_time: 0.075ms, per_image_inference_time: 0.045ms
2023-05-31 01:23:58 - until epoch: 147, best_acc1: 76.280%
2023-05-31 01:23:58 - epoch 148 lr: 0.004000
2023-05-31 01:24:01 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 0.0056
2023-05-31 01:24:02 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 0.0050
2023-05-31 01:24:03 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.0048
2023-05-31 01:24:05 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 0.0025
2023-05-31 01:24:06 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 0.0038
2023-05-31 01:24:07 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 0.0041
2023-05-31 01:24:09 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 0.0101
2023-05-31 01:24:10 - train: epoch 148, train_loss: 0.0056
2023-05-31 01:24:11 - eval: epoch: 148, acc1: 76.380%, acc5: 93.350%, test_loss: 1.0708, per_image_load_time: 0.080ms, per_image_inference_time: 0.047ms
2023-05-31 01:24:12 - until epoch: 148, best_acc1: 76.380%
2023-05-31 01:24:12 - epoch 149 lr: 0.004000
2023-05-31 01:24:14 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 0.0065
2023-05-31 01:24:15 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 0.0044
2023-05-31 01:24:17 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.0056
2023-05-31 01:24:18 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 0.0121
2023-05-31 01:24:19 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.0055
2023-05-31 01:24:21 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 0.0031
2023-05-31 01:24:22 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 0.0035
2023-05-31 01:24:23 - train: epoch 149, train_loss: 0.0056
2023-05-31 01:24:25 - eval: epoch: 149, acc1: 76.260%, acc5: 93.540%, test_loss: 1.0689, per_image_load_time: 0.076ms, per_image_inference_time: 0.047ms
2023-05-31 01:24:25 - until epoch: 149, best_acc1: 76.380%
2023-05-31 01:24:25 - epoch 150 lr: 0.004000
2023-05-31 01:24:27 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:24:28 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.0046
2023-05-31 01:24:29 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.0038
2023-05-31 01:24:31 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 0.0044
2023-05-31 01:24:32 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 0.0104
2023-05-31 01:24:33 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 0.0042
2023-05-31 01:24:35 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 0.0106
2023-05-31 01:24:36 - train: epoch 150, train_loss: 0.0055
2023-05-31 01:24:37 - eval: epoch: 150, acc1: 76.440%, acc5: 93.520%, test_loss: 1.0641, per_image_load_time: 0.076ms, per_image_inference_time: 0.045ms
2023-05-31 01:24:38 - until epoch: 150, best_acc1: 76.440%
2023-05-31 01:24:38 - epoch 151 lr: 0.004000
2023-05-31 01:24:40 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 0.0033
2023-05-31 01:24:41 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 0.0044
2023-05-31 01:24:43 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 0.0068
2023-05-31 01:24:44 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 0.0286
2023-05-31 01:24:45 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 0.0017
2023-05-31 01:24:47 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:24:48 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.0031
2023-05-31 01:24:49 - train: epoch 151, train_loss: 0.0052
2023-05-31 01:24:50 - eval: epoch: 151, acc1: 76.360%, acc5: 93.640%, test_loss: 1.0636, per_image_load_time: 0.068ms, per_image_inference_time: 0.043ms
2023-05-31 01:24:50 - until epoch: 151, best_acc1: 76.440%
2023-05-31 01:24:50 - epoch 152 lr: 0.004000
2023-05-31 01:24:53 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 0.0021
2023-05-31 01:24:54 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.0041
2023-05-31 01:24:55 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.0028
2023-05-31 01:24:56 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.0072
2023-05-31 01:24:58 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.0031
2023-05-31 01:24:59 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 0.0037
2023-05-31 01:25:00 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 0.0064
2023-05-31 01:25:02 - train: epoch 152, train_loss: 0.0052
2023-05-31 01:25:03 - eval: epoch: 152, acc1: 76.420%, acc5: 93.580%, test_loss: 1.0635, per_image_load_time: 0.066ms, per_image_inference_time: 0.044ms
2023-05-31 01:25:03 - until epoch: 152, best_acc1: 76.440%
2023-05-31 01:25:03 - epoch 153 lr: 0.004000
2023-05-31 01:25:05 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.0044
2023-05-31 01:25:06 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 0.0031
2023-05-31 01:25:08 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 0.0035
2023-05-31 01:25:09 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 0.0021
2023-05-31 01:25:10 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:25:12 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 0.0055
2023-05-31 01:25:13 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 0.0028
2023-05-31 01:25:14 - train: epoch 153, train_loss: 0.0052
2023-05-31 01:25:15 - eval: epoch: 153, acc1: 76.300%, acc5: 93.670%, test_loss: 1.0627, per_image_load_time: 0.077ms, per_image_inference_time: 0.044ms
2023-05-31 01:25:16 - until epoch: 153, best_acc1: 76.440%
2023-05-31 01:25:16 - epoch 154 lr: 0.004000
2023-05-31 01:25:18 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 0.0044
2023-05-31 01:25:19 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 0.0090
2023-05-31 01:25:20 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 0.0072
2023-05-31 01:25:22 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 0.0103
2023-05-31 01:25:23 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 0.0029
2023-05-31 01:25:24 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 0.0039
2023-05-31 01:25:25 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.0026
2023-05-31 01:25:27 - train: epoch 154, train_loss: 0.0055
2023-05-31 01:25:28 - eval: epoch: 154, acc1: 76.380%, acc5: 93.660%, test_loss: 1.0599, per_image_load_time: 0.072ms, per_image_inference_time: 0.045ms
2023-05-31 01:25:28 - until epoch: 154, best_acc1: 76.440%
2023-05-31 01:25:28 - epoch 155 lr: 0.004000
2023-05-31 01:25:30 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 0.0036
2023-05-31 01:25:32 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 0.0030
2023-05-31 01:25:33 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 0.0038
2023-05-31 01:25:34 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 0.0055
2023-05-31 01:25:35 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 0.0046
2023-05-31 01:25:37 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.0053
2023-05-31 01:25:38 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 0.0033
2023-05-31 01:25:39 - train: epoch 155, train_loss: 0.0050
2023-05-31 01:25:40 - eval: epoch: 155, acc1: 76.350%, acc5: 93.570%, test_loss: 1.0652, per_image_load_time: 0.069ms, per_image_inference_time: 0.045ms
2023-05-31 01:25:41 - until epoch: 155, best_acc1: 76.440%
2023-05-31 01:25:41 - epoch 156 lr: 0.004000
2023-05-31 01:25:43 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 0.0034
2023-05-31 01:25:44 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 0.0034
2023-05-31 01:25:45 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 0.0034
2023-05-31 01:25:47 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.0024
2023-05-31 01:25:48 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.0366
2023-05-31 01:25:49 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 0.0082
2023-05-31 01:25:50 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 0.0014
2023-05-31 01:25:51 - train: epoch 156, train_loss: 0.0054
2023-05-31 01:25:53 - eval: epoch: 156, acc1: 76.400%, acc5: 93.550%, test_loss: 1.0574, per_image_load_time: 0.066ms, per_image_inference_time: 0.045ms
2023-05-31 01:25:53 - until epoch: 156, best_acc1: 76.440%
2023-05-31 01:25:53 - epoch 157 lr: 0.004000
2023-05-31 01:25:55 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 0.0135
2023-05-31 01:25:56 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.0295
2023-05-31 01:25:58 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 0.0039
2023-05-31 01:25:59 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:26:00 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 0.0032
2023-05-31 01:26:01 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.0039
2023-05-31 01:26:03 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 0.0030
2023-05-31 01:26:04 - train: epoch 157, train_loss: 0.0048
2023-05-31 01:26:05 - eval: epoch: 157, acc1: 76.360%, acc5: 93.630%, test_loss: 1.0518, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 01:26:05 - until epoch: 157, best_acc1: 76.440%
2023-05-31 01:26:05 - epoch 158 lr: 0.004000
2023-05-31 01:26:07 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.0034
2023-05-31 01:26:09 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 0.0033
2023-05-31 01:26:10 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 0.0020
2023-05-31 01:26:11 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 0.0061
2023-05-31 01:26:13 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 0.0028
2023-05-31 01:26:14 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 0.0048
2023-05-31 01:26:15 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 0.0061
2023-05-31 01:26:16 - train: epoch 158, train_loss: 0.0050
2023-05-31 01:26:18 - eval: epoch: 158, acc1: 76.530%, acc5: 93.540%, test_loss: 1.0562, per_image_load_time: 0.072ms, per_image_inference_time: 0.048ms
2023-05-31 01:26:18 - until epoch: 158, best_acc1: 76.530%
2023-05-31 01:26:18 - epoch 159 lr: 0.004000
2023-05-31 01:26:20 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 0.0025
2023-05-31 01:26:21 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 0.0029
2023-05-31 01:26:23 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.0033
2023-05-31 01:26:24 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.0026
2023-05-31 01:26:25 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 0.0236
2023-05-31 01:26:26 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 0.0035
2023-05-31 01:26:28 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.0035
2023-05-31 01:26:29 - train: epoch 159, train_loss: 0.0049
2023-05-31 01:26:30 - eval: epoch: 159, acc1: 76.460%, acc5: 93.570%, test_loss: 1.0547, per_image_load_time: 0.068ms, per_image_inference_time: 0.043ms
2023-05-31 01:26:30 - until epoch: 159, best_acc1: 76.530%
2023-05-31 01:26:30 - epoch 160 lr: 0.004000
2023-05-31 01:26:32 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 0.0056
2023-05-31 01:26:34 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 0.0033
2023-05-31 01:26:35 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 0.0040
2023-05-31 01:26:36 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 0.0044
2023-05-31 01:26:38 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 0.0019
2023-05-31 01:26:39 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 0.0042
2023-05-31 01:26:40 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.0063
2023-05-31 01:26:41 - train: epoch 160, train_loss: 0.0049
2023-05-31 01:26:43 - eval: epoch: 160, acc1: 76.360%, acc5: 93.650%, test_loss: 1.0532, per_image_load_time: 0.068ms, per_image_inference_time: 0.046ms
2023-05-31 01:26:43 - until epoch: 160, best_acc1: 76.530%
2023-05-31 01:26:43 - epoch 161 lr: 0.000800
2023-05-31 01:26:45 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 0.0051
2023-05-31 01:26:46 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.0040
2023-05-31 01:26:47 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.0045
2023-05-31 01:26:49 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:26:50 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.0051
2023-05-31 01:26:51 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 0.0051
2023-05-31 01:26:52 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 0.0192
2023-05-31 01:26:54 - train: epoch 161, train_loss: 0.0047
2023-05-31 01:26:55 - eval: epoch: 161, acc1: 76.400%, acc5: 93.530%, test_loss: 1.0490, per_image_load_time: 0.072ms, per_image_inference_time: 0.046ms
2023-05-31 01:26:55 - until epoch: 161, best_acc1: 76.530%
2023-05-31 01:26:55 - epoch 162 lr: 0.000800
2023-05-31 01:26:57 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 0.0048
2023-05-31 01:26:59 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:27:00 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:27:01 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 0.0038
2023-05-31 01:27:02 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.0038
2023-05-31 01:27:04 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:27:05 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 0.0042
2023-05-31 01:27:06 - train: epoch 162, train_loss: 0.0046
2023-05-31 01:27:08 - eval: epoch: 162, acc1: 76.420%, acc5: 93.670%, test_loss: 1.0460, per_image_load_time: 0.071ms, per_image_inference_time: 0.052ms
2023-05-31 01:27:08 - until epoch: 162, best_acc1: 76.530%
2023-05-31 01:27:08 - epoch 163 lr: 0.000800
2023-05-31 01:27:10 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 0.0085
2023-05-31 01:27:11 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:27:12 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 01:27:14 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 01:27:15 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:27:16 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 0.0017
2023-05-31 01:27:18 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 0.0057
2023-05-31 01:27:19 - train: epoch 163, train_loss: 0.0043
2023-05-31 01:27:20 - eval: epoch: 163, acc1: 76.570%, acc5: 93.630%, test_loss: 1.0416, per_image_load_time: 0.069ms, per_image_inference_time: 0.045ms
2023-05-31 01:27:20 - until epoch: 163, best_acc1: 76.570%
2023-05-31 01:27:20 - epoch 164 lr: 0.000800
2023-05-31 01:27:22 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 0.0106
2023-05-31 01:27:24 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:27:25 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:27:26 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 0.0013
2023-05-31 01:27:28 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.0048
2023-05-31 01:27:29 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 01:27:30 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 0.0020
2023-05-31 01:27:31 - train: epoch 164, train_loss: 0.0046
2023-05-31 01:27:32 - eval: epoch: 164, acc1: 76.510%, acc5: 93.670%, test_loss: 1.0440, per_image_load_time: 0.071ms, per_image_inference_time: 0.045ms
2023-05-31 01:27:33 - until epoch: 164, best_acc1: 76.570%
2023-05-31 01:27:33 - epoch 165 lr: 0.000800
2023-05-31 01:27:35 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:27:36 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:27:37 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 0.0098
2023-05-31 01:27:39 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:27:40 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 0.0067
2023-05-31 01:27:41 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.0064
2023-05-31 01:27:42 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:27:44 - train: epoch 165, train_loss: 0.0045
2023-05-31 01:27:45 - eval: epoch: 165, acc1: 76.470%, acc5: 93.670%, test_loss: 1.0464, per_image_load_time: 0.068ms, per_image_inference_time: 0.046ms
2023-05-31 01:27:45 - until epoch: 165, best_acc1: 76.570%
2023-05-31 01:27:45 - epoch 166 lr: 0.000800
2023-05-31 01:27:47 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:27:48 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:27:50 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 0.0129
2023-05-31 01:27:51 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:27:52 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 0.0044
2023-05-31 01:27:53 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:27:55 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 0.0042
2023-05-31 01:27:56 - train: epoch 166, train_loss: 0.0041
2023-05-31 01:27:57 - eval: epoch: 166, acc1: 76.610%, acc5: 93.740%, test_loss: 1.0469, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:27:58 - until epoch: 166, best_acc1: 76.610%
2023-05-31 01:27:58 - epoch 167 lr: 0.000800
2023-05-31 01:28:00 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.0037
2023-05-31 01:28:01 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:28:03 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:28:04 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 0.0017
2023-05-31 01:28:05 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 0.0019
2023-05-31 01:28:06 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.0046
2023-05-31 01:28:08 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:28:09 - train: epoch 167, train_loss: 0.0042
2023-05-31 01:28:10 - eval: epoch: 167, acc1: 76.640%, acc5: 93.730%, test_loss: 1.0423, per_image_load_time: 0.066ms, per_image_inference_time: 0.045ms
2023-05-31 01:28:10 - until epoch: 167, best_acc1: 76.640%
2023-05-31 01:28:10 - epoch 168 lr: 0.000800
2023-05-31 01:28:12 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:28:14 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 0.0054
2023-05-31 01:28:15 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:28:16 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 0.0023
2023-05-31 01:28:18 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:28:19 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:28:20 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 0.0054
2023-05-31 01:28:21 - train: epoch 168, train_loss: 0.0041
2023-05-31 01:28:22 - eval: epoch: 168, acc1: 76.550%, acc5: 93.750%, test_loss: 1.0422, per_image_load_time: 0.071ms, per_image_inference_time: 0.043ms
2023-05-31 01:28:23 - until epoch: 168, best_acc1: 76.640%
2023-05-31 01:28:23 - epoch 169 lr: 0.000800
2023-05-31 01:28:25 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:28:26 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 0.0042
2023-05-31 01:28:27 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 0.0069
2023-05-31 01:28:29 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 0.0017
2023-05-31 01:28:30 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.0040
2023-05-31 01:28:31 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:28:32 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.0023
2023-05-31 01:28:33 - train: epoch 169, train_loss: 0.0040
2023-05-31 01:28:35 - eval: epoch: 169, acc1: 76.630%, acc5: 93.630%, test_loss: 1.0462, per_image_load_time: 0.071ms, per_image_inference_time: 0.045ms
2023-05-31 01:28:35 - until epoch: 169, best_acc1: 76.640%
2023-05-31 01:28:35 - epoch 170 lr: 0.000800
2023-05-31 01:28:37 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 0.0066
2023-05-31 01:28:39 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 0.0079
2023-05-31 01:28:40 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 0.0025
2023-05-31 01:28:41 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:28:42 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 0.0071
2023-05-31 01:28:44 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 0.0022
2023-05-31 01:28:45 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:28:46 - train: epoch 170, train_loss: 0.0040
2023-05-31 01:28:47 - eval: epoch: 170, acc1: 76.770%, acc5: 93.630%, test_loss: 1.0405, per_image_load_time: 0.065ms, per_image_inference_time: 0.046ms
2023-05-31 01:28:48 - until epoch: 170, best_acc1: 76.770%
2023-05-31 01:28:48 - epoch 171 lr: 0.000800
2023-05-31 01:28:50 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.0019
2023-05-31 01:28:51 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 0.0037
2023-05-31 01:28:52 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.0039
2023-05-31 01:28:54 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:28:55 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.0037
2023-05-31 01:28:56 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 0.0047
2023-05-31 01:28:57 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 0.0041
2023-05-31 01:28:59 - train: epoch 171, train_loss: 0.0041
2023-05-31 01:29:00 - eval: epoch: 171, acc1: 76.570%, acc5: 93.550%, test_loss: 1.0430, per_image_load_time: 0.071ms, per_image_inference_time: 0.043ms
2023-05-31 01:29:00 - until epoch: 171, best_acc1: 76.770%
2023-05-31 01:29:00 - epoch 172 lr: 0.000800
2023-05-31 01:29:02 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:29:03 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.0136
2023-05-31 01:29:05 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:29:06 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 0.0056
2023-05-31 01:29:07 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 01:29:09 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 0.0123
2023-05-31 01:29:10 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:29:11 - train: epoch 172, train_loss: 0.0041
2023-05-31 01:29:12 - eval: epoch: 172, acc1: 76.610%, acc5: 93.660%, test_loss: 1.0411, per_image_load_time: 0.069ms, per_image_inference_time: 0.048ms
2023-05-31 01:29:13 - until epoch: 172, best_acc1: 76.770%
2023-05-31 01:29:13 - epoch 173 lr: 0.000800
2023-05-31 01:29:15 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:29:16 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.0069
2023-05-31 01:29:17 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:29:18 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 0.0060
2023-05-31 01:29:20 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:29:21 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.0065
2023-05-31 01:29:22 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 0.0063
2023-05-31 01:29:23 - train: epoch 173, train_loss: 0.0041
2023-05-31 01:29:25 - eval: epoch: 173, acc1: 76.740%, acc5: 93.640%, test_loss: 1.0404, per_image_load_time: 0.073ms, per_image_inference_time: 0.043ms
2023-05-31 01:29:25 - until epoch: 173, best_acc1: 76.770%
2023-05-31 01:29:25 - epoch 174 lr: 0.000800
2023-05-31 01:29:27 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:29:28 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:29:29 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.0051
2023-05-31 01:29:31 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 01:29:32 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 0.0050
2023-05-31 01:29:33 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:29:35 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.0016
2023-05-31 01:29:36 - train: epoch 174, train_loss: 0.0040
2023-05-31 01:29:37 - eval: epoch: 174, acc1: 76.530%, acc5: 93.720%, test_loss: 1.0391, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:29:37 - until epoch: 174, best_acc1: 76.770%
2023-05-31 01:29:37 - epoch 175 lr: 0.000800
2023-05-31 01:29:39 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 0.0036
2023-05-31 01:29:41 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 0.0060
2023-05-31 01:29:42 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:29:43 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.0042
2023-05-31 01:29:45 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 0.0058
2023-05-31 01:29:46 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:29:47 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:29:48 - train: epoch 175, train_loss: 0.0039
2023-05-31 01:29:49 - eval: epoch: 175, acc1: 76.500%, acc5: 93.640%, test_loss: 1.0390, per_image_load_time: 0.064ms, per_image_inference_time: 0.043ms
2023-05-31 01:29:50 - until epoch: 175, best_acc1: 76.770%
2023-05-31 01:29:50 - epoch 176 lr: 0.000800
2023-05-31 01:29:52 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 0.0067
2023-05-31 01:29:53 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 0.0081
2023-05-31 01:29:55 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 0.0054
2023-05-31 01:29:56 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:29:57 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:29:58 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:30:00 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:30:01 - train: epoch 176, train_loss: 0.0039
2023-05-31 01:30:02 - eval: epoch: 176, acc1: 76.600%, acc5: 93.670%, test_loss: 1.0386, per_image_load_time: 0.062ms, per_image_inference_time: 0.043ms
2023-05-31 01:30:02 - until epoch: 176, best_acc1: 76.770%
2023-05-31 01:30:02 - epoch 177 lr: 0.000800
2023-05-31 01:30:04 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.0039
2023-05-31 01:30:06 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:30:07 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.0086
2023-05-31 01:30:08 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:30:10 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.0086
2023-05-31 01:30:11 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 0.0053
2023-05-31 01:30:12 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.0061
2023-05-31 01:30:13 - train: epoch 177, train_loss: 0.0038
2023-05-31 01:30:15 - eval: epoch: 177, acc1: 76.430%, acc5: 93.630%, test_loss: 1.0374, per_image_load_time: 0.070ms, per_image_inference_time: 0.045ms
2023-05-31 01:30:15 - until epoch: 177, best_acc1: 76.770%
2023-05-31 01:30:15 - epoch 178 lr: 0.000800
2023-05-31 01:30:17 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.0016
2023-05-31 01:30:18 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 0.0037
2023-05-31 01:30:19 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 0.0025
2023-05-31 01:30:21 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:30:22 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:30:23 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 0.0047
2023-05-31 01:30:25 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 01:30:26 - train: epoch 178, train_loss: 0.0040
2023-05-31 01:30:27 - eval: epoch: 178, acc1: 76.450%, acc5: 93.690%, test_loss: 1.0402, per_image_load_time: 0.067ms, per_image_inference_time: 0.046ms
2023-05-31 01:30:27 - until epoch: 178, best_acc1: 76.770%
2023-05-31 01:30:27 - epoch 179 lr: 0.000800
2023-05-31 01:30:29 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 0.0086
2023-05-31 01:30:31 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:30:32 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 0.0115
2023-05-31 01:30:33 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:30:35 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:30:36 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.0173
2023-05-31 01:30:37 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 0.0039
2023-05-31 01:30:38 - train: epoch 179, train_loss: 0.0041
2023-05-31 01:30:39 - eval: epoch: 179, acc1: 76.620%, acc5: 93.620%, test_loss: 1.0431, per_image_load_time: 0.063ms, per_image_inference_time: 0.046ms
2023-05-31 01:30:40 - until epoch: 179, best_acc1: 76.770%
2023-05-31 01:30:40 - epoch 180 lr: 0.000800
2023-05-31 01:30:42 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 0.0037
2023-05-31 01:30:43 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.0036
2023-05-31 01:30:44 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:30:46 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:30:47 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:30:48 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 0.0111
2023-05-31 01:30:49 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.0023
2023-05-31 01:30:51 - train: epoch 180, train_loss: 0.0042
2023-05-31 01:30:52 - eval: epoch: 180, acc1: 76.690%, acc5: 93.710%, test_loss: 1.0409, per_image_load_time: 0.068ms, per_image_inference_time: 0.045ms
2023-05-31 01:30:52 - until epoch: 180, best_acc1: 76.770%
2023-05-31 01:30:52 - epoch 181 lr: 0.000800
2023-05-31 01:30:54 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 0.0113
2023-05-31 01:30:55 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:30:57 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:30:58 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:30:59 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.0054
2023-05-31 01:31:01 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 0.0025
2023-05-31 01:31:02 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.0036
2023-05-31 01:31:03 - train: epoch 181, train_loss: 0.0039
2023-05-31 01:31:04 - eval: epoch: 181, acc1: 76.550%, acc5: 93.670%, test_loss: 1.0353, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:31:04 - until epoch: 181, best_acc1: 76.770%
2023-05-31 01:31:04 - epoch 182 lr: 0.000800
2023-05-31 01:31:07 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 0.0079
2023-05-31 01:31:08 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 0.0059
2023-05-31 01:31:09 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 0.0055
2023-05-31 01:31:11 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:31:12 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:31:13 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 0.0154
2023-05-31 01:31:14 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 0.0046
2023-05-31 01:31:15 - train: epoch 182, train_loss: 0.0039
2023-05-31 01:31:17 - eval: epoch: 182, acc1: 76.600%, acc5: 93.750%, test_loss: 1.0384, per_image_load_time: 0.072ms, per_image_inference_time: 0.044ms
2023-05-31 01:31:17 - until epoch: 182, best_acc1: 76.770%
2023-05-31 01:31:17 - epoch 183 lr: 0.000800
2023-05-31 01:31:19 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 01:31:20 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.0022
2023-05-31 01:31:22 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:31:23 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:31:24 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:31:25 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:31:27 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:31:28 - train: epoch 183, train_loss: 0.0041
2023-05-31 01:31:29 - eval: epoch: 183, acc1: 76.590%, acc5: 93.680%, test_loss: 1.0352, per_image_load_time: 0.065ms, per_image_inference_time: 0.047ms
2023-05-31 01:31:29 - until epoch: 183, best_acc1: 76.770%
2023-05-31 01:31:29 - epoch 184 lr: 0.000800
2023-05-31 01:31:31 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 0.0049
2023-05-31 01:31:33 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:31:34 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:31:35 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:31:37 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:31:38 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.0124
2023-05-31 01:31:39 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:31:40 - train: epoch 184, train_loss: 0.0039
2023-05-31 01:31:41 - eval: epoch: 184, acc1: 76.710%, acc5: 93.660%, test_loss: 1.0373, per_image_load_time: 0.065ms, per_image_inference_time: 0.044ms
2023-05-31 01:31:42 - until epoch: 184, best_acc1: 76.770%
2023-05-31 01:31:42 - epoch 185 lr: 0.000800
2023-05-31 01:31:44 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:31:45 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 0.0136
2023-05-31 01:31:46 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:31:48 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:31:49 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:31:50 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:31:51 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 0.0055
2023-05-31 01:31:53 - train: epoch 185, train_loss: 0.0037
2023-05-31 01:31:54 - eval: epoch: 185, acc1: 76.620%, acc5: 93.700%, test_loss: 1.0325, per_image_load_time: 0.069ms, per_image_inference_time: 0.043ms
2023-05-31 01:31:54 - until epoch: 185, best_acc1: 76.770%
2023-05-31 01:31:54 - epoch 186 lr: 0.000800
2023-05-31 01:31:56 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:31:57 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.0017
2023-05-31 01:31:59 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 0.0124
2023-05-31 01:32:00 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:32:01 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 0.0047
2023-05-31 01:32:03 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 0.0051
2023-05-31 01:32:04 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 0.0020
2023-05-31 01:32:05 - train: epoch 186, train_loss: 0.0038
2023-05-31 01:32:06 - eval: epoch: 186, acc1: 76.650%, acc5: 93.720%, test_loss: 1.0305, per_image_load_time: 0.070ms, per_image_inference_time: 0.046ms
2023-05-31 01:32:07 - until epoch: 186, best_acc1: 76.770%
2023-05-31 01:32:07 - epoch 187 lr: 0.000800
2023-05-31 01:32:09 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:32:10 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.0045
2023-05-31 01:32:11 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:32:12 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 0.0024
2023-05-31 01:32:14 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.0042
2023-05-31 01:32:15 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:32:16 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:32:17 - train: epoch 187, train_loss: 0.0038
2023-05-31 01:32:19 - eval: epoch: 187, acc1: 76.770%, acc5: 93.710%, test_loss: 1.0327, per_image_load_time: 0.072ms, per_image_inference_time: 0.043ms
2023-05-31 01:32:19 - until epoch: 187, best_acc1: 76.770%
2023-05-31 01:32:19 - epoch 188 lr: 0.000800
2023-05-31 01:32:21 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:32:22 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:32:24 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:32:25 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:32:26 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:32:28 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 0.0020
2023-05-31 01:32:29 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:32:30 - train: epoch 188, train_loss: 0.0037
2023-05-31 01:32:31 - eval: epoch: 188, acc1: 76.740%, acc5: 93.750%, test_loss: 1.0372, per_image_load_time: 0.079ms, per_image_inference_time: 0.043ms
2023-05-31 01:32:32 - until epoch: 188, best_acc1: 76.770%
2023-05-31 01:32:32 - epoch 189 lr: 0.000800
2023-05-31 01:32:34 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.0053
2023-05-31 01:32:35 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 0.0022
2023-05-31 01:32:36 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:32:38 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 0.0042
2023-05-31 01:32:39 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:32:40 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:32:42 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:32:43 - train: epoch 189, train_loss: 0.0039
2023-05-31 01:32:44 - eval: epoch: 189, acc1: 76.710%, acc5: 93.750%, test_loss: 1.0310, per_image_load_time: 0.069ms, per_image_inference_time: 0.047ms
2023-05-31 01:32:44 - until epoch: 189, best_acc1: 76.770%
2023-05-31 01:32:44 - epoch 190 lr: 0.000800
2023-05-31 01:32:46 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:32:48 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 0.0036
2023-05-31 01:32:49 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 0.0135
2023-05-31 01:32:50 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.0063
2023-05-31 01:32:51 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 0.0066
2023-05-31 01:32:53 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:32:54 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:32:55 - train: epoch 190, train_loss: 0.0040
2023-05-31 01:32:57 - eval: epoch: 190, acc1: 76.870%, acc5: 93.680%, test_loss: 1.0343, per_image_load_time: 0.070ms, per_image_inference_time: 0.048ms
2023-05-31 01:32:57 - until epoch: 190, best_acc1: 76.870%
2023-05-31 01:32:57 - epoch 191 lr: 0.000800
2023-05-31 01:32:59 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:33:00 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 0.0019
2023-05-31 01:33:02 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:33:03 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 0.0036
2023-05-31 01:33:04 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.0044
2023-05-31 01:33:06 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:33:07 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:33:08 - train: epoch 191, train_loss: 0.0039
2023-05-31 01:33:09 - eval: epoch: 191, acc1: 76.750%, acc5: 93.720%, test_loss: 1.0356, per_image_load_time: 0.082ms, per_image_inference_time: 0.050ms
2023-05-31 01:33:10 - until epoch: 191, best_acc1: 76.870%
2023-05-31 01:33:10 - epoch 192 lr: 0.000800
2023-05-31 01:33:12 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 0.0038
2023-05-31 01:33:13 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 0.0019
2023-05-31 01:33:15 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:33:16 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:33:17 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 0.0034
2023-05-31 01:33:19 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 0.0016
2023-05-31 01:33:20 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 0.0025
2023-05-31 01:33:21 - train: epoch 192, train_loss: 0.0037
2023-05-31 01:33:22 - eval: epoch: 192, acc1: 76.700%, acc5: 93.680%, test_loss: 1.0337, per_image_load_time: 0.069ms, per_image_inference_time: 0.045ms
2023-05-31 01:33:22 - until epoch: 192, best_acc1: 76.870%
2023-05-31 01:33:22 - epoch 193 lr: 0.000800
2023-05-31 01:33:24 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 0.0020
2023-05-31 01:33:26 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 0.0021
2023-05-31 01:33:27 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:33:28 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:33:30 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:33:31 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:33:32 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 0.0076
2023-05-31 01:33:33 - train: epoch 193, train_loss: 0.0039
2023-05-31 01:33:35 - eval: epoch: 193, acc1: 76.550%, acc5: 93.690%, test_loss: 1.0360, per_image_load_time: 0.065ms, per_image_inference_time: 0.049ms
2023-05-31 01:33:35 - until epoch: 193, best_acc1: 76.870%
2023-05-31 01:33:35 - epoch 194 lr: 0.000800
2023-05-31 01:33:37 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:33:38 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 0.0045
2023-05-31 01:33:40 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.0088
2023-05-31 01:33:41 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 0.0025
2023-05-31 01:33:42 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:33:43 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.0090
2023-05-31 01:33:45 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 0.0040
2023-05-31 01:33:46 - train: epoch 194, train_loss: 0.0037
2023-05-31 01:33:47 - eval: epoch: 194, acc1: 76.760%, acc5: 93.670%, test_loss: 1.0355, per_image_load_time: 0.067ms, per_image_inference_time: 0.046ms
2023-05-31 01:33:47 - until epoch: 194, best_acc1: 76.870%
2023-05-31 01:33:47 - epoch 195 lr: 0.000800
2023-05-31 01:33:50 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 0.0120
2023-05-31 01:33:51 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:33:52 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:33:53 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:33:55 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 0.0038
2023-05-31 01:33:56 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:33:57 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.0016
2023-05-31 01:33:58 - train: epoch 195, train_loss: 0.0039
2023-05-31 01:34:00 - eval: epoch: 195, acc1: 76.670%, acc5: 93.710%, test_loss: 1.0325, per_image_load_time: 0.068ms, per_image_inference_time: 0.043ms
2023-05-31 01:34:00 - until epoch: 195, best_acc1: 76.870%
2023-05-31 01:34:00 - epoch 196 lr: 0.000800
2023-05-31 01:34:02 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:34:03 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:34:04 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 0.0105
2023-05-31 01:34:06 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.0047
2023-05-31 01:34:07 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.0031
2023-05-31 01:34:08 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.0029
2023-05-31 01:34:10 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 0.0014
2023-05-31 01:34:11 - train: epoch 196, train_loss: 0.0039
2023-05-31 01:34:12 - eval: epoch: 196, acc1: 76.660%, acc5: 93.750%, test_loss: 1.0289, per_image_load_time: 0.075ms, per_image_inference_time: 0.044ms
2023-05-31 01:34:12 - until epoch: 196, best_acc1: 76.870%
2023-05-31 01:34:12 - epoch 197 lr: 0.000800
2023-05-31 01:34:14 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.0014
2023-05-31 01:34:16 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:34:17 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 0.0040
2023-05-31 01:34:18 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 0.0022
2023-05-31 01:34:20 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.0027
2023-05-31 01:34:21 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:34:22 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 0.0023
2023-05-31 01:34:23 - train: epoch 197, train_loss: 0.0040
2023-05-31 01:34:25 - eval: epoch: 197, acc1: 76.610%, acc5: 93.690%, test_loss: 1.0325, per_image_load_time: 0.077ms, per_image_inference_time: 0.046ms
2023-05-31 01:34:25 - until epoch: 197, best_acc1: 76.870%
2023-05-31 01:34:25 - epoch 198 lr: 0.000800
2023-05-31 01:34:27 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 0.0058
2023-05-31 01:34:28 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.0032
2023-05-31 01:34:30 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.0035
2023-05-31 01:34:31 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 0.0090
2023-05-31 01:34:32 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 0.0069
2023-05-31 01:34:33 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 0.0018
2023-05-31 01:34:35 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.0022
2023-05-31 01:34:36 - train: epoch 198, train_loss: 0.0037
2023-05-31 01:34:37 - eval: epoch: 198, acc1: 76.700%, acc5: 93.730%, test_loss: 1.0320, per_image_load_time: 0.067ms, per_image_inference_time: 0.048ms
2023-05-31 01:34:37 - until epoch: 198, best_acc1: 76.870%
2023-05-31 01:34:37 - epoch 199 lr: 0.000800
2023-05-31 01:34:39 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.0019
2023-05-31 01:34:41 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.0013
2023-05-31 01:34:42 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 0.0047
2023-05-31 01:34:43 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.0023
2023-05-31 01:34:45 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 0.0033
2023-05-31 01:34:46 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 0.0152
2023-05-31 01:34:47 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.0045
2023-05-31 01:34:48 - train: epoch 199, train_loss: 0.0037
2023-05-31 01:34:50 - eval: epoch: 199, acc1: 76.700%, acc5: 93.630%, test_loss: 1.0312, per_image_load_time: 0.085ms, per_image_inference_time: 0.046ms
2023-05-31 01:34:50 - until epoch: 199, best_acc1: 76.870%
2023-05-31 01:34:50 - epoch 200 lr: 0.000800
2023-05-31 01:34:52 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 0.0025
2023-05-31 01:34:53 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.0057
2023-05-31 01:34:55 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 0.0026
2023-05-31 01:34:56 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.0030
2023-05-31 01:34:57 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 0.0022
2023-05-31 01:34:59 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 0.0028
2023-05-31 01:35:00 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 0.0054
2023-05-31 01:35:01 - train: epoch 200, train_loss: 0.0036
2023-05-31 01:35:02 - eval: epoch: 200, acc1: 76.660%, acc5: 93.670%, test_loss: 1.0287, per_image_load_time: 0.071ms, per_image_inference_time: 0.044ms
2023-05-31 01:35:02 - until epoch: 200, best_acc1: 76.870%
2023-05-31 01:35:02 - train done. model: resnet18cifar, train time: 0.680 hours, best_acc1: 76.870%
2023-05-31 01:41:10 - network: resnet18cifar
2023-05-31 01:41:10 - num_classes: 100
2023-05-31 01:41:10 - input_image_size: 32
2023-05-31 01:41:10 - trained_model_path: 
2023-05-31 01:41:10 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:41:10 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:41:10 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f4bc0e147f0>
2023-05-31 01:41:10 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f4bc0e14af0>
2023-05-31 01:41:10 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f4bc0e149d0>
2023-05-31 01:41:10 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f4bc0e14a00>
2023-05-31 01:41:10 - seed: 0
2023-05-31 01:41:10 - batch_size: 128
2023-05-31 01:41:10 - num_workers: 16
2023-05-31 01:41:10 - accumulation_steps: 1
2023-05-31 01:41:10 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 01:41:10 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 01:41:10 - epochs: 200
2023-05-31 01:41:10 - print_interval: 50
2023-05-31 01:41:10 - sync_bn: False
2023-05-31 01:41:10 - apex: True
2023-05-31 01:41:10 - use_ema_model: False
2023-05-31 01:41:10 - ema_model_decay: 0.9999
2023-05-31 01:41:10 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 01:41:10 - gpus_num: 1
2023-05-31 01:41:10 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f4bc0e3bf30>
2023-05-31 01:41:10 - --------------------parameters--------------------
2023-05-31 01:41:10 - name: conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 01:41:10 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 01:41:10 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 01:41:10 - name: fc.weight, grad: True
2023-05-31 01:41:10 - name: fc.bias, grad: True
2023-05-31 01:41:10 - --------------------buffers--------------------
2023-05-31 01:41:10 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:10 - name: conv1.layer.1.running_var, grad: False
2023-05-31 01:41:10 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:10 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:10 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:10 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:10 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:10 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:10 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:10 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:10 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:10 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:10 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:10 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:10 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:10 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:10 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:10 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:10 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:10 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:10 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:41:11 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:41:11 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:41:11 - -----------no weight decay layers--------------
2023-05-31 01:41:11 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:41:11 - -------------weight decay layers---------------
2023-05-31 01:41:11 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:41:11 - epoch 001 lr: 0.100000
2023-05-31 01:41:18 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.1124
2023-05-31 01:41:19 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.1368
2023-05-31 01:41:20 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9642
2023-05-31 01:41:21 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7826
2023-05-31 01:41:23 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.7547
2023-05-31 01:41:24 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.6848
2023-05-31 01:41:25 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.6863
2023-05-31 01:41:27 - train: epoch 001, train_loss: 3.9080
2023-05-31 01:42:35 - network: resnet18cifar
2023-05-31 01:42:35 - num_classes: 100
2023-05-31 01:42:35 - input_image_size: 32
2023-05-31 01:42:35 - trained_model_path: 
2023-05-31 01:42:35 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:42:35 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:42:35 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f92cc3528b0>
2023-05-31 01:42:35 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f92cc352700>
2023-05-31 01:42:35 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f92cc352460>
2023-05-31 01:42:35 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f92cc3522b0>
2023-05-31 01:42:35 - seed: 0
2023-05-31 01:42:35 - batch_size: 128
2023-05-31 01:42:35 - num_workers: 16
2023-05-31 01:42:35 - accumulation_steps: 1
2023-05-31 01:42:35 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 01:42:35 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 01:42:35 - epochs: 200
2023-05-31 01:42:35 - print_interval: 50
2023-05-31 01:42:35 - sync_bn: False
2023-05-31 01:42:35 - apex: True
2023-05-31 01:42:35 - use_ema_model: False
2023-05-31 01:42:35 - ema_model_decay: 0.9999
2023-05-31 01:42:35 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 01:42:35 - gpus_num: 1
2023-05-31 01:42:35 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f92cc3354b0>
2023-05-31 01:42:35 - --------------------parameters--------------------
2023-05-31 01:42:35 - name: conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 01:42:35 - name: fc.weight, grad: True
2023-05-31 01:42:35 - name: fc.bias, grad: True
2023-05-31 01:42:35 - --------------------buffers--------------------
2023-05-31 01:42:35 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:42:35 - -----------no weight decay layers--------------
2023-05-31 01:42:35 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:42:35 - -------------weight decay layers---------------
2023-05-31 01:42:35 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:42:35 - epoch 001 lr: 0.100000
2023-05-31 01:42:42 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.0693
2023-05-31 01:42:43 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.0994
2023-05-31 01:42:44 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9196
2023-05-31 01:42:45 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7518
2023-05-31 01:42:47 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.7120
2023-05-31 01:42:48 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.6004
2023-05-31 01:42:49 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.5646
2023-05-31 01:42:50 - train: epoch 001, train_loss: 3.8798
2023-05-31 01:43:28 - network: resnet18cifar
2023-05-31 01:43:28 - num_classes: 100
2023-05-31 01:43:28 - input_image_size: 32
2023-05-31 01:43:28 - trained_model_path: 
2023-05-31 01:43:28 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:43:28 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:43:28 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f78af1aa8b0>
2023-05-31 01:43:28 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f78af1b33a0>
2023-05-31 01:43:28 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f78af1b3220>
2023-05-31 01:43:28 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f78af1b3310>
2023-05-31 01:43:28 - seed: 0
2023-05-31 01:43:28 - batch_size: 128
2023-05-31 01:43:28 - num_workers: 16
2023-05-31 01:43:28 - accumulation_steps: 1
2023-05-31 01:43:28 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 01:43:28 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 01:43:28 - epochs: 200
2023-05-31 01:43:28 - print_interval: 50
2023-05-31 01:43:28 - sync_bn: False
2023-05-31 01:43:28 - apex: True
2023-05-31 01:43:28 - use_ema_model: False
2023-05-31 01:43:28 - ema_model_decay: 0.9999
2023-05-31 01:43:28 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 01:43:28 - gpus_num: 1
2023-05-31 01:43:28 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f78af1abf30>
2023-05-31 01:43:28 - --------------------parameters--------------------
2023-05-31 01:43:28 - name: conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 01:43:28 - name: fc.weight, grad: True
2023-05-31 01:43:28 - name: fc.bias, grad: True
2023-05-31 01:43:28 - --------------------buffers--------------------
2023-05-31 01:43:28 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:43:28 - -----------no weight decay layers--------------
2023-05-31 01:43:28 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:43:28 - -------------weight decay layers---------------
2023-05-31 01:43:28 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:43:28 - epoch 001 lr: 0.100000
2023-05-31 01:43:35 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.0787
2023-05-31 01:43:36 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.0697
2023-05-31 01:43:37 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9082
2023-05-31 01:43:39 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7735
2023-05-31 01:43:40 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.7943
2023-05-31 01:43:41 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.6216
2023-05-31 01:43:42 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.6149
2023-05-31 01:43:43 - train: epoch 001, train_loss: 3.8902
2023-05-31 01:43:45 - eval: epoch: 001, acc1: 8.140%, acc5: 23.850%, test_loss: 4.3068, per_image_load_time: 0.069ms, per_image_inference_time: 0.048ms
2023-05-31 01:46:22 - network: resnet18cifar
2023-05-31 01:46:22 - num_classes: 100
2023-05-31 01:46:22 - input_image_size: 32
2023-05-31 01:46:22 - trained_model_path: 
2023-05-31 01:46:22 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:46:22 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:46:22 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f3d894bceb0>
2023-05-31 01:46:22 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f3daa364610>
2023-05-31 01:46:22 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f3daa3645b0>
2023-05-31 01:46:22 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f3d894bcbe0>
2023-05-31 01:46:22 - seed: 0
2023-05-31 01:46:22 - batch_size: 128
2023-05-31 01:46:22 - num_workers: 16
2023-05-31 01:46:22 - accumulation_steps: 1
2023-05-31 01:46:22 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 01:46:22 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 01:46:22 - epochs: 200
2023-05-31 01:46:22 - print_interval: 50
2023-05-31 01:46:22 - sync_bn: False
2023-05-31 01:46:22 - apex: True
2023-05-31 01:46:22 - use_ema_model: False
2023-05-31 01:46:22 - ema_model_decay: 0.9999
2023-05-31 01:46:22 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 01:46:22 - gpus_num: 1
2023-05-31 01:46:22 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f3d895858f0>
2023-05-31 01:46:22 - --------------------parameters--------------------
2023-05-31 01:46:22 - name: conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 01:46:22 - name: fc.weight, grad: True
2023-05-31 01:46:22 - name: fc.bias, grad: True
2023-05-31 01:46:22 - --------------------buffers--------------------
2023-05-31 01:46:22 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:46:22 - -----------no weight decay layers--------------
2023-05-31 01:46:22 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:46:22 - -------------weight decay layers---------------
2023-05-31 01:46:22 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:46:22 - epoch 001 lr: 0.100000
2023-05-31 01:46:29 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.1124
2023-05-31 01:46:30 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.1625
2023-05-31 01:46:32 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9195
2023-05-31 01:46:33 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7283
2023-05-31 01:46:34 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.6965
2023-05-31 01:46:35 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.6114
2023-05-31 01:46:37 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.5964
2023-05-31 01:46:38 - train: epoch 001, train_loss: 3.8827
2023-05-31 01:46:39 - eval: epoch: 001, acc1: 8.400%, acc5: 24.620%, test_loss: 4.3621, per_image_load_time: 0.067ms, per_image_inference_time: 0.045ms
2023-05-31 01:46:39 - until epoch: 001, best_acc1: 8.400%
2023-05-31 01:46:39 - epoch 002 lr: 0.100000
2023-05-31 01:46:41 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.3520
2023-05-31 01:46:43 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.1631
2023-05-31 01:46:44 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.2894
2023-05-31 01:46:45 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 3.3864
2023-05-31 01:46:47 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 3.0058
2023-05-31 01:46:48 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.3196
2023-05-31 01:46:49 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 2.8273
2023-05-31 01:46:50 - train: epoch 002, train_loss: 3.1894
2023-05-31 01:46:52 - eval: epoch: 002, acc1: 15.680%, acc5: 38.210%, test_loss: 3.8635, per_image_load_time: 0.070ms, per_image_inference_time: 0.048ms
2023-05-31 01:46:52 - until epoch: 002, best_acc1: 15.680%
2023-05-31 01:46:52 - epoch 003 lr: 0.100000
2023-05-31 01:46:54 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 2.8455
2023-05-31 01:46:56 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 2.7114
2023-05-31 01:46:57 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 2.7054
2023-05-31 01:46:58 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 2.3933
2023-05-31 01:46:59 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 2.5822
2023-05-31 01:47:01 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 2.8063
2023-05-31 01:47:02 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 2.4919
2023-05-31 01:47:03 - train: epoch 003, train_loss: 2.6460
2023-05-31 01:47:04 - eval: epoch: 003, acc1: 19.440%, acc5: 44.170%, test_loss: 3.6867, per_image_load_time: 0.072ms, per_image_inference_time: 0.047ms
2023-05-31 01:47:05 - until epoch: 003, best_acc1: 19.440%
2023-05-31 01:47:05 - epoch 004 lr: 0.100000
2023-05-31 01:47:07 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 2.3701
2023-05-31 01:47:08 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 2.4962
2023-05-31 01:47:10 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 2.2477
2023-05-31 01:47:11 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 2.5894
2023-05-31 01:47:12 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 2.1303
2023-05-31 01:47:13 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 2.2554
2023-05-31 01:47:15 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 1.8773
2023-05-31 01:47:16 - train: epoch 004, train_loss: 2.2669
2023-05-31 01:47:17 - eval: epoch: 004, acc1: 21.910%, acc5: 46.180%, test_loss: 3.6225, per_image_load_time: 0.078ms, per_image_inference_time: 0.046ms
2023-05-31 01:47:18 - until epoch: 004, best_acc1: 21.910%
2023-05-31 01:47:18 - epoch 005 lr: 0.100000
2023-05-31 01:47:20 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 2.0583
2023-05-31 01:47:21 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 2.0775
2023-05-31 01:47:22 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 1.8552
2023-05-31 01:47:23 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 2.1953
2023-05-31 01:47:25 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 1.7642
2023-05-31 01:47:26 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 1.6933
2023-05-31 01:47:27 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 1.6130
2023-05-31 01:47:28 - train: epoch 005, train_loss: 2.0025
2023-05-31 01:47:30 - eval: epoch: 005, acc1: 19.150%, acc5: 41.020%, test_loss: 4.1173, per_image_load_time: 0.079ms, per_image_inference_time: 0.051ms
2023-05-31 01:47:30 - until epoch: 005, best_acc1: 21.910%
2023-05-31 01:47:30 - epoch 006 lr: 0.100000
2023-05-31 01:47:32 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 1.8593
2023-05-31 01:47:33 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 1.7118
2023-05-31 01:47:35 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 1.9101
2023-05-31 01:47:36 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 1.8503
2023-05-31 01:47:37 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 1.6226
2023-05-31 01:47:38 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 1.5505
2023-05-31 01:47:40 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 1.6889
2023-05-31 01:47:41 - train: epoch 006, train_loss: 1.8128
2023-05-31 01:47:42 - eval: epoch: 006, acc1: 26.060%, acc5: 51.720%, test_loss: 3.6957, per_image_load_time: 0.069ms, per_image_inference_time: 0.048ms
2023-05-31 01:47:43 - until epoch: 006, best_acc1: 26.060%
2023-05-31 01:47:43 - epoch 007 lr: 0.100000
2023-05-31 01:47:45 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 1.8538
2023-05-31 01:47:46 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 1.6329
2023-05-31 01:47:47 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 1.6067
2023-05-31 01:47:49 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 1.5625
2023-05-31 01:47:50 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 1.5784
2023-05-31 01:47:51 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 1.1301
2023-05-31 01:47:52 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 1.6487
2023-05-31 01:47:53 - train: epoch 007, train_loss: 1.6794
2023-05-31 01:47:55 - eval: epoch: 007, acc1: 26.280%, acc5: 51.610%, test_loss: 3.5995, per_image_load_time: 0.071ms, per_image_inference_time: 0.048ms
2023-05-31 01:47:55 - until epoch: 007, best_acc1: 26.280%
2023-05-31 01:47:55 - epoch 008 lr: 0.100000
2023-05-31 01:47:57 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 1.6113
2023-05-31 01:47:59 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 1.4622
2023-05-31 01:48:00 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 1.4591
2023-05-31 01:48:01 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 1.3623
2023-05-31 01:48:03 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 1.3719
2023-05-31 01:48:04 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 1.5027
2023-05-31 01:48:05 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 1.5620
2023-05-31 01:48:06 - train: epoch 008, train_loss: 1.5701
2023-05-31 01:48:08 - eval: epoch: 008, acc1: 25.000%, acc5: 49.570%, test_loss: 3.8020, per_image_load_time: 0.067ms, per_image_inference_time: 0.048ms
2023-05-31 01:48:08 - until epoch: 008, best_acc1: 26.280%
2023-05-31 01:48:08 - epoch 009 lr: 0.100000
2023-05-31 01:48:10 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 1.3365
2023-05-31 01:48:11 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 1.5246
2023-05-31 01:48:12 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 1.5516
2023-05-31 01:48:14 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 1.4934
2023-05-31 01:48:15 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 1.6967
2023-05-31 01:48:16 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 1.2760
2023-05-31 01:48:18 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 1.6265
2023-05-31 01:48:19 - train: epoch 009, train_loss: 1.4905
2023-05-31 01:48:20 - eval: epoch: 009, acc1: 25.050%, acc5: 48.840%, test_loss: 3.7787, per_image_load_time: 0.076ms, per_image_inference_time: 0.058ms
2023-05-31 01:48:20 - until epoch: 009, best_acc1: 26.280%
2023-05-31 01:48:20 - epoch 010 lr: 0.100000
2023-05-31 01:48:22 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 1.6237
2023-05-31 01:48:24 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 1.3986
2023-05-31 01:48:25 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 1.1462
2023-05-31 01:48:26 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 1.3841
2023-05-31 01:48:27 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 1.6272
2023-05-31 01:48:29 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 1.4060
2023-05-31 01:48:30 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 1.2070
2023-05-31 01:48:31 - train: epoch 010, train_loss: 1.4156
2023-05-31 01:48:32 - eval: epoch: 010, acc1: 26.490%, acc5: 49.610%, test_loss: 3.7698, per_image_load_time: 0.071ms, per_image_inference_time: 0.048ms
2023-05-31 01:48:33 - until epoch: 010, best_acc1: 26.490%
2023-05-31 01:48:33 - epoch 011 lr: 0.100000
2023-05-31 01:48:35 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 1.4939
2023-05-31 01:48:36 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 1.0794
2023-05-31 01:48:38 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 1.5858
2023-05-31 01:48:39 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 1.2654
2023-05-31 01:48:40 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 1.3291
2023-05-31 01:48:41 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 1.1865
2023-05-31 01:48:43 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 1.4708
2023-05-31 01:48:44 - train: epoch 011, train_loss: 1.3585
2023-05-31 01:48:45 - eval: epoch: 011, acc1: 31.110%, acc5: 56.600%, test_loss: 3.3891, per_image_load_time: 0.073ms, per_image_inference_time: 0.049ms
2023-05-31 01:48:45 - until epoch: 011, best_acc1: 31.110%
2023-05-31 01:48:45 - epoch 012 lr: 0.100000
2023-05-31 01:48:48 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 1.2891
2023-05-31 01:48:49 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 1.5586
2023-05-31 01:48:50 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 1.2783
2023-05-31 01:48:51 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 1.6269
2023-05-31 01:48:53 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 1.2398
2023-05-31 01:48:54 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 1.4899
2023-05-31 01:48:55 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 1.2008
2023-05-31 01:48:56 - train: epoch 012, train_loss: 1.3058
2023-05-31 01:48:58 - eval: epoch: 012, acc1: 26.960%, acc5: 51.860%, test_loss: 3.6788, per_image_load_time: 0.076ms, per_image_inference_time: 0.051ms
2023-05-31 01:48:58 - until epoch: 012, best_acc1: 31.110%
2023-05-31 01:48:58 - epoch 013 lr: 0.100000
2023-05-31 01:49:00 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 1.0878
2023-05-31 01:49:01 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 1.3369
2023-05-31 01:49:03 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 1.4447
2023-05-31 01:49:04 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 1.1894
2023-05-31 01:49:05 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 1.4192
2023-05-31 01:49:07 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 1.2664
2023-05-31 01:49:08 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 1.0582
2023-05-31 01:49:09 - train: epoch 013, train_loss: 1.2779
2023-05-31 01:49:10 - eval: epoch: 013, acc1: 30.910%, acc5: 56.820%, test_loss: 3.4860, per_image_load_time: 0.071ms, per_image_inference_time: 0.046ms
2023-05-31 01:49:10 - until epoch: 013, best_acc1: 31.110%
2023-05-31 01:49:10 - epoch 014 lr: 0.100000
2023-05-31 01:49:13 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 1.0089
2023-05-31 01:49:14 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 1.0747
2023-05-31 01:49:15 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 1.1566
2023-05-31 01:49:16 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 1.1527
2023-05-31 01:49:18 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 1.1179
2023-05-31 01:49:19 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 1.3596
2023-05-31 01:49:20 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 1.2296
2023-05-31 01:49:21 - train: epoch 014, train_loss: 1.2326
2023-05-31 01:49:23 - eval: epoch: 014, acc1: 30.300%, acc5: 55.870%, test_loss: 3.5648, per_image_load_time: 0.073ms, per_image_inference_time: 0.048ms
2023-05-31 01:49:23 - until epoch: 014, best_acc1: 31.110%
2023-05-31 01:49:23 - epoch 015 lr: 0.100000
2023-05-31 01:49:25 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 0.8190
2023-05-31 01:49:26 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 1.4628
2023-05-31 01:49:28 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 1.5227
2023-05-31 01:49:29 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 1.3328
2023-05-31 01:49:30 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.1905
2023-05-31 01:49:31 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 1.2889
2023-05-31 01:49:33 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 1.3760
2023-05-31 01:49:34 - train: epoch 015, train_loss: 1.2052
2023-05-31 01:49:35 - eval: epoch: 015, acc1: 29.090%, acc5: 53.430%, test_loss: 3.7133, per_image_load_time: 0.069ms, per_image_inference_time: 0.047ms
2023-05-31 01:49:35 - until epoch: 015, best_acc1: 31.110%
2023-05-31 01:49:35 - epoch 016 lr: 0.100000
2023-05-31 01:49:37 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 1.1498
2023-05-31 01:49:39 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 1.1344
2023-05-31 01:49:40 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 1.1903
2023-05-31 01:49:41 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 1.1666
2023-05-31 01:49:42 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 1.0743
2023-05-31 01:49:44 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 1.0941
2023-05-31 01:49:45 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 1.0684
2023-05-31 01:49:46 - train: epoch 016, train_loss: 1.1619
2023-05-31 01:49:47 - eval: epoch: 016, acc1: 25.430%, acc5: 49.580%, test_loss: 4.0036, per_image_load_time: 0.076ms, per_image_inference_time: 0.046ms
2023-05-31 01:49:48 - until epoch: 016, best_acc1: 31.110%
2023-05-31 01:49:48 - epoch 017 lr: 0.100000
2023-05-31 01:49:50 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 0.8699
2023-05-31 01:49:51 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 1.1843
2023-05-31 01:49:53 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 0.9497
2023-05-31 01:49:54 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 1.0826
2023-05-31 01:49:55 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 1.2163
2023-05-31 01:49:56 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 1.5466
2023-05-31 01:49:58 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 0.9027
2023-05-31 01:49:59 - train: epoch 017, train_loss: 1.1535
2023-05-31 01:50:00 - eval: epoch: 017, acc1: 27.970%, acc5: 51.530%, test_loss: 3.6902, per_image_load_time: 0.078ms, per_image_inference_time: 0.044ms
2023-05-31 01:50:00 - until epoch: 017, best_acc1: 31.110%
2023-05-31 01:50:00 - epoch 018 lr: 0.100000
2023-05-31 01:50:03 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 1.0069
2023-05-31 01:50:04 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 0.8340
2023-05-31 01:50:05 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.2585
2023-05-31 01:50:06 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 0.9705
2023-05-31 01:50:08 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 1.1055
2023-05-31 01:50:09 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 0.9772
2023-05-31 01:50:10 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 1.1237
2023-05-31 01:50:11 - train: epoch 018, train_loss: 1.1189
2023-05-31 01:50:13 - eval: epoch: 018, acc1: 28.910%, acc5: 53.740%, test_loss: 3.6391, per_image_load_time: 0.073ms, per_image_inference_time: 0.048ms
2023-05-31 01:50:13 - until epoch: 018, best_acc1: 31.110%
2023-05-31 01:50:13 - epoch 019 lr: 0.100000
2023-05-31 01:50:15 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 0.9860
2023-05-31 01:50:16 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 0.8648
2023-05-31 01:50:18 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 1.3631
2023-05-31 01:50:19 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 1.2715
2023-05-31 01:50:20 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 1.0791
2023-05-31 01:50:22 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 1.1880
2023-05-31 01:50:23 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 1.1208
2023-05-31 01:50:24 - train: epoch 019, train_loss: 1.1002
2023-05-31 01:50:25 - eval: epoch: 019, acc1: 25.130%, acc5: 47.620%, test_loss: 4.0045, per_image_load_time: 0.068ms, per_image_inference_time: 0.051ms
2023-05-31 01:50:25 - until epoch: 019, best_acc1: 31.110%
2023-05-31 01:50:25 - epoch 020 lr: 0.100000
2023-05-31 01:50:28 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 1.1531
2023-05-31 01:50:29 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 1.0893
2023-05-31 01:50:30 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 1.2435
2023-05-31 01:50:31 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 1.0582
2023-05-31 01:50:33 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 1.0809
2023-05-31 01:50:34 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 1.1163
2023-05-31 01:50:35 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 0.9691
2023-05-31 01:50:36 - train: epoch 020, train_loss: 1.0841
2023-05-31 01:50:38 - eval: epoch: 020, acc1: 33.830%, acc5: 58.600%, test_loss: 3.3652, per_image_load_time: 0.067ms, per_image_inference_time: 0.050ms
2023-05-31 01:50:38 - until epoch: 020, best_acc1: 33.830%
2023-05-31 01:50:38 - epoch 021 lr: 0.100000
2023-05-31 01:50:40 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 0.9352
2023-05-31 01:50:41 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.1782
2023-05-31 01:50:43 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 1.1789
2023-05-31 01:50:44 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.2102
2023-05-31 01:50:45 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 1.0190
2023-05-31 01:50:46 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 1.1665
2023-05-31 01:50:48 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 1.1603
2023-05-31 01:50:49 - train: epoch 021, train_loss: 1.0714
2023-05-31 01:50:50 - eval: epoch: 021, acc1: 31.650%, acc5: 56.700%, test_loss: 3.5815, per_image_load_time: 0.077ms, per_image_inference_time: 0.047ms
2023-05-31 01:50:50 - until epoch: 021, best_acc1: 33.830%
2023-05-31 01:50:50 - epoch 022 lr: 0.100000
2023-05-31 01:50:52 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 0.9678
2023-05-31 01:50:54 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 1.0555
2023-05-31 01:50:55 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 0.9378
2023-05-31 01:50:56 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 1.3739
2023-05-31 01:50:58 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 1.2296
2023-05-31 01:50:59 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 1.1523
2023-05-31 01:51:00 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.1586
2023-05-31 01:51:01 - train: epoch 022, train_loss: 1.0554
2023-05-31 01:51:03 - eval: epoch: 022, acc1: 25.510%, acc5: 47.790%, test_loss: 3.9711, per_image_load_time: 0.075ms, per_image_inference_time: 0.047ms
2023-05-31 01:51:03 - until epoch: 022, best_acc1: 33.830%
2023-05-31 01:51:03 - epoch 023 lr: 0.100000
2023-05-31 01:51:05 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 0.7561
2023-05-31 01:51:06 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 0.9481
2023-05-31 01:51:07 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 0.9717
2023-05-31 01:51:09 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.1311
2023-05-31 01:51:10 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 1.0195
2023-05-31 01:51:11 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 1.0889
2023-05-31 01:51:13 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 1.0616
2023-05-31 01:51:14 - train: epoch 023, train_loss: 1.0339
2023-05-31 01:51:15 - eval: epoch: 023, acc1: 26.730%, acc5: 49.780%, test_loss: 4.1340, per_image_load_time: 0.075ms, per_image_inference_time: 0.050ms
2023-05-31 01:51:15 - until epoch: 023, best_acc1: 33.830%
2023-05-31 01:51:15 - epoch 024 lr: 0.100000
2023-05-31 01:51:17 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 0.7949
2023-05-31 01:51:19 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 0.8856
2023-05-31 01:51:20 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 1.0047
2023-05-31 01:51:21 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 1.4680
2023-05-31 01:51:23 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 1.0682
2023-05-31 01:51:24 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.0171
2023-05-31 01:51:25 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 1.2017
2023-05-31 01:51:26 - train: epoch 024, train_loss: 1.0226
2023-05-31 01:51:28 - eval: epoch: 024, acc1: 31.700%, acc5: 56.710%, test_loss: 3.7401, per_image_load_time: 0.092ms, per_image_inference_time: 0.046ms
2023-05-31 01:51:28 - until epoch: 024, best_acc1: 33.830%
2023-05-31 01:51:28 - epoch 025 lr: 0.100000
2023-05-31 01:51:30 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 1.0019
2023-05-31 01:51:31 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 0.9537
2023-05-31 01:51:33 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.0542
2023-05-31 01:51:34 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 0.9832
2023-05-31 01:51:35 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 1.0159
2023-05-31 01:51:37 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 1.1290
2023-05-31 01:51:38 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 1.0621
2023-05-31 01:51:39 - train: epoch 025, train_loss: 1.0122
2023-05-31 01:51:40 - eval: epoch: 025, acc1: 28.970%, acc5: 53.080%, test_loss: 3.8760, per_image_load_time: 0.074ms, per_image_inference_time: 0.049ms
2023-05-31 01:51:41 - until epoch: 025, best_acc1: 33.830%
2023-05-31 01:51:41 - epoch 026 lr: 0.100000
2023-05-31 01:51:43 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 0.9114
2023-05-31 01:51:44 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 0.8760
2023-05-31 01:51:45 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 1.1343
2023-05-31 01:51:47 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 1.0010
2023-05-31 01:51:48 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 0.7976
2023-05-31 01:51:49 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.0223
2023-05-31 01:51:50 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.2387
2023-05-31 01:51:51 - train: epoch 026, train_loss: 1.0066
2023-05-31 01:51:53 - eval: epoch: 026, acc1: 31.460%, acc5: 56.110%, test_loss: 3.7266, per_image_load_time: 0.077ms, per_image_inference_time: 0.045ms
2023-05-31 01:51:53 - until epoch: 026, best_acc1: 33.830%
2023-05-31 01:51:53 - epoch 027 lr: 0.100000
2023-05-31 01:51:55 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 0.8430
2023-05-31 01:51:57 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 1.1648
2023-05-31 01:55:06 - network: resnet18cifar
2023-05-31 01:55:06 - num_classes: 100
2023-05-31 01:55:06 - input_image_size: 32
2023-05-31 01:55:06 - trained_model_path: 
2023-05-31 01:55:06 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:55:06 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 01:55:06 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f3f775e1850>
2023-05-31 01:55:06 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f3f775e1940>
2023-05-31 01:55:06 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f3f775e1a90>
2023-05-31 01:55:06 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f3f775e1910>
2023-05-31 01:55:06 - seed: 0
2023-05-31 01:55:06 - batch_size: 128
2023-05-31 01:55:06 - num_workers: 16
2023-05-31 01:55:06 - accumulation_steps: 1
2023-05-31 01:55:06 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 01:55:06 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 01:55:06 - epochs: 200
2023-05-31 01:55:06 - print_interval: 50
2023-05-31 01:55:06 - sync_bn: False
2023-05-31 01:55:06 - apex: True
2023-05-31 01:55:06 - use_ema_model: False
2023-05-31 01:55:06 - ema_model_decay: 0.9999
2023-05-31 01:55:06 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 01:55:06 - gpus_num: 1
2023-05-31 01:55:06 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f3f775d88f0>
2023-05-31 01:55:07 - --------------------parameters--------------------
2023-05-31 01:55:07 - name: conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 01:55:07 - name: fc.weight, grad: True
2023-05-31 01:55:07 - name: fc.bias, grad: True
2023-05-31 01:55:07 - --------------------buffers--------------------
2023-05-31 01:55:07 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 01:55:07 - -----------no weight decay layers--------------
2023-05-31 01:55:07 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 01:55:07 - -------------weight decay layers---------------
2023-05-31 01:55:07 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 01:55:07 - epoch 001 lr: 0.100000
2023-05-31 01:55:14 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.4620
2023-05-31 01:55:15 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.4874
2023-05-31 01:55:16 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.0488
2023-05-31 01:55:18 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 4.2322
2023-05-31 01:55:19 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 4.2146
2023-05-31 01:55:20 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 4.4118
2023-05-31 01:55:21 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 4.2845
2023-05-31 01:55:22 - train: epoch 001, train_loss: 4.2958
2023-05-31 01:55:24 - eval: epoch: 001, acc1: 10.060%, acc5: 32.010%, test_loss: 3.8446, per_image_load_time: 0.067ms, per_image_inference_time: 0.044ms
2023-05-31 01:55:24 - until epoch: 001, best_acc1: 10.060%
2023-05-31 01:55:24 - epoch 002 lr: 0.100000
2023-05-31 01:55:27 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 4.1626
2023-05-31 01:55:28 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.7296
2023-05-31 01:55:29 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.7212
2023-05-31 01:55:30 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 4.1996
2023-05-31 01:55:32 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 4.1684
2023-05-31 01:55:33 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 4.0223
2023-05-31 01:55:34 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.7224
2023-05-31 01:55:36 - train: epoch 002, train_loss: 3.9925
2023-05-31 01:55:37 - eval: epoch: 002, acc1: 18.170%, acc5: 45.430%, test_loss: 3.3948, per_image_load_time: 0.071ms, per_image_inference_time: 0.045ms
2023-05-31 01:55:37 - until epoch: 002, best_acc1: 18.170%
2023-05-31 01:55:37 - epoch 003 lr: 0.100000
2023-05-31 01:55:39 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 3.6738
2023-05-31 01:55:41 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 4.0741
2023-05-31 01:55:42 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 3.6983
2023-05-31 01:55:43 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 3.9527
2023-05-31 01:55:45 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 3.9486
2023-05-31 01:55:46 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 3.7746
2023-05-31 01:55:47 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 4.2438
2023-05-31 01:55:48 - train: epoch 003, train_loss: 3.7759
2023-05-31 01:55:50 - eval: epoch: 003, acc1: 20.970%, acc5: 51.090%, test_loss: 3.1969, per_image_load_time: 0.082ms, per_image_inference_time: 0.045ms
2023-05-31 01:55:50 - until epoch: 003, best_acc1: 20.970%
2023-05-31 01:55:50 - epoch 004 lr: 0.100000
2023-05-31 01:55:52 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.1008
2023-05-31 01:55:54 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.2013
2023-05-31 01:55:55 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 2.8946
2023-05-31 01:55:56 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.4405
2023-05-31 01:55:58 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 3.4876
2023-05-31 01:55:59 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 3.4938
2023-05-31 01:56:00 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.7605
2023-05-31 01:56:01 - train: epoch 004, train_loss: 3.6347
2023-05-31 01:56:03 - eval: epoch: 004, acc1: 25.860%, acc5: 57.540%, test_loss: 3.0046, per_image_load_time: 0.075ms, per_image_inference_time: 0.044ms
2023-05-31 01:56:03 - until epoch: 004, best_acc1: 25.860%
2023-05-31 01:56:03 - epoch 005 lr: 0.100000
2023-05-31 01:56:05 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.8118
2023-05-31 01:56:07 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 3.0896
2023-05-31 01:56:08 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 3.7839
2023-05-31 01:56:09 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 3.6494
2023-05-31 01:56:11 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 3.7183
2023-05-31 01:56:12 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 3.6512
2023-05-31 01:56:13 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 3.6646
2023-05-31 01:56:14 - train: epoch 005, train_loss: 3.4503
2023-05-31 01:56:16 - eval: epoch: 005, acc1: 32.120%, acc5: 64.930%, test_loss: 2.6242, per_image_load_time: 0.081ms, per_image_inference_time: 0.044ms
2023-05-31 01:56:16 - until epoch: 005, best_acc1: 32.120%
2023-05-31 01:56:16 - epoch 006 lr: 0.100000
2023-05-31 01:56:18 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 2.6052
2023-05-31 01:56:20 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.7450
2023-05-31 01:56:21 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.7489
2023-05-31 01:56:22 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 3.5669
2023-05-31 01:56:24 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.5999
2023-05-31 01:56:25 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 2.1775
2023-05-31 01:56:26 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 3.0138
2023-05-31 01:56:27 - train: epoch 006, train_loss: 3.2238
2023-05-31 01:56:29 - eval: epoch: 006, acc1: 37.170%, acc5: 68.820%, test_loss: 2.4544, per_image_load_time: 0.071ms, per_image_inference_time: 0.044ms
2023-05-31 01:56:29 - until epoch: 006, best_acc1: 37.170%
2023-05-31 01:56:29 - epoch 007 lr: 0.100000
2023-05-31 01:56:31 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.6994
2023-05-31 01:56:32 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 3.5822
2023-05-31 01:56:34 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 2.4722
2023-05-31 01:56:35 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 3.5610
2023-05-31 01:56:36 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 2.9498
2023-05-31 01:56:38 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 3.3758
2023-05-31 01:56:39 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 2.1402
2023-05-31 01:56:40 - train: epoch 007, train_loss: 3.1462
2023-05-31 01:56:41 - eval: epoch: 007, acc1: 40.560%, acc5: 73.400%, test_loss: 2.2607, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:56:42 - until epoch: 007, best_acc1: 40.560%
2023-05-31 01:56:42 - epoch 008 lr: 0.100000
2023-05-31 01:56:44 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 2.6222
2023-05-31 01:56:45 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 3.6135
2023-05-31 01:56:46 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 3.4981
2023-05-31 01:56:48 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 2.8194
2023-05-31 01:56:49 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 3.1214
2023-05-31 01:56:50 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 3.7032
2023-05-31 01:56:52 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 2.9218
2023-05-31 01:56:53 - train: epoch 008, train_loss: 3.0637
2023-05-31 01:56:54 - eval: epoch: 008, acc1: 43.460%, acc5: 75.330%, test_loss: 2.1582, per_image_load_time: 0.073ms, per_image_inference_time: 0.048ms
2023-05-31 01:56:55 - until epoch: 008, best_acc1: 43.460%
2023-05-31 01:56:55 - epoch 009 lr: 0.100000
2023-05-31 01:56:57 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 2.6972
2023-05-31 01:56:58 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 2.2277
2023-05-31 01:56:59 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 3.4957
2023-05-31 01:57:01 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 2.2563
2023-05-31 01:57:02 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 2.6699
2023-05-31 01:57:03 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 2.8367
2023-05-31 01:57:04 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 2.7946
2023-05-31 01:57:05 - train: epoch 009, train_loss: 2.9401
2023-05-31 01:57:07 - eval: epoch: 009, acc1: 46.800%, acc5: 77.580%, test_loss: 2.0332, per_image_load_time: 0.070ms, per_image_inference_time: 0.046ms
2023-05-31 01:57:07 - until epoch: 009, best_acc1: 46.800%
2023-05-31 01:57:07 - epoch 010 lr: 0.100000
2023-05-31 01:57:10 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 3.5389
2023-05-31 01:57:11 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 3.3359
2023-05-31 01:57:12 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 3.2799
2023-05-31 01:57:13 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 3.3708
2023-05-31 01:57:15 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 2.6470
2023-05-31 01:57:16 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 2.8689
2023-05-31 01:57:17 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 3.1915
2023-05-31 01:57:18 - train: epoch 010, train_loss: 2.8835
2023-05-31 01:57:20 - eval: epoch: 010, acc1: 49.240%, acc5: 79.770%, test_loss: 1.8921, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:57:20 - until epoch: 010, best_acc1: 49.240%
2023-05-31 01:57:20 - epoch 011 lr: 0.100000
2023-05-31 01:57:22 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 2.6753
2023-05-31 01:57:24 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 3.2478
2023-05-31 01:57:25 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 3.5390
2023-05-31 01:57:26 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 1.7179
2023-05-31 01:57:27 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 2.0559
2023-05-31 01:57:29 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 1.4964
2023-05-31 01:57:30 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 2.1961
2023-05-31 01:57:31 - train: epoch 011, train_loss: 2.8550
2023-05-31 01:57:32 - eval: epoch: 011, acc1: 46.880%, acc5: 78.450%, test_loss: 2.0010, per_image_load_time: 0.071ms, per_image_inference_time: 0.046ms
2023-05-31 01:57:33 - until epoch: 011, best_acc1: 49.240%
2023-05-31 01:57:33 - epoch 012 lr: 0.100000
2023-05-31 01:57:35 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 3.1434
2023-05-31 01:57:36 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 3.3418
2023-05-31 01:57:38 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 3.5038
2023-05-31 01:57:39 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 3.2321
2023-05-31 01:57:40 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 3.2676
2023-05-31 01:57:41 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 1.7524
2023-05-31 01:57:43 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 2.3274
2023-05-31 01:57:44 - train: epoch 012, train_loss: 2.8125
2023-05-31 01:57:45 - eval: epoch: 012, acc1: 51.470%, acc5: 82.010%, test_loss: 1.8439, per_image_load_time: 0.073ms, per_image_inference_time: 0.044ms
2023-05-31 01:57:46 - until epoch: 012, best_acc1: 51.470%
2023-05-31 01:57:46 - epoch 013 lr: 0.100000
2023-05-31 01:57:48 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 3.3365
2023-05-31 01:57:49 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 3.2748
2023-05-31 01:57:50 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 1.7053
2023-05-31 01:57:52 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 3.3252
2023-05-31 01:57:53 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 3.4090
2023-05-31 01:57:54 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 3.0820
2023-05-31 01:57:55 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 3.1898
2023-05-31 01:57:57 - train: epoch 013, train_loss: 2.7206
2023-05-31 01:57:58 - eval: epoch: 013, acc1: 50.210%, acc5: 80.850%, test_loss: 1.8747, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 01:57:58 - until epoch: 013, best_acc1: 51.470%
2023-05-31 01:57:58 - epoch 014 lr: 0.100000
2023-05-31 01:58:00 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 3.2214
2023-05-31 01:58:01 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 2.6630
2023-05-31 01:58:03 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 2.3676
2023-05-31 01:58:04 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 2.8561
2023-05-31 01:58:05 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 3.3257
2023-05-31 01:58:07 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 3.0822
2023-05-31 01:58:08 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 3.3984
2023-05-31 01:58:09 - train: epoch 014, train_loss: 2.6844
2023-05-31 01:58:10 - eval: epoch: 014, acc1: 53.240%, acc5: 83.100%, test_loss: 1.7482, per_image_load_time: 0.070ms, per_image_inference_time: 0.046ms
2023-05-31 01:58:11 - until epoch: 014, best_acc1: 53.240%
2023-05-31 01:58:11 - epoch 015 lr: 0.100000
2023-05-31 01:58:13 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 2.7970
2023-05-31 01:58:14 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 3.5974
2023-05-31 01:58:16 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 3.5568
2023-05-31 01:58:17 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 1.9581
2023-05-31 01:58:18 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.7359
2023-05-31 01:58:19 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 2.3186
2023-05-31 01:58:21 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 3.0836
2023-05-31 01:58:22 - train: epoch 015, train_loss: 2.6710
2023-05-31 01:58:23 - eval: epoch: 015, acc1: 52.600%, acc5: 82.010%, test_loss: 1.7762, per_image_load_time: 0.069ms, per_image_inference_time: 0.050ms
2023-05-31 01:58:23 - until epoch: 015, best_acc1: 53.240%
2023-05-31 01:58:23 - epoch 016 lr: 0.100000
2023-05-31 01:58:26 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 3.1509
2023-05-31 01:58:27 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 2.1982
2023-05-31 01:58:28 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 2.5228
2023-05-31 01:58:29 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 2.1658
2023-05-31 01:58:31 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 2.3040
2023-05-31 01:58:32 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 3.1356
2023-05-31 01:58:33 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 2.8151
2023-05-31 01:58:34 - train: epoch 016, train_loss: 2.6590
2023-05-31 01:58:36 - eval: epoch: 016, acc1: 53.120%, acc5: 82.130%, test_loss: 1.7478, per_image_load_time: 0.077ms, per_image_inference_time: 0.044ms
2023-05-31 01:58:36 - until epoch: 016, best_acc1: 53.240%
2023-05-31 01:58:36 - epoch 017 lr: 0.100000
2023-05-31 01:58:38 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 3.2954
2023-05-31 01:58:39 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 3.3137
2023-05-31 01:58:41 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 3.1499
2023-05-31 01:58:42 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 3.0799
2023-05-31 01:58:43 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 2.9249
2023-05-31 01:58:45 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 3.2215
2023-05-31 01:58:46 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 1.4424
2023-05-31 01:58:47 - train: epoch 017, train_loss: 2.6234
2023-05-31 01:58:48 - eval: epoch: 017, acc1: 53.990%, acc5: 83.170%, test_loss: 1.7176, per_image_load_time: 0.074ms, per_image_inference_time: 0.046ms
2023-05-31 01:58:49 - until epoch: 017, best_acc1: 53.990%
2023-05-31 01:58:49 - epoch 018 lr: 0.100000
2023-05-31 01:58:51 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 3.2459
2023-05-31 01:58:52 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 3.0584
2023-05-31 01:58:53 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.8001
2023-05-31 01:58:55 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 2.6560
2023-05-31 01:58:56 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 3.0824
2023-05-31 01:58:57 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 1.3561
2023-05-31 01:58:59 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 2.9128
2023-05-31 01:59:00 - train: epoch 018, train_loss: 2.5992
2023-05-31 01:59:01 - eval: epoch: 018, acc1: 56.190%, acc5: 84.170%, test_loss: 1.6876, per_image_load_time: 0.068ms, per_image_inference_time: 0.044ms
2023-05-31 01:59:02 - until epoch: 018, best_acc1: 56.190%
2023-05-31 01:59:02 - epoch 019 lr: 0.100000
2023-05-31 01:59:04 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 1.8560
2023-05-31 01:59:05 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 1.2807
2023-05-31 01:59:06 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 3.3185
2023-05-31 01:59:08 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 3.2353
2023-05-31 01:59:09 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 2.8913
2023-05-31 01:59:10 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 3.1369
2023-05-31 01:59:12 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 3.2622
2023-05-31 01:59:13 - train: epoch 019, train_loss: 2.5919
2023-05-31 01:59:14 - eval: epoch: 019, acc1: 56.330%, acc5: 85.500%, test_loss: 1.6423, per_image_load_time: 0.070ms, per_image_inference_time: 0.042ms
2023-05-31 01:59:14 - until epoch: 019, best_acc1: 56.330%
2023-05-31 01:59:14 - epoch 020 lr: 0.100000
2023-05-31 01:59:16 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 3.2494
2023-05-31 01:59:18 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 2.4624
2023-05-31 01:59:19 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 3.3056
2023-05-31 01:59:20 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 2.6059
2023-05-31 01:59:22 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 1.3347
2023-05-31 01:59:23 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 2.6960
2023-05-31 01:59:24 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 2.5462
2023-05-31 01:59:25 - train: epoch 020, train_loss: 2.5767
2023-05-31 01:59:27 - eval: epoch: 020, acc1: 56.760%, acc5: 85.360%, test_loss: 1.6479, per_image_load_time: 0.070ms, per_image_inference_time: 0.045ms
2023-05-31 01:59:27 - until epoch: 020, best_acc1: 56.760%
2023-05-31 01:59:27 - epoch 021 lr: 0.100000
2023-05-31 01:59:29 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 3.1057
2023-05-31 01:59:30 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.6809
2023-05-31 01:59:32 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 2.9116
2023-05-31 01:59:33 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.4346
2023-05-31 01:59:34 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 3.1037
2023-05-31 01:59:36 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 2.9723
2023-05-31 01:59:37 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 2.3623
2023-05-31 01:59:38 - train: epoch 021, train_loss: 2.5583
2023-05-31 01:59:39 - eval: epoch: 021, acc1: 57.480%, acc5: 84.500%, test_loss: 1.6382, per_image_load_time: 0.070ms, per_image_inference_time: 0.043ms
2023-05-31 01:59:40 - until epoch: 021, best_acc1: 57.480%
2023-05-31 01:59:40 - epoch 022 lr: 0.100000
2023-05-31 01:59:42 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 3.0334
2023-05-31 01:59:43 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 3.0974
2023-05-31 01:59:44 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 3.0193
2023-05-31 01:59:46 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 1.6657
2023-05-31 01:59:47 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 3.0492
2023-05-31 01:59:48 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 2.6414
2023-05-31 01:59:49 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.2840
2023-05-31 01:59:51 - train: epoch 022, train_loss: 2.4793
2023-05-31 01:59:52 - eval: epoch: 022, acc1: 58.610%, acc5: 86.930%, test_loss: 1.4965, per_image_load_time: 0.069ms, per_image_inference_time: 0.044ms
2023-05-31 01:59:52 - until epoch: 022, best_acc1: 58.610%
2023-05-31 01:59:52 - epoch 023 lr: 0.100000
2023-05-31 01:59:54 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 3.1003
2023-05-31 01:59:56 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 2.4069
2023-05-31 01:59:57 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 1.8109
2023-05-31 01:59:58 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.5984
2023-05-31 02:00:00 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 2.9357
2023-05-31 02:00:01 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 2.1891
2023-05-31 02:00:03 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 1.9261
2023-05-31 02:00:04 - train: epoch 023, train_loss: 2.4923
2023-05-31 02:00:05 - eval: epoch: 023, acc1: 59.120%, acc5: 86.490%, test_loss: 1.5140, per_image_load_time: 0.071ms, per_image_inference_time: 0.043ms
2023-05-31 02:00:05 - until epoch: 023, best_acc1: 59.120%
2023-05-31 02:00:05 - epoch 024 lr: 0.100000
2023-05-31 02:00:08 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 2.9152
2023-05-31 02:00:09 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 1.2236
2023-05-31 02:00:10 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 2.8982
2023-05-31 02:00:12 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 1.9551
2023-05-31 02:00:13 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 2.9442
2023-05-31 02:00:14 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.2892
2023-05-31 02:00:16 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 3.0845
2023-05-31 02:00:17 - train: epoch 024, train_loss: 2.4783
2023-05-31 02:00:18 - eval: epoch: 024, acc1: 60.140%, acc5: 87.450%, test_loss: 1.5403, per_image_load_time: 0.075ms, per_image_inference_time: 0.042ms
2023-05-31 02:00:18 - until epoch: 024, best_acc1: 60.140%
2023-05-31 02:00:18 - epoch 025 lr: 0.100000
2023-05-31 02:00:20 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 2.9541
2023-05-31 02:00:22 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 3.0194
2023-05-31 02:00:23 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.9022
2023-05-31 02:00:24 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 2.4801
2023-05-31 02:00:25 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 1.2700
2023-05-31 02:00:27 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 2.7065
2023-05-31 02:00:28 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 3.1377
2023-05-31 02:00:29 - train: epoch 025, train_loss: 2.4653
2023-05-31 02:00:30 - eval: epoch: 025, acc1: 57.850%, acc5: 85.510%, test_loss: 1.5872, per_image_load_time: 0.070ms, per_image_inference_time: 0.043ms
2023-05-31 02:00:31 - until epoch: 025, best_acc1: 60.140%
2023-05-31 02:00:31 - epoch 026 lr: 0.100000
2023-05-31 02:00:33 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 1.3787
2023-05-31 02:00:34 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 2.4127
2023-05-31 02:00:35 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 3.1550
2023-05-31 02:00:37 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 2.3447
2023-05-31 02:00:38 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 2.7412
2023-05-31 02:00:39 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.2486
2023-05-31 02:00:41 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.9714
2023-05-31 02:00:42 - train: epoch 026, train_loss: 2.3727
2023-05-31 02:00:43 - eval: epoch: 026, acc1: 58.350%, acc5: 86.470%, test_loss: 1.5427, per_image_load_time: 0.069ms, per_image_inference_time: 0.043ms
2023-05-31 02:00:43 - until epoch: 026, best_acc1: 60.140%
2023-05-31 02:00:43 - epoch 027 lr: 0.100000
2023-05-31 02:00:45 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 1.6529
2023-05-31 02:00:47 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 2.2139
2023-05-31 02:00:48 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 2.0614
2023-05-31 02:00:49 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 1.5155
2023-05-31 02:00:51 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 1.9953
2023-05-31 02:00:52 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 2.7293
2023-05-31 02:00:53 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 1.7278
2023-05-31 02:00:54 - train: epoch 027, train_loss: 2.4624
2023-05-31 02:00:56 - eval: epoch: 027, acc1: 55.430%, acc5: 83.700%, test_loss: 1.7281, per_image_load_time: 0.075ms, per_image_inference_time: 0.045ms
2023-05-31 02:00:56 - until epoch: 027, best_acc1: 60.140%
2023-05-31 02:00:56 - epoch 028 lr: 0.100000
2023-05-31 02:00:58 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 2.0394
2023-05-31 02:01:00 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 1.8601
2023-05-31 02:01:01 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 1.4545
2023-05-31 02:01:02 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 2.2359
2023-05-31 02:01:03 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 2.8252
2023-05-31 02:01:05 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 1.6876
2023-05-31 02:01:06 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 2.9868
2023-05-31 02:01:07 - train: epoch 028, train_loss: 2.4406
2023-05-31 02:01:09 - eval: epoch: 028, acc1: 59.870%, acc5: 87.620%, test_loss: 1.4802, per_image_load_time: 0.074ms, per_image_inference_time: 0.043ms
2023-05-31 02:01:09 - until epoch: 028, best_acc1: 60.140%
2023-05-31 02:01:09 - epoch 029 lr: 0.100000
2023-05-31 02:01:11 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 2.7279
2023-05-31 02:01:12 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 2.9260
2023-05-31 02:01:13 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 2.7535
2023-05-31 02:01:15 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 1.3414
2023-05-31 02:01:16 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 1.1808
2023-05-31 02:01:17 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 3.0927
2023-05-31 02:01:19 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 1.2798
2023-05-31 02:01:20 - train: epoch 029, train_loss: 2.4535
2023-05-31 02:01:21 - eval: epoch: 029, acc1: 61.740%, acc5: 87.410%, test_loss: 1.4670, per_image_load_time: 0.073ms, per_image_inference_time: 0.043ms
2023-05-31 02:01:22 - until epoch: 029, best_acc1: 61.740%
2023-05-31 02:01:22 - epoch 030 lr: 0.100000
2023-05-31 02:01:24 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 2.3306
2023-05-31 02:01:25 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 2.6098
2023-05-31 02:01:26 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 1.9054
2023-05-31 02:01:28 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 2.7025
2023-05-31 02:01:29 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 2.8449
2023-05-31 02:01:30 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 2.0726
2023-05-31 02:01:32 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 2.0348
2023-05-31 02:01:33 - train: epoch 030, train_loss: 2.3688
2023-05-31 02:01:34 - eval: epoch: 030, acc1: 59.670%, acc5: 86.650%, test_loss: 1.5322, per_image_load_time: 0.073ms, per_image_inference_time: 0.046ms
2023-05-31 02:01:34 - until epoch: 030, best_acc1: 61.740%
2023-05-31 02:01:34 - epoch 031 lr: 0.100000
2023-05-31 02:01:37 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 1.4267
2023-05-31 02:01:38 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 2.8509
2023-05-31 02:01:39 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 2.6751
2023-05-31 02:01:41 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 1.5169
2023-05-31 02:01:42 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 3.0183
2023-05-31 02:01:43 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 3.0532
2023-05-31 02:01:44 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 2.4274
2023-05-31 02:01:46 - train: epoch 031, train_loss: 2.4066
2023-05-31 02:01:47 - eval: epoch: 031, acc1: 61.750%, acc5: 87.150%, test_loss: 1.4506, per_image_load_time: 0.075ms, per_image_inference_time: 0.046ms
2023-05-31 02:01:48 - until epoch: 031, best_acc1: 61.750%
2023-05-31 02:01:48 - epoch 032 lr: 0.100000
2023-05-31 02:01:50 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 3.0079
2023-05-31 02:01:51 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 2.9452
2023-05-31 02:01:52 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 2.7545
2023-05-31 02:01:54 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 2.6486
2023-05-31 02:01:55 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 2.0639
2023-05-31 02:01:56 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 1.1074
2023-05-31 02:01:57 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 2.6024
2023-05-31 02:01:59 - train: epoch 032, train_loss: 2.3945
2023-05-31 02:02:00 - eval: epoch: 032, acc1: 60.710%, acc5: 87.640%, test_loss: 1.4819, per_image_load_time: 0.071ms, per_image_inference_time: 0.045ms
2023-05-31 02:02:00 - until epoch: 032, best_acc1: 61.750%
2023-05-31 02:02:00 - epoch 033 lr: 0.100000
2023-05-31 02:02:03 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 2.7671
2023-05-31 02:02:04 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 1.1966
2023-05-31 02:02:05 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 2.1358
2023-05-31 02:02:06 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 3.2114
2023-05-31 02:02:08 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 2.7314
2023-05-31 02:02:09 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 3.0213
2023-05-31 02:02:10 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 2.0242
2023-05-31 02:02:11 - train: epoch 033, train_loss: 2.3961
2023-05-31 02:02:13 - eval: epoch: 033, acc1: 62.240%, acc5: 88.390%, test_loss: 1.3882, per_image_load_time: 0.075ms, per_image_inference_time: 0.042ms
2023-05-31 02:02:13 - until epoch: 033, best_acc1: 62.240%
2023-05-31 02:02:13 - epoch 034 lr: 0.100000
2023-05-31 02:02:15 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 3.0521
2023-05-31 02:02:17 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 2.9319
2023-05-31 02:02:18 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 1.2076
2023-05-31 02:02:19 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 2.9155
2023-05-31 02:02:20 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 1.6042
2023-05-31 02:02:22 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 3.0275
2023-05-31 02:02:23 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 2.9807
2023-05-31 02:02:24 - train: epoch 034, train_loss: 2.3689
2023-05-31 02:02:25 - eval: epoch: 034, acc1: 62.850%, acc5: 88.410%, test_loss: 1.3735, per_image_load_time: 0.071ms, per_image_inference_time: 0.045ms
2023-05-31 02:02:26 - until epoch: 034, best_acc1: 62.850%
2023-05-31 02:02:26 - epoch 035 lr: 0.100000
2023-05-31 02:02:28 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 2.6062
2023-05-31 02:02:29 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 2.0883
2023-05-31 02:02:30 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 1.9290
2023-05-31 02:02:32 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 2.0364
2023-05-31 02:02:33 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 3.0415
2023-05-31 02:02:34 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 2.8642
2023-05-31 02:02:35 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 3.1910
2023-05-31 02:02:37 - train: epoch 035, train_loss: 2.3645
2023-05-31 02:02:38 - eval: epoch: 035, acc1: 61.260%, acc5: 87.370%, test_loss: 1.4510, per_image_load_time: 0.074ms, per_image_inference_time: 0.044ms
2023-05-31 02:02:38 - until epoch: 035, best_acc1: 62.850%
2023-05-31 02:02:38 - epoch 036 lr: 0.100000
2023-05-31 02:02:40 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 2.5053
2023-05-31 02:02:42 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 1.1588
2023-05-31 02:02:43 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 1.8253
2023-05-31 02:02:44 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 2.9536
2023-05-31 02:02:46 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 2.5801
2023-05-31 02:02:47 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 1.7093
2023-05-31 02:02:48 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 2.5742
2023-05-31 02:02:49 - train: epoch 036, train_loss: 2.3830
2023-05-31 02:02:50 - eval: epoch: 036, acc1: 60.810%, acc5: 87.840%, test_loss: 1.4539, per_image_load_time: 0.070ms, per_image_inference_time: 0.044ms
2023-05-31 02:02:51 - until epoch: 036, best_acc1: 62.850%
2023-05-31 02:02:51 - epoch 037 lr: 0.100000
2023-05-31 02:02:53 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 2.8742
2023-05-31 02:02:54 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 1.3507
2023-05-31 02:02:55 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 2.8273
2023-05-31 02:02:57 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 2.8844
2023-05-31 02:02:58 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 2.0746
2023-05-31 02:02:59 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 1.5642
2023-05-31 02:03:00 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 3.0200
2023-05-31 02:03:01 - train: epoch 037, train_loss: 2.3686
2023-05-31 02:03:03 - eval: epoch: 037, acc1: 63.210%, acc5: 88.770%, test_loss: 1.4078, per_image_load_time: 0.087ms, per_image_inference_time: 0.041ms
2023-05-31 02:03:03 - until epoch: 037, best_acc1: 63.210%
2023-05-31 02:03:03 - epoch 038 lr: 0.100000
2023-05-31 02:03:05 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 2.3053
2023-05-31 02:03:07 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 1.1068
2023-05-31 02:03:08 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 3.0500
2023-05-31 02:03:09 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 1.1921
2023-05-31 02:03:10 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 1.2050
2023-05-31 02:03:12 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 1.8786
2023-05-31 02:03:13 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 2.0505
2023-05-31 02:03:14 - train: epoch 038, train_loss: 2.3053
2023-05-31 02:03:15 - eval: epoch: 038, acc1: 63.030%, acc5: 88.660%, test_loss: 1.3961, per_image_load_time: 0.074ms, per_image_inference_time: 0.042ms
2023-05-31 02:03:16 - until epoch: 038, best_acc1: 63.210%
2023-05-31 02:03:16 - epoch 039 lr: 0.100000
2023-05-31 02:03:18 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 2.8203
2023-05-31 02:03:19 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 1.5769
2023-05-31 02:03:20 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 1.7037
2023-05-31 02:03:22 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 2.4101
2023-05-31 02:03:23 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 2.2392
2023-05-31 02:03:24 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 2.0316
2023-05-31 02:03:25 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 1.7475
2023-05-31 02:03:27 - train: epoch 039, train_loss: 2.2994
2023-05-31 02:03:28 - eval: epoch: 039, acc1: 58.870%, acc5: 86.150%, test_loss: 1.5591, per_image_load_time: 0.071ms, per_image_inference_time: 0.046ms
2023-05-31 02:03:28 - until epoch: 039, best_acc1: 63.210%
2023-05-31 02:03:28 - epoch 040 lr: 0.100000
2023-05-31 02:03:30 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 1.2627
2023-05-31 02:03:32 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 1.8161
2023-05-31 02:03:33 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 2.8850
2023-05-31 02:03:34 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 3.1464
2023-05-31 02:03:35 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 2.0822
2023-05-31 02:03:37 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 2.6648
2023-05-31 02:03:38 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 1.4210
2023-05-31 02:03:39 - train: epoch 040, train_loss: 2.3366
2023-05-31 02:03:40 - eval: epoch: 040, acc1: 60.950%, acc5: 86.860%, test_loss: 1.5400, per_image_load_time: 0.071ms, per_image_inference_time: 0.042ms
2023-05-31 02:03:41 - until epoch: 040, best_acc1: 63.210%
2023-05-31 02:03:41 - epoch 041 lr: 0.100000
2023-05-31 02:03:43 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 2.0485
2023-05-31 02:03:44 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 2.2870
2023-05-31 02:03:45 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 2.9323
2023-05-31 02:03:47 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 1.6587
2023-05-31 02:03:48 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 2.5686
2023-05-31 02:03:49 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 1.3399
2023-05-31 02:03:50 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 2.8120
2023-05-31 02:03:51 - train: epoch 041, train_loss: 2.2922
2023-05-31 02:03:53 - eval: epoch: 041, acc1: 62.800%, acc5: 88.680%, test_loss: 1.3857, per_image_load_time: 0.069ms, per_image_inference_time: 0.045ms
2023-05-31 02:03:53 - until epoch: 041, best_acc1: 63.210%
2023-05-31 02:03:53 - epoch 042 lr: 0.100000
2023-05-31 02:03:55 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 2.6119
2023-05-31 02:03:56 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 2.9563
2023-05-31 02:03:58 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 2.7204
2023-05-31 02:03:59 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 3.0325
2023-05-31 02:04:00 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 1.6329
2023-05-31 02:04:02 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 2.2238
2023-05-31 02:04:03 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 1.5503
2023-05-31 02:04:04 - train: epoch 042, train_loss: 2.3442
2023-05-31 02:04:05 - eval: epoch: 042, acc1: 63.150%, acc5: 88.260%, test_loss: 1.3948, per_image_load_time: 0.073ms, per_image_inference_time: 0.045ms
2023-05-31 02:04:06 - until epoch: 042, best_acc1: 63.210%
2023-05-31 02:04:06 - epoch 043 lr: 0.100000
2023-05-31 02:04:08 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 2.9091
2023-05-31 02:04:09 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 2.9085
2023-05-31 02:04:10 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 1.1024
2023-05-31 02:04:11 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 2.9125
2023-05-31 02:04:13 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 1.8585
2023-05-31 02:04:14 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 1.5925
2023-05-31 02:04:15 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 2.7499
2023-05-31 02:04:16 - train: epoch 043, train_loss: 2.2497
2023-05-31 02:04:18 - eval: epoch: 043, acc1: 60.860%, acc5: 87.460%, test_loss: 1.4533, per_image_load_time: 0.069ms, per_image_inference_time: 0.045ms
2023-05-31 02:04:18 - until epoch: 043, best_acc1: 63.210%
2023-05-31 02:04:18 - epoch 044 lr: 0.100000
2023-05-31 02:04:20 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 1.9234
2023-05-31 02:04:22 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 2.7737
2023-05-31 02:04:23 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 2.7889
2023-05-31 02:04:24 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 1.5007
2023-05-31 02:04:25 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 2.4340
2023-05-31 02:04:27 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 2.6267
2023-05-31 02:04:28 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 1.2028
2023-05-31 02:04:29 - train: epoch 044, train_loss: 2.2934
2023-05-31 02:04:30 - eval: epoch: 044, acc1: 62.000%, acc5: 87.860%, test_loss: 1.4597, per_image_load_time: 0.068ms, per_image_inference_time: 0.047ms
2023-05-31 02:04:31 - until epoch: 044, best_acc1: 63.210%
2023-05-31 02:04:31 - epoch 045 lr: 0.100000
2023-05-31 02:04:33 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 1.5513
2023-05-31 02:04:34 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 2.0888
2023-05-31 02:04:35 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 1.7325
2023-05-31 02:04:37 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 1.2059
2023-05-31 02:04:38 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 1.4633
2023-05-31 02:04:39 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 2.9231
2023-05-31 02:04:41 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 3.0143
2023-05-31 02:04:42 - train: epoch 045, train_loss: 2.2922
2023-05-31 02:04:43 - eval: epoch: 045, acc1: 60.760%, acc5: 87.470%, test_loss: 1.4571, per_image_load_time: 0.074ms, per_image_inference_time: 0.056ms
2023-05-31 02:04:43 - until epoch: 045, best_acc1: 63.210%
2023-05-31 02:04:43 - epoch 046 lr: 0.100000
2023-05-31 02:04:46 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 1.1376
2023-05-31 02:04:47 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 1.8211
2023-05-31 02:04:48 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 2.4586
2023-05-31 02:04:50 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 2.4379
2023-05-31 02:04:51 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 2.2383
2023-05-31 02:04:52 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 0.9212
2023-05-31 02:04:53 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 2.9512
2023-05-31 02:04:54 - train: epoch 046, train_loss: 2.3361
2023-05-31 02:04:56 - eval: epoch: 046, acc1: 63.590%, acc5: 88.270%, test_loss: 1.4072, per_image_load_time: 0.084ms, per_image_inference_time: 0.044ms
2023-05-31 02:04:56 - until epoch: 046, best_acc1: 63.590%
2023-05-31 02:04:56 - epoch 047 lr: 0.100000
2023-05-31 02:04:59 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 1.2628
2023-05-31 02:05:00 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 1.2353
2023-05-31 02:05:01 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 1.8037
2023-05-31 02:05:03 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 2.6604
2023-05-31 02:05:04 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 2.4217
2023-05-31 02:05:05 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 1.8782
2023-05-31 02:05:07 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 2.5444
2023-05-31 02:05:08 - train: epoch 047, train_loss: 2.3193
2023-05-31 02:05:09 - eval: epoch: 047, acc1: 62.690%, acc5: 87.700%, test_loss: 1.3962, per_image_load_time: 0.078ms, per_image_inference_time: 0.044ms
2023-05-31 02:05:09 - until epoch: 047, best_acc1: 63.590%
2023-05-31 02:05:09 - epoch 048 lr: 0.100000
2023-05-31 02:05:11 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 2.4481
2023-05-31 02:05:13 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 2.4634
2023-05-31 02:05:14 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 1.2720
2023-05-31 02:05:15 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 2.7810
2023-05-31 02:05:17 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 2.2342
2023-05-31 02:05:18 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 1.0254
2023-05-31 02:05:19 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 1.4535
2023-05-31 02:05:20 - train: epoch 048, train_loss: 2.2853
2023-05-31 02:05:22 - eval: epoch: 048, acc1: 62.250%, acc5: 87.980%, test_loss: 1.4420, per_image_load_time: 0.081ms, per_image_inference_time: 0.043ms
2023-05-31 02:05:22 - until epoch: 048, best_acc1: 63.590%
2023-05-31 02:05:22 - epoch 049 lr: 0.100000
2023-05-31 02:05:24 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 2.2255
2023-05-31 02:05:25 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 2.6855
2023-05-31 02:05:27 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 1.3411
2023-05-31 02:05:28 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 2.3229
2023-05-31 02:05:29 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 2.7934
2023-05-31 02:05:31 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 2.8078
2023-05-31 02:05:32 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 2.9003
2023-05-31 02:05:33 - train: epoch 049, train_loss: 2.2329
2023-05-31 02:05:35 - eval: epoch: 049, acc1: 61.740%, acc5: 88.020%, test_loss: 1.4306, per_image_load_time: 0.072ms, per_image_inference_time: 0.047ms
2023-05-31 02:05:35 - until epoch: 049, best_acc1: 63.590%
2023-05-31 02:05:35 - epoch 050 lr: 0.100000
2023-05-31 02:05:37 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 2.8375
2023-05-31 02:05:38 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 0.9985
2023-05-31 02:05:38 - network: resnet18cifar
2023-05-31 02:05:38 - num_classes: 100
2023-05-31 02:05:38 - input_image_size: 32
2023-05-31 02:05:38 - trained_model_path: 
2023-05-31 02:05:38 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 02:05:38 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 02:05:38 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7ff031579d60>
2023-05-31 02:05:38 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7ff031579e20>
2023-05-31 02:05:38 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7ff031579ca0>
2023-05-31 02:05:38 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7ff031579be0>
2023-05-31 02:05:38 - seed: 0
2023-05-31 02:05:38 - batch_size: 128
2023-05-31 02:05:38 - num_workers: 16
2023-05-31 02:05:38 - accumulation_steps: 1
2023-05-31 02:05:38 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 02:05:38 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 02:05:38 - epochs: 200
2023-05-31 02:05:38 - print_interval: 50
2023-05-31 02:05:38 - sync_bn: False
2023-05-31 02:05:38 - apex: True
2023-05-31 02:05:38 - use_ema_model: False
2023-05-31 02:05:38 - ema_model_decay: 0.9999
2023-05-31 02:05:38 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 02:05:38 - gpus_num: 1
2023-05-31 02:05:38 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7ff03156b7b0>
2023-05-31 02:05:38 - --------------------parameters--------------------
2023-05-31 02:05:38 - name: conv1.layer.0.weight, grad: True
2023-05-31 02:05:38 - name: conv1.layer.1.weight, grad: True
2023-05-31 02:05:38 - name: conv1.layer.1.bias, grad: True
2023-05-31 02:05:38 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 02:05:39 - name: fc.weight, grad: True
2023-05-31 02:05:39 - name: fc.bias, grad: True
2023-05-31 02:05:39 - --------------------buffers--------------------
2023-05-31 02:05:39 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:05:39 - -----------no weight decay layers--------------
2023-05-31 02:05:39 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:05:39 - -------------weight decay layers---------------
2023-05-31 02:05:39 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:05:39 - epoch 001 lr: 0.100000
2023-05-31 02:05:41 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 3.0093
2023-05-31 02:05:43 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 2.3377
2023-05-31 02:05:44 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 1.4752
2023-05-31 02:05:46 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 2.4563
2023-05-31 02:05:47 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.2171
2023-05-31 02:05:48 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 3.0688
2023-05-31 02:05:50 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.2738
2023-05-31 02:05:50 - train: epoch 050, train_loss: 2.3638
2023-05-31 02:05:51 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.0771
2023-05-31 02:05:52 - eval: epoch: 050, acc1: 63.810%, acc5: 88.890%, test_loss: 1.4240, per_image_load_time: 0.087ms, per_image_inference_time: 0.051ms
2023-05-31 02:05:52 - until epoch: 050, best_acc1: 63.810%
2023-05-31 02:05:52 - epoch 051 lr: 0.100000
2023-05-31 02:05:53 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.8962
2023-05-31 02:05:55 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 2.6007
2023-05-31 02:05:55 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.8986
2023-05-31 02:05:57 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 2.6218
2023-05-31 02:05:57 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.9529
2023-05-31 02:06:00 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 2.8938
2023-05-31 02:06:00 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.8823
2023-05-31 02:06:02 - train: epoch 001, train_loss: 4.1076
2023-05-31 02:06:02 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 2.8622
2023-05-31 02:06:03 - eval: epoch: 001, acc1: 11.290%, acc5: 32.810%, test_loss: 3.8671, per_image_load_time: 0.066ms, per_image_inference_time: 0.050ms
2023-05-31 02:06:03 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 2.9502
2023-05-31 02:06:04 - until epoch: 001, best_acc1: 11.290%
2023-05-31 02:06:04 - epoch 002 lr: 0.100000
2023-05-31 02:06:05 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 1.5243
2023-05-31 02:06:06 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.7614
2023-05-31 02:06:08 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 2.9151
2023-05-31 02:06:09 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.4910
2023-05-31 02:06:10 - train: epoch 051, train_loss: 2.2859
2023-05-31 02:06:10 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.5827
2023-05-31 02:06:11 - eval: epoch: 051, acc1: 63.930%, acc5: 89.150%, test_loss: 1.3732, per_image_load_time: 0.082ms, per_image_inference_time: 0.047ms
2023-05-31 02:06:12 - until epoch: 051, best_acc1: 63.930%
2023-05-31 02:06:12 - epoch 052 lr: 0.100000
2023-05-31 02:06:12 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 3.8896
2023-05-31 02:06:14 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 3.8276
2023-05-31 02:06:15 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 1.6790
2023-05-31 02:06:17 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.7015
2023-05-31 02:06:17 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 2.7770
2023-05-31 02:06:19 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.3082
2023-05-31 02:06:19 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 2.9243
2023-05-31 02:06:21 - train: epoch 002, train_loss: 3.6550
2023-05-31 02:06:21 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 2.4282
2023-05-31 02:06:22 - eval: epoch: 002, acc1: 18.690%, acc5: 47.440%, test_loss: 3.3453, per_image_load_time: 0.065ms, per_image_inference_time: 0.048ms
2023-05-31 02:06:22 - until epoch: 002, best_acc1: 18.690%
2023-05-31 02:06:22 - epoch 003 lr: 0.100000
2023-05-31 02:06:23 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 2.8231
2023-05-31 02:06:25 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 1.8307
2023-05-31 02:06:26 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 3.3694
2023-05-31 02:06:27 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 2.9436
2023-05-31 02:06:28 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 3.5386
2023-05-31 02:06:29 - train: epoch 052, train_loss: 2.2902
2023-05-31 02:06:30 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 3.2098
2023-05-31 02:06:31 - eval: epoch: 052, acc1: 63.280%, acc5: 88.980%, test_loss: 1.3740, per_image_load_time: 0.084ms, per_image_inference_time: 0.051ms
2023-05-31 02:06:31 - until epoch: 052, best_acc1: 63.930%
2023-05-31 02:06:31 - epoch 053 lr: 0.100000
2023-05-31 02:06:31 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 3.6188
2023-05-31 02:06:33 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 3.4201
2023-05-31 02:06:34 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 1.8614
2023-05-31 02:06:35 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 3.4506
2023-05-31 02:06:37 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 1.1474
2023-05-31 02:06:38 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 3.5459
2023-05-31 02:06:39 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 1.0973
2023-05-31 02:06:40 - train: epoch 003, train_loss: 3.3600
2023-05-31 02:06:41 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 2.8469
2023-05-31 02:06:41 - eval: epoch: 003, acc1: 22.330%, acc5: 51.600%, test_loss: 3.2211, per_image_load_time: 0.065ms, per_image_inference_time: 0.050ms
2023-05-31 02:06:41 - until epoch: 003, best_acc1: 22.330%
2023-05-31 02:06:41 - epoch 004 lr: 0.100000
2023-05-31 02:06:42 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 1.3063
2023-05-31 02:06:44 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 3.0577
2023-05-31 02:06:45 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 2.7964
2023-05-31 02:06:47 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 3.1949
2023-05-31 02:06:47 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 2.8218
2023-05-31 02:06:49 - train: epoch 053, train_loss: 2.3044
2023-05-31 02:06:49 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 2.8992
2023-05-31 02:06:50 - eval: epoch: 053, acc1: 60.730%, acc5: 88.090%, test_loss: 1.4364, per_image_load_time: 0.080ms, per_image_inference_time: 0.054ms
2023-05-31 02:06:50 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.2608
2023-05-31 02:06:51 - until epoch: 053, best_acc1: 63.930%
2023-05-31 02:06:51 - epoch 054 lr: 0.100000
2023-05-31 02:06:52 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 2.9369
2023-05-31 02:06:54 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 2.9422
2023-05-31 02:06:54 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 2.9106
2023-05-31 02:06:56 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 2.9030
2023-05-31 02:06:57 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 3.1112
2023-05-31 02:06:58 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 1.4112
2023-05-31 02:06:58 - train: epoch 004, train_loss: 3.1683
2023-05-31 02:07:00 - eval: epoch: 004, acc1: 23.760%, acc5: 52.960%, test_loss: 3.1899, per_image_load_time: 0.062ms, per_image_inference_time: 0.052ms
2023-05-31 02:07:00 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 1.6857
2023-05-31 02:07:00 - until epoch: 004, best_acc1: 23.760%
2023-05-31 02:07:00 - epoch 005 lr: 0.100000
2023-05-31 02:07:02 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 2.4750
2023-05-31 02:07:03 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 3.0228
2023-05-31 02:07:04 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 1.1897
2023-05-31 02:07:06 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 2.7131
2023-05-31 02:07:06 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 1.5063
2023-05-31 02:07:08 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 2.8795
2023-05-31 02:07:08 - train: epoch 054, train_loss: 2.3040
2023-05-31 02:07:10 - eval: epoch: 054, acc1: 64.280%, acc5: 89.570%, test_loss: 1.3314, per_image_load_time: 0.084ms, per_image_inference_time: 0.050ms
2023-05-31 02:07:10 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 2.9852
2023-05-31 02:07:10 - until epoch: 054, best_acc1: 64.280%
2023-05-31 02:07:10 - epoch 055 lr: 0.100000
2023-05-31 02:07:11 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 2.7838
2023-05-31 02:07:13 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 2.6690
2023-05-31 02:07:13 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 2.5708
2023-05-31 02:07:15 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 1.8752
2023-05-31 02:07:16 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 2.8560
2023-05-31 02:07:17 - train: epoch 005, train_loss: 2.9329
2023-05-31 02:07:18 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 2.5839
2023-05-31 02:07:19 - eval: epoch: 005, acc1: 31.940%, acc5: 64.930%, test_loss: 2.5991, per_image_load_time: 0.060ms, per_image_inference_time: 0.051ms
2023-05-31 02:07:19 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 2.2029
2023-05-31 02:07:19 - until epoch: 005, best_acc1: 31.940%
2023-05-31 02:07:19 - epoch 006 lr: 0.100000
2023-05-31 02:07:21 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 2.7279
2023-05-31 02:07:22 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 2.5856
2023-05-31 02:07:24 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 2.8400
2023-05-31 02:07:25 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 3.0075
2023-05-31 02:07:26 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 2.2961
2023-05-31 02:07:27 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 3.1537
2023-05-31 02:07:28 - train: epoch 055, train_loss: 2.3274
2023-05-31 02:07:29 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 3.1743
2023-05-31 02:07:29 - eval: epoch: 055, acc1: 64.240%, acc5: 89.460%, test_loss: 1.3237, per_image_load_time: 0.084ms, per_image_inference_time: 0.047ms
2023-05-31 02:07:30 - until epoch: 055, best_acc1: 64.280%
2023-05-31 02:07:30 - epoch 056 lr: 0.100000
2023-05-31 02:07:30 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 3.2567
2023-05-31 02:07:32 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 2.1558
2023-05-31 02:07:33 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 2.4936
2023-05-31 02:07:35 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 2.3268
2023-05-31 02:07:35 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 0.9964
2023-05-31 02:07:36 - train: epoch 006, train_loss: 2.7123
2023-05-31 02:07:37 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 3.0826
2023-05-31 02:07:38 - eval: epoch: 006, acc1: 30.930%, acc5: 63.210%, test_loss: 2.7931, per_image_load_time: 0.063ms, per_image_inference_time: 0.049ms
2023-05-31 02:07:38 - network: resnet18cifar
2023-05-31 02:07:38 - num_classes: 100
2023-05-31 02:07:38 - input_image_size: 32
2023-05-31 02:07:38 - trained_model_path: 
2023-05-31 02:07:38 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 02:07:38 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-05-31 02:07:38 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7faf0a385d90>
2023-05-31 02:07:38 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7faf0a385130>
2023-05-31 02:07:38 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7faf0a385280>
2023-05-31 02:07:38 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7faf0a3851c0>
2023-05-31 02:07:38 - seed: 0
2023-05-31 02:07:38 - batch_size: 128
2023-05-31 02:07:38 - num_workers: 16
2023-05-31 02:07:38 - accumulation_steps: 1
2023-05-31 02:07:38 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-05-31 02:07:38 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-05-31 02:07:38 - epochs: 200
2023-05-31 02:07:38 - print_interval: 50
2023-05-31 02:07:38 - sync_bn: False
2023-05-31 02:07:38 - apex: True
2023-05-31 02:07:38 - use_ema_model: False
2023-05-31 02:07:38 - ema_model_decay: 0.9999
2023-05-31 02:07:38 - gpus_type: NVIDIA GeForce RTX 3090
2023-05-31 02:07:38 - gpus_num: 1
2023-05-31 02:07:38 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7faf0a3f0770>
2023-05-31 02:07:38 - until epoch: 006, best_acc1: 31.940%
2023-05-31 02:07:38 - epoch 007 lr: 0.100000
2023-05-31 02:07:38 - --------------------parameters--------------------
2023-05-31 02:07:38 - name: conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-05-31 02:07:38 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-05-31 02:07:38 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-05-31 02:07:38 - name: fc.weight, grad: True
2023-05-31 02:07:38 - name: fc.bias, grad: True
2023-05-31 02:07:38 - --------------------buffers--------------------
2023-05-31 02:07:38 - name: conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: conv1.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:38 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:38 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:38 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-05-31 02:07:39 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-05-31 02:07:39 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-05-31 02:07:39 - -----------no weight decay layers--------------
2023-05-31 02:07:39 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-05-31 02:07:39 - -------------weight decay layers---------------
2023-05-31 02:07:39 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 2.8384
2023-05-31 02:07:39 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-05-31 02:07:39 - epoch 001 lr: 0.100000
2023-05-31 02:07:43 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 1.0480
2023-05-31 02:07:43 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 3.1193
2023-05-31 02:07:45 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 2.6977
2023-05-31 02:07:45 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 3.3723
2023-05-31 02:07:48 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 2.0872
2023-05-31 02:07:49 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 2.1355
2023-05-31 02:07:49 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.2198
2023-05-31 02:07:51 - train: epoch 056, train_loss: 2.2683
2023-05-31 02:07:51 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 3.0985
2023-05-31 02:07:52 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.1834
2023-05-31 02:07:52 - eval: epoch: 056, acc1: 64.310%, acc5: 89.400%, test_loss: 1.3709, per_image_load_time: 0.085ms, per_image_inference_time: 0.053ms
2023-05-31 02:07:53 - until epoch: 056, best_acc1: 64.310%
2023-05-31 02:07:53 - epoch 057 lr: 0.100000
2023-05-31 02:07:54 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 2.2713
2023-05-31 02:07:54 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 4.1284
2023-05-31 02:07:57 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 1.1248
2023-05-31 02:07:58 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 2.3868
2023-05-31 02:07:58 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.9671
2023-05-31 02:08:00 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 1.9430
2023-05-31 02:08:01 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 2.1976
2023-05-31 02:08:01 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.9407
2023-05-31 02:08:03 - train: epoch 007, train_loss: 2.5733
2023-05-31 02:08:04 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 0.9089
2023-05-31 02:08:04 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.9331
2023-05-31 02:08:05 - eval: epoch: 007, acc1: 36.870%, acc5: 69.270%, test_loss: 2.4970, per_image_load_time: 0.065ms, per_image_inference_time: 0.052ms
2023-05-31 02:08:05 - until epoch: 007, best_acc1: 36.870%
2023-05-31 02:08:05 - epoch 008 lr: 0.100000
2023-05-31 02:08:06 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 2.8064
2023-05-31 02:08:07 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.8085
2023-05-31 02:08:09 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 2.1430
2023-05-31 02:08:09 - train: epoch 001, train_loss: 4.0436
2023-05-31 02:08:10 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 1.1096
2023-05-31 02:08:11 - eval: epoch: 001, acc1: 15.910%, acc5: 41.530%, test_loss: 3.5208, per_image_load_time: 0.069ms, per_image_inference_time: 0.059ms
2023-05-31 02:08:11 - until epoch: 001, best_acc1: 15.910%
2023-05-31 02:08:11 - epoch 002 lr: 0.100000
2023-05-31 02:08:12 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 3.0178
2023-05-31 02:08:12 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 2.5781
2023-05-31 02:08:15 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 2.9469
2023-05-31 02:08:16 - train: epoch 0002, iter [00050, 00390], lr: 0.100000, loss: 3.6145
2023-05-31 02:08:16 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 0.9111
2023-05-31 02:08:18 - train: epoch 057, train_loss: 2.2669
2023-05-31 02:08:19 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 3.5677
2023-05-31 02:08:19 - train: epoch 0002, iter [00100, 00390], lr: 0.100000, loss: 3.4484
2023-05-31 02:08:20 - eval: epoch: 057, acc1: 61.390%, acc5: 87.390%, test_loss: 1.4920, per_image_load_time: 0.090ms, per_image_inference_time: 0.055ms
2023-05-31 02:08:20 - until epoch: 057, best_acc1: 64.310%
2023-05-31 02:08:20 - epoch 058 lr: 0.100000
2023-05-31 02:08:21 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 1.9697
2023-05-31 02:08:21 - train: epoch 0002, iter [00150, 00390], lr: 0.100000, loss: 3.6667
2023-05-31 02:08:25 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 2.9007
2023-05-31 02:08:25 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 2.9559
2023-05-31 02:08:25 - train: epoch 0002, iter [00200, 00390], lr: 0.100000, loss: 3.7127
2023-05-31 02:08:28 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 2.1131
2023-05-31 02:08:28 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 2.5617
2023-05-31 02:08:28 - train: epoch 0002, iter [00250, 00390], lr: 0.100000, loss: 3.2819
2023-05-31 02:08:30 - train: epoch 008, train_loss: 2.4324
2023-05-31 02:08:31 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 2.8248
2023-05-31 02:08:31 - train: epoch 0002, iter [00300, 00390], lr: 0.100000, loss: 3.5855
2023-05-31 02:08:32 - eval: epoch: 008, acc1: 33.700%, acc5: 65.870%, test_loss: 2.7096, per_image_load_time: 0.072ms, per_image_inference_time: 0.056ms
2023-05-31 02:08:33 - until epoch: 008, best_acc1: 36.870%
2023-05-31 02:08:33 - epoch 009 lr: 0.100000
2023-05-31 02:08:34 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 1.0598
2023-05-31 02:08:34 - train: epoch 0002, iter [00350, 00390], lr: 0.100000, loss: 3.2484
2023-05-31 02:08:36 - train: epoch 002, train_loss: 3.4985
2023-05-31 02:08:37 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 3.0037
2023-05-31 02:08:37 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 1.7630
2023-05-31 02:08:38 - eval: epoch: 002, acc1: 24.810%, acc5: 56.220%, test_loss: 2.9790, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-05-31 02:08:39 - until epoch: 002, best_acc1: 24.810%
2023-05-31 02:08:39 - epoch 003 lr: 0.100000
2023-05-31 02:08:39 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 2.1707
2023-05-31 02:08:40 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 2.0096
2023-05-31 02:08:43 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 1.5081
2023-05-31 02:08:43 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 2.5346
2023-05-31 02:08:43 - train: epoch 0003, iter [00050, 00390], lr: 0.100000, loss: 3.3455
2023-05-31 02:08:45 - train: epoch 058, train_loss: 2.2789
2023-05-31 02:08:46 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 2.0140
2023-05-31 02:08:46 - train: epoch 0003, iter [00100, 00390], lr: 0.100000, loss: 3.1525
2023-05-31 02:08:47 - eval: epoch: 058, acc1: 65.350%, acc5: 89.870%, test_loss: 1.3207, per_image_load_time: 0.082ms, per_image_inference_time: 0.055ms
2023-05-31 02:08:48 - until epoch: 058, best_acc1: 65.350%
2023-05-31 02:08:48 - epoch 059 lr: 0.100000
2023-05-31 02:08:48 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 2.1978
2023-05-31 02:08:49 - train: epoch 0003, iter [00150, 00390], lr: 0.100000, loss: 3.0892
2023-05-31 02:08:52 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 3.1176
2023-05-31 02:08:52 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 2.0420
2023-05-31 02:08:52 - train: epoch 0003, iter [00200, 00390], lr: 0.100000, loss: 2.9465
2023-05-31 02:08:55 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 2.2056
2023-05-31 02:08:55 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 2.8143
2023-05-31 02:08:55 - train: epoch 0003, iter [00250, 00390], lr: 0.100000, loss: 3.0341
2023-05-31 02:08:58 - train: epoch 009, train_loss: 2.3291
2023-05-31 02:08:58 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 2.8537
2023-05-31 02:08:58 - train: epoch 0003, iter [00300, 00390], lr: 0.100000, loss: 3.1674
2023-05-31 02:08:59 - eval: epoch: 009, acc1: 38.930%, acc5: 73.510%, test_loss: 2.3768, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-05-31 02:09:00 - until epoch: 009, best_acc1: 38.930%
2023-05-31 02:09:00 - epoch 010 lr: 0.100000
2023-05-31 02:09:01 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 1.5097
2023-05-31 02:09:01 - train: epoch 0003, iter [00350, 00390], lr: 0.100000, loss: 2.9406
2023-05-31 02:09:04 - train: epoch 003, train_loss: 3.0636
2023-05-31 02:09:04 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 2.5115
2023-05-31 02:09:04 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 2.5396
2023-05-31 02:09:06 - eval: epoch: 003, acc1: 34.150%, acc5: 66.740%, test_loss: 2.5375, per_image_load_time: 0.072ms, per_image_inference_time: 0.059ms
2023-05-31 02:09:06 - until epoch: 003, best_acc1: 34.150%
2023-05-31 02:09:06 - epoch 004 lr: 0.100000
2023-05-31 02:09:07 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 2.8747
2023-05-31 02:09:07 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 2.7462
2023-05-31 02:09:10 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 2.5744
2023-05-31 02:09:10 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 2.7222
2023-05-31 02:09:10 - train: epoch 0004, iter [00050, 00390], lr: 0.100000, loss: 2.7774
2023-05-31 02:09:13 - train: epoch 059, train_loss: 2.2277
2023-05-31 02:09:13 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 2.5217
2023-05-31 02:09:13 - train: epoch 0004, iter [00100, 00390], lr: 0.100000, loss: 2.9074
2023-05-31 02:09:15 - eval: epoch: 059, acc1: 62.340%, acc5: 87.950%, test_loss: 1.4035, per_image_load_time: 0.090ms, per_image_inference_time: 0.055ms
2023-05-31 02:09:15 - until epoch: 059, best_acc1: 65.350%
2023-05-31 02:09:15 - epoch 060 lr: 0.100000
2023-05-31 02:09:16 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 1.9842
2023-05-31 02:09:16 - train: epoch 0004, iter [00150, 00390], lr: 0.100000, loss: 2.6827
2023-05-31 02:09:19 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 1.8968
2023-05-31 02:09:19 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 1.3034
2023-05-31 02:09:19 - train: epoch 0004, iter [00200, 00390], lr: 0.100000, loss: 3.0600
2023-05-31 02:09:22 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 2.4223
2023-05-31 02:09:22 - train: epoch 0004, iter [00250, 00390], lr: 0.100000, loss: 2.6338
2023-05-31 02:09:22 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 2.1311
2023-05-31 02:09:25 - train: epoch 010, train_loss: 2.2176
2023-05-31 02:09:25 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 2.6051
2023-05-31 02:09:26 - train: epoch 0004, iter [00300, 00390], lr: 0.100000, loss: 2.6953
2023-05-31 02:09:27 - eval: epoch: 010, acc1: 45.080%, acc5: 76.570%, test_loss: 2.0679, per_image_load_time: 0.078ms, per_image_inference_time: 0.055ms
2023-05-31 02:09:27 - until epoch: 010, best_acc1: 45.080%
2023-05-31 02:09:27 - epoch 011 lr: 0.100000
2023-05-31 02:09:28 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 1.4300
2023-05-31 02:09:28 - train: epoch 0004, iter [00350, 00390], lr: 0.100000, loss: 2.5560
2023-05-31 02:09:31 - train: epoch 004, train_loss: 2.7633
2023-05-31 02:09:31 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 1.8976
2023-05-31 02:09:31 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 2.6839
2023-05-31 02:09:33 - eval: epoch: 004, acc1: 40.080%, acc5: 72.280%, test_loss: 2.2817, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-05-31 02:09:33 - until epoch: 004, best_acc1: 40.080%
2023-05-31 02:09:33 - epoch 005 lr: 0.100000
2023-05-31 02:09:34 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 2.1675
2023-05-31 02:09:34 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 1.1007
2023-05-31 02:09:37 - train: epoch 0005, iter [00050, 00390], lr: 0.100000, loss: 2.4589
2023-05-31 02:09:37 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 2.6878
2023-05-31 02:09:37 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 1.2119
2023-05-31 02:09:40 - train: epoch 060, train_loss: 2.2683
2023-05-31 02:09:40 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 1.6231
2023-05-31 02:09:40 - train: epoch 0005, iter [00100, 00390], lr: 0.100000, loss: 2.6664
2023-05-31 02:09:42 - eval: epoch: 060, acc1: 64.180%, acc5: 89.300%, test_loss: 1.3706, per_image_load_time: 0.089ms, per_image_inference_time: 0.053ms
2023-05-31 02:09:42 - until epoch: 060, best_acc1: 65.350%
2023-05-31 02:09:42 - epoch 061 lr: 0.020000
2023-05-31 02:09:43 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 1.8054
2023-05-31 02:09:43 - train: epoch 0005, iter [00150, 00390], lr: 0.100000, loss: 2.4286
2023-05-31 02:09:46 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 0.6792
2023-05-31 02:09:46 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 1.6839
2023-05-31 02:09:47 - train: epoch 0005, iter [00200, 00390], lr: 0.100000, loss: 2.7208
2023-05-31 02:09:50 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 2.0096
2023-05-31 02:09:50 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 1.6575
2023-05-31 02:09:50 - train: epoch 0005, iter [00250, 00390], lr: 0.100000, loss: 2.4984
2023-05-31 02:09:52 - train: epoch 011, train_loss: 2.2065
2023-05-31 02:09:53 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 2.7612
2023-05-31 02:09:53 - train: epoch 0005, iter [00300, 00390], lr: 0.100000, loss: 2.4246
2023-05-31 02:09:54 - eval: epoch: 011, acc1: 47.890%, acc5: 79.350%, test_loss: 1.9235, per_image_load_time: 0.077ms, per_image_inference_time: 0.059ms
2023-05-31 02:09:54 - until epoch: 011, best_acc1: 47.890%
2023-05-31 02:09:54 - epoch 012 lr: 0.100000
2023-05-31 02:09:55 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 1.2577
2023-05-31 02:09:56 - train: epoch 0005, iter [00350, 00390], lr: 0.100000, loss: 2.2728
2023-05-31 02:09:58 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 2.0412
2023-05-31 02:09:59 - train: epoch 005, train_loss: 2.5491
2023-05-31 02:09:59 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 0.5311
2023-05-31 02:10:00 - eval: epoch: 005, acc1: 38.830%, acc5: 71.730%, test_loss: 2.3691, per_image_load_time: 0.075ms, per_image_inference_time: 0.057ms
2023-05-31 02:10:01 - until epoch: 005, best_acc1: 40.080%
2023-05-31 02:10:01 - epoch 006 lr: 0.100000
2023-05-31 02:10:01 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 2.2547
2023-05-31 02:10:01 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 2.4756
2023-05-31 02:10:04 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 2.9387
2023-05-31 02:10:05 - train: epoch 0006, iter [00050, 00390], lr: 0.100000, loss: 2.4376
2023-05-31 02:10:05 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 2.6300
2023-05-31 02:10:07 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 2.1736
2023-05-31 02:10:07 - train: epoch 061, train_loss: 1.9336
2023-05-31 02:10:08 - train: epoch 0006, iter [00100, 00390], lr: 0.100000, loss: 2.3786
2023-05-31 02:10:09 - eval: epoch: 061, acc1: 74.240%, acc5: 93.910%, test_loss: 0.9759, per_image_load_time: 0.089ms, per_image_inference_time: 0.055ms
2023-05-31 02:10:10 - until epoch: 061, best_acc1: 74.240%
2023-05-31 02:10:10 - epoch 062 lr: 0.020000
2023-05-31 02:10:10 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 2.2485
2023-05-31 02:10:11 - train: epoch 0006, iter [00150, 00390], lr: 0.100000, loss: 2.4567
2023-05-31 02:10:13 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 1.7338
2023-05-31 02:10:14 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 2.0365
2023-05-31 02:10:14 - train: epoch 0006, iter [00200, 00390], lr: 0.100000, loss: 2.4252
2023-05-31 02:10:17 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 1.6803
2023-05-31 02:10:17 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 2.1816
2023-05-31 02:10:17 - train: epoch 0006, iter [00250, 00390], lr: 0.100000, loss: 2.4337
2023-05-31 02:10:19 - train: epoch 012, train_loss: 2.1183
2023-05-31 02:10:20 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 2.7586
2023-05-31 02:10:20 - train: epoch 0006, iter [00300, 00390], lr: 0.100000, loss: 2.1992
2023-05-31 02:10:21 - eval: epoch: 012, acc1: 45.280%, acc5: 77.480%, test_loss: 2.0382, per_image_load_time: 0.071ms, per_image_inference_time: 0.055ms
2023-05-31 02:10:21 - until epoch: 012, best_acc1: 47.890%
2023-05-31 02:10:21 - epoch 013 lr: 0.100000
2023-05-31 02:10:23 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 0.6654
2023-05-31 02:10:23 - train: epoch 0006, iter [00350, 00390], lr: 0.100000, loss: 2.3020
2023-05-31 02:10:25 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 2.3312
2023-05-31 02:10:26 - train: epoch 006, train_loss: 2.4012
2023-05-31 02:10:26 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 2.1148
2023-05-31 02:10:27 - eval: epoch: 006, acc1: 47.020%, acc5: 79.490%, test_loss: 1.9583, per_image_load_time: 0.077ms, per_image_inference_time: 0.054ms
2023-05-31 02:10:28 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 2.2159
2023-05-31 02:10:28 - until epoch: 006, best_acc1: 47.020%
2023-05-31 02:10:28 - epoch 007 lr: 0.100000
2023-05-31 02:10:29 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 0.5201
2023-05-31 02:10:31 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 1.8276
2023-05-31 02:10:32 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 2.2892
2023-05-31 02:10:32 - train: epoch 0007, iter [00050, 00390], lr: 0.100000, loss: 2.4214
2023-05-31 02:10:34 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 2.2646
2023-05-31 02:10:35 - train: epoch 062, train_loss: 1.9114
2023-05-31 02:10:35 - train: epoch 0007, iter [00100, 00390], lr: 0.100000, loss: 2.1925
2023-05-31 02:10:36 - eval: epoch: 062, acc1: 75.290%, acc5: 94.010%, test_loss: 0.9605, per_image_load_time: 0.088ms, per_image_inference_time: 0.059ms
2023-05-31 02:10:37 - until epoch: 062, best_acc1: 75.290%
2023-05-31 02:10:37 - epoch 063 lr: 0.020000
2023-05-31 02:10:37 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 2.4995
2023-05-31 02:10:38 - train: epoch 0007, iter [00150, 00390], lr: 0.100000, loss: 2.2668
2023-05-31 02:10:40 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 1.9690
2023-05-31 02:10:41 - train: epoch 0007, iter [00200, 00390], lr: 0.100000, loss: 2.1776
2023-05-31 02:10:41 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 1.2963
2023-05-31 02:10:43 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 2.1103
2023-05-31 02:10:44 - train: epoch 0007, iter [00250, 00390], lr: 0.100000, loss: 2.2616
2023-05-31 02:10:44 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 2.3537
2023-05-31 02:10:46 - train: epoch 013, train_loss: 2.0423
2023-05-31 02:10:47 - train: epoch 0007, iter [00300, 00390], lr: 0.100000, loss: 1.9427
2023-05-31 02:10:48 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 2.0899
2023-05-31 02:10:48 - eval: epoch: 013, acc1: 46.130%, acc5: 78.110%, test_loss: 2.0268, per_image_load_time: 0.077ms, per_image_inference_time: 0.054ms
2023-05-31 02:10:48 - until epoch: 013, best_acc1: 47.890%
2023-05-31 02:10:48 - epoch 014 lr: 0.100000
2023-05-31 02:10:50 - train: epoch 0007, iter [00350, 00390], lr: 0.100000, loss: 2.2316
2023-05-31 02:10:50 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 0.5513
2023-05-31 02:10:52 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 2.6984
2023-05-31 02:10:53 - train: epoch 007, train_loss: 2.2938
2023-05-31 02:10:54 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 2.2672
2023-05-31 02:10:55 - eval: epoch: 007, acc1: 49.370%, acc5: 80.240%, test_loss: 1.8996, per_image_load_time: 0.074ms, per_image_inference_time: 0.054ms
2023-05-31 02:10:55 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 1.6404
2023-05-31 02:10:55 - until epoch: 007, best_acc1: 49.370%
2023-05-31 02:10:55 - epoch 008 lr: 0.100000
2023-05-31 02:10:56 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 2.1525
2023-05-31 02:10:58 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 1.6141
2023-05-31 02:10:59 - train: epoch 0008, iter [00050, 00390], lr: 0.100000, loss: 2.2993
2023-05-31 02:11:00 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 1.6947
2023-05-31 02:11:01 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 3.1223
2023-05-31 02:11:02 - train: epoch 0008, iter [00100, 00390], lr: 0.100000, loss: 2.2082
2023-05-31 02:11:03 - train: epoch 063, train_loss: 1.8234
2023-05-31 02:11:04 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 2.2183
2023-05-31 02:11:04 - eval: epoch: 063, acc1: 75.820%, acc5: 94.180%, test_loss: 0.9404, per_image_load_time: 0.084ms, per_image_inference_time: 0.054ms
2023-05-31 02:11:05 - until epoch: 063, best_acc1: 75.820%
2023-05-31 02:11:05 - epoch 064 lr: 0.020000
2023-05-31 02:11:05 - train: epoch 0008, iter [00150, 00390], lr: 0.100000, loss: 2.1981
2023-05-31 02:11:07 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 2.0093
2023-05-31 02:11:08 - train: epoch 0008, iter [00200, 00390], lr: 0.100000, loss: 2.0166
2023-05-31 02:11:09 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 2.3538
2023-05-31 02:11:10 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 2.5783
2023-05-31 02:11:11 - train: epoch 0008, iter [00250, 00390], lr: 0.100000, loss: 1.9563
2023-05-31 02:11:12 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 2.2600
2023-05-31 02:11:13 - train: epoch 014, train_loss: 2.0413
2023-05-31 02:11:14 - train: epoch 0008, iter [00300, 00390], lr: 0.100000, loss: 2.2361
2023-05-31 02:11:15 - eval: epoch: 014, acc1: 50.920%, acc5: 80.880%, test_loss: 1.8376, per_image_load_time: 0.070ms, per_image_inference_time: 0.057ms
2023-05-31 02:11:15 - until epoch: 014, best_acc1: 50.920%
2023-05-31 02:11:15 - epoch 015 lr: 0.100000
2023-05-31 02:11:15 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 2.1883
2023-05-31 02:11:17 - train: epoch 0008, iter [00350, 00390], lr: 0.100000, loss: 2.2228
2023-05-31 02:11:18 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 2.1178
2023-05-31 02:11:19 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 1.4864
2023-05-31 02:11:20 - train: epoch 008, train_loss: 2.2061
2023-05-31 02:11:21 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 2.4503
2023-05-31 02:11:22 - eval: epoch: 008, acc1: 51.190%, acc5: 80.990%, test_loss: 1.8357, per_image_load_time: 0.074ms, per_image_inference_time: 0.054ms
2023-05-31 02:11:22 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 2.8326
2023-05-31 02:11:22 - until epoch: 008, best_acc1: 51.190%
2023-05-31 02:11:22 - epoch 009 lr: 0.100000
2023-05-31 02:11:24 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 2.2837
2023-05-31 02:11:25 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 2.6285
2023-05-31 02:11:26 - train: epoch 0009, iter [00050, 00390], lr: 0.100000, loss: 2.0566
2023-05-31 02:11:27 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 2.4567
2023-05-31 02:11:28 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 1.8189
2023-05-31 02:11:29 - train: epoch 0009, iter [00100, 00390], lr: 0.100000, loss: 2.2251
2023-05-31 02:11:30 - train: epoch 064, train_loss: 1.7466
2023-05-31 02:11:31 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.5697
2023-05-31 02:11:32 - eval: epoch: 064, acc1: 75.610%, acc5: 94.280%, test_loss: 0.9359, per_image_load_time: 0.085ms, per_image_inference_time: 0.056ms
2023-05-31 02:11:32 - until epoch: 064, best_acc1: 75.820%
2023-05-31 02:11:32 - epoch 065 lr: 0.020000
2023-05-31 02:11:32 - train: epoch 0009, iter [00150, 00390], lr: 0.100000, loss: 2.0590
2023-05-31 02:11:34 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 1.5779
2023-05-31 02:11:35 - train: epoch 0009, iter [00200, 00390], lr: 0.100000, loss: 2.1153
2023-05-31 02:11:36 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 1.2862
2023-05-31 02:11:37 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 2.5485
2023-05-31 02:11:39 - train: epoch 0009, iter [00250, 00390], lr: 0.100000, loss: 2.2728
2023-05-31 02:11:40 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 2.2734
2023-05-31 02:11:40 - train: epoch 015, train_loss: 1.9631
2023-05-31 02:11:42 - eval: epoch: 015, acc1: 49.040%, acc5: 80.540%, test_loss: 1.8877, per_image_load_time: 0.076ms, per_image_inference_time: 0.057ms
2023-05-31 02:11:42 - train: epoch 0009, iter [00300, 00390], lr: 0.100000, loss: 1.9665
2023-05-31 02:11:42 - until epoch: 015, best_acc1: 50.920%
2023-05-31 02:11:42 - epoch 016 lr: 0.100000
2023-05-31 02:11:42 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 2.3361
2023-05-31 02:11:45 - train: epoch 0009, iter [00350, 00390], lr: 0.100000, loss: 2.2330
2023-05-31 02:11:45 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 1.0823
2023-05-31 02:11:46 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 2.0561
2023-05-31 02:11:47 - train: epoch 009, train_loss: 2.1341
2023-05-31 02:11:48 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 1.8400
2023-05-31 02:11:49 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 1.4620
2023-05-31 02:11:49 - eval: epoch: 009, acc1: 54.100%, acc5: 83.640%, test_loss: 1.6888, per_image_load_time: 0.071ms, per_image_inference_time: 0.065ms
2023-05-31 02:11:49 - until epoch: 009, best_acc1: 54.100%
2023-05-31 02:11:49 - epoch 010 lr: 0.100000
2023-05-31 02:11:51 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 1.3964
2023-05-31 02:11:52 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 1.8327
2023-05-31 02:11:53 - train: epoch 0010, iter [00050, 00390], lr: 0.100000, loss: 2.1598
2023-05-31 02:11:55 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 2.3880
2023-05-31 02:11:55 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 1.5537
2023-05-31 02:11:57 - train: epoch 0010, iter [00100, 00390], lr: 0.100000, loss: 2.0754
2023-05-31 02:11:57 - train: epoch 065, train_loss: 1.7730
2023-05-31 02:11:58 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 1.6246
2023-05-31 02:11:59 - eval: epoch: 065, acc1: 75.510%, acc5: 94.390%, test_loss: 0.9309, per_image_load_time: 0.095ms, per_image_inference_time: 0.058ms
2023-05-31 02:11:59 - until epoch: 065, best_acc1: 75.820%
2023-05-31 02:11:59 - epoch 066 lr: 0.020000
2023-05-31 02:12:00 - train: epoch 0010, iter [00150, 00390], lr: 0.100000, loss: 2.0279
2023-05-31 02:12:01 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 1.8831
2023-05-31 02:12:03 - train: epoch 0010, iter [00200, 00390], lr: 0.100000, loss: 2.1915
2023-05-31 02:12:04 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 2.4331
2023-05-31 02:12:04 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 2.5804
2023-05-31 02:12:06 - train: epoch 0010, iter [00250, 00390], lr: 0.100000, loss: 2.1426
2023-05-31 02:12:07 - train: epoch 016, train_loss: 1.9534
2023-05-31 02:12:07 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 1.9390
2023-05-31 02:12:08 - eval: epoch: 016, acc1: 52.960%, acc5: 83.420%, test_loss: 1.7228, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-05-31 02:12:09 - train: epoch 0010, iter [00300, 00390], lr: 0.100000, loss: 2.0947
2023-05-31 02:12:09 - until epoch: 016, best_acc1: 52.960%
2023-05-31 02:12:09 - epoch 017 lr: 0.100000
2023-05-31 02:12:10 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 2.0302
2023-05-31 02:12:12 - train: epoch 0010, iter [00350, 00390], lr: 0.100000, loss: 1.9322
2023-05-31 02:12:13 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 1.9841
2023-05-31 02:12:13 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 2.1447
2023-05-31 02:12:15 - train: epoch 010, train_loss: 2.0780
2023-05-31 02:12:16 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 1.0034
2023-05-31 02:12:16 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 2.1816
2023-05-31 02:12:16 - eval: epoch: 010, acc1: 54.830%, acc5: 84.040%, test_loss: 1.6730, per_image_load_time: 0.073ms, per_image_inference_time: 0.060ms
2023-05-31 02:12:17 - until epoch: 010, best_acc1: 54.830%
2023-05-31 02:12:17 - epoch 011 lr: 0.100000
2023-05-31 02:12:19 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 2.6007
2023-05-31 02:12:19 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 1.3602
2023-05-31 02:12:21 - train: epoch 0011, iter [00050, 00390], lr: 0.100000, loss: 2.0020
2023-05-31 02:12:22 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 2.3902
2023-05-31 02:12:22 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 1.0263
2023-05-31 02:12:24 - train: epoch 0011, iter [00100, 00390], lr: 0.100000, loss: 1.8027
2023-05-31 02:12:25 - train: epoch 066, train_loss: 1.7531
2023-05-31 02:12:25 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 2.5597
2023-05-31 02:12:27 - eval: epoch: 066, acc1: 76.210%, acc5: 94.260%, test_loss: 0.9150, per_image_load_time: 0.087ms, per_image_inference_time: 0.055ms
2023-05-31 02:12:27 - until epoch: 066, best_acc1: 76.210%
2023-05-31 02:12:27 - epoch 067 lr: 0.020000
2023-05-31 02:12:27 - train: epoch 0011, iter [00150, 00390], lr: 0.100000, loss: 2.1561
2023-05-31 02:12:28 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 2.3919
2023-05-31 02:12:30 - train: epoch 0011, iter [00200, 00390], lr: 0.100000, loss: 2.0044
2023-05-31 02:12:31 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 1.2558
2023-05-31 02:12:31 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 1.9201
2023-05-31 02:12:33 - train: epoch 0011, iter [00250, 00390], lr: 0.100000, loss: 2.0080
2023-05-31 02:12:34 - train: epoch 017, train_loss: 1.9491
2023-05-31 02:12:34 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 1.4572
2023-05-31 02:12:35 - eval: epoch: 017, acc1: 52.690%, acc5: 82.340%, test_loss: 1.7438, per_image_load_time: 0.074ms, per_image_inference_time: 0.054ms
2023-05-31 02:12:36 - until epoch: 017, best_acc1: 52.960%
2023-05-31 02:12:36 - epoch 018 lr: 0.100000
2023-05-31 02:12:36 - train: epoch 0011, iter [00300, 00390], lr: 0.100000, loss: 1.9814
2023-05-31 02:12:37 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 1.6097
2023-05-31 02:12:39 - train: epoch 0011, iter [00350, 00390], lr: 0.100000, loss: 1.9562
2023-05-31 02:12:40 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 2.6101
2023-05-31 02:12:40 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 1.1391
2023-05-31 02:12:42 - train: epoch 011, train_loss: 2.0324
2023-05-31 02:12:43 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 2.1185
2023-05-31 02:12:43 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 0.5164
2023-05-31 02:12:44 - eval: epoch: 011, acc1: 55.420%, acc5: 84.500%, test_loss: 1.6857, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-05-31 02:12:44 - until epoch: 011, best_acc1: 55.420%
2023-05-31 02:12:44 - epoch 012 lr: 0.100000
2023-05-31 02:12:46 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.5889
2023-05-31 02:12:46 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 2.3347
2023-05-31 02:12:48 - train: epoch 0012, iter [00050, 00390], lr: 0.100000, loss: 1.7970
2023-05-31 02:12:49 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 1.5346
2023-05-31 02:12:49 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 2.3029
2023-05-31 02:12:51 - train: epoch 0012, iter [00100, 00390], lr: 0.100000, loss: 2.0308
2023-05-31 02:12:52 - train: epoch 067, train_loss: 1.7618
2023-05-31 02:12:52 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 2.0262
2023-05-31 02:12:54 - eval: epoch: 067, acc1: 75.130%, acc5: 94.040%, test_loss: 0.9907, per_image_load_time: 0.081ms, per_image_inference_time: 0.059ms
2023-05-31 02:12:54 - until epoch: 067, best_acc1: 76.210%
2023-05-31 02:12:54 - epoch 068 lr: 0.020000
2023-05-31 02:12:54 - train: epoch 0012, iter [00150, 00390], lr: 0.100000, loss: 1.9897
2023-05-31 02:12:55 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 1.3237
2023-05-31 02:12:57 - train: epoch 0012, iter [00200, 00390], lr: 0.100000, loss: 2.1235
2023-05-31 02:12:58 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 1.6329
2023-05-31 02:12:58 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 1.7773
2023-05-31 02:13:00 - train: epoch 0012, iter [00250, 00390], lr: 0.100000, loss: 1.8738
2023-05-31 02:13:01 - train: epoch 018, train_loss: 1.8987
2023-05-31 02:13:01 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 1.8565
2023-05-31 02:13:03 - eval: epoch: 018, acc1: 50.560%, acc5: 81.830%, test_loss: 1.8537, per_image_load_time: 0.076ms, per_image_inference_time: 0.055ms
2023-05-31 02:13:03 - until epoch: 018, best_acc1: 52.960%
2023-05-31 02:13:03 - epoch 019 lr: 0.100000
2023-05-31 02:13:03 - train: epoch 0012, iter [00300, 00390], lr: 0.100000, loss: 2.0833
2023-05-31 02:13:04 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 2.6831
2023-05-31 02:13:06 - train: epoch 0012, iter [00350, 00390], lr: 0.100000, loss: 1.8982
2023-05-31 02:13:07 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 1.4056
2023-05-31 02:13:07 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 2.0367
2023-05-31 02:13:09 - train: epoch 012, train_loss: 1.9846
2023-05-31 02:13:10 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 1.3344
2023-05-31 02:13:10 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 2.3920
2023-05-31 02:13:11 - eval: epoch: 012, acc1: 54.930%, acc5: 83.190%, test_loss: 1.7229, per_image_load_time: 0.065ms, per_image_inference_time: 0.054ms
2023-05-31 02:13:11 - until epoch: 012, best_acc1: 55.420%
2023-05-31 02:13:11 - epoch 013 lr: 0.100000
2023-05-31 02:13:13 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 2.9401
2023-05-31 02:13:13 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 1.9656
2023-05-31 02:13:15 - train: epoch 0013, iter [00050, 00390], lr: 0.100000, loss: 1.9585
2023-05-31 02:13:16 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 2.1935
2023-05-31 02:13:17 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 2.1920
2023-05-31 02:13:18 - train: epoch 0013, iter [00100, 00390], lr: 0.100000, loss: 1.9038
2023-05-31 02:13:19 - train: epoch 068, train_loss: 1.7235
2023-05-31 02:13:19 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 1.8293
2023-05-31 02:13:21 - train: epoch 0013, iter [00150, 00390], lr: 0.100000, loss: 2.0763
2023-05-31 02:13:21 - eval: epoch: 068, acc1: 74.570%, acc5: 94.100%, test_loss: 0.9886, per_image_load_time: 0.091ms, per_image_inference_time: 0.055ms
2023-05-31 02:13:21 - until epoch: 068, best_acc1: 76.210%
2023-05-31 02:13:21 - epoch 069 lr: 0.020000
2023-05-31 02:13:22 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 2.0148
2023-05-31 02:13:24 - train: epoch 0013, iter [00200, 00390], lr: 0.100000, loss: 1.8745
2023-05-31 02:13:25 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 2.4569
2023-05-31 02:13:26 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 2.1830
2023-05-31 02:13:27 - train: epoch 0013, iter [00250, 00390], lr: 0.100000, loss: 2.0352
2023-05-31 02:13:28 - train: epoch 019, train_loss: 1.9127
2023-05-31 02:13:29 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 0.7179
2023-05-31 02:13:30 - eval: epoch: 019, acc1: 53.060%, acc5: 83.460%, test_loss: 1.7239, per_image_load_time: 0.067ms, per_image_inference_time: 0.055ms
2023-05-31 02:13:30 - until epoch: 019, best_acc1: 53.060%
2023-05-31 02:13:30 - epoch 020 lr: 0.100000
2023-05-31 02:13:30 - train: epoch 0013, iter [00300, 00390], lr: 0.100000, loss: 1.9891
2023-05-31 02:13:31 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 1.0108
2023-05-31 02:13:33 - train: epoch 0013, iter [00350, 00390], lr: 0.100000, loss: 1.8202
2023-05-31 02:13:34 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 2.4373
2023-05-31 02:13:35 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 2.3920
2023-05-31 02:13:36 - train: epoch 013, train_loss: 1.9572
2023-05-31 02:13:37 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 1.4968
2023-05-31 02:13:37 - eval: epoch: 013, acc1: 53.820%, acc5: 83.710%, test_loss: 1.7313, per_image_load_time: 0.071ms, per_image_inference_time: 0.056ms
2023-05-31 02:13:38 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 2.0922
2023-05-31 02:13:38 - until epoch: 013, best_acc1: 55.420%
2023-05-31 02:13:38 - epoch 014 lr: 0.100000
2023-05-31 02:13:40 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 2.6660
2023-05-31 02:13:41 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 1.4109
2023-05-31 02:13:42 - train: epoch 0014, iter [00050, 00390], lr: 0.100000, loss: 1.7961
2023-05-31 02:13:43 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 3.1252
2023-05-31 02:13:44 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 2.3741
2023-05-31 02:13:45 - train: epoch 0014, iter [00100, 00390], lr: 0.100000, loss: 1.7396
2023-05-31 02:13:46 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 1.2665
2023-05-31 02:13:47 - train: epoch 069, train_loss: 1.6895
2023-05-31 02:13:48 - train: epoch 0014, iter [00150, 00390], lr: 0.100000, loss: 1.8774
2023-05-31 02:13:48 - eval: epoch: 069, acc1: 75.260%, acc5: 94.100%, test_loss: 0.9624, per_image_load_time: 0.081ms, per_image_inference_time: 0.052ms
2023-05-31 02:13:48 - until epoch: 069, best_acc1: 76.210%
2023-05-31 02:13:48 - epoch 070 lr: 0.020000
2023-05-31 02:13:49 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 1.7070
2023-05-31 02:13:51 - train: epoch 0014, iter [00200, 00390], lr: 0.100000, loss: 1.8719
2023-05-31 02:13:52 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 1.4906
2023-05-31 02:13:53 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 2.3186
2023-05-31 02:13:54 - train: epoch 0014, iter [00250, 00390], lr: 0.100000, loss: 1.9183
2023-05-31 02:13:55 - train: epoch 020, train_loss: 1.8895
2023-05-31 02:13:56 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 2.3575
2023-05-31 02:13:57 - eval: epoch: 020, acc1: 54.730%, acc5: 84.200%, test_loss: 1.6524, per_image_load_time: 0.073ms, per_image_inference_time: 0.058ms
2023-05-31 02:13:57 - train: epoch 0014, iter [00300, 00390], lr: 0.100000, loss: 2.0035
2023-05-31 02:13:57 - until epoch: 020, best_acc1: 54.730%
2023-05-31 02:13:57 - epoch 021 lr: 0.100000
2023-05-31 02:13:59 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 0.6902
2023-05-31 02:14:00 - train: epoch 0014, iter [00350, 00390], lr: 0.100000, loss: 1.9579
2023-05-31 02:14:01 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 2.0734
2023-05-31 02:14:02 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 2.0417
2023-05-31 02:14:03 - train: epoch 014, train_loss: 1.9181
2023-05-31 02:14:04 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.4269
2023-05-31 02:14:04 - eval: epoch: 014, acc1: 57.440%, acc5: 85.870%, test_loss: 1.5734, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-05-31 02:14:05 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 1.5290
2023-05-31 02:14:05 - until epoch: 014, best_acc1: 57.440%
2023-05-31 02:14:05 - epoch 015 lr: 0.100000
2023-05-31 02:14:07 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 1.8248
2023-05-31 02:14:08 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 0.7040
2023-05-31 02:14:09 - train: epoch 0015, iter [00050, 00390], lr: 0.100000, loss: 1.6073
2023-05-31 02:14:10 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.5189
2023-05-31 02:14:11 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 2.3799
2023-05-31 02:14:12 - train: epoch 0015, iter [00100, 00390], lr: 0.100000, loss: 2.0152
2023-05-31 02:14:13 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 2.6954
2023-05-31 02:14:14 - train: epoch 070, train_loss: 1.7065
2023-05-31 02:14:15 - eval: epoch: 070, acc1: 74.710%, acc5: 93.820%, test_loss: 0.9523, per_image_load_time: 0.081ms, per_image_inference_time: 0.054ms
2023-05-31 02:14:15 - train: epoch 0015, iter [00150, 00390], lr: 0.100000, loss: 2.2069
2023-05-31 02:14:15 - until epoch: 070, best_acc1: 76.210%
2023-05-31 02:14:15 - epoch 071 lr: 0.020000
2023-05-31 02:14:16 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 1.6918
2023-05-31 02:14:18 - train: epoch 0015, iter [00200, 00390], lr: 0.100000, loss: 1.9549
2023-05-31 02:14:19 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 1.4302
2023-05-31 02:14:20 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 2.1009
2023-05-31 02:14:22 - train: epoch 0015, iter [00250, 00390], lr: 0.100000, loss: 1.9627
2023-05-31 02:14:22 - train: epoch 021, train_loss: 1.8574
2023-05-31 02:14:23 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 2.2333
2023-05-31 02:14:23 - eval: epoch: 021, acc1: 46.510%, acc5: 77.450%, test_loss: 2.2235, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-05-31 02:14:24 - until epoch: 021, best_acc1: 54.730%
2023-05-31 02:14:24 - epoch 022 lr: 0.100000
2023-05-31 02:14:24 - train: epoch 0015, iter [00300, 00390], lr: 0.100000, loss: 1.9027
2023-05-31 02:14:26 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 2.2227
2023-05-31 02:14:28 - train: epoch 0015, iter [00350, 00390], lr: 0.100000, loss: 1.9442
2023-05-31 02:14:28 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 1.8725
2023-05-31 02:14:29 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 2.1585
2023-05-31 02:14:30 - train: epoch 015, train_loss: 1.8976
2023-05-31 02:14:31 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 1.9780
2023-05-31 02:14:32 - eval: epoch: 015, acc1: 58.620%, acc5: 85.510%, test_loss: 1.5634, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-05-31 02:14:32 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 1.4093
2023-05-31 02:14:32 - until epoch: 015, best_acc1: 58.620%
2023-05-31 02:14:32 - epoch 016 lr: 0.100000
2023-05-31 02:14:34 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 2.4901
2023-05-31 02:14:35 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 2.4315
2023-05-31 02:14:36 - train: epoch 0016, iter [00050, 00390], lr: 0.100000, loss: 1.8682
2023-05-31 02:14:37 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 1.6122
2023-05-31 02:14:38 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 2.1083
2023-05-31 02:14:40 - train: epoch 0016, iter [00100, 00390], lr: 0.100000, loss: 1.7265
2023-05-31 02:14:40 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 1.8696
2023-05-31 02:14:41 - train: epoch 071, train_loss: 1.6887
2023-05-31 02:14:42 - eval: epoch: 071, acc1: 75.080%, acc5: 94.190%, test_loss: 0.9240, per_image_load_time: 0.077ms, per_image_inference_time: 0.053ms
2023-05-31 02:14:43 - train: epoch 0016, iter [00150, 00390], lr: 0.100000, loss: 2.0875
2023-05-31 02:14:43 - until epoch: 071, best_acc1: 76.210%
2023-05-31 02:14:43 - epoch 072 lr: 0.020000
2023-05-31 02:14:43 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 1.6014
2023-05-31 02:14:46 - train: epoch 0016, iter [00200, 00390], lr: 0.100000, loss: 1.9404
2023-05-31 02:14:46 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.3891
2023-05-31 02:14:47 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 2.1968
2023-05-31 02:14:49 - train: epoch 0016, iter [00250, 00390], lr: 0.100000, loss: 1.8355
2023-05-31 02:14:49 - train: epoch 022, train_loss: 1.8296
2023-05-31 02:14:50 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 2.4807
2023-05-31 02:14:51 - eval: epoch: 022, acc1: 57.670%, acc5: 86.000%, test_loss: 1.4986, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-05-31 02:14:51 - until epoch: 022, best_acc1: 57.670%
2023-05-31 02:14:51 - epoch 023 lr: 0.100000
2023-05-31 02:14:51 - train: epoch 0016, iter [00300, 00390], lr: 0.100000, loss: 1.9047
2023-05-31 02:14:53 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 2.3512
2023-05-31 02:14:55 - train: epoch 0016, iter [00350, 00390], lr: 0.100000, loss: 1.8513
2023-05-31 02:14:55 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 2.0820
2023-05-31 02:14:56 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 2.1410
2023-05-31 02:14:57 - train: epoch 016, train_loss: 1.8623
2023-05-31 02:14:58 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 1.5833
2023-05-31 02:14:59 - eval: epoch: 016, acc1: 56.470%, acc5: 84.900%, test_loss: 1.6398, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-05-31 02:14:59 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 0.4763
2023-05-31 02:14:59 - until epoch: 016, best_acc1: 58.620%
2023-05-31 02:14:59 - epoch 017 lr: 0.100000
2023-05-31 02:15:01 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 1.4182
2023-05-31 02:15:02 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 1.6584
2023-05-31 02:15:03 - train: epoch 0017, iter [00050, 00390], lr: 0.100000, loss: 1.7729
2023-05-31 02:15:04 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.3500
2023-05-31 02:15:05 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 2.4773
2023-05-31 02:15:07 - train: epoch 0017, iter [00100, 00390], lr: 0.100000, loss: 1.9610
2023-05-31 02:15:07 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 1.9490
2023-05-31 02:15:08 - train: epoch 072, train_loss: 1.7149
2023-05-31 02:15:10 - eval: epoch: 072, acc1: 75.110%, acc5: 93.780%, test_loss: 0.9559, per_image_load_time: 0.076ms, per_image_inference_time: 0.055ms
2023-05-31 02:15:10 - train: epoch 0017, iter [00150, 00390], lr: 0.100000, loss: 1.6580
2023-05-31 02:15:10 - until epoch: 072, best_acc1: 76.210%
2023-05-31 02:15:10 - epoch 073 lr: 0.020000
2023-05-31 02:15:10 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 1.5526
2023-05-31 02:15:13 - train: epoch 0017, iter [00200, 00390], lr: 0.100000, loss: 1.8418
2023-05-31 02:15:13 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 1.3910
2023-05-31 02:15:14 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 0.9922
2023-05-31 02:15:16 - train: epoch 0017, iter [00250, 00390], lr: 0.100000, loss: 1.8844
2023-05-31 02:15:16 - train: epoch 023, train_loss: 1.8095
2023-05-31 02:15:17 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 1.9396
2023-05-31 02:15:17 - eval: epoch: 023, acc1: 55.370%, acc5: 84.160%, test_loss: 1.6696, per_image_load_time: 0.065ms, per_image_inference_time: 0.052ms
2023-05-31 02:15:18 - until epoch: 023, best_acc1: 57.670%
2023-05-31 02:15:18 - epoch 024 lr: 0.100000
2023-05-31 02:15:19 - train: epoch 0017, iter [00300, 00390], lr: 0.100000, loss: 2.0538
2023-05-31 02:15:20 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 2.3121
2023-05-31 02:15:22 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 1.7918
2023-05-31 02:15:22 - train: epoch 0017, iter [00350, 00390], lr: 0.100000, loss: 1.6077
2023-05-31 02:15:23 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 1.2057
2023-05-31 02:15:25 - train: epoch 017, train_loss: 1.8449
2023-05-31 02:15:25 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 1.2692
2023-05-31 02:15:26 - eval: epoch: 017, acc1: 58.310%, acc5: 86.050%, test_loss: 1.5490, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-05-31 02:15:26 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 1.5963
2023-05-31 02:15:27 - until epoch: 017, best_acc1: 58.620%
2023-05-31 02:15:27 - epoch 018 lr: 0.100000
2023-05-31 02:15:28 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 1.6832
2023-05-31 02:15:29 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 2.2112
2023-05-31 02:15:31 - train: epoch 0018, iter [00050, 00390], lr: 0.100000, loss: 1.7554
2023-05-31 02:15:31 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 1.6387
2023-05-31 02:15:33 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 2.1450
2023-05-31 02:15:34 - train: epoch 0018, iter [00100, 00390], lr: 0.100000, loss: 1.6617
2023-05-31 02:15:34 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 1.7635
2023-05-31 02:15:35 - train: epoch 073, train_loss: 1.6526
2023-05-31 02:15:37 - eval: epoch: 073, acc1: 74.470%, acc5: 93.720%, test_loss: 0.9633, per_image_load_time: 0.078ms, per_image_inference_time: 0.053ms
2023-05-31 02:15:37 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.1638
2023-05-31 02:15:37 - train: epoch 0018, iter [00150, 00390], lr: 0.100000, loss: 1.9194
2023-05-31 02:15:37 - until epoch: 073, best_acc1: 76.210%
2023-05-31 02:15:37 - epoch 074 lr: 0.020000
2023-05-31 02:15:40 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 2.2376
2023-05-31 02:15:40 - train: epoch 0018, iter [00200, 00390], lr: 0.100000, loss: 1.8507
2023-05-31 02:15:41 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 2.3497
2023-05-31 02:15:43 - train: epoch 024, train_loss: 1.7434
2023-05-31 02:15:43 - train: epoch 0018, iter [00250, 00390], lr: 0.100000, loss: 1.8164
2023-05-31 02:15:44 - eval: epoch: 024, acc1: 55.100%, acc5: 83.220%, test_loss: 1.7058, per_image_load_time: 0.071ms, per_image_inference_time: 0.052ms
2023-05-31 02:15:44 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 0.5323
2023-05-31 02:15:44 - until epoch: 024, best_acc1: 57.670%
2023-05-31 02:15:44 - epoch 025 lr: 0.100000
2023-05-31 02:15:46 - train: epoch 0018, iter [00300, 00390], lr: 0.100000, loss: 1.6650
2023-05-31 02:15:47 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 1.7510
2023-05-31 02:15:48 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 2.0354
2023-05-31 02:15:49 - train: epoch 0018, iter [00350, 00390], lr: 0.100000, loss: 1.8983
2023-05-31 02:15:51 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 2.3799
2023-05-31 02:15:52 - train: epoch 018, train_loss: 1.8315
2023-05-31 02:15:52 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 1.7906
2023-05-31 02:15:53 - eval: epoch: 018, acc1: 59.870%, acc5: 87.280%, test_loss: 1.4973, per_image_load_time: 0.068ms, per_image_inference_time: 0.055ms
2023-05-31 02:15:54 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 2.1738
2023-05-31 02:15:54 - until epoch: 018, best_acc1: 59.870%
2023-05-31 02:15:54 - epoch 019 lr: 0.100000
2023-05-31 02:15:54 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.5417
2023-05-31 02:15:56 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 2.2935
2023-05-31 02:15:58 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 1.6134
2023-05-31 02:15:58 - train: epoch 0019, iter [00050, 00390], lr: 0.100000, loss: 1.7379
2023-05-31 02:16:00 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 1.8747
2023-05-31 02:16:01 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 1.3091
2023-05-31 02:16:01 - train: epoch 0019, iter [00100, 00390], lr: 0.100000, loss: 1.7411
2023-05-31 02:16:02 - train: epoch 074, train_loss: 1.6991
2023-05-31 02:16:04 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 1.8178
2023-05-31 02:16:04 - train: epoch 0019, iter [00150, 00390], lr: 0.100000, loss: 2.0417
2023-05-31 02:16:04 - eval: epoch: 074, acc1: 74.750%, acc5: 94.010%, test_loss: 0.9188, per_image_load_time: 0.086ms, per_image_inference_time: 0.061ms
2023-05-31 02:16:05 - until epoch: 074, best_acc1: 76.210%
2023-05-31 02:16:05 - epoch 075 lr: 0.020000
2023-05-31 02:16:07 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 2.5397
2023-05-31 02:16:07 - train: epoch 0019, iter [00200, 00390], lr: 0.100000, loss: 1.8847
2023-05-31 02:16:09 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 0.5142
2023-05-31 02:16:09 - train: epoch 025, train_loss: 1.7944
2023-05-31 02:16:10 - train: epoch 0019, iter [00250, 00390], lr: 0.100000, loss: 1.8033
2023-05-31 02:16:11 - eval: epoch: 025, acc1: 54.960%, acc5: 84.240%, test_loss: 1.6802, per_image_load_time: 0.068ms, per_image_inference_time: 0.061ms
2023-05-31 02:16:12 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 2.4265
2023-05-31 02:16:12 - until epoch: 025, best_acc1: 57.670%
2023-05-31 02:16:12 - epoch 026 lr: 0.100000
2023-05-31 02:16:13 - train: epoch 0019, iter [00300, 00390], lr: 0.100000, loss: 1.9327
2023-05-31 02:16:14 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 2.0539
2023-05-31 02:16:16 - train: epoch 0019, iter [00350, 00390], lr: 0.100000, loss: 1.7391
2023-05-31 02:16:16 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 1.2222
2023-05-31 02:16:18 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 1.5053
2023-05-31 02:16:19 - train: epoch 019, train_loss: 1.7987
2023-05-31 02:16:19 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 1.2739
2023-05-31 02:16:20 - eval: epoch: 019, acc1: 62.780%, acc5: 88.830%, test_loss: 1.3897, per_image_load_time: 0.070ms, per_image_inference_time: 0.052ms
2023-05-31 02:16:20 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 2.2520
2023-05-31 02:16:21 - until epoch: 019, best_acc1: 62.780%
2023-05-31 02:16:21 - epoch 020 lr: 0.100000
2023-05-31 02:16:22 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 2.1191
2023-05-31 02:16:23 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 2.1389
2023-05-31 02:16:25 - train: epoch 0020, iter [00050, 00390], lr: 0.100000, loss: 1.9120
2023-05-31 02:16:25 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 1.5089
2023-05-31 02:16:27 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 2.0746
2023-05-31 02:16:28 - train: epoch 0020, iter [00100, 00390], lr: 0.100000, loss: 1.7071
2023-05-31 02:16:28 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 1.5001
2023-05-31 02:16:29 - train: epoch 075, train_loss: 1.6908
2023-05-31 02:16:31 - train: epoch 0020, iter [00150, 00390], lr: 0.100000, loss: 1.9867
2023-05-31 02:16:31 - eval: epoch: 075, acc1: 74.210%, acc5: 93.390%, test_loss: 0.9705, per_image_load_time: 0.084ms, per_image_inference_time: 0.052ms
2023-05-31 02:16:31 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.2287
2023-05-31 02:16:31 - until epoch: 075, best_acc1: 76.210%
2023-05-31 02:16:31 - epoch 076 lr: 0.020000
2023-05-31 02:16:34 - train: epoch 0020, iter [00200, 00390], lr: 0.100000, loss: 1.8090
2023-05-31 02:16:34 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.7156
2023-05-31 02:16:36 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 1.9786
2023-05-31 02:16:37 - train: epoch 026, train_loss: 1.6983
2023-05-31 02:16:37 - train: epoch 0020, iter [00250, 00390], lr: 0.100000, loss: 1.7414
2023-05-31 02:16:38 - eval: epoch: 026, acc1: 52.460%, acc5: 82.090%, test_loss: 1.8400, per_image_load_time: 0.072ms, per_image_inference_time: 0.057ms
2023-05-31 02:16:39 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 1.3512
2023-05-31 02:16:39 - until epoch: 026, best_acc1: 57.670%
2023-05-31 02:16:39 - epoch 027 lr: 0.100000
2023-05-31 02:16:40 - train: epoch 0020, iter [00300, 00390], lr: 0.100000, loss: 1.7702
2023-05-31 02:16:41 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 2.1305
2023-05-31 02:16:43 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 1.1962
2023-05-31 02:16:43 - train: epoch 0020, iter [00350, 00390], lr: 0.100000, loss: 1.7118
2023-05-31 02:16:45 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 0.4976
2023-05-31 02:16:46 - train: epoch 020, train_loss: 1.7811
2023-05-31 02:16:46 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 1.3779
2023-05-31 02:16:47 - eval: epoch: 020, acc1: 58.650%, acc5: 85.390%, test_loss: 1.5762, per_image_load_time: 0.065ms, per_image_inference_time: 0.057ms
2023-05-31 02:16:48 - until epoch: 020, best_acc1: 62.780%
2023-05-31 02:16:48 - epoch 021 lr: 0.100000
2023-05-31 02:16:48 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 2.2596
2023-05-31 02:16:49 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 1.1859
2023-05-31 02:16:51 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 1.0530
2023-05-31 02:16:52 - train: epoch 0021, iter [00050, 00390], lr: 0.100000, loss: 1.7506
2023-05-31 02:16:52 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 1.3583
2023-05-31 02:16:54 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 2.5002
2023-05-31 02:16:55 - train: epoch 0021, iter [00100, 00390], lr: 0.100000, loss: 1.6882
2023-05-31 02:16:55 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 1.6133
2023-05-31 02:16:57 - train: epoch 076, train_loss: 1.6662
2023-05-31 02:16:58 - train: epoch 0021, iter [00150, 00390], lr: 0.100000, loss: 1.8885
2023-05-31 02:16:58 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 1.8494
2023-05-31 02:16:58 - eval: epoch: 076, acc1: 74.150%, acc5: 93.460%, test_loss: 0.9885, per_image_load_time: 0.082ms, per_image_inference_time: 0.056ms
2023-05-31 02:16:59 - until epoch: 076, best_acc1: 76.210%
2023-05-31 02:16:59 - epoch 077 lr: 0.020000
2023-05-31 02:17:01 - train: epoch 0021, iter [00200, 00390], lr: 0.100000, loss: 1.8714
2023-05-31 02:17:01 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 1.4837
2023-05-31 02:17:03 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 1.0278
2023-05-31 02:17:04 - train: epoch 027, train_loss: 1.7622
2023-05-31 02:17:04 - train: epoch 0021, iter [00250, 00390], lr: 0.100000, loss: 1.7774
2023-05-31 02:17:06 - eval: epoch: 027, acc1: 53.620%, acc5: 83.900%, test_loss: 1.7115, per_image_load_time: 0.067ms, per_image_inference_time: 0.058ms
2023-05-31 02:17:06 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 2.2848
2023-05-31 02:17:06 - until epoch: 027, best_acc1: 57.670%
2023-05-31 02:17:06 - epoch 028 lr: 0.100000
2023-05-31 02:17:07 - train: epoch 0021, iter [00300, 00390], lr: 0.100000, loss: 1.9302
2023-05-31 02:17:09 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 1.3098
2023-05-31 02:17:10 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 1.6071
2023-05-31 02:17:10 - train: epoch 0021, iter [00350, 00390], lr: 0.100000, loss: 1.6888
2023-05-31 02:17:12 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 2.1181
2023-05-31 02:17:13 - train: epoch 021, train_loss: 1.7736
2023-05-31 02:17:13 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 1.4209
2023-05-31 02:17:15 - eval: epoch: 021, acc1: 59.220%, acc5: 86.880%, test_loss: 1.5308, per_image_load_time: 0.072ms, per_image_inference_time: 0.058ms
2023-05-31 02:17:15 - until epoch: 021, best_acc1: 62.780%
2023-05-31 02:17:15 - epoch 022 lr: 0.100000
2023-05-31 02:17:15 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 2.4215
2023-05-31 02:17:16 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 1.2724
2023-05-31 02:17:18 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 1.3435
2023-05-31 02:17:19 - train: epoch 0022, iter [00050, 00390], lr: 0.100000, loss: 1.6504
2023-05-31 02:17:19 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 1.4532
2023-05-31 02:17:21 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 2.3481
2023-05-31 02:17:22 - train: epoch 0022, iter [00100, 00390], lr: 0.100000, loss: 1.7294
2023-05-31 02:17:22 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 1.5907
2023-05-31 02:17:24 - train: epoch 077, train_loss: 1.6653
2023-05-31 02:17:25 - train: epoch 0022, iter [00150, 00390], lr: 0.100000, loss: 1.7919
2023-05-31 02:17:25 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 1.2471
2023-05-31 02:17:26 - eval: epoch: 077, acc1: 73.990%, acc5: 93.620%, test_loss: 0.9723, per_image_load_time: 0.080ms, per_image_inference_time: 0.053ms
2023-05-31 02:17:26 - until epoch: 077, best_acc1: 76.210%
2023-05-31 02:17:26 - epoch 078 lr: 0.020000
2023-05-31 02:17:28 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 2.7276
2023-05-31 02:17:28 - train: epoch 0022, iter [00200, 00390], lr: 0.100000, loss: 2.0711
2023-05-31 02:17:30 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 1.8464
2023-05-31 02:17:31 - train: epoch 028, train_loss: 1.7502
2023-05-31 02:17:31 - train: epoch 0022, iter [00250, 00390], lr: 0.100000, loss: 1.8417
2023-05-31 02:17:32 - eval: epoch: 028, acc1: 55.900%, acc5: 84.880%, test_loss: 1.5965, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-05-31 02:17:33 - until epoch: 028, best_acc1: 57.670%
2023-05-31 02:17:33 - epoch 029 lr: 0.100000
2023-05-31 02:17:33 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 0.3574
2023-05-31 02:17:34 - train: epoch 0022, iter [00300, 00390], lr: 0.100000, loss: 1.8170
2023-05-31 02:17:36 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 1.2882
2023-05-31 02:17:37 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 1.5803
2023-05-31 02:17:37 - train: epoch 0022, iter [00350, 00390], lr: 0.100000, loss: 1.7695
2023-05-31 02:17:39 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 2.3521
2023-05-31 02:17:40 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 2.4860
2023-05-31 02:17:40 - train: epoch 022, train_loss: 1.7601
2023-05-31 02:17:42 - eval: epoch: 022, acc1: 61.010%, acc5: 87.570%, test_loss: 1.4583, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-05-31 02:17:42 - until epoch: 022, best_acc1: 62.780%
2023-05-31 02:17:42 - epoch 023 lr: 0.100000
2023-05-31 02:17:42 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 2.2463
2023-05-31 02:17:43 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 2.9087
2023-05-31 02:17:45 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 2.4036
2023-05-31 02:17:46 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 1.2421
2023-05-31 02:17:46 - train: epoch 0023, iter [00050, 00390], lr: 0.100000, loss: 1.6022
2023-05-31 02:17:49 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 0.3971
2023-05-31 02:17:49 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 1.2426
2023-05-31 02:17:49 - train: epoch 0023, iter [00100, 00390], lr: 0.100000, loss: 1.7023
2023-05-31 02:17:51 - train: epoch 078, train_loss: 1.6428
2023-05-31 02:17:52 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 2.3777
2023-05-31 02:17:52 - train: epoch 0023, iter [00150, 00390], lr: 0.100000, loss: 1.7511
2023-05-31 02:17:53 - eval: epoch: 078, acc1: 74.050%, acc5: 93.440%, test_loss: 0.9859, per_image_load_time: 0.080ms, per_image_inference_time: 0.052ms
2023-05-31 02:17:53 - until epoch: 078, best_acc1: 76.210%
2023-05-31 02:17:53 - epoch 079 lr: 0.020000
2023-05-31 02:17:55 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 1.1487
2023-05-31 02:17:55 - train: epoch 0023, iter [00200, 00390], lr: 0.100000, loss: 1.8719
2023-05-31 02:17:57 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 1.4598
2023-05-31 02:17:57 - train: epoch 029, train_loss: 1.7438
2023-05-31 02:17:58 - train: epoch 0023, iter [00250, 00390], lr: 0.100000, loss: 1.8589
2023-05-31 02:17:59 - eval: epoch: 029, acc1: 57.800%, acc5: 85.890%, test_loss: 1.5300, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-05-31 02:18:00 - until epoch: 029, best_acc1: 57.800%
2023-05-31 02:18:00 - epoch 030 lr: 0.100000
2023-05-31 02:18:00 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 0.4871
2023-05-31 02:18:01 - train: epoch 0023, iter [00300, 00390], lr: 0.100000, loss: 1.9081
2023-05-31 02:18:03 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 2.0585
2023-05-31 02:18:04 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 3.0072
2023-05-31 02:18:04 - train: epoch 0023, iter [00350, 00390], lr: 0.100000, loss: 1.6407
2023-05-31 02:18:06 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 2.3431
2023-05-31 02:18:07 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 2.9584
2023-05-31 02:18:07 - train: epoch 023, train_loss: 1.7423
2023-05-31 02:18:08 - eval: epoch: 023, acc1: 60.630%, acc5: 86.430%, test_loss: 1.5045, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-05-31 02:18:09 - until epoch: 023, best_acc1: 62.780%
2023-05-31 02:18:09 - epoch 024 lr: 0.100000
2023-05-31 02:18:09 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 2.1695
2023-05-31 02:18:09 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 1.0888
2023-05-31 02:18:12 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 1.9328
2023-05-31 02:18:13 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 1.7790
2023-05-31 02:18:13 - train: epoch 0024, iter [00050, 00390], lr: 0.100000, loss: 1.4820
2023-05-31 02:18:15 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 1.8148
2023-05-31 02:18:16 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 1.6493
2023-05-31 02:18:16 - train: epoch 0024, iter [00100, 00390], lr: 0.100000, loss: 1.7580
2023-05-31 02:18:18 - train: epoch 079, train_loss: 1.5858
2023-05-31 02:18:19 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 1.1089
2023-05-31 02:18:19 - train: epoch 0024, iter [00150, 00390], lr: 0.100000, loss: 1.6523
2023-05-31 02:18:20 - eval: epoch: 079, acc1: 74.050%, acc5: 93.360%, test_loss: 0.9706, per_image_load_time: 0.082ms, per_image_inference_time: 0.058ms
2023-05-31 02:18:20 - until epoch: 079, best_acc1: 76.210%
2023-05-31 02:18:20 - epoch 080 lr: 0.020000
2023-05-31 02:18:22 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 1.4589
2023-05-31 02:18:22 - train: epoch 0024, iter [00200, 00390], lr: 0.100000, loss: 2.0180
2023-05-31 02:18:24 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 1.8958
2023-05-31 02:18:25 - train: epoch 030, train_loss: 1.7284
2023-05-31 02:18:25 - train: epoch 0024, iter [00250, 00390], lr: 0.100000, loss: 1.7685
2023-05-31 02:18:26 - eval: epoch: 030, acc1: 54.580%, acc5: 83.450%, test_loss: 1.7050, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-05-31 02:18:26 - until epoch: 030, best_acc1: 57.800%
2023-05-31 02:18:26 - epoch 031 lr: 0.100000
2023-05-31 02:18:27 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 2.1526
2023-05-31 02:18:28 - train: epoch 0024, iter [00300, 00390], lr: 0.100000, loss: 1.6954
2023-05-31 02:18:30 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 0.9887
2023-05-31 02:18:30 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 1.2946
2023-05-31 02:18:31 - train: epoch 0024, iter [00350, 00390], lr: 0.100000, loss: 1.7860
2023-05-31 02:18:34 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 2.3393
2023-05-31 02:18:34 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 1.8047
2023-05-31 02:18:34 - train: epoch 024, train_loss: 1.7328
2023-05-31 02:18:36 - eval: epoch: 024, acc1: 59.820%, acc5: 86.740%, test_loss: 1.5107, per_image_load_time: 0.075ms, per_image_inference_time: 0.055ms
2023-05-31 02:18:36 - until epoch: 024, best_acc1: 62.780%
2023-05-31 02:18:36 - epoch 025 lr: 0.100000
2023-05-31 02:18:36 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 1.7296
2023-05-31 02:18:36 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 1.6132
2023-05-31 02:18:39 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 1.3514
2023-05-31 02:18:40 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 1.3803
2023-05-31 02:18:40 - train: epoch 0025, iter [00050, 00390], lr: 0.100000, loss: 1.6734
2023-05-31 02:18:43 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 2.6379
2023-05-31 02:18:43 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 2.0414
2023-05-31 02:18:43 - train: epoch 0025, iter [00100, 00390], lr: 0.100000, loss: 1.5944
2023-05-31 02:18:45 - train: epoch 080, train_loss: 1.6565
2023-05-31 02:18:46 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 2.2259
2023-05-31 02:18:46 - train: epoch 0025, iter [00150, 00390], lr: 0.100000, loss: 1.8199
2023-05-31 02:18:47 - eval: epoch: 080, acc1: 74.150%, acc5: 93.490%, test_loss: 0.9690, per_image_load_time: 0.085ms, per_image_inference_time: 0.059ms
2023-05-31 02:18:48 - until epoch: 080, best_acc1: 76.210%
2023-05-31 02:18:48 - epoch 081 lr: 0.020000
2023-05-31 02:18:49 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 3.1134
2023-05-31 02:18:49 - train: epoch 0025, iter [00200, 00390], lr: 0.100000, loss: 1.7531
2023-05-31 02:18:51 - train: epoch 031, train_loss: 1.7183
2023-05-31 02:18:51 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 2.1690
2023-05-31 02:18:52 - train: epoch 0025, iter [00250, 00390], lr: 0.100000, loss: 1.7097
2023-05-31 02:18:53 - eval: epoch: 031, acc1: 56.050%, acc5: 84.970%, test_loss: 1.6255, per_image_load_time: 0.066ms, per_image_inference_time: 0.055ms
2023-05-31 02:18:53 - until epoch: 031, best_acc1: 57.800%
2023-05-31 02:18:53 - epoch 032 lr: 0.100000
2023-05-31 02:18:54 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 1.5459
2023-05-31 02:18:55 - train: epoch 0025, iter [00300, 00390], lr: 0.100000, loss: 1.8795
2023-05-31 02:18:57 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 1.8058
2023-05-31 02:18:58 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 2.1773
2023-05-31 02:18:59 - train: epoch 0025, iter [00350, 00390], lr: 0.100000, loss: 1.6465
2023-05-31 02:19:00 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 1.9326
2023-05-31 02:19:01 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 0.7697
2023-05-31 02:19:01 - train: epoch 025, train_loss: 1.7171
2023-05-31 02:19:03 - eval: epoch: 025, acc1: 59.690%, acc5: 87.100%, test_loss: 1.5279, per_image_load_time: 0.067ms, per_image_inference_time: 0.055ms
2023-05-31 02:19:03 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 3.1120
2023-05-31 02:19:03 - until epoch: 025, best_acc1: 62.780%
2023-05-31 02:19:03 - epoch 026 lr: 0.100000
2023-05-31 02:19:04 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 1.7112
2023-05-31 02:19:06 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 1.3703
2023-05-31 02:19:07 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 1.9851
2023-05-31 02:19:07 - train: epoch 0026, iter [00050, 00390], lr: 0.100000, loss: 1.6674
2023-05-31 02:19:09 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 1.4444
2023-05-31 02:19:10 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 1.6682
2023-05-31 02:19:11 - train: epoch 0026, iter [00100, 00390], lr: 0.100000, loss: 1.5210
2023-05-31 02:19:12 - train: epoch 081, train_loss: 1.6854
2023-05-31 02:19:13 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 1.2082
2023-05-31 02:19:14 - train: epoch 0026, iter [00150, 00390], lr: 0.100000, loss: 1.7095
2023-05-31 02:19:14 - eval: epoch: 081, acc1: 74.360%, acc5: 93.580%, test_loss: 0.9629, per_image_load_time: 0.084ms, per_image_inference_time: 0.055ms
2023-05-31 02:19:14 - until epoch: 081, best_acc1: 76.210%
2023-05-31 02:19:14 - epoch 082 lr: 0.020000
2023-05-31 02:19:15 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 1.3970
2023-05-31 02:19:17 - train: epoch 0026, iter [00200, 00390], lr: 0.100000, loss: 1.7227
2023-05-31 02:19:18 - train: epoch 032, train_loss: 1.7013
2023-05-31 02:19:18 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 2.1993
2023-05-31 02:19:20 - eval: epoch: 032, acc1: 56.150%, acc5: 84.460%, test_loss: 1.6635, per_image_load_time: 0.064ms, per_image_inference_time: 0.056ms
2023-05-31 02:19:20 - train: epoch 0026, iter [00250, 00390], lr: 0.100000, loss: 1.6433
2023-05-31 02:19:20 - until epoch: 032, best_acc1: 57.800%
2023-05-31 02:19:20 - epoch 033 lr: 0.100000
2023-05-31 02:19:21 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 1.3533
2023-05-31 02:19:23 - train: epoch 0026, iter [00300, 00390], lr: 0.100000, loss: 1.8339
2023-05-31 02:19:24 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 1.5851
2023-05-31 02:19:24 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 2.1186
2023-05-31 02:19:26 - train: epoch 0026, iter [00350, 00390], lr: 0.100000, loss: 1.9310
2023-05-31 02:19:27 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 1.2128
2023-05-31 02:19:28 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 2.2959
2023-05-31 02:19:29 - train: epoch 026, train_loss: 1.7098
2023-05-31 02:19:30 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 1.3680
2023-05-31 02:19:30 - eval: epoch: 026, acc1: 62.220%, acc5: 88.680%, test_loss: 1.4030, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-05-31 02:19:31 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 2.1713
2023-05-31 02:19:31 - until epoch: 026, best_acc1: 62.780%
2023-05-31 02:19:31 - epoch 027 lr: 0.100000
2023-05-31 02:19:33 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 2.3611
2023-05-31 02:19:33 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 0.4514
2023-05-31 02:19:35 - train: epoch 0027, iter [00050, 00390], lr: 0.100000, loss: 1.6918
2023-05-31 02:19:36 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 1.6061
2023-05-31 02:19:37 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 0.5503
2023-05-31 02:19:38 - train: epoch 0027, iter [00100, 00390], lr: 0.100000, loss: 1.6632
2023-05-31 02:19:39 - train: epoch 082, train_loss: 1.7166
2023-05-31 02:19:39 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 2.2249
2023-05-31 02:19:41 - eval: epoch: 082, acc1: 74.000%, acc5: 93.470%, test_loss: 1.0019, per_image_load_time: 0.075ms, per_image_inference_time: 0.058ms
2023-05-31 02:19:41 - train: epoch 0027, iter [00150, 00390], lr: 0.100000, loss: 1.7274
2023-05-31 02:19:41 - until epoch: 082, best_acc1: 76.210%
2023-05-31 02:19:41 - epoch 083 lr: 0.020000
2023-05-31 02:19:42 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 1.1750
2023-05-31 02:19:44 - train: epoch 0027, iter [00200, 00390], lr: 0.100000, loss: 1.8582
2023-05-31 02:19:45 - train: epoch 033, train_loss: 1.6974
2023-05-31 02:19:45 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 1.4950
2023-05-31 02:19:46 - eval: epoch: 033, acc1: 58.420%, acc5: 85.730%, test_loss: 1.5393, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-05-31 02:19:47 - until epoch: 033, best_acc1: 58.420%
2023-05-31 02:19:47 - epoch 034 lr: 0.100000
2023-05-31 02:19:47 - train: epoch 0027, iter [00250, 00390], lr: 0.100000, loss: 1.8512
2023-05-31 02:19:48 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 1.1657
2023-05-31 02:19:50 - train: epoch 0027, iter [00300, 00390], lr: 0.100000, loss: 1.7995
2023-05-31 02:19:51 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 2.3585
2023-05-31 02:19:51 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 2.2393
2023-05-31 02:19:53 - train: epoch 0027, iter [00350, 00390], lr: 0.100000, loss: 1.7521
2023-05-31 02:19:54 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 2.4293
2023-05-31 02:19:55 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 0.5233
2023-05-31 02:19:56 - train: epoch 027, train_loss: 1.7005
2023-05-31 02:19:57 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 1.2424
2023-05-31 02:19:58 - eval: epoch: 027, acc1: 58.640%, acc5: 86.160%, test_loss: 1.5585, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-05-31 02:19:58 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 0.8809
2023-05-31 02:19:58 - until epoch: 027, best_acc1: 62.780%
2023-05-31 02:19:58 - epoch 028 lr: 0.100000
2023-05-31 02:20:00 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 2.2046
2023-05-31 02:20:01 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 0.6045
2023-05-31 02:20:02 - train: epoch 0028, iter [00050, 00390], lr: 0.100000, loss: 1.7759
2023-05-31 02:20:03 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 1.1933
2023-05-31 02:20:04 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 0.6162
2023-05-31 02:20:05 - train: epoch 0028, iter [00100, 00390], lr: 0.100000, loss: 1.7273
2023-05-31 02:20:07 - train: epoch 083, train_loss: 1.6771
2023-05-31 02:20:07 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 1.8532
2023-05-31 02:20:08 - eval: epoch: 083, acc1: 74.320%, acc5: 93.370%, test_loss: 0.9852, per_image_load_time: 0.076ms, per_image_inference_time: 0.051ms
2023-05-31 02:20:08 - train: epoch 0028, iter [00150, 00390], lr: 0.100000, loss: 1.7118
2023-05-31 02:20:08 - until epoch: 083, best_acc1: 76.210%
2023-05-31 02:20:08 - epoch 084 lr: 0.020000
2023-05-31 02:20:09 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 2.5327
2023-05-31 02:20:11 - train: epoch 0028, iter [00200, 00390], lr: 0.100000, loss: 1.7420
2023-05-31 02:20:12 - train: epoch 034, train_loss: 1.7065
2023-05-31 02:20:12 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 0.5647
2023-05-31 02:20:14 - eval: epoch: 034, acc1: 57.300%, acc5: 85.270%, test_loss: 1.5628, per_image_load_time: 0.072ms, per_image_inference_time: 0.056ms
2023-05-31 02:20:14 - until epoch: 034, best_acc1: 58.420%
2023-05-31 02:20:14 - epoch 035 lr: 0.100000
2023-05-31 02:20:14 - train: epoch 0028, iter [00250, 00390], lr: 0.100000, loss: 1.7084
2023-05-31 02:20:16 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 2.2512
2023-05-31 02:20:17 - train: epoch 0028, iter [00300, 00390], lr: 0.100000, loss: 1.5311
2023-05-31 02:20:18 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 1.4269
2023-05-31 02:20:19 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 1.7656
2023-05-31 02:20:20 - train: epoch 0028, iter [00350, 00390], lr: 0.100000, loss: 1.6435
2023-05-31 02:20:21 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 1.3641
2023-05-31 02:20:22 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 1.8325
2023-05-31 02:20:23 - train: epoch 028, train_loss: 1.6852
2023-05-31 02:20:24 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 1.2382
2023-05-31 02:20:25 - eval: epoch: 028, acc1: 62.830%, acc5: 88.030%, test_loss: 1.4109, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-05-31 02:20:25 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 2.3053
2023-05-31 02:20:25 - until epoch: 028, best_acc1: 62.830%
2023-05-31 02:20:25 - epoch 029 lr: 0.100000
2023-05-31 02:20:27 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 1.1438
2023-05-31 02:20:28 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 1.0884
2023-05-31 02:20:29 - train: epoch 0029, iter [00050, 00390], lr: 0.100000, loss: 1.6283
2023-05-31 02:20:30 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 2.3781
2023-05-31 02:20:31 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 2.4310
2023-05-31 02:20:32 - train: epoch 0029, iter [00100, 00390], lr: 0.100000, loss: 1.6045
2023-05-31 02:20:34 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 1.7921
2023-05-31 02:20:34 - train: epoch 084, train_loss: 1.6674
2023-05-31 02:20:35 - train: epoch 0029, iter [00150, 00390], lr: 0.100000, loss: 1.6961
2023-05-31 02:20:36 - eval: epoch: 084, acc1: 74.000%, acc5: 93.420%, test_loss: 1.0152, per_image_load_time: 0.083ms, per_image_inference_time: 0.053ms
2023-05-31 02:20:36 - until epoch: 084, best_acc1: 76.210%
2023-05-31 02:20:36 - epoch 085 lr: 0.020000
2023-05-31 02:20:36 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 2.3186
2023-05-31 02:20:38 - train: epoch 0029, iter [00200, 00390], lr: 0.100000, loss: 1.7673
2023-05-31 02:20:39 - train: epoch 035, train_loss: 1.6786
2023-05-31 02:20:40 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 1.7415
2023-05-31 02:20:40 - eval: epoch: 035, acc1: 58.230%, acc5: 85.860%, test_loss: 1.5420, per_image_load_time: 0.061ms, per_image_inference_time: 0.055ms
2023-05-31 02:20:41 - until epoch: 035, best_acc1: 58.420%
2023-05-31 02:20:41 - epoch 036 lr: 0.100000
2023-05-31 02:20:41 - train: epoch 0029, iter [00250, 00390], lr: 0.100000, loss: 1.6367
2023-05-31 02:20:43 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 1.9732
2023-05-31 02:20:44 - train: epoch 0029, iter [00300, 00390], lr: 0.100000, loss: 1.7147
2023-05-31 02:20:45 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 1.3780
2023-05-31 02:20:46 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 1.6732
2023-05-31 02:20:48 - train: epoch 0029, iter [00350, 00390], lr: 0.100000, loss: 1.7395
2023-05-31 02:20:48 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 1.1163
2023-05-31 02:20:49 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 1.0324
2023-05-31 02:20:50 - train: epoch 029, train_loss: 1.6771
2023-05-31 02:20:51 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 3.7439
2023-05-31 02:20:52 - eval: epoch: 029, acc1: 60.410%, acc5: 86.590%, test_loss: 1.5093, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-05-31 02:20:52 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 1.9425
2023-05-31 02:20:52 - until epoch: 029, best_acc1: 62.830%
2023-05-31 02:20:52 - epoch 030 lr: 0.100000
2023-05-31 02:20:54 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 2.4118
2023-05-31 02:20:55 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 0.6332
2023-05-31 02:20:56 - train: epoch 0030, iter [00050, 00390], lr: 0.100000, loss: 1.5738
2023-05-31 02:20:57 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 1.5018
2023-05-31 02:20:58 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 2.4827
2023-05-31 02:21:00 - train: epoch 0030, iter [00100, 00390], lr: 0.100000, loss: 1.5392
2023-05-31 02:21:00 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 1.1274
2023-05-31 02:21:01 - train: epoch 085, train_loss: 1.6457
2023-05-31 02:21:03 - train: epoch 0030, iter [00150, 00390], lr: 0.100000, loss: 1.5417
2023-05-31 02:21:03 - eval: epoch: 085, acc1: 74.560%, acc5: 93.810%, test_loss: 0.9378, per_image_load_time: 0.079ms, per_image_inference_time: 0.053ms
2023-05-31 02:21:03 - until epoch: 085, best_acc1: 76.210%
2023-05-31 02:21:03 - epoch 086 lr: 0.020000
2023-05-31 02:21:03 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 1.6031
2023-05-31 02:21:05 - train: epoch 0030, iter [00200, 00390], lr: 0.100000, loss: 1.4615
2023-05-31 02:21:06 - train: epoch 036, train_loss: 1.7062
2023-05-31 02:21:07 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 0.3655
2023-05-31 02:21:07 - eval: epoch: 036, acc1: 57.860%, acc5: 86.200%, test_loss: 1.5300, per_image_load_time: 0.061ms, per_image_inference_time: 0.054ms
2023-05-31 02:21:07 - until epoch: 036, best_acc1: 58.420%
2023-05-31 02:21:07 - epoch 037 lr: 0.100000
2023-05-31 02:21:08 - train: epoch 0030, iter [00250, 00390], lr: 0.100000, loss: 1.7405
2023-05-31 02:21:10 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 0.3482
2023-05-31 02:21:11 - train: epoch 0030, iter [00300, 00390], lr: 0.100000, loss: 1.5161
2023-05-31 02:21:11 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 2.7960
2023-05-31 02:21:13 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 1.3956
2023-05-31 02:21:15 - train: epoch 0030, iter [00350, 00390], lr: 0.100000, loss: 1.6287
2023-05-31 02:21:15 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 1.2497
2023-05-31 02:21:16 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 1.3023
2023-05-31 02:21:17 - train: epoch 030, train_loss: 1.6733
2023-05-31 02:21:18 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 1.5543
2023-05-31 02:21:19 - eval: epoch: 030, acc1: 58.690%, acc5: 85.630%, test_loss: 1.5802, per_image_load_time: 0.072ms, per_image_inference_time: 0.056ms
2023-05-31 02:21:19 - until epoch: 030, best_acc1: 62.830%
2023-05-31 02:21:19 - epoch 031 lr: 0.100000
2023-05-31 02:21:19 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 0.3980
2023-05-31 02:21:20 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 1.9397
2023-05-31 02:21:22 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 2.2709
2023-05-31 02:21:23 - train: epoch 0031, iter [00050, 00390], lr: 0.100000, loss: 1.6367
2023-05-31 02:21:24 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 1.3643
2023-05-31 02:21:26 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 1.7292
2023-05-31 02:21:27 - train: epoch 0031, iter [00100, 00390], lr: 0.100000, loss: 1.6829
2023-05-31 02:21:27 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 1.5507
2023-05-31 02:21:28 - train: epoch 086, train_loss: 1.6728
2023-05-31 02:21:30 - train: epoch 0031, iter [00150, 00390], lr: 0.100000, loss: 1.8316
2023-05-31 02:21:30 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 2.3072
2023-05-31 02:21:30 - eval: epoch: 086, acc1: 74.660%, acc5: 93.690%, test_loss: 0.9808, per_image_load_time: 0.091ms, per_image_inference_time: 0.056ms
2023-05-31 02:21:30 - until epoch: 086, best_acc1: 76.210%
2023-05-31 02:21:30 - epoch 087 lr: 0.020000
2023-05-31 02:21:32 - train: epoch 037, train_loss: 1.7184
2023-05-31 02:21:32 - train: epoch 0031, iter [00200, 00390], lr: 0.100000, loss: 1.6956
2023-05-31 02:21:34 - eval: epoch: 037, acc1: 58.650%, acc5: 86.440%, test_loss: 1.5053, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-05-31 02:21:34 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 1.7193
2023-05-31 02:21:34 - until epoch: 037, best_acc1: 58.650%
2023-05-31 02:21:34 - epoch 038 lr: 0.100000
2023-05-31 02:21:35 - train: epoch 0031, iter [00250, 00390], lr: 0.100000, loss: 1.7394
2023-05-31 02:21:37 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 0.3110
2023-05-31 02:21:38 - train: epoch 0031, iter [00300, 00390], lr: 0.100000, loss: 1.7925
2023-05-31 02:21:38 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 1.2074
2023-05-31 02:21:40 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 2.0823
2023-05-31 02:21:42 - train: epoch 0031, iter [00350, 00390], lr: 0.100000, loss: 1.8353
2023-05-31 02:21:42 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 0.9828
2023-05-31 02:21:44 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 2.0438
2023-05-31 02:21:44 - train: epoch 031, train_loss: 1.6686
2023-05-31 02:21:45 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 2.3965
2023-05-31 02:21:46 - eval: epoch: 031, acc1: 62.740%, acc5: 87.700%, test_loss: 1.3971, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-05-31 02:21:46 - until epoch: 031, best_acc1: 62.830%
2023-05-31 02:21:46 - epoch 032 lr: 0.100000
2023-05-31 02:21:46 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 1.2790
2023-05-31 02:21:48 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 1.0390
2023-05-31 02:21:49 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 2.2887
2023-05-31 02:21:50 - train: epoch 0032, iter [00050, 00390], lr: 0.100000, loss: 1.8217
2023-05-31 02:21:51 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 1.1269
2023-05-31 02:21:53 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 1.5077
2023-05-31 02:21:54 - train: epoch 0032, iter [00100, 00390], lr: 0.100000, loss: 1.5208
2023-05-31 02:21:54 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 1.4838
2023-05-31 02:21:55 - train: epoch 087, train_loss: 1.6716
2023-05-31 02:21:56 - train: epoch 0032, iter [00150, 00390], lr: 0.100000, loss: 1.7123
2023-05-31 02:21:57 - eval: epoch: 087, acc1: 73.980%, acc5: 93.630%, test_loss: 1.0011, per_image_load_time: 0.081ms, per_image_inference_time: 0.053ms
2023-05-31 02:21:57 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 1.2870
2023-05-31 02:21:57 - until epoch: 087, best_acc1: 76.210%
2023-05-31 02:21:57 - epoch 088 lr: 0.020000
2023-05-31 02:21:59 - train: epoch 0032, iter [00200, 00390], lr: 0.100000, loss: 1.7182
2023-05-31 02:21:59 - train: epoch 038, train_loss: 1.6440
2023-05-31 02:22:01 - eval: epoch: 038, acc1: 56.700%, acc5: 85.280%, test_loss: 1.6444, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-05-31 02:22:01 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 1.2126
2023-05-31 02:22:01 - until epoch: 038, best_acc1: 58.650%
2023-05-31 02:22:01 - epoch 039 lr: 0.100000
2023-05-31 02:22:02 - train: epoch 0032, iter [00250, 00390], lr: 0.100000, loss: 1.8326
2023-05-31 02:22:04 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 1.0834
2023-05-31 02:22:05 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 1.9385
2023-05-31 02:22:05 - train: epoch 0032, iter [00300, 00390], lr: 0.100000, loss: 1.7597
2023-05-31 02:22:07 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 2.0194
2023-05-31 02:22:09 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 1.1047
2023-05-31 02:22:09 - train: epoch 0032, iter [00350, 00390], lr: 0.100000, loss: 1.5590
2023-05-31 02:22:11 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 0.6591
2023-05-31 02:22:11 - train: epoch 032, train_loss: 1.6683
2023-05-31 02:22:12 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 1.3153
2023-05-31 02:22:13 - eval: epoch: 032, acc1: 62.280%, acc5: 87.830%, test_loss: 1.4272, per_image_load_time: 0.070ms, per_image_inference_time: 0.062ms
2023-05-31 02:22:13 - until epoch: 032, best_acc1: 62.830%
2023-05-31 02:22:13 - epoch 033 lr: 0.100000
2023-05-31 02:22:13 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 2.2537
2023-05-31 02:22:15 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 3.0319
2023-05-31 02:22:17 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 2.1691
2023-05-31 02:22:17 - train: epoch 0033, iter [00050, 00390], lr: 0.100000, loss: 1.4863
2023-05-31 02:22:18 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 1.2693
2023-05-31 02:22:20 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 2.3235
2023-05-31 02:22:21 - train: epoch 0033, iter [00100, 00390], lr: 0.100000, loss: 1.4556
2023-05-31 02:22:21 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 1.2409
2023-05-31 02:22:23 - train: epoch 088, train_loss: 1.6753
2023-05-31 02:22:24 - train: epoch 0033, iter [00150, 00390], lr: 0.100000, loss: 1.6272
2023-05-31 02:22:24 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 1.3026
2023-05-31 02:22:24 - eval: epoch: 088, acc1: 75.060%, acc5: 93.990%, test_loss: 0.9409, per_image_load_time: 0.088ms, per_image_inference_time: 0.056ms
2023-05-31 02:22:25 - until epoch: 088, best_acc1: 76.210%
2023-05-31 02:22:25 - epoch 089 lr: 0.020000
2023-05-31 02:22:26 - train: epoch 039, train_loss: 1.6621
2023-05-31 02:22:26 - train: epoch 0033, iter [00200, 00390], lr: 0.100000, loss: 1.7593
2023-05-31 02:22:28 - eval: epoch: 039, acc1: 57.960%, acc5: 86.000%, test_loss: 1.5551, per_image_load_time: 0.065ms, per_image_inference_time: 0.055ms
2023-05-31 02:22:28 - until epoch: 039, best_acc1: 58.650%
2023-05-31 02:22:28 - epoch 040 lr: 0.100000
2023-05-31 02:22:29 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 1.8971
2023-05-31 02:22:29 - train: epoch 0033, iter [00250, 00390], lr: 0.100000, loss: 1.6324
2023-05-31 02:22:32 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 0.4890
2023-05-31 02:22:32 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 1.1117
2023-05-31 02:22:32 - train: epoch 0033, iter [00300, 00390], lr: 0.100000, loss: 1.7951
2023-05-31 02:22:35 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 2.2286
2023-05-31 02:22:36 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 0.9831
2023-05-31 02:22:36 - train: epoch 0033, iter [00350, 00390], lr: 0.100000, loss: 1.6353
2023-05-31 02:22:38 - train: epoch 033, train_loss: 1.6568
2023-05-31 02:22:38 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 2.1461
2023-05-31 02:22:39 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 2.1271
2023-05-31 02:22:40 - eval: epoch: 033, acc1: 63.310%, acc5: 88.910%, test_loss: 1.3688, per_image_load_time: 0.064ms, per_image_inference_time: 0.053ms
2023-05-31 02:22:40 - until epoch: 033, best_acc1: 63.310%
2023-05-31 02:22:40 - epoch 034 lr: 0.100000
2023-05-31 02:22:41 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 2.3126
2023-05-31 02:22:41 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 2.0033
2023-05-31 02:22:44 - train: epoch 0034, iter [00050, 00390], lr: 0.100000, loss: 1.6053
2023-05-31 02:22:44 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 1.9249
2023-05-31 02:22:45 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 1.3867
2023-05-31 02:22:47 - train: epoch 0034, iter [00100, 00390], lr: 0.100000, loss: 1.6070
2023-05-31 02:22:48 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 0.9008
2023-05-31 02:22:48 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 1.7700
2023-05-31 02:22:50 - train: epoch 089, train_loss: 1.6664
2023-05-31 02:22:50 - train: epoch 0034, iter [00150, 00390], lr: 0.100000, loss: 1.6689
2023-05-31 02:22:51 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 1.2216
2023-05-31 02:22:52 - eval: epoch: 089, acc1: 73.380%, acc5: 92.900%, test_loss: 1.0427, per_image_load_time: 0.076ms, per_image_inference_time: 0.052ms
2023-05-31 02:22:52 - until epoch: 089, best_acc1: 76.210%
2023-05-31 02:22:52 - epoch 090 lr: 0.020000
2023-05-31 02:22:53 - train: epoch 0034, iter [00200, 00390], lr: 0.100000, loss: 1.5790
2023-05-31 02:22:53 - train: epoch 040, train_loss: 1.6284
2023-05-31 02:22:55 - eval: epoch: 040, acc1: 60.410%, acc5: 87.200%, test_loss: 1.4530, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-05-31 02:22:55 - until epoch: 040, best_acc1: 60.410%
2023-05-31 02:22:55 - epoch 041 lr: 0.100000
2023-05-31 02:22:56 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 0.4857
2023-05-31 02:22:56 - train: epoch 0034, iter [00250, 00390], lr: 0.100000, loss: 1.6350
2023-05-31 02:22:59 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 0.4659
2023-05-31 02:22:59 - train: epoch 0034, iter [00300, 00390], lr: 0.100000, loss: 1.8231
2023-05-31 02:22:59 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 1.1941
2023-05-31 02:23:02 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 1.6579
2023-05-31 02:23:02 - train: epoch 0034, iter [00350, 00390], lr: 0.100000, loss: 1.6673
2023-05-31 02:23:03 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 1.2117
2023-05-31 02:23:05 - train: epoch 034, train_loss: 1.6482
2023-05-31 02:23:05 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 1.8589
2023-05-31 02:23:06 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 2.1964
2023-05-31 02:23:07 - eval: epoch: 034, acc1: 61.480%, acc5: 87.590%, test_loss: 1.4412, per_image_load_time: 0.074ms, per_image_inference_time: 0.057ms
2023-05-31 02:23:07 - until epoch: 034, best_acc1: 63.310%
2023-05-31 02:23:07 - epoch 035 lr: 0.100000
2023-05-31 02:23:08 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 1.6558
2023-05-31 02:23:08 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 1.1155
2023-05-31 02:23:11 - train: epoch 0035, iter [00050, 00390], lr: 0.100000, loss: 1.4660
2023-05-31 02:23:11 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 0.8644
2023-05-31 02:23:12 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 1.4752
2023-05-31 02:23:14 - train: epoch 0035, iter [00100, 00390], lr: 0.100000, loss: 1.6101
2023-05-31 02:23:15 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 1.8856
2023-05-31 02:23:15 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 1.2420
2023-05-31 02:23:17 - train: epoch 090, train_loss: 1.6204
2023-05-31 02:23:17 - train: epoch 0035, iter [00150, 00390], lr: 0.100000, loss: 1.6651
2023-05-31 02:23:18 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 1.7991
2023-05-31 02:23:19 - eval: epoch: 090, acc1: 73.530%, acc5: 93.260%, test_loss: 1.0036, per_image_load_time: 0.075ms, per_image_inference_time: 0.055ms
2023-05-31 02:23:19 - until epoch: 090, best_acc1: 76.210%
2023-05-31 02:23:19 - epoch 091 lr: 0.020000
2023-05-31 02:23:20 - train: epoch 0035, iter [00200, 00390], lr: 0.100000, loss: 1.5493
2023-05-31 02:23:20 - train: epoch 041, train_loss: 1.6209
2023-05-31 02:23:22 - eval: epoch: 041, acc1: 59.300%, acc5: 87.150%, test_loss: 1.4798, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-05-31 02:23:22 - until epoch: 041, best_acc1: 60.410%
2023-05-31 02:23:22 - epoch 042 lr: 0.100000
2023-05-31 02:23:23 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 0.2623
2023-05-31 02:23:23 - train: epoch 0035, iter [00250, 00390], lr: 0.100000, loss: 1.6421
2023-05-31 02:23:26 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 2.0100
2023-05-31 02:23:26 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 1.6290
2023-05-31 02:23:26 - train: epoch 0035, iter [00300, 00390], lr: 0.100000, loss: 1.6511
2023-05-31 02:23:29 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 0.4706
2023-05-31 02:23:29 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 2.0442
2023-05-31 02:23:29 - train: epoch 0035, iter [00350, 00390], lr: 0.100000, loss: 1.9044
2023-05-31 02:23:32 - train: epoch 035, train_loss: 1.6439
2023-05-31 02:23:32 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 0.3587
2023-05-31 02:23:33 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 2.5521
2023-05-31 02:23:34 - eval: epoch: 035, acc1: 62.120%, acc5: 87.290%, test_loss: 1.4417, per_image_load_time: 0.067ms, per_image_inference_time: 0.051ms
2023-05-31 02:23:34 - until epoch: 035, best_acc1: 63.310%
2023-05-31 02:23:34 - epoch 036 lr: 0.100000
2023-05-31 02:23:35 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 2.2287
2023-05-31 02:23:35 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 2.1321
2023-05-31 02:23:38 - train: epoch 0036, iter [00050, 00390], lr: 0.100000, loss: 1.6584
2023-05-31 02:23:38 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 1.2606
2023-05-31 02:23:39 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 1.4418
2023-05-31 02:23:41 - train: epoch 0036, iter [00100, 00390], lr: 0.100000, loss: 1.6144
2023-05-31 02:23:42 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 2.4115
2023-05-31 02:23:42 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 1.0588
2023-05-31 02:23:44 - train: epoch 091, train_loss: 1.6345
2023-05-31 02:23:44 - train: epoch 0036, iter [00150, 00390], lr: 0.100000, loss: 1.5729
2023-05-31 02:23:45 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 1.0913
2023-05-31 02:23:46 - eval: epoch: 091, acc1: 73.480%, acc5: 93.190%, test_loss: 0.9761, per_image_load_time: 0.082ms, per_image_inference_time: 0.054ms
2023-05-31 02:23:46 - until epoch: 091, best_acc1: 76.210%
2023-05-31 02:23:46 - epoch 092 lr: 0.020000
2023-05-31 02:23:47 - train: epoch 0036, iter [00200, 00390], lr: 0.100000, loss: 1.5343
2023-05-31 02:23:47 - train: epoch 042, train_loss: 1.6414
2023-05-31 02:23:49 - eval: epoch: 042, acc1: 56.490%, acc5: 84.990%, test_loss: 1.6496, per_image_load_time: 0.074ms, per_image_inference_time: 0.054ms
2023-05-31 02:23:49 - until epoch: 042, best_acc1: 60.410%
2023-05-31 02:23:49 - epoch 043 lr: 0.100000
2023-05-31 02:23:50 - train: epoch 0036, iter [00250, 00390], lr: 0.100000, loss: 1.6093
2023-05-31 02:23:50 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 0.8924
2023-05-31 02:23:53 - train: epoch 0036, iter [00300, 00390], lr: 0.100000, loss: 1.4784
2023-05-31 02:23:53 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 1.2167
2023-05-31 02:23:53 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 2.0311
2023-05-31 02:23:56 - train: epoch 0036, iter [00350, 00390], lr: 0.100000, loss: 1.7972
2023-05-31 02:23:56 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 2.1762
2023-05-31 02:23:57 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 1.7382
2023-05-31 02:23:59 - train: epoch 036, train_loss: 1.6244
2023-05-31 02:23:59 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 2.3493
2023-05-31 02:24:00 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 1.0779
2023-05-31 02:24:01 - eval: epoch: 036, acc1: 62.230%, acc5: 87.740%, test_loss: 1.4165, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-05-31 02:24:01 - until epoch: 036, best_acc1: 63.310%
2023-05-31 02:24:01 - epoch 037 lr: 0.100000
2023-05-31 02:24:02 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 1.8973
2023-05-31 02:24:03 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 1.7619
2023-05-31 02:24:05 - train: epoch 0037, iter [00050, 00390], lr: 0.100000, loss: 1.5395
2023-05-31 02:24:06 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 1.7015
2023-05-31 02:24:06 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 1.4029
2023-05-31 02:24:08 - train: epoch 0037, iter [00100, 00390], lr: 0.100000, loss: 1.6674
2023-05-31 02:24:09 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 2.2829
2023-05-31 02:24:09 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 1.2695
2023-05-31 02:24:11 - train: epoch 0037, iter [00150, 00390], lr: 0.100000, loss: 1.5643
2023-05-31 02:24:12 - train: epoch 092, train_loss: 1.6210
2023-05-31 02:24:12 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 1.6028
2023-05-31 02:24:13 - eval: epoch: 092, acc1: 74.200%, acc5: 93.390%, test_loss: 0.9530, per_image_load_time: 0.076ms, per_image_inference_time: 0.055ms
2023-05-31 02:24:14 - until epoch: 092, best_acc1: 76.210%
2023-05-31 02:24:14 - epoch 093 lr: 0.020000
2023-05-31 02:24:14 - train: epoch 0037, iter [00200, 00390], lr: 0.100000, loss: 1.7916
2023-05-31 02:24:14 - train: epoch 043, train_loss: 1.5966
2023-05-31 02:24:16 - eval: epoch: 043, acc1: 54.810%, acc5: 82.890%, test_loss: 1.7381, per_image_load_time: 0.078ms, per_image_inference_time: 0.055ms
2023-05-31 02:24:16 - until epoch: 043, best_acc1: 60.410%
2023-05-31 02:24:16 - epoch 044 lr: 0.100000
2023-05-31 02:24:17 - train: epoch 0037, iter [00250, 00390], lr: 0.100000, loss: 1.5835
2023-05-31 02:24:17 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 1.9564
2023-05-31 02:24:20 - train: epoch 0037, iter [00300, 00390], lr: 0.100000, loss: 1.9012
2023-05-31 02:24:20 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 1.3175
2023-05-31 02:24:21 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 0.3490
2023-05-31 02:24:23 - train: epoch 0037, iter [00350, 00390], lr: 0.100000, loss: 1.6839
2023-05-31 02:24:24 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 3.2167
2023-05-31 02:24:24 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 1.7115
2023-05-31 02:24:26 - train: epoch 037, train_loss: 1.6353
2023-05-31 02:24:27 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 1.6821
2023-05-31 02:24:27 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 0.5263
2023-05-31 02:24:27 - eval: epoch: 037, acc1: 62.650%, acc5: 88.960%, test_loss: 1.3935, per_image_load_time: 0.076ms, per_image_inference_time: 0.057ms
2023-05-31 02:24:28 - until epoch: 037, best_acc1: 63.310%
2023-05-31 02:24:28 - epoch 038 lr: 0.100000
2023-05-31 02:24:30 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 1.2920
2023-05-31 02:24:30 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 2.4042
2023-05-31 02:24:32 - train: epoch 0038, iter [00050, 00390], lr: 0.100000, loss: 1.4970
2023-05-31 02:24:33 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 1.5593
2023-05-31 02:24:33 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 2.1811
2023-05-31 02:24:35 - train: epoch 0038, iter [00100, 00390], lr: 0.100000, loss: 1.4736
2023-05-31 02:24:36 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 1.5098
2023-05-31 02:24:36 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 1.7117
2023-05-31 02:24:38 - train: epoch 0038, iter [00150, 00390], lr: 0.100000, loss: 1.6380
2023-05-31 02:24:39 - train: epoch 093, train_loss: 1.5962
2023-05-31 02:24:39 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 1.0287
2023-05-31 02:24:41 - eval: epoch: 093, acc1: 73.810%, acc5: 92.930%, test_loss: 0.9765, per_image_load_time: 0.081ms, per_image_inference_time: 0.061ms
2023-05-31 02:24:41 - until epoch: 093, best_acc1: 76.210%
2023-05-31 02:24:41 - epoch 094 lr: 0.020000
2023-05-31 02:24:41 - train: epoch 0038, iter [00200, 00390], lr: 0.100000, loss: 1.5671
2023-05-31 02:24:42 - train: epoch 044, train_loss: 1.6387
2023-05-31 02:24:43 - eval: epoch: 044, acc1: 58.730%, acc5: 87.070%, test_loss: 1.5232, per_image_load_time: 0.075ms, per_image_inference_time: 0.055ms
2023-05-31 02:24:43 - until epoch: 044, best_acc1: 60.410%
2023-05-31 02:24:43 - epoch 045 lr: 0.100000
2023-05-31 02:24:44 - train: epoch 0038, iter [00250, 00390], lr: 0.100000, loss: 1.6054
2023-05-31 02:24:45 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 0.3048
2023-05-31 02:24:47 - train: epoch 0038, iter [00300, 00390], lr: 0.100000, loss: 1.8314
2023-05-31 02:24:48 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 1.2574
2023-05-31 02:24:48 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 2.0319
2023-05-31 02:24:50 - train: epoch 0038, iter [00350, 00390], lr: 0.100000, loss: 1.6896
2023-05-31 02:24:51 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 1.1648
2023-05-31 02:24:51 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 0.7147
2023-05-31 02:24:53 - train: epoch 038, train_loss: 1.6295
2023-05-31 02:24:54 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 1.0246
2023-05-31 02:24:54 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 1.6261
2023-05-31 02:24:54 - eval: epoch: 038, acc1: 63.320%, acc5: 88.300%, test_loss: 1.4027, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-05-31 02:24:55 - until epoch: 038, best_acc1: 63.320%
2023-05-31 02:24:55 - epoch 039 lr: 0.100000
2023-05-31 02:24:57 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 1.1467
2023-05-31 02:24:57 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 0.9576
2023-05-31 02:24:59 - train: epoch 0039, iter [00050, 00390], lr: 0.100000, loss: 1.6750
2023-05-31 02:25:00 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 0.9689
2023-05-31 02:25:00 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 2.1613
2023-05-31 02:25:02 - train: epoch 0039, iter [00100, 00390], lr: 0.100000, loss: 1.8091
2023-05-31 02:25:03 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 2.2333
2023-05-31 02:25:04 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 2.0072
2023-05-31 02:25:05 - train: epoch 0039, iter [00150, 00390], lr: 0.100000, loss: 1.6773
2023-05-31 02:25:06 - train: epoch 094, train_loss: 1.6308
2023-05-31 02:25:06 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 1.8875
2023-05-31 02:25:08 - eval: epoch: 094, acc1: 74.100%, acc5: 92.920%, test_loss: 0.9875, per_image_load_time: 0.085ms, per_image_inference_time: 0.053ms
2023-05-31 02:25:08 - train: epoch 0039, iter [00200, 00390], lr: 0.100000, loss: 1.5608
2023-05-31 02:25:08 - until epoch: 094, best_acc1: 76.210%
2023-05-31 02:25:08 - epoch 095 lr: 0.020000
2023-05-31 02:25:09 - train: epoch 045, train_loss: 1.6635
2023-05-31 02:25:10 - eval: epoch: 045, acc1: 59.260%, acc5: 86.520%, test_loss: 1.4926, per_image_load_time: 0.082ms, per_image_inference_time: 0.052ms
2023-05-31 02:25:10 - until epoch: 045, best_acc1: 60.410%
2023-05-31 02:25:10 - epoch 046 lr: 0.100000
2023-05-31 02:25:11 - train: epoch 0039, iter [00250, 00390], lr: 0.100000, loss: 1.7082
2023-05-31 02:25:12 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 1.6476
2023-05-31 02:25:14 - train: epoch 0039, iter [00300, 00390], lr: 0.100000, loss: 1.5552
2023-05-31 02:25:15 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 1.1929
2023-05-31 02:25:16 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 1.1255
2023-05-31 02:25:17 - train: epoch 0039, iter [00350, 00390], lr: 0.100000, loss: 1.6932
2023-05-31 02:25:18 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 1.0434
2023-05-31 02:25:19 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 0.4841
2023-05-31 02:25:20 - train: epoch 039, train_loss: 1.6206
2023-05-31 02:25:21 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 1.2507
2023-05-31 02:25:21 - eval: epoch: 039, acc1: 61.360%, acc5: 87.140%, test_loss: 1.4689, per_image_load_time: 0.068ms, per_image_inference_time: 0.052ms
2023-05-31 02:25:21 - until epoch: 039, best_acc1: 63.320%
2023-05-31 02:25:21 - epoch 040 lr: 0.100000
2023-05-31 02:25:22 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 2.0086
2023-05-31 02:25:24 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 3.0577
2023-05-31 02:25:25 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 1.8326
2023-05-31 02:25:26 - train: epoch 0040, iter [00050, 00390], lr: 0.100000, loss: 1.5125
2023-05-31 02:25:27 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 1.2542
2023-05-31 02:25:28 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 2.0388
2023-05-31 02:25:29 - train: epoch 0040, iter [00100, 00390], lr: 0.100000, loss: 1.4320
2023-05-31 02:25:30 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 1.0918
2023-05-31 02:25:31 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 0.4242
2023-05-31 02:25:32 - train: epoch 0040, iter [00150, 00390], lr: 0.100000, loss: 1.6437
2023-05-31 02:25:33 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 2.0286
2023-05-31 02:25:34 - train: epoch 095, train_loss: 1.6359
2023-05-31 02:25:35 - train: epoch 0040, iter [00200, 00390], lr: 0.100000, loss: 1.5790
2023-05-31 02:25:36 - eval: epoch: 095, acc1: 74.060%, acc5: 93.160%, test_loss: 1.0091, per_image_load_time: 0.082ms, per_image_inference_time: 0.058ms
2023-05-31 02:25:36 - train: epoch 046, train_loss: 1.6479
2023-05-31 02:25:36 - until epoch: 095, best_acc1: 76.210%
2023-05-31 02:25:36 - epoch 096 lr: 0.020000
2023-05-31 02:25:37 - train: epoch 0040, iter [00250, 00390], lr: 0.100000, loss: 1.9426
2023-05-31 02:25:37 - eval: epoch: 046, acc1: 55.410%, acc5: 84.400%, test_loss: 1.6561, per_image_load_time: 0.068ms, per_image_inference_time: 0.058ms
2023-05-31 02:25:38 - until epoch: 046, best_acc1: 60.410%
2023-05-31 02:25:38 - epoch 047 lr: 0.100000
2023-05-31 02:25:40 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 0.4802
2023-05-31 02:25:40 - train: epoch 0040, iter [00300, 00390], lr: 0.100000, loss: 1.6832
2023-05-31 02:25:42 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 1.0137
2023-05-31 02:25:43 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 1.6108
2023-05-31 02:25:44 - train: epoch 0040, iter [00350, 00390], lr: 0.100000, loss: 1.7366
2023-05-31 02:25:45 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 0.9750
2023-05-31 02:25:46 - train: epoch 040, train_loss: 1.6251
2023-05-31 02:25:46 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 1.7672
2023-05-31 02:25:48 - eval: epoch: 040, acc1: 62.130%, acc5: 87.390%, test_loss: 1.4312, per_image_load_time: 0.066ms, per_image_inference_time: 0.053ms
2023-05-31 02:25:48 - until epoch: 040, best_acc1: 63.320%
2023-05-31 02:25:48 - epoch 041 lr: 0.100000
2023-05-31 02:25:48 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 1.1406
2023-05-31 02:25:49 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 0.4600
2023-05-31 02:25:51 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 1.6819
2023-05-31 02:25:52 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 1.9253
2023-05-31 02:25:52 - train: epoch 0041, iter [00050, 00390], lr: 0.100000, loss: 1.4797
2023-05-31 02:25:54 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 1.1482
2023-05-31 02:25:55 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 1.4624
2023-05-31 02:25:55 - train: epoch 0041, iter [00100, 00390], lr: 0.100000, loss: 1.5662
2023-05-31 02:25:58 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 1.0734
2023-05-31 02:25:59 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 1.2938
2023-05-31 02:25:59 - train: epoch 0041, iter [00150, 00390], lr: 0.100000, loss: 1.6162
2023-05-31 02:26:01 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 1.4506
2023-05-31 02:26:01 - train: epoch 096, train_loss: 1.6400
2023-05-31 02:26:02 - train: epoch 0041, iter [00200, 00390], lr: 0.100000, loss: 1.5088
2023-05-31 02:26:03 - eval: epoch: 096, acc1: 74.060%, acc5: 93.520%, test_loss: 0.9500, per_image_load_time: 0.078ms, per_image_inference_time: 0.052ms
2023-05-31 02:26:03 - until epoch: 096, best_acc1: 76.210%
2023-05-31 02:26:03 - epoch 097 lr: 0.020000
2023-05-31 02:26:03 - train: epoch 047, train_loss: 1.6112
2023-05-31 02:26:04 - train: epoch 0041, iter [00250, 00390], lr: 0.100000, loss: 1.7486
2023-05-31 02:26:05 - eval: epoch: 047, acc1: 59.540%, acc5: 86.940%, test_loss: 1.4763, per_image_load_time: 0.073ms, per_image_inference_time: 0.057ms
2023-05-31 02:26:05 - until epoch: 047, best_acc1: 60.410%
2023-05-31 02:26:05 - epoch 048 lr: 0.100000
2023-05-31 02:26:07 - train: epoch 0041, iter [00300, 00390], lr: 0.100000, loss: 1.7042
2023-05-31 02:26:07 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 2.0809
2023-05-31 02:26:09 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 1.3606
2023-05-31 02:26:10 - train: epoch 0041, iter [00350, 00390], lr: 0.100000, loss: 1.7439
2023-05-31 02:26:10 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 0.3733
2023-05-31 02:26:13 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 2.5220
2023-05-31 02:26:13 - train: epoch 041, train_loss: 1.6196
2023-05-31 02:26:13 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 1.2124
2023-05-31 02:26:14 - eval: epoch: 041, acc1: 62.630%, acc5: 88.280%, test_loss: 1.4264, per_image_load_time: 0.065ms, per_image_inference_time: 0.053ms
2023-05-31 02:26:15 - until epoch: 041, best_acc1: 63.320%
2023-05-31 02:26:15 - epoch 042 lr: 0.100000
2023-05-31 02:26:15 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 0.9904
2023-05-31 02:26:16 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 1.8312
2023-05-31 02:26:19 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 1.6171
2023-05-31 02:26:19 - train: epoch 0042, iter [00050, 00390], lr: 0.100000, loss: 1.3922
2023-05-31 02:26:20 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 1.6950
2023-05-31 02:26:22 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 1.1747
2023-05-31 02:26:22 - train: epoch 0042, iter [00100, 00390], lr: 0.100000, loss: 1.6637
2023-05-31 02:26:23 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 1.3154
2023-05-31 02:26:25 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 1.0777
2023-05-31 02:26:25 - train: epoch 0042, iter [00150, 00390], lr: 0.100000, loss: 1.5091
2023-05-31 02:26:26 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 2.2799
2023-05-31 02:26:28 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 1.3185
2023-05-31 02:26:28 - train: epoch 0042, iter [00200, 00390], lr: 0.100000, loss: 1.5080
2023-05-31 02:26:29 - train: epoch 097, train_loss: 1.5341
2023-05-31 02:26:31 - eval: epoch: 097, acc1: 73.790%, acc5: 93.080%, test_loss: 1.0132, per_image_load_time: 0.076ms, per_image_inference_time: 0.053ms
2023-05-31 02:26:31 - train: epoch 048, train_loss: 1.6239
2023-05-31 02:26:31 - until epoch: 097, best_acc1: 76.210%
2023-05-31 02:26:31 - epoch 098 lr: 0.020000
2023-05-31 02:26:31 - train: epoch 0042, iter [00250, 00390], lr: 0.100000, loss: 1.8266
2023-05-31 02:26:32 - eval: epoch: 048, acc1: 57.580%, acc5: 84.850%, test_loss: 1.6393, per_image_load_time: 0.073ms, per_image_inference_time: 0.060ms
2023-05-31 02:26:33 - until epoch: 048, best_acc1: 60.410%
2023-05-31 02:26:33 - epoch 049 lr: 0.100000
2023-05-31 02:26:34 - train: epoch 0042, iter [00300, 00390], lr: 0.100000, loss: 1.5855
2023-05-31 02:26:35 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 0.5470
2023-05-31 02:26:37 - train: epoch 0042, iter [00350, 00390], lr: 0.100000, loss: 1.6586
2023-05-31 02:26:37 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 1.5534
2023-05-31 02:26:38 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 1.6228
2023-05-31 02:26:39 - train: epoch 042, train_loss: 1.6092
2023-05-31 02:26:40 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 1.6789
2023-05-31 02:26:41 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 1.0771
2023-05-31 02:26:41 - eval: epoch: 042, acc1: 61.860%, acc5: 87.020%, test_loss: 1.4648, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-05-31 02:26:41 - until epoch: 042, best_acc1: 63.320%
2023-05-31 02:26:41 - epoch 043 lr: 0.100000
2023-05-31 02:26:43 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 1.2189
2023-05-31 02:26:44 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 0.4390
2023-05-31 02:26:46 - train: epoch 0043, iter [00050, 00390], lr: 0.100000, loss: 1.5088
2023-05-31 02:26:46 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 1.3866
2023-05-31 02:26:47 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 2.0279
2023-05-31 02:26:49 - train: epoch 0043, iter [00100, 00390], lr: 0.100000, loss: 1.5846
2023-05-31 02:26:49 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 1.6428
2023-05-31 02:26:51 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 2.2044
2023-05-31 02:26:52 - train: epoch 0043, iter [00150, 00390], lr: 0.100000, loss: 1.6145
2023-05-31 02:26:53 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 2.4726
2023-05-31 02:26:54 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 1.4291
2023-05-31 02:26:55 - train: epoch 0043, iter [00200, 00390], lr: 0.100000, loss: 1.6447
2023-05-31 02:26:56 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 1.6872
2023-05-31 02:26:56 - train: epoch 098, train_loss: 1.6161
2023-05-31 02:26:58 - eval: epoch: 098, acc1: 74.070%, acc5: 93.260%, test_loss: 0.9972, per_image_load_time: 0.084ms, per_image_inference_time: 0.055ms
2023-05-31 02:26:58 - train: epoch 0043, iter [00250, 00390], lr: 0.100000, loss: 1.6514
2023-05-31 02:26:58 - train: epoch 049, train_loss: 1.5566
2023-05-31 02:26:59 - until epoch: 098, best_acc1: 76.210%
2023-05-31 02:26:59 - epoch 099 lr: 0.020000
2023-05-31 02:27:00 - eval: epoch: 049, acc1: 57.540%, acc5: 85.460%, test_loss: 1.5829, per_image_load_time: 0.074ms, per_image_inference_time: 0.069ms
2023-05-31 02:27:00 - until epoch: 049, best_acc1: 60.410%
2023-05-31 02:27:00 - epoch 050 lr: 0.100000
2023-05-31 02:27:00 - train: epoch 0043, iter [00300, 00390], lr: 0.100000, loss: 1.5668
2023-05-31 02:27:03 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 2.3455
2023-05-31 02:27:03 - train: epoch 0043, iter [00350, 00390], lr: 0.100000, loss: 1.5922
2023-05-31 02:27:04 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 2.0561
2023-05-31 02:27:06 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 0.4106
2023-05-31 02:27:06 - train: epoch 043, train_loss: 1.6119
2023-05-31 02:27:07 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 0.9971
2023-05-31 02:27:08 - eval: epoch: 043, acc1: 62.660%, acc5: 88.330%, test_loss: 1.4049, per_image_load_time: 0.076ms, per_image_inference_time: 0.056ms
2023-05-31 02:27:08 - until epoch: 043, best_acc1: 63.320%
2023-05-31 02:27:08 - epoch 044 lr: 0.100000
2023-05-31 02:27:09 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 2.0753
2023-05-31 02:27:10 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 2.2869
2023-05-31 02:27:12 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 0.5041
2023-05-31 02:27:12 - train: epoch 0044, iter [00050, 00390], lr: 0.100000, loss: 1.5023
2023-05-31 02:27:13 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 1.2615
2023-05-31 02:27:15 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 2.2477
2023-05-31 02:27:15 - train: epoch 0044, iter [00100, 00390], lr: 0.100000, loss: 1.6536
2023-05-31 02:27:17 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 0.9612
2023-05-31 02:27:18 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 0.7040
2023-05-31 02:27:19 - train: epoch 0044, iter [00150, 00390], lr: 0.100000, loss: 1.3209
2023-05-31 02:27:20 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 3.3653
2023-05-31 02:27:21 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 2.3676
2023-05-31 02:27:22 - train: epoch 0044, iter [00200, 00390], lr: 0.100000, loss: 1.6307
2023-05-31 02:27:23 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 2.3116
2023-05-31 02:27:24 - train: epoch 099, train_loss: 1.6055
2023-05-31 02:27:25 - train: epoch 0044, iter [00250, 00390], lr: 0.100000, loss: 1.7110
2023-05-31 02:27:26 - train: epoch 050, train_loss: 1.6167
2023-05-31 02:27:26 - eval: epoch: 099, acc1: 73.440%, acc5: 92.830%, test_loss: 1.0481, per_image_load_time: 0.085ms, per_image_inference_time: 0.053ms
2023-05-31 02:27:26 - until epoch: 099, best_acc1: 76.210%
2023-05-31 02:27:26 - epoch 100 lr: 0.020000
2023-05-31 02:27:27 - eval: epoch: 050, acc1: 57.750%, acc5: 84.410%, test_loss: 1.6161, per_image_load_time: 0.071ms, per_image_inference_time: 0.049ms
2023-05-31 02:27:27 - train: epoch 0044, iter [00300, 00390], lr: 0.100000, loss: 1.5994
2023-05-31 02:27:27 - until epoch: 050, best_acc1: 60.410%
2023-05-31 02:27:27 - epoch 051 lr: 0.100000
2023-05-31 02:27:30 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 1.4360
2023-05-31 02:27:30 - train: epoch 0044, iter [00350, 00390], lr: 0.100000, loss: 1.5957
2023-05-31 02:27:32 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 3.1865
2023-05-31 02:27:33 - train: epoch 044, train_loss: 1.6000
2023-05-31 02:27:33 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 0.2397
2023-05-31 02:27:34 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 2.1079
2023-05-31 02:27:35 - eval: epoch: 044, acc1: 61.620%, acc5: 87.090%, test_loss: 1.4850, per_image_load_time: 0.078ms, per_image_inference_time: 0.058ms
2023-05-31 02:27:35 - until epoch: 044, best_acc1: 63.320%
2023-05-31 02:27:35 - epoch 045 lr: 0.100000
2023-05-31 02:27:36 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 2.1352
2023-05-31 02:27:37 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 1.6153
2023-05-31 02:27:39 - train: epoch 0045, iter [00050, 00390], lr: 0.100000, loss: 1.5128
2023-05-31 02:27:39 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 2.0835
2023-05-31 02:27:41 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 1.9201
2023-05-31 02:27:42 - train: epoch 0045, iter [00100, 00390], lr: 0.100000, loss: 1.5010
2023-05-31 02:27:43 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 1.9893
2023-05-31 02:27:44 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 2.3724
2023-05-31 02:27:45 - train: epoch 0045, iter [00150, 00390], lr: 0.100000, loss: 1.4601
2023-05-31 02:27:46 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 2.2278
2023-05-31 02:27:47 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 1.0508
2023-05-31 02:27:49 - train: epoch 0045, iter [00200, 00390], lr: 0.100000, loss: 1.5620
2023-05-31 02:27:49 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 1.1133
2023-05-31 02:27:50 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 1.9626
2023-05-31 02:27:52 - train: epoch 100, train_loss: 1.6772
2023-05-31 02:27:52 - train: epoch 0045, iter [00250, 00390], lr: 0.100000, loss: 1.5456
2023-05-31 02:27:53 - train: epoch 051, train_loss: 1.6022
2023-05-31 02:27:53 - eval: epoch: 100, acc1: 73.970%, acc5: 92.920%, test_loss: 1.0072, per_image_load_time: 0.076ms, per_image_inference_time: 0.048ms
2023-05-31 02:27:54 - until epoch: 100, best_acc1: 76.210%
2023-05-31 02:27:54 - epoch 101 lr: 0.020000
2023-05-31 02:27:54 - train: epoch 0045, iter [00300, 00390], lr: 0.100000, loss: 1.7433
2023-05-31 02:27:55 - eval: epoch: 051, acc1: 57.700%, acc5: 85.740%, test_loss: 1.5703, per_image_load_time: 0.096ms, per_image_inference_time: 0.064ms
2023-05-31 02:27:55 - until epoch: 051, best_acc1: 60.410%
2023-05-31 02:27:55 - epoch 052 lr: 0.100000
2023-05-31 02:27:57 - train: epoch 0045, iter [00350, 00390], lr: 0.100000, loss: 1.7416
2023-05-31 02:27:58 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 1.6834
2023-05-31 02:27:59 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 1.2187
2023-05-31 02:28:00 - train: epoch 045, train_loss: 1.6025
2023-05-31 02:28:01 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 2.1462
2023-05-31 02:28:01 - eval: epoch: 045, acc1: 62.280%, acc5: 87.540%, test_loss: 1.4675, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-05-31 02:28:01 - until epoch: 045, best_acc1: 63.320%
2023-05-31 02:28:01 - epoch 046 lr: 0.100000
2023-05-31 02:28:02 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 1.7438
2023-05-31 02:28:04 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 0.5998
2023-05-31 02:28:05 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 1.6528
2023-05-31 02:28:06 - train: epoch 0046, iter [00050, 00390], lr: 0.100000, loss: 1.4860
2023-05-31 02:28:07 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 1.9353
2023-05-31 02:28:08 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 1.2801
2023-05-31 02:28:09 - train: epoch 0046, iter [00100, 00390], lr: 0.100000, loss: 1.4954
2023-05-31 02:28:10 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 1.7295
2023-05-31 02:28:12 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 2.0435
2023-05-31 02:28:12 - train: epoch 0046, iter [00150, 00390], lr: 0.100000, loss: 1.5077
2023-05-31 02:28:13 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 2.0023
2023-05-31 02:28:15 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 1.2400
2023-05-31 02:28:15 - train: epoch 0046, iter [00200, 00390], lr: 0.100000, loss: 1.5350
2023-05-31 02:28:17 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 2.0166
2023-05-31 02:28:18 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 1.7371
2023-05-31 02:28:19 - train: epoch 0046, iter [00250, 00390], lr: 0.100000, loss: 1.7188
2023-05-31 02:28:19 - train: epoch 101, train_loss: 1.6020
2023-05-31 02:28:21 - train: epoch 052, train_loss: 1.5967
2023-05-31 02:28:21 - eval: epoch: 101, acc1: 73.740%, acc5: 92.570%, test_loss: 1.0065, per_image_load_time: 0.080ms, per_image_inference_time: 0.052ms
2023-05-31 02:28:21 - train: epoch 0046, iter [00300, 00390], lr: 0.100000, loss: 1.5450
2023-05-31 02:28:21 - until epoch: 101, best_acc1: 76.210%
2023-05-31 02:28:21 - epoch 102 lr: 0.020000
2023-05-31 02:28:22 - eval: epoch: 052, acc1: 61.410%, acc5: 87.800%, test_loss: 1.4118, per_image_load_time: 0.072ms, per_image_inference_time: 0.053ms
2023-05-31 02:28:23 - until epoch: 052, best_acc1: 61.410%
2023-05-31 02:28:23 - epoch 053 lr: 0.100000
2023-05-31 02:28:23 - train: epoch 0046, iter [00350, 00390], lr: 0.100000, loss: 1.5548
2023-05-31 02:28:25 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 2.0333
2023-05-31 02:28:26 - train: epoch 046, train_loss: 1.5964
2023-05-31 02:28:27 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 0.9786
2023-05-31 02:28:28 - eval: epoch: 046, acc1: 61.920%, acc5: 87.690%, test_loss: 1.4569, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-05-31 02:28:28 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 1.7970
2023-05-31 02:28:28 - until epoch: 046, best_acc1: 63.320%
2023-05-31 02:28:28 - epoch 047 lr: 0.100000
2023-05-31 02:28:29 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 0.8780
2023-05-31 02:28:31 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 1.6164
2023-05-31 02:28:32 - train: epoch 0047, iter [00050, 00390], lr: 0.100000, loss: 1.5042
2023-05-31 02:28:33 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 1.0497
2023-05-31 02:28:34 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 0.3585
2023-05-31 02:28:35 - train: epoch 0047, iter [00100, 00390], lr: 0.100000, loss: 1.4449
2023-05-31 02:28:36 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 2.5262
2023-05-31 02:28:37 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 2.0865
2023-05-31 02:28:39 - train: epoch 0047, iter [00150, 00390], lr: 0.100000, loss: 1.5851
2023-05-31 02:28:39 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 1.2819
2023-05-31 02:28:41 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 2.0732
2023-05-31 02:28:42 - train: epoch 0047, iter [00200, 00390], lr: 0.100000, loss: 1.6442
2023-05-31 02:28:42 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 2.5064
2023-05-31 02:28:44 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 1.3845
2023-05-31 02:28:45 - train: epoch 0047, iter [00250, 00390], lr: 0.100000, loss: 1.5378
2023-05-31 02:28:46 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 1.7786
2023-05-31 02:28:46 - train: epoch 102, train_loss: 1.6554
2023-05-31 02:28:48 - train: epoch 053, train_loss: 1.6104
2023-05-31 02:28:48 - train: epoch 0047, iter [00300, 00390], lr: 0.100000, loss: 1.5782
2023-05-31 02:28:48 - eval: epoch: 102, acc1: 73.180%, acc5: 92.910%, test_loss: 1.0282, per_image_load_time: 0.079ms, per_image_inference_time: 0.053ms
2023-05-31 02:28:48 - until epoch: 102, best_acc1: 76.210%
2023-05-31 02:28:48 - epoch 103 lr: 0.020000
2023-05-31 02:28:50 - eval: epoch: 053, acc1: 60.090%, acc5: 87.690%, test_loss: 1.4433, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-05-31 02:28:50 - until epoch: 053, best_acc1: 61.410%
2023-05-31 02:28:50 - epoch 054 lr: 0.100000
2023-05-31 02:28:50 - train: epoch 0047, iter [00350, 00390], lr: 0.100000, loss: 1.5141
2023-05-31 02:28:52 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 2.2801
2023-05-31 02:28:53 - train: epoch 047, train_loss: 1.5955
2023-05-31 02:28:54 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 1.7507
2023-05-31 02:28:54 - eval: epoch: 047, acc1: 63.060%, acc5: 88.780%, test_loss: 1.3882, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-05-31 02:28:55 - until epoch: 047, best_acc1: 63.320%
2023-05-31 02:28:55 - epoch 048 lr: 0.100000
2023-05-31 02:28:55 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 1.8241
2023-05-31 02:28:57 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 1.4812
2023-05-31 02:28:58 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 2.0960
2023-05-31 02:28:59 - train: epoch 0048, iter [00050, 00390], lr: 0.100000, loss: 1.6203
2023-05-31 02:29:00 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 0.9970
2023-05-31 02:29:01 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 2.2506
2023-05-31 02:29:02 - train: epoch 0048, iter [00100, 00390], lr: 0.100000, loss: 1.3605
2023-05-31 02:29:03 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 1.2146
2023-05-31 02:29:05 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 0.8265
2023-05-31 02:29:05 - train: epoch 0048, iter [00150, 00390], lr: 0.100000, loss: 1.5892
2023-05-31 02:29:06 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 1.3263
2023-05-31 02:29:08 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 2.4747
2023-05-31 02:29:09 - train: epoch 0048, iter [00200, 00390], lr: 0.100000, loss: 1.5778
2023-05-31 02:29:10 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 1.3252
2023-05-31 02:29:11 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 1.3905
2023-05-31 02:29:12 - train: epoch 0048, iter [00250, 00390], lr: 0.100000, loss: 1.6142
2023-05-31 02:29:13 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 1.1648
2023-05-31 02:29:14 - train: epoch 103, train_loss: 1.5622
2023-05-31 02:29:15 - train: epoch 0048, iter [00300, 00390], lr: 0.100000, loss: 1.5813
2023-05-31 02:29:15 - train: epoch 054, train_loss: 1.6317
2023-05-31 02:29:15 - eval: epoch: 103, acc1: 74.010%, acc5: 92.910%, test_loss: 0.9826, per_image_load_time: 0.083ms, per_image_inference_time: 0.052ms
2023-05-31 02:29:16 - until epoch: 103, best_acc1: 76.210%
2023-05-31 02:29:16 - epoch 104 lr: 0.020000
2023-05-31 02:29:17 - eval: epoch: 054, acc1: 60.970%, acc5: 88.080%, test_loss: 1.3943, per_image_load_time: 0.071ms, per_image_inference_time: 0.060ms
2023-05-31 02:29:17 - train: epoch 0048, iter [00350, 00390], lr: 0.100000, loss: 1.7740
2023-05-31 02:29:17 - until epoch: 054, best_acc1: 61.410%
2023-05-31 02:29:17 - epoch 055 lr: 0.100000
2023-05-31 02:29:20 - train: epoch 048, train_loss: 1.6001
2023-05-31 02:29:20 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 1.3260
2023-05-31 02:29:21 - eval: epoch: 048, acc1: 63.810%, acc5: 88.730%, test_loss: 1.3724, per_image_load_time: 0.068ms, per_image_inference_time: 0.052ms
2023-05-31 02:29:21 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 1.4782
2023-05-31 02:29:22 - until epoch: 048, best_acc1: 63.810%
2023-05-31 02:29:22 - epoch 049 lr: 0.100000
2023-05-31 02:29:22 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 1.8443
2023-05-31 02:29:24 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 1.0636
2023-05-31 02:29:26 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 2.0656
2023-05-31 02:29:26 - train: epoch 0049, iter [00050, 00390], lr: 0.100000, loss: 1.6947
2023-05-31 02:29:27 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 1.4514
2023-05-31 02:29:29 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 2.1440
2023-05-31 02:29:29 - train: epoch 0049, iter [00100, 00390], lr: 0.100000, loss: 1.5795
2023-05-31 02:29:30 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 1.2696
2023-05-31 02:29:32 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 0.2894
2023-05-31 02:29:32 - train: epoch 0049, iter [00150, 00390], lr: 0.100000, loss: 1.6626
2023-05-31 02:29:34 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 1.5029
2023-05-31 02:29:35 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 1.9419
2023-05-31 02:29:35 - train: epoch 0049, iter [00200, 00390], lr: 0.100000, loss: 1.7030
2023-05-31 02:29:37 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 1.9120
2023-05-31 02:29:39 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 1.7462
2023-05-31 02:29:39 - train: epoch 0049, iter [00250, 00390], lr: 0.100000, loss: 1.5702
2023-05-31 02:29:40 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 1.2923
2023-05-31 02:29:41 - train: epoch 104, train_loss: 1.5934
2023-05-31 02:29:42 - train: epoch 0049, iter [00300, 00390], lr: 0.100000, loss: 1.5887
2023-05-31 02:29:43 - train: epoch 055, train_loss: 1.6271
2023-05-31 02:29:43 - eval: epoch: 104, acc1: 75.010%, acc5: 93.680%, test_loss: 0.9389, per_image_load_time: 0.080ms, per_image_inference_time: 0.053ms
2023-05-31 02:29:43 - until epoch: 104, best_acc1: 76.210%
2023-05-31 02:29:43 - epoch 105 lr: 0.020000
2023-05-31 02:29:44 - train: epoch 0049, iter [00350, 00390], lr: 0.100000, loss: 1.6358
2023-05-31 02:29:44 - eval: epoch: 055, acc1: 57.950%, acc5: 85.360%, test_loss: 1.6092, per_image_load_time: 0.075ms, per_image_inference_time: 0.061ms
2023-05-31 02:29:45 - until epoch: 055, best_acc1: 61.410%
2023-05-31 02:29:45 - epoch 056 lr: 0.100000
2023-05-31 02:29:46 - train: epoch 049, train_loss: 1.5888
2023-05-31 02:29:47 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 1.8522
2023-05-31 02:29:48 - eval: epoch: 049, acc1: 61.290%, acc5: 86.400%, test_loss: 1.5204, per_image_load_time: 0.066ms, per_image_inference_time: 0.053ms
2023-05-31 02:29:48 - until epoch: 049, best_acc1: 63.810%
2023-05-31 02:29:48 - epoch 050 lr: 0.100000
2023-05-31 02:29:48 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 1.4554
2023-05-31 02:29:50 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 1.9850
2023-05-31 02:29:51 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 0.9287
2023-05-31 02:29:52 - train: epoch 0050, iter [00050, 00390], lr: 0.100000, loss: 1.4725
2023-05-31 02:29:53 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 1.3544
2023-05-31 02:29:55 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 2.0131
2023-05-31 02:29:55 - train: epoch 0050, iter [00100, 00390], lr: 0.100000, loss: 1.5197
2023-05-31 02:29:56 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 0.9876
2023-05-31 02:29:58 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 2.0276
2023-05-31 02:29:59 - train: epoch 0050, iter [00150, 00390], lr: 0.100000, loss: 1.7211
2023-05-31 02:29:59 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 0.6554
2023-05-31 02:30:01 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 0.8404
2023-05-31 02:30:02 - train: epoch 0050, iter [00200, 00390], lr: 0.100000, loss: 1.5021
2023-05-31 02:30:03 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 2.0865
2023-05-31 02:30:05 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 3.2472
2023-05-31 02:30:05 - train: epoch 0050, iter [00250, 00390], lr: 0.100000, loss: 1.6861
2023-05-31 02:30:06 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 0.9067
2023-05-31 02:30:08 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 1.2607
2023-05-31 02:30:08 - train: epoch 0050, iter [00300, 00390], lr: 0.100000, loss: 1.6345
2023-05-31 02:30:09 - train: epoch 105, train_loss: 1.5925
2023-05-31 02:30:10 - train: epoch 056, train_loss: 1.5937
2023-05-31 02:30:10 - eval: epoch: 105, acc1: 74.000%, acc5: 93.200%, test_loss: 0.9938, per_image_load_time: 0.081ms, per_image_inference_time: 0.052ms
2023-05-31 02:30:11 - until epoch: 105, best_acc1: 76.210%
2023-05-31 02:30:11 - epoch 106 lr: 0.020000
2023-05-31 02:30:11 - train: epoch 0050, iter [00350, 00390], lr: 0.100000, loss: 1.6511
2023-05-31 02:30:12 - eval: epoch: 056, acc1: 60.010%, acc5: 86.910%, test_loss: 1.4791, per_image_load_time: 0.076ms, per_image_inference_time: 0.058ms
2023-05-31 02:30:12 - until epoch: 056, best_acc1: 61.410%
2023-05-31 02:30:12 - epoch 057 lr: 0.100000
2023-05-31 02:30:13 - train: epoch 050, train_loss: 1.5914
2023-05-31 02:30:14 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 2.4395
2023-05-31 02:30:14 - eval: epoch: 050, acc1: 61.750%, acc5: 87.220%, test_loss: 1.4797, per_image_load_time: 0.077ms, per_image_inference_time: 0.057ms
2023-05-31 02:30:15 - until epoch: 050, best_acc1: 63.810%
2023-05-31 02:30:15 - epoch 051 lr: 0.100000
2023-05-31 02:30:16 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 1.0758
2023-05-31 02:30:17 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 0.3149
2023-05-31 02:30:19 - train: epoch 0051, iter [00050, 00390], lr: 0.100000, loss: 1.5968
2023-05-31 02:30:19 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 1.4342
2023-05-31 02:30:20 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 1.9343
2023-05-31 02:30:22 - train: epoch 0051, iter [00100, 00390], lr: 0.100000, loss: 1.5023
2023-05-31 02:30:22 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 0.9827
2023-05-31 02:30:24 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 1.1603
2023-05-31 02:30:25 - train: epoch 0051, iter [00150, 00390], lr: 0.100000, loss: 1.5415
2023-05-31 02:30:26 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 2.6158
2023-05-31 02:30:27 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 1.6358
2023-05-31 02:30:29 - train: epoch 0051, iter [00200, 00390], lr: 0.100000, loss: 1.5712
2023-05-31 02:30:29 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 1.0168
2023-05-31 02:30:30 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 1.8759
2023-05-31 02:30:32 - train: epoch 0051, iter [00250, 00390], lr: 0.100000, loss: 1.6535
2023-05-31 02:30:32 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 1.5297
2023-05-31 02:30:33 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 1.7523
2023-05-31 02:30:35 - train: epoch 0051, iter [00300, 00390], lr: 0.100000, loss: 1.4970
2023-05-31 02:30:35 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 1.0424
2023-05-31 02:30:36 - train: epoch 106, train_loss: 1.5964
2023-05-31 02:30:38 - train: epoch 057, train_loss: 1.5679
2023-05-31 02:30:38 - eval: epoch: 106, acc1: 73.980%, acc5: 93.240%, test_loss: 0.9856, per_image_load_time: 0.082ms, per_image_inference_time: 0.052ms
2023-05-31 02:30:38 - train: epoch 0051, iter [00350, 00390], lr: 0.100000, loss: 1.4850
2023-05-31 02:30:38 - until epoch: 106, best_acc1: 76.210%
2023-05-31 02:30:38 - epoch 107 lr: 0.020000
2023-05-31 02:30:39 - eval: epoch: 057, acc1: 55.650%, acc5: 83.800%, test_loss: 1.7109, per_image_load_time: 0.066ms, per_image_inference_time: 0.052ms
2023-05-31 02:30:39 - until epoch: 057, best_acc1: 61.410%
2023-05-31 02:30:39 - epoch 058 lr: 0.100000
2023-05-31 02:30:40 - train: epoch 051, train_loss: 1.5843
2023-05-31 02:30:41 - eval: epoch: 051, acc1: 63.950%, acc5: 88.900%, test_loss: 1.3800, per_image_load_time: 0.076ms, per_image_inference_time: 0.052ms
2023-05-31 02:30:41 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 0.5304
2023-05-31 02:30:42 - until epoch: 051, best_acc1: 63.950%
2023-05-31 02:30:42 - epoch 052 lr: 0.100000
2023-05-31 02:30:43 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 2.3014
2023-05-31 02:30:44 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 0.2882
2023-05-31 02:30:46 - train: epoch 0052, iter [00050, 00390], lr: 0.100000, loss: 1.6936
2023-05-31 02:30:46 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 1.4283
2023-05-31 02:30:48 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 0.8674
2023-05-31 02:30:49 - train: epoch 0052, iter [00100, 00390], lr: 0.100000, loss: 1.5951
2023-05-31 02:30:49 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 1.8434
2023-05-31 02:30:51 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 1.7196
2023-05-31 02:30:53 - train: epoch 0052, iter [00150, 00390], lr: 0.100000, loss: 1.4945
2023-05-31 02:30:53 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 1.0694
2023-05-31 02:30:54 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 0.5014
2023-05-31 02:30:56 - train: epoch 0052, iter [00200, 00390], lr: 0.100000, loss: 1.6022
2023-05-31 02:30:56 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 2.1513
2023-05-31 02:30:57 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 2.0566
2023-05-31 02:30:59 - train: epoch 0052, iter [00250, 00390], lr: 0.100000, loss: 1.6645
2023-05-31 02:30:59 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 1.3290
2023-05-31 02:31:01 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 1.6327
2023-05-31 02:31:02 - train: epoch 0052, iter [00300, 00390], lr: 0.100000, loss: 1.7115
2023-05-31 02:31:03 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 1.4254
2023-05-31 02:31:03 - train: epoch 107, train_loss: 1.5505
2023-05-31 02:31:05 - eval: epoch: 107, acc1: 73.510%, acc5: 93.140%, test_loss: 0.9918, per_image_load_time: 0.083ms, per_image_inference_time: 0.054ms
2023-05-31 02:31:05 - train: epoch 058, train_loss: 1.6040
2023-05-31 02:31:05 - train: epoch 0052, iter [00350, 00390], lr: 0.100000, loss: 1.5290
2023-05-31 02:31:05 - until epoch: 107, best_acc1: 76.210%
2023-05-31 02:31:05 - epoch 108 lr: 0.020000
2023-05-31 02:31:07 - eval: epoch: 058, acc1: 60.500%, acc5: 86.630%, test_loss: 1.4755, per_image_load_time: 0.075ms, per_image_inference_time: 0.058ms
2023-05-31 02:31:07 - train: epoch 052, train_loss: 1.5834
2023-05-31 02:31:07 - until epoch: 058, best_acc1: 61.410%
2023-05-31 02:31:07 - epoch 059 lr: 0.100000
2023-05-31 02:31:08 - eval: epoch: 052, acc1: 63.460%, acc5: 88.700%, test_loss: 1.4004, per_image_load_time: 0.067ms, per_image_inference_time: 0.061ms
2023-05-31 02:31:09 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 2.2030
2023-05-31 02:31:09 - until epoch: 052, best_acc1: 63.950%
2023-05-31 02:31:09 - epoch 053 lr: 0.100000
2023-05-31 02:31:11 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 2.1394
2023-05-31 02:31:12 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 1.9982
2023-05-31 02:31:13 - train: epoch 0053, iter [00050, 00390], lr: 0.100000, loss: 1.4262
2023-05-31 02:31:14 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 2.6118
2023-05-31 02:31:15 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 1.9958
2023-05-31 02:31:16 - train: epoch 0053, iter [00100, 00390], lr: 0.100000, loss: 1.4763
2023-05-31 02:31:17 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 1.6082
2023-05-31 02:31:18 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 1.5998
2023-05-31 02:31:19 - train: epoch 0053, iter [00150, 00390], lr: 0.100000, loss: 1.6057
2023-05-31 02:31:21 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 1.0911
2023-05-31 02:31:21 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 2.1219
2023-05-31 02:31:22 - train: epoch 0053, iter [00200, 00390], lr: 0.100000, loss: 1.6262
2023-05-31 02:31:24 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 1.5109
2023-05-31 02:31:25 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 2.0347
2023-05-31 02:31:26 - train: epoch 0053, iter [00250, 00390], lr: 0.100000, loss: 1.5998
2023-05-31 02:31:27 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 1.6123
2023-05-31 02:31:28 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 0.8622
2023-05-31 02:31:29 - train: epoch 0053, iter [00300, 00390], lr: 0.100000, loss: 1.5376
2023-05-31 02:31:30 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 2.7336
2023-05-31 02:31:30 - train: epoch 108, train_loss: 1.6264
2023-05-31 02:31:32 - train: epoch 0053, iter [00350, 00390], lr: 0.100000, loss: 1.6766
2023-05-31 02:31:32 - eval: epoch: 108, acc1: 73.200%, acc5: 92.960%, test_loss: 0.9994, per_image_load_time: 0.073ms, per_image_inference_time: 0.054ms
2023-05-31 02:31:32 - until epoch: 108, best_acc1: 76.210%
2023-05-31 02:31:32 - epoch 109 lr: 0.020000
2023-05-31 02:31:33 - train: epoch 059, train_loss: 1.5663
2023-05-31 02:31:33 - train: epoch 053, train_loss: 1.5813
2023-05-31 02:31:34 - eval: epoch: 059, acc1: 59.790%, acc5: 86.570%, test_loss: 1.4546, per_image_load_time: 0.080ms, per_image_inference_time: 0.048ms
2023-05-31 02:31:34 - until epoch: 059, best_acc1: 61.410%
2023-05-31 02:31:34 - epoch 060 lr: 0.100000
2023-05-31 02:31:35 - eval: epoch: 053, acc1: 63.120%, acc5: 88.710%, test_loss: 1.3990, per_image_load_time: 0.066ms, per_image_inference_time: 0.051ms
2023-05-31 02:31:35 - until epoch: 053, best_acc1: 63.950%
2023-05-31 02:31:35 - epoch 054 lr: 0.100000
2023-05-31 02:31:36 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 1.8478
2023-05-31 02:31:38 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 1.0411
2023-05-31 02:31:39 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 0.3867
2023-05-31 02:31:39 - train: epoch 0054, iter [00050, 00390], lr: 0.100000, loss: 1.5275
2023-05-31 02:31:42 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 1.1161
2023-05-31 02:31:42 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 2.0259
2023-05-31 02:31:42 - train: epoch 0054, iter [00100, 00390], lr: 0.100000, loss: 1.5954
2023-05-31 02:31:45 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 1.2775
2023-05-31 02:31:45 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 1.6981
2023-05-31 02:31:46 - train: epoch 0054, iter [00150, 00390], lr: 0.100000, loss: 1.3585
2023-05-31 02:31:48 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 1.0146
2023-05-31 02:31:49 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 2.1834
2023-05-31 02:31:49 - train: epoch 0054, iter [00200, 00390], lr: 0.100000, loss: 1.8816
2023-05-31 02:31:51 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 2.2569
2023-05-31 02:31:52 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 0.4851
2023-05-31 02:31:52 - train: epoch 0054, iter [00250, 00390], lr: 0.100000, loss: 1.6379
2023-05-31 02:31:55 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 1.0906
2023-05-31 02:31:55 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 2.2722
2023-05-31 02:31:55 - train: epoch 0054, iter [00300, 00390], lr: 0.100000, loss: 1.7213
2023-05-31 02:31:58 - train: epoch 109, train_loss: 1.5551
2023-05-31 02:31:58 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 1.1815
2023-05-31 02:31:58 - train: epoch 0054, iter [00350, 00390], lr: 0.100000, loss: 1.6207
2023-05-31 02:31:59 - eval: epoch: 109, acc1: 73.980%, acc5: 92.950%, test_loss: 1.0065, per_image_load_time: 0.074ms, per_image_inference_time: 0.056ms
2023-05-31 02:32:00 - until epoch: 109, best_acc1: 76.210%
2023-05-31 02:32:00 - epoch 110 lr: 0.020000
2023-05-31 02:32:00 - train: epoch 060, train_loss: 1.5535
2023-05-31 02:32:01 - train: epoch 054, train_loss: 1.5735
2023-05-31 02:32:02 - eval: epoch: 060, acc1: 61.140%, acc5: 87.670%, test_loss: 1.4253, per_image_load_time: 0.090ms, per_image_inference_time: 0.063ms
2023-05-31 02:32:02 - eval: epoch: 054, acc1: 63.790%, acc5: 88.540%, test_loss: 1.3718, per_image_load_time: 0.065ms, per_image_inference_time: 0.063ms
2023-05-31 02:32:02 - until epoch: 060, best_acc1: 61.410%
2023-05-31 02:32:02 - epoch 061 lr: 0.020000
2023-05-31 02:32:02 - until epoch: 054, best_acc1: 63.950%
2023-05-31 02:32:02 - epoch 055 lr: 0.100000
2023-05-31 02:32:03 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 1.6809
2023-05-31 02:32:05 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 1.6953
2023-05-31 02:32:07 - train: epoch 0055, iter [00050, 00390], lr: 0.100000, loss: 1.5857
2023-05-31 02:32:07 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 0.6994
2023-05-31 02:32:09 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 2.1656
2023-05-31 02:32:10 - train: epoch 0055, iter [00100, 00390], lr: 0.100000, loss: 1.6719
2023-05-31 02:32:10 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 0.7943
2023-05-31 02:32:12 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 0.8302
2023-05-31 02:32:13 - train: epoch 0055, iter [00150, 00390], lr: 0.100000, loss: 1.5899
2023-05-31 02:32:13 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 1.5019
2023-05-31 02:32:15 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 2.5053
2023-05-31 02:32:16 - train: epoch 0055, iter [00200, 00390], lr: 0.100000, loss: 1.6610
2023-05-31 02:32:17 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 0.8072
2023-05-31 02:32:18 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 2.2417
2023-05-31 02:32:20 - train: epoch 0055, iter [00250, 00390], lr: 0.100000, loss: 1.5540
2023-05-31 02:32:20 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 0.5040
2023-05-31 02:32:22 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 1.5787
2023-05-31 02:32:23 - train: epoch 0055, iter [00300, 00390], lr: 0.100000, loss: 1.6023
2023-05-31 02:32:23 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 2.1192
2023-05-31 02:32:24 - train: epoch 110, train_loss: 1.6050
2023-05-31 02:32:26 - train: epoch 0055, iter [00350, 00390], lr: 0.100000, loss: 1.5454
2023-05-31 02:32:26 - eval: epoch: 110, acc1: 74.980%, acc5: 93.380%, test_loss: 0.9804, per_image_load_time: 0.081ms, per_image_inference_time: 0.057ms
2023-05-31 02:32:26 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 1.7776
2023-05-31 02:32:26 - until epoch: 110, best_acc1: 76.210%
2023-05-31 02:32:26 - epoch 111 lr: 0.020000
2023-05-31 02:32:28 - train: epoch 055, train_loss: 1.5823
2023-05-31 02:32:28 - train: epoch 061, train_loss: 1.2037
2023-05-31 02:32:29 - eval: epoch: 055, acc1: 63.850%, acc5: 88.450%, test_loss: 1.3696, per_image_load_time: 0.064ms, per_image_inference_time: 0.052ms
2023-05-31 02:32:30 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 0.8020
2023-05-31 02:32:30 - until epoch: 055, best_acc1: 63.950%
2023-05-31 02:32:30 - epoch 056 lr: 0.100000
2023-05-31 02:32:30 - eval: epoch: 061, acc1: 71.590%, acc5: 92.700%, test_loss: 1.0131, per_image_load_time: 0.069ms, per_image_inference_time: 0.060ms
2023-05-31 02:32:30 - until epoch: 061, best_acc1: 71.590%
2023-05-31 02:32:30 - epoch 062 lr: 0.020000
2023-05-31 02:32:32 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 1.0103
2023-05-31 02:32:34 - train: epoch 0056, iter [00050, 00390], lr: 0.100000, loss: 1.6021
2023-05-31 02:32:34 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 0.5815
2023-05-31 02:32:35 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 2.3872
2023-05-31 02:32:37 - train: epoch 0056, iter [00100, 00390], lr: 0.100000, loss: 1.3684
2023-05-31 02:32:38 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 0.8425
2023-05-31 02:32:38 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 0.5551
2023-05-31 02:32:40 - train: epoch 0056, iter [00150, 00390], lr: 0.100000, loss: 1.6159
2023-05-31 02:32:41 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 1.9632
2023-05-31 02:32:42 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 0.4713
2023-05-31 02:32:43 - train: epoch 0056, iter [00200, 00390], lr: 0.100000, loss: 1.6668
2023-05-31 02:32:44 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 0.5721
2023-05-31 02:32:45 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 0.8529
2023-05-31 02:32:47 - train: epoch 0056, iter [00250, 00390], lr: 0.100000, loss: 1.5097
2023-05-31 02:32:48 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 0.8571
2023-05-31 02:32:48 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 2.1207
2023-05-31 02:32:50 - train: epoch 0056, iter [00300, 00390], lr: 0.100000, loss: 1.8346
2023-05-31 02:32:51 - train: epoch 111, train_loss: 1.6397
2023-05-31 02:32:51 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 0.4669
2023-05-31 02:32:52 - eval: epoch: 111, acc1: 74.440%, acc5: 93.370%, test_loss: 0.9987, per_image_load_time: 0.073ms, per_image_inference_time: 0.051ms
2023-05-31 02:32:53 - until epoch: 111, best_acc1: 76.210%
2023-05-31 02:32:53 - epoch 112 lr: 0.020000
2023-05-31 02:32:53 - train: epoch 0056, iter [00350, 00390], lr: 0.100000, loss: 1.6259
2023-05-31 02:32:53 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 0.9661
2023-05-31 02:32:55 - train: epoch 056, train_loss: 1.5747
2023-05-31 02:32:56 - train: epoch 062, train_loss: 1.0776
2023-05-31 02:32:56 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 2.0412
2023-05-31 02:32:57 - eval: epoch: 056, acc1: 62.920%, acc5: 88.350%, test_loss: 1.4172, per_image_load_time: 0.066ms, per_image_inference_time: 0.050ms
2023-05-31 02:32:57 - until epoch: 056, best_acc1: 63.950%
2023-05-31 02:32:57 - epoch 057 lr: 0.100000
2023-05-31 02:32:57 - eval: epoch: 062, acc1: 72.920%, acc5: 93.050%, test_loss: 0.9649, per_image_load_time: 0.075ms, per_image_inference_time: 0.049ms
2023-05-31 02:32:58 - until epoch: 062, best_acc1: 72.920%
2023-05-31 02:32:58 - epoch 063 lr: 0.020000
2023-05-31 02:32:59 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 0.6726
2023-05-31 02:33:01 - train: epoch 0057, iter [00050, 00390], lr: 0.100000, loss: 1.5633
2023-05-31 02:33:02 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 0.5861
2023-05-31 02:33:02 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 1.9936
2023-05-31 02:33:04 - train: epoch 0057, iter [00100, 00390], lr: 0.100000, loss: 1.6437
2023-05-31 02:33:05 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 1.8199
2023-05-31 02:33:05 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 1.6983
2023-05-31 02:33:07 - train: epoch 0057, iter [00150, 00390], lr: 0.100000, loss: 1.5590
2023-05-31 02:33:08 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 1.7996
2023-05-31 02:33:08 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 0.8579
2023-05-31 02:33:10 - train: epoch 0057, iter [00200, 00390], lr: 0.100000, loss: 1.5340
2023-05-31 02:33:12 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 2.0625
2023-05-31 02:33:12 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 0.6039
2023-05-31 02:33:14 - train: epoch 0057, iter [00250, 00390], lr: 0.100000, loss: 1.4689
2023-05-31 02:33:15 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 0.5608
2023-05-31 02:33:15 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 0.9269
2023-05-31 02:33:17 - train: epoch 0057, iter [00300, 00390], lr: 0.100000, loss: 1.5690
2023-05-31 02:33:17 - train: epoch 112, train_loss: 1.5932
2023-05-31 02:33:18 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 0.9064
2023-05-31 02:33:19 - eval: epoch: 112, acc1: 74.290%, acc5: 93.150%, test_loss: 0.9858, per_image_load_time: 0.081ms, per_image_inference_time: 0.053ms
2023-05-31 02:33:19 - until epoch: 112, best_acc1: 76.210%
2023-05-31 02:33:19 - epoch 113 lr: 0.020000
2023-05-31 02:33:20 - train: epoch 0057, iter [00350, 00390], lr: 0.100000, loss: 1.5913
2023-05-31 02:33:21 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 0.5864
2023-05-31 02:33:22 - train: epoch 057, train_loss: 1.5781
2023-05-31 02:33:23 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 1.7243
2023-05-31 02:33:23 - train: epoch 063, train_loss: 1.0098
2023-05-31 02:33:24 - eval: epoch: 057, acc1: 62.020%, acc5: 87.870%, test_loss: 1.4462, per_image_load_time: 0.067ms, per_image_inference_time: 0.050ms
2023-05-31 02:33:24 - until epoch: 057, best_acc1: 63.950%
2023-05-31 02:33:24 - epoch 058 lr: 0.100000
2023-05-31 02:33:25 - eval: epoch: 063, acc1: 72.560%, acc5: 93.160%, test_loss: 0.9817, per_image_load_time: 0.077ms, per_image_inference_time: 0.055ms
2023-05-31 02:33:25 - until epoch: 063, best_acc1: 72.920%
2023-05-31 02:33:25 - epoch 064 lr: 0.020000
2023-05-31 02:33:26 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 1.8744
2023-05-31 02:33:28 - train: epoch 0058, iter [00050, 00390], lr: 0.100000, loss: 1.6005
2023-05-31 02:33:29 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 2.1652
2023-05-31 02:33:29 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 1.9348
2023-05-31 02:33:31 - train: epoch 0058, iter [00100, 00390], lr: 0.100000, loss: 1.4237
2023-05-31 02:33:32 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 1.9224
2023-05-31 02:33:33 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 0.9940
2023-05-31 02:33:34 - train: epoch 0058, iter [00150, 00390], lr: 0.100000, loss: 1.5478
2023-05-31 02:33:35 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 2.0877
2023-05-31 02:33:36 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 0.8526
2023-05-31 02:33:37 - train: epoch 0058, iter [00200, 00390], lr: 0.100000, loss: 1.4641
2023-05-31 02:33:39 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 1.8524
2023-05-31 02:33:39 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 0.7996
2023-05-31 02:33:41 - train: epoch 0058, iter [00250, 00390], lr: 0.100000, loss: 1.6264
2023-05-31 02:33:42 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 1.0267
2023-05-31 02:33:42 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 1.7695
2023-05-31 02:33:44 - train: epoch 0058, iter [00300, 00390], lr: 0.100000, loss: 1.7064
2023-05-31 02:33:44 - train: epoch 113, train_loss: 1.6363
2023-05-31 02:33:45 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 1.1907
2023-05-31 02:33:46 - eval: epoch: 113, acc1: 74.540%, acc5: 93.440%, test_loss: 0.9578, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-05-31 02:33:46 - until epoch: 113, best_acc1: 76.210%
2023-05-31 02:33:46 - epoch 114 lr: 0.020000
2023-05-31 02:33:47 - train: epoch 0058, iter [00350, 00390], lr: 0.100000, loss: 1.7711
2023-05-31 02:33:48 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 1.8206
2023-05-31 02:33:49 - train: epoch 058, train_loss: 1.5700
2023-05-31 02:33:50 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 1.7517
2023-05-31 02:33:51 - train: epoch 064, train_loss: 0.9826
2023-05-31 02:33:51 - eval: epoch: 058, acc1: 63.790%, acc5: 88.580%, test_loss: 1.3806, per_image_load_time: 0.072ms, per_image_inference_time: 0.052ms
2023-05-31 02:33:51 - until epoch: 058, best_acc1: 63.950%
2023-05-31 02:33:51 - epoch 059 lr: 0.100000
2023-05-31 02:33:52 - eval: epoch: 064, acc1: 71.800%, acc5: 92.940%, test_loss: 1.0163, per_image_load_time: 0.070ms, per_image_inference_time: 0.060ms
2023-05-31 02:33:52 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 2.3219
2023-05-31 02:33:53 - until epoch: 064, best_acc1: 72.920%
2023-05-31 02:33:53 - epoch 065 lr: 0.020000
2023-05-31 02:33:55 - train: epoch 0059, iter [00050, 00390], lr: 0.100000, loss: 1.5776
2023-05-31 02:33:55 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 1.2307
2023-05-31 02:33:57 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 0.4984
2023-05-31 02:33:58 - train: epoch 0059, iter [00100, 00390], lr: 0.100000, loss: 1.5334
2023-05-31 02:33:59 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 1.9915
2023-05-31 02:34:00 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 0.9256
2023-05-31 02:34:01 - train: epoch 0059, iter [00150, 00390], lr: 0.100000, loss: 1.5416
2023-05-31 02:34:02 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 1.9791
2023-05-31 02:34:03 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 0.9799
2023-05-31 02:34:04 - train: epoch 0059, iter [00200, 00390], lr: 0.100000, loss: 1.7306
2023-05-31 02:34:05 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 1.7688
2023-05-31 02:34:07 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 0.6364
2023-05-31 02:34:08 - train: epoch 0059, iter [00250, 00390], lr: 0.100000, loss: 1.6348
2023-05-31 02:34:08 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 2.2003
2023-05-31 02:34:10 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 0.7862
2023-05-31 02:34:11 - train: epoch 0059, iter [00300, 00390], lr: 0.100000, loss: 1.6431
2023-05-31 02:34:11 - train: epoch 114, train_loss: 1.5106
2023-05-31 02:34:13 - eval: epoch: 114, acc1: 74.080%, acc5: 93.000%, test_loss: 0.9889, per_image_load_time: 0.080ms, per_image_inference_time: 0.051ms
2023-05-31 02:34:13 - until epoch: 114, best_acc1: 76.210%
2023-05-31 02:34:13 - epoch 115 lr: 0.020000
2023-05-31 02:34:13 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 0.7191
2023-05-31 02:34:13 - train: epoch 0059, iter [00350, 00390], lr: 0.100000, loss: 1.9028
2023-05-31 02:34:16 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 1.3153
2023-05-31 02:34:16 - train: epoch 059, train_loss: 1.5706
2023-05-31 02:34:17 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 2.0208
2023-05-31 02:34:18 - eval: epoch: 059, acc1: 63.980%, acc5: 88.180%, test_loss: 1.3803, per_image_load_time: 0.064ms, per_image_inference_time: 0.053ms
2023-05-31 02:34:18 - until epoch: 059, best_acc1: 63.980%
2023-05-31 02:34:18 - epoch 060 lr: 0.100000
2023-05-31 02:34:18 - train: epoch 065, train_loss: 0.9638
2023-05-31 02:34:19 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 1.6954
2023-05-31 02:34:20 - eval: epoch: 065, acc1: 72.840%, acc5: 93.110%, test_loss: 0.9904, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-05-31 02:34:20 - until epoch: 065, best_acc1: 72.920%
2023-05-31 02:34:20 - epoch 066 lr: 0.020000
2023-05-31 02:34:22 - train: epoch 0060, iter [00050, 00390], lr: 0.100000, loss: 1.4211
2023-05-31 02:34:22 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 0.4719
2023-05-31 02:34:24 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 1.2443
2023-05-31 02:34:25 - train: epoch 0060, iter [00100, 00390], lr: 0.100000, loss: 1.4452
2023-05-31 02:34:25 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 2.1441
2023-05-31 02:34:27 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 0.6047
2023-05-31 02:34:28 - train: epoch 0060, iter [00150, 00390], lr: 0.100000, loss: 1.3714
2023-05-31 02:34:29 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 2.1274
2023-05-31 02:34:31 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 0.8058
2023-05-31 02:34:32 - train: epoch 0060, iter [00200, 00390], lr: 0.100000, loss: 1.5130
2023-05-31 02:34:32 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 2.2232
2023-05-31 02:34:34 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 0.6543
2023-05-31 02:34:35 - train: epoch 0060, iter [00250, 00390], lr: 0.100000, loss: 1.5050
2023-05-31 02:34:35 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 2.3707
2023-05-31 02:34:37 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 0.4874
2023-05-31 02:34:38 - train: epoch 115, train_loss: 1.6871
2023-05-31 02:34:38 - train: epoch 0060, iter [00300, 00390], lr: 0.100000, loss: 1.6762
2023-05-31 02:34:39 - eval: epoch: 115, acc1: 73.990%, acc5: 93.260%, test_loss: 1.0253, per_image_load_time: 0.081ms, per_image_inference_time: 0.053ms
2023-05-31 02:34:40 - until epoch: 115, best_acc1: 76.210%
2023-05-31 02:34:40 - epoch 116 lr: 0.020000
2023-05-31 02:34:40 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 0.4851
2023-05-31 02:34:41 - train: epoch 0060, iter [00350, 00390], lr: 0.100000, loss: 1.6165
2023-05-31 02:34:43 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 0.5475
2023-05-31 02:34:43 - train: epoch 060, train_loss: 1.5648
2023-05-31 02:34:44 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 2.0641
2023-05-31 02:34:45 - eval: epoch: 060, acc1: 63.630%, acc5: 88.140%, test_loss: 1.4008, per_image_load_time: 0.066ms, per_image_inference_time: 0.055ms
2023-05-31 02:34:45 - train: epoch 066, train_loss: 0.9288
2023-05-31 02:34:45 - until epoch: 060, best_acc1: 63.980%
2023-05-31 02:34:45 - epoch 061 lr: 0.020000
2023-05-31 02:34:46 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 1.9702
2023-05-31 02:34:47 - eval: epoch: 066, acc1: 71.540%, acc5: 92.730%, test_loss: 1.0366, per_image_load_time: 0.081ms, per_image_inference_time: 0.061ms
2023-05-31 02:34:47 - until epoch: 066, best_acc1: 72.920%
2023-05-31 02:34:47 - epoch 067 lr: 0.020000
2023-05-31 02:34:49 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 0.3749
2023-05-31 02:34:49 - train: epoch 0061, iter [00050, 00390], lr: 0.020000, loss: 1.2537
2023-05-31 02:34:51 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 0.7952
2023-05-31 02:34:52 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 0.3166
2023-05-31 02:34:52 - train: epoch 0061, iter [00100, 00390], lr: 0.020000, loss: 1.2116
2023-05-31 02:34:54 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 0.5073
2023-05-31 02:34:55 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 2.2207
2023-05-31 02:34:56 - train: epoch 0061, iter [00150, 00390], lr: 0.020000, loss: 1.1632
2023-05-31 02:34:58 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 0.4024
2023-05-31 02:34:59 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 1.9554
2023-05-31 02:34:59 - train: epoch 0061, iter [00200, 00390], lr: 0.020000, loss: 1.3006
2023-05-31 02:35:01 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 0.4249
2023-05-31 02:35:02 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 2.1024
2023-05-31 02:35:02 - train: epoch 0061, iter [00250, 00390], lr: 0.020000, loss: 1.1807
2023-05-31 02:35:04 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 0.4650
2023-05-31 02:35:04 - train: epoch 116, train_loss: 1.5837
2023-05-31 02:35:05 - train: epoch 0061, iter [00300, 00390], lr: 0.020000, loss: 1.2412
2023-05-31 02:35:06 - eval: epoch: 116, acc1: 73.490%, acc5: 93.230%, test_loss: 0.9936, per_image_load_time: 0.077ms, per_image_inference_time: 0.062ms
2023-05-31 02:35:06 - until epoch: 116, best_acc1: 76.210%
2023-05-31 02:35:06 - epoch 117 lr: 0.020000
2023-05-31 02:35:07 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 1.1681
2023-05-31 02:35:08 - train: epoch 0061, iter [00350, 00390], lr: 0.020000, loss: 1.2028
2023-05-31 02:35:10 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 1.4188
2023-05-31 02:35:11 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 1.8527
2023-05-31 02:35:11 - train: epoch 061, train_loss: 1.2454
2023-05-31 02:35:12 - eval: epoch: 061, acc1: 74.970%, acc5: 93.570%, test_loss: 0.9688, per_image_load_time: 0.072ms, per_image_inference_time: 0.055ms
2023-05-31 02:35:12 - train: epoch 067, train_loss: 0.9142
2023-05-31 02:35:13 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 1.4412
2023-05-31 02:35:13 - until epoch: 061, best_acc1: 74.970%
2023-05-31 02:35:13 - epoch 062 lr: 0.020000
2023-05-31 02:35:14 - eval: epoch: 067, acc1: 72.320%, acc5: 92.940%, test_loss: 1.0359, per_image_load_time: 0.067ms, per_image_inference_time: 0.053ms
2023-05-31 02:35:14 - until epoch: 067, best_acc1: 72.920%
2023-05-31 02:35:14 - epoch 068 lr: 0.020000
2023-05-31 02:35:15 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 1.2484
2023-05-31 02:35:17 - train: epoch 0062, iter [00050, 00390], lr: 0.020000, loss: 1.0795
2023-05-31 02:35:18 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 0.6900
2023-05-31 02:35:19 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 1.9633
2023-05-31 02:35:20 - train: epoch 0062, iter [00100, 00390], lr: 0.020000, loss: 1.1316
2023-05-31 02:35:22 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 0.5064
2023-05-31 02:35:22 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 2.2337
2023-05-31 02:35:23 - train: epoch 0062, iter [00150, 00390], lr: 0.020000, loss: 1.1564
2023-05-31 02:35:25 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 1.4479
2023-05-31 02:35:25 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 2.0270
2023-05-31 02:35:27 - train: epoch 0062, iter [00200, 00390], lr: 0.020000, loss: 1.1004
2023-05-31 02:35:28 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 0.9090
2023-05-31 02:35:28 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 0.3605
2023-05-31 02:35:30 - train: epoch 0062, iter [00250, 00390], lr: 0.020000, loss: 1.0618
2023-05-31 02:35:31 - train: epoch 117, train_loss: 1.5940
2023-05-31 02:35:31 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 1.1328
2023-05-31 02:35:33 - eval: epoch: 117, acc1: 73.570%, acc5: 92.960%, test_loss: 0.9899, per_image_load_time: 0.081ms, per_image_inference_time: 0.053ms
2023-05-31 02:35:33 - train: epoch 0062, iter [00300, 00390], lr: 0.020000, loss: 1.0442
2023-05-31 02:35:33 - until epoch: 117, best_acc1: 76.210%
2023-05-31 02:35:33 - epoch 118 lr: 0.020000
2023-05-31 02:35:34 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 0.4872
2023-05-31 02:35:36 - train: epoch 0062, iter [00350, 00390], lr: 0.020000, loss: 1.1825
2023-05-31 02:35:37 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 1.5916
2023-05-31 02:35:37 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 1.0496
2023-05-31 02:35:38 - train: epoch 062, train_loss: 1.1257
2023-05-31 02:35:40 - train: epoch 068, train_loss: 0.9331
2023-05-31 02:35:40 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 2.2554
2023-05-31 02:35:40 - eval: epoch: 062, acc1: 75.420%, acc5: 93.730%, test_loss: 0.9535, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-05-31 02:35:40 - until epoch: 062, best_acc1: 75.420%
2023-05-31 02:35:40 - epoch 063 lr: 0.020000
2023-05-31 02:35:41 - eval: epoch: 068, acc1: 71.890%, acc5: 92.580%, test_loss: 1.0646, per_image_load_time: 0.074ms, per_image_inference_time: 0.057ms
2023-05-31 02:35:42 - until epoch: 068, best_acc1: 72.920%
2023-05-31 02:35:42 - epoch 069 lr: 0.020000
2023-05-31 02:35:42 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 1.8981
2023-05-31 02:35:44 - train: epoch 0063, iter [00050, 00390], lr: 0.020000, loss: 1.0667
2023-05-31 02:35:45 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 2.2661
2023-05-31 02:35:46 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 0.6646
2023-05-31 02:35:47 - train: epoch 0063, iter [00100, 00390], lr: 0.020000, loss: 1.0210
2023-05-31 02:35:48 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 0.3222
2023-05-31 02:35:49 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 0.4425
2023-05-31 02:35:51 - train: epoch 0063, iter [00150, 00390], lr: 0.020000, loss: 1.0217
2023-05-31 02:35:51 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 2.0650
2023-05-31 02:35:52 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 0.4876
2023-05-31 02:35:54 - train: epoch 0063, iter [00200, 00390], lr: 0.020000, loss: 1.0616
2023-05-31 02:35:55 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 2.2354
2023-05-31 02:35:56 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 1.4028
2023-05-31 02:35:57 - train: epoch 0063, iter [00250, 00390], lr: 0.020000, loss: 1.0625
2023-05-31 02:35:57 - train: epoch 118, train_loss: 1.5797
2023-05-31 02:35:59 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 0.7730
2023-05-31 02:35:59 - eval: epoch: 118, acc1: 74.210%, acc5: 93.610%, test_loss: 0.9467, per_image_load_time: 0.081ms, per_image_inference_time: 0.055ms
2023-05-31 02:35:59 - until epoch: 118, best_acc1: 76.210%
2023-05-31 02:35:59 - epoch 119 lr: 0.020000
2023-05-31 02:36:00 - train: epoch 0063, iter [00300, 00390], lr: 0.020000, loss: 1.0781
2023-05-31 02:36:02 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 0.4943
2023-05-31 02:36:03 - train: epoch 0063, iter [00350, 00390], lr: 0.020000, loss: 1.0427
2023-05-31 02:36:03 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 0.2614
2023-05-31 02:36:05 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 1.0026
2023-05-31 02:36:06 - train: epoch 063, train_loss: 1.0720
2023-05-31 02:36:06 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 0.2989
2023-05-31 02:36:07 - train: epoch 069, train_loss: 0.9147
2023-05-31 02:36:07 - eval: epoch: 063, acc1: 75.440%, acc5: 93.550%, test_loss: 0.9615, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-05-31 02:36:08 - until epoch: 063, best_acc1: 75.440%
2023-05-31 02:36:08 - epoch 064 lr: 0.020000
2023-05-31 02:36:09 - eval: epoch: 069, acc1: 72.320%, acc5: 93.010%, test_loss: 1.0304, per_image_load_time: 0.075ms, per_image_inference_time: 0.061ms
2023-05-31 02:36:09 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 1.6924
2023-05-31 02:36:09 - until epoch: 069, best_acc1: 72.920%
2023-05-31 02:36:09 - epoch 070 lr: 0.020000
2023-05-31 02:36:11 - train: epoch 0064, iter [00050, 00390], lr: 0.020000, loss: 1.0129
2023-05-31 02:36:12 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 0.8928
2023-05-31 02:36:13 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 1.2806
2023-05-31 02:36:15 - train: epoch 0064, iter [00100, 00390], lr: 0.020000, loss: 1.0035
2023-05-31 02:36:15 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 1.3253
2023-05-31 02:36:17 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 1.2336
2023-05-31 02:36:18 - train: epoch 0064, iter [00150, 00390], lr: 0.020000, loss: 1.0697
2023-05-31 02:36:18 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 1.9650
2023-05-31 02:36:20 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 0.4506
2023-05-31 02:36:21 - train: epoch 0064, iter [00200, 00390], lr: 0.020000, loss: 0.9812
2023-05-31 02:36:22 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 2.3101
2023-05-31 02:36:23 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 0.7467
2023-05-31 02:36:24 - train: epoch 0064, iter [00250, 00390], lr: 0.020000, loss: 1.0886
2023-05-31 02:36:24 - train: epoch 119, train_loss: 1.6564
2023-05-31 02:36:26 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 0.2998
2023-05-31 02:36:26 - eval: epoch: 119, acc1: 74.620%, acc5: 93.450%, test_loss: 0.9701, per_image_load_time: 0.079ms, per_image_inference_time: 0.061ms
2023-05-31 02:36:26 - until epoch: 119, best_acc1: 76.210%
2023-05-31 02:36:26 - epoch 120 lr: 0.020000
2023-05-31 02:36:27 - train: epoch 0064, iter [00300, 00390], lr: 0.020000, loss: 1.0941
2023-05-31 02:36:29 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 0.3737
2023-05-31 02:36:30 - train: epoch 0064, iter [00350, 00390], lr: 0.020000, loss: 1.1064
2023-05-31 02:36:30 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 2.2347
2023-05-31 02:36:32 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 1.3646
2023-05-31 02:36:33 - train: epoch 064, train_loss: 1.0363
2023-05-31 02:36:33 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 1.7718
2023-05-31 02:36:35 - eval: epoch: 064, acc1: 75.390%, acc5: 93.720%, test_loss: 0.9675, per_image_load_time: 0.067ms, per_image_inference_time: 0.054ms
2023-05-31 02:36:35 - train: epoch 070, train_loss: 0.8591
2023-05-31 02:36:35 - until epoch: 064, best_acc1: 75.440%
2023-05-31 02:36:35 - epoch 065 lr: 0.020000
2023-05-31 02:36:36 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 1.9297
2023-05-31 02:36:36 - eval: epoch: 070, acc1: 72.850%, acc5: 93.110%, test_loss: 0.9914, per_image_load_time: 0.070ms, per_image_inference_time: 0.064ms
2023-05-31 02:36:37 - until epoch: 070, best_acc1: 72.920%
2023-05-31 02:36:37 - epoch 071 lr: 0.020000
2023-05-31 02:36:38 - train: epoch 0065, iter [00050, 00390], lr: 0.020000, loss: 0.9602
2023-05-31 02:36:39 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 1.6882
2023-05-31 02:36:41 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 1.0770
2023-05-31 02:36:42 - train: epoch 0065, iter [00100, 00390], lr: 0.020000, loss: 1.0382
2023-05-31 02:36:42 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 1.9035
2023-05-31 02:36:44 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 0.8699
2023-05-31 02:36:45 - train: epoch 0065, iter [00150, 00390], lr: 0.020000, loss: 1.0070
2023-05-31 02:36:45 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 0.9127
2023-05-31 02:36:47 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 1.3900
2023-05-31 02:36:48 - train: epoch 0065, iter [00200, 00390], lr: 0.020000, loss: 1.0724
2023-05-31 02:36:49 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 2.5498
2023-05-31 02:36:50 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 1.8674
2023-05-31 02:36:51 - train: epoch 0065, iter [00250, 00390], lr: 0.020000, loss: 1.0633
2023-05-31 02:36:51 - train: epoch 120, train_loss: 1.6027
2023-05-31 02:36:53 - eval: epoch: 120, acc1: 74.130%, acc5: 93.000%, test_loss: 1.0287, per_image_load_time: 0.080ms, per_image_inference_time: 0.057ms
2023-05-31 02:36:53 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 0.4426
2023-05-31 02:36:53 - until epoch: 120, best_acc1: 76.210%
2023-05-31 02:36:53 - epoch 121 lr: 0.004000
2023-05-31 02:36:54 - train: epoch 0065, iter [00300, 00390], lr: 0.020000, loss: 1.1225
2023-05-31 02:36:56 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 2.1168
2023-05-31 02:36:57 - train: epoch 0065, iter [00350, 00390], lr: 0.020000, loss: 1.0802
2023-05-31 02:36:58 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 1.8754
2023-05-31 02:37:00 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 0.8756
2023-05-31 02:37:00 - train: epoch 065, train_loss: 1.0108
2023-05-31 02:37:01 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 1.6869
2023-05-31 02:37:02 - eval: epoch: 065, acc1: 75.310%, acc5: 93.190%, test_loss: 0.9772, per_image_load_time: 0.067ms, per_image_inference_time: 0.057ms
2023-05-31 02:37:02 - until epoch: 065, best_acc1: 75.440%
2023-05-31 02:37:02 - epoch 066 lr: 0.020000
2023-05-31 02:37:02 - train: epoch 071, train_loss: 0.9111
2023-05-31 02:37:03 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 1.3148
2023-05-31 02:37:04 - eval: epoch: 071, acc1: 71.560%, acc5: 92.850%, test_loss: 1.0567, per_image_load_time: 0.083ms, per_image_inference_time: 0.057ms
2023-05-31 02:37:04 - until epoch: 071, best_acc1: 72.920%
2023-05-31 02:37:04 - epoch 072 lr: 0.020000
2023-05-31 02:37:06 - train: epoch 0066, iter [00050, 00390], lr: 0.020000, loss: 0.9719
2023-05-31 02:37:06 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 1.8064
2023-05-31 02:37:08 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 1.7265
2023-05-31 02:37:09 - train: epoch 0066, iter [00100, 00390], lr: 0.020000, loss: 0.9814
2023-05-31 02:37:09 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 1.1322
2023-05-31 02:37:11 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 1.3440
2023-05-31 02:37:12 - train: epoch 0066, iter [00150, 00390], lr: 0.020000, loss: 0.9857
2023-05-31 02:37:13 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 0.9773
2023-05-31 02:37:15 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 1.7200
2023-05-31 02:37:15 - train: epoch 0066, iter [00200, 00390], lr: 0.020000, loss: 0.9453
2023-05-31 02:37:16 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 1.0970
2023-05-31 02:37:18 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 0.7698
2023-05-31 02:37:18 - train: epoch 0066, iter [00250, 00390], lr: 0.020000, loss: 1.0150
2023-05-31 02:37:19 - train: epoch 121, train_loss: 1.3499
2023-05-31 02:37:20 - eval: epoch: 121, acc1: 78.230%, acc5: 94.580%, test_loss: 0.8444, per_image_load_time: 0.074ms, per_image_inference_time: 0.056ms
2023-05-31 02:37:21 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 0.3586
2023-05-31 02:37:21 - until epoch: 121, best_acc1: 78.230%
2023-05-31 02:37:21 - epoch 122 lr: 0.004000
2023-05-31 02:37:21 - train: epoch 0066, iter [00300, 00390], lr: 0.020000, loss: 1.0250
2023-05-31 02:37:24 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 0.4779
2023-05-31 02:37:24 - train: epoch 0066, iter [00350, 00390], lr: 0.020000, loss: 0.9864
2023-05-31 02:37:25 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 1.7497
2023-05-31 02:37:27 - train: epoch 066, train_loss: 0.9932
2023-05-31 02:37:27 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 1.3355
2023-05-31 02:37:28 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 1.6228
2023-05-31 02:37:28 - eval: epoch: 066, acc1: 74.840%, acc5: 93.140%, test_loss: 0.9918, per_image_load_time: 0.072ms, per_image_inference_time: 0.056ms
2023-05-31 02:37:29 - until epoch: 066, best_acc1: 75.440%
2023-05-31 02:37:29 - epoch 067 lr: 0.020000
2023-05-31 02:37:29 - train: epoch 072, train_loss: 0.8930
2023-05-31 02:37:31 - eval: epoch: 072, acc1: 71.510%, acc5: 92.550%, test_loss: 1.0467, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-05-31 02:37:31 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 0.9256
2023-05-31 02:37:31 - until epoch: 072, best_acc1: 72.920%
2023-05-31 02:37:31 - epoch 073 lr: 0.020000
2023-05-31 02:37:32 - train: epoch 0067, iter [00050, 00390], lr: 0.020000, loss: 1.0006
2023-05-31 02:37:34 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 1.7830
2023-05-31 02:37:35 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 0.4708
2023-05-31 02:37:35 - train: epoch 0067, iter [00100, 00390], lr: 0.020000, loss: 0.9527
2023-05-31 02:37:37 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 1.8416
2023-05-31 02:37:38 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 0.5556
2023-05-31 02:37:39 - train: epoch 0067, iter [00150, 00390], lr: 0.020000, loss: 0.9132
2023-05-31 02:37:40 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 1.9832
2023-05-31 02:37:42 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 1.6118
2023-05-31 02:37:42 - train: epoch 0067, iter [00200, 00390], lr: 0.020000, loss: 0.9584
2023-05-31 02:37:44 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 2.0411
2023-05-31 02:37:45 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 0.3977
2023-05-31 02:37:45 - train: epoch 0067, iter [00250, 00390], lr: 0.020000, loss: 0.9317
2023-05-31 02:37:46 - train: epoch 122, train_loss: 1.3255
2023-05-31 02:37:48 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 0.6206
2023-05-31 02:37:48 - eval: epoch: 122, acc1: 78.690%, acc5: 94.620%, test_loss: 0.8117, per_image_load_time: 0.086ms, per_image_inference_time: 0.054ms
2023-05-31 02:37:48 - train: epoch 0067, iter [00300, 00390], lr: 0.020000, loss: 0.9287
2023-05-31 02:37:48 - until epoch: 122, best_acc1: 78.690%
2023-05-31 02:37:48 - epoch 123 lr: 0.004000
2023-05-31 02:37:50 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 0.9650
2023-05-31 02:37:51 - train: epoch 0067, iter [00350, 00390], lr: 0.020000, loss: 0.9136
2023-05-31 02:37:53 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 1.8494
2023-05-31 02:37:54 - train: epoch 067, train_loss: 0.9750
2023-05-31 02:37:54 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 1.0994
2023-05-31 02:37:55 - eval: epoch: 067, acc1: 75.180%, acc5: 93.100%, test_loss: 0.9982, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-05-31 02:37:56 - until epoch: 067, best_acc1: 75.440%
2023-05-31 02:37:56 - epoch 068 lr: 0.020000
2023-05-31 02:37:56 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 1.5435
2023-05-31 02:37:56 - train: epoch 073, train_loss: 0.8588
2023-05-31 02:37:58 - eval: epoch: 073, acc1: 72.440%, acc5: 92.950%, test_loss: 1.0336, per_image_load_time: 0.074ms, per_image_inference_time: 0.056ms
2023-05-31 02:37:58 - until epoch: 073, best_acc1: 72.920%
2023-05-31 02:37:58 - epoch 074 lr: 0.020000
2023-05-31 02:37:58 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 1.6156
2023-05-31 02:37:59 - train: epoch 0068, iter [00050, 00390], lr: 0.020000, loss: 0.9655
2023-05-31 02:38:01 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 0.2274
2023-05-31 02:38:02 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 1.2210
2023-05-31 02:38:02 - train: epoch 0068, iter [00100, 00390], lr: 0.020000, loss: 0.9311
2023-05-31 02:38:04 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 0.9729
2023-05-31 02:38:05 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 0.3608
2023-05-31 02:38:06 - train: epoch 0068, iter [00150, 00390], lr: 0.020000, loss: 0.9557
2023-05-31 02:38:07 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.1175
2023-05-31 02:38:09 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 0.6376
2023-05-31 02:38:09 - train: epoch 0068, iter [00200, 00390], lr: 0.020000, loss: 0.9722
2023-05-31 02:38:11 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 1.6555
2023-05-31 02:38:12 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 1.2654
2023-05-31 02:38:12 - train: epoch 0068, iter [00250, 00390], lr: 0.020000, loss: 0.9765
2023-05-31 02:38:13 - train: epoch 123, train_loss: 1.2969
2023-05-31 02:38:15 - eval: epoch: 123, acc1: 78.260%, acc5: 94.650%, test_loss: 0.8290, per_image_load_time: 0.081ms, per_image_inference_time: 0.057ms
2023-05-31 02:38:15 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 0.8637
2023-05-31 02:38:15 - train: epoch 0068, iter [00300, 00390], lr: 0.020000, loss: 0.9765
2023-05-31 02:38:15 - until epoch: 123, best_acc1: 78.690%
2023-05-31 02:38:15 - epoch 124 lr: 0.004000
2023-05-31 02:38:18 - train: epoch 0068, iter [00350, 00390], lr: 0.020000, loss: 1.0033
2023-05-31 02:38:18 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 1.7229
2023-05-31 02:38:19 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.1406
2023-05-31 02:38:21 - train: epoch 068, train_loss: 0.9640
2023-05-31 02:38:21 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 2.6158
2023-05-31 02:38:22 - eval: epoch: 068, acc1: 75.390%, acc5: 93.100%, test_loss: 1.0178, per_image_load_time: 0.065ms, per_image_inference_time: 0.054ms
2023-05-31 02:38:22 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 1.3502
2023-05-31 02:38:22 - until epoch: 068, best_acc1: 75.440%
2023-05-31 02:38:22 - epoch 069 lr: 0.020000
2023-05-31 02:38:23 - train: epoch 074, train_loss: 0.8714
2023-05-31 02:38:25 - eval: epoch: 074, acc1: 72.330%, acc5: 92.720%, test_loss: 1.0396, per_image_load_time: 0.072ms, per_image_inference_time: 0.056ms
2023-05-31 02:38:25 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 1.9837
2023-05-31 02:38:25 - until epoch: 074, best_acc1: 72.920%
2023-05-31 02:38:25 - epoch 075 lr: 0.020000
2023-05-31 02:38:26 - train: epoch 0069, iter [00050, 00390], lr: 0.020000, loss: 0.9352
2023-05-31 02:38:28 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 1.6641
2023-05-31 02:38:29 - train: epoch 0069, iter [00100, 00390], lr: 0.020000, loss: 0.8852
2023-05-31 02:38:29 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 0.4249
2023-05-31 02:38:31 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 1.5709
2023-05-31 02:38:33 - train: epoch 0069, iter [00150, 00390], lr: 0.020000, loss: 0.9882
2023-05-31 02:38:33 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 1.9963
2023-05-31 02:38:34 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 1.6339
2023-05-31 02:38:36 - train: epoch 0069, iter [00200, 00390], lr: 0.020000, loss: 1.0171
2023-05-31 02:38:36 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 1.1742
2023-05-31 02:38:38 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 1.5535
2023-05-31 02:38:39 - train: epoch 0069, iter [00250, 00390], lr: 0.020000, loss: 0.9818
2023-05-31 02:38:39 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 0.5194
2023-05-31 02:38:40 - train: epoch 124, train_loss: 1.2438
2023-05-31 02:38:42 - train: epoch 0069, iter [00300, 00390], lr: 0.020000, loss: 0.9299
2023-05-31 02:38:42 - eval: epoch: 124, acc1: 78.560%, acc5: 94.720%, test_loss: 0.8015, per_image_load_time: 0.082ms, per_image_inference_time: 0.052ms
2023-05-31 02:38:42 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 1.5058
2023-05-31 02:38:42 - until epoch: 124, best_acc1: 78.690%
2023-05-31 02:38:42 - epoch 125 lr: 0.004000
2023-05-31 02:38:45 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 0.8730
2023-05-31 02:38:45 - train: epoch 0069, iter [00350, 00390], lr: 0.020000, loss: 0.9310
2023-05-31 02:38:47 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.1937
2023-05-31 02:38:48 - train: epoch 069, train_loss: 0.9571
2023-05-31 02:38:48 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 0.7764
2023-05-31 02:38:49 - eval: epoch: 069, acc1: 75.220%, acc5: 92.610%, test_loss: 1.0220, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-05-31 02:38:49 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.6641
2023-05-31 02:38:49 - until epoch: 069, best_acc1: 75.440%
2023-05-31 02:38:49 - epoch 070 lr: 0.020000
2023-05-31 02:38:50 - train: epoch 075, train_loss: 0.8413
2023-05-31 02:38:52 - eval: epoch: 075, acc1: 72.240%, acc5: 92.920%, test_loss: 1.0257, per_image_load_time: 0.072ms, per_image_inference_time: 0.055ms
2023-05-31 02:38:52 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 0.3927
2023-05-31 02:38:52 - until epoch: 075, best_acc1: 72.920%
2023-05-31 02:38:52 - epoch 076 lr: 0.020000
2023-05-31 02:38:53 - train: epoch 0070, iter [00050, 00390], lr: 0.020000, loss: 0.9231
2023-05-31 02:38:55 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 1.2809
2023-05-31 02:38:56 - train: epoch 0070, iter [00100, 00390], lr: 0.020000, loss: 0.9737
2023-05-31 02:38:56 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 0.7330
2023-05-31 02:38:58 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 1.9255
2023-05-31 02:39:00 - train: epoch 0070, iter [00150, 00390], lr: 0.020000, loss: 0.9722
2023-05-31 02:39:00 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 0.4328
2023-05-31 02:39:02 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 0.6876
2023-05-31 02:39:03 - train: epoch 0070, iter [00200, 00390], lr: 0.020000, loss: 0.9624
2023-05-31 02:39:03 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 0.7688
2023-05-31 02:39:05 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 1.6124
2023-05-31 02:39:06 - train: epoch 0070, iter [00250, 00390], lr: 0.020000, loss: 0.9294
2023-05-31 02:39:06 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 0.3661
2023-05-31 02:39:08 - train: epoch 125, train_loss: 1.3023
2023-05-31 02:39:09 - train: epoch 0070, iter [00300, 00390], lr: 0.020000, loss: 0.9991
2023-05-31 02:39:09 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 0.8689
2023-05-31 02:39:09 - eval: epoch: 125, acc1: 79.020%, acc5: 94.780%, test_loss: 0.8133, per_image_load_time: 0.082ms, per_image_inference_time: 0.054ms
2023-05-31 02:39:10 - until epoch: 125, best_acc1: 79.020%
2023-05-31 02:39:10 - epoch 126 lr: 0.004000
2023-05-31 02:39:12 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 0.3072
2023-05-31 02:39:12 - train: epoch 0070, iter [00350, 00390], lr: 0.020000, loss: 0.9060
2023-05-31 02:39:14 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.4037
2023-05-31 02:39:15 - train: epoch 070, train_loss: 0.9508
2023-05-31 02:39:15 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 1.6042
2023-05-31 02:39:16 - eval: epoch: 070, acc1: 74.870%, acc5: 92.760%, test_loss: 1.0232, per_image_load_time: 0.067ms, per_image_inference_time: 0.052ms
2023-05-31 02:39:17 - until epoch: 070, best_acc1: 75.440%
2023-05-31 02:39:17 - epoch 071 lr: 0.020000
2023-05-31 02:39:17 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 1.0931
2023-05-31 02:39:17 - train: epoch 076, train_loss: 0.8470
2023-05-31 02:39:19 - eval: epoch: 076, acc1: 71.970%, acc5: 92.880%, test_loss: 1.0464, per_image_load_time: 0.083ms, per_image_inference_time: 0.054ms
2023-05-31 02:39:19 - until epoch: 076, best_acc1: 72.920%
2023-05-31 02:39:19 - epoch 077 lr: 0.020000
2023-05-31 02:39:19 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 1.8087
2023-05-31 02:39:20 - train: epoch 0071, iter [00050, 00390], lr: 0.020000, loss: 0.9039
2023-05-31 02:39:23 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 1.4983
2023-05-31 02:39:23 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 0.3243
2023-05-31 02:39:24 - train: epoch 0071, iter [00100, 00390], lr: 0.020000, loss: 0.9366
2023-05-31 02:39:26 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 1.4947
2023-05-31 02:39:27 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 1.9245
2023-05-31 02:39:27 - train: epoch 0071, iter [00150, 00390], lr: 0.020000, loss: 0.9015
2023-05-31 02:39:29 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 1.7306
2023-05-31 02:39:30 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 0.4362
2023-05-31 02:39:30 - train: epoch 0071, iter [00200, 00390], lr: 0.020000, loss: 0.9326
2023-05-31 02:39:32 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 1.9006
2023-05-31 02:39:33 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 0.9022
2023-05-31 02:39:33 - train: epoch 0071, iter [00250, 00390], lr: 0.020000, loss: 0.9587
2023-05-31 02:39:35 - train: epoch 126, train_loss: 1.2728
2023-05-31 02:39:36 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 0.8963
2023-05-31 02:39:36 - train: epoch 0071, iter [00300, 00390], lr: 0.020000, loss: 1.0234
2023-05-31 02:39:37 - eval: epoch: 126, acc1: 78.750%, acc5: 94.820%, test_loss: 0.8049, per_image_load_time: 0.084ms, per_image_inference_time: 0.054ms
2023-05-31 02:39:37 - until epoch: 126, best_acc1: 79.020%
2023-05-31 02:39:37 - epoch 127 lr: 0.004000
2023-05-31 02:39:39 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 0.4826
2023-05-31 02:39:39 - train: epoch 0071, iter [00350, 00390], lr: 0.020000, loss: 0.9323
2023-05-31 02:39:41 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.2254
2023-05-31 02:39:42 - train: epoch 071, train_loss: 0.9460
2023-05-31 02:39:42 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 1.3026
2023-05-31 02:39:43 - eval: epoch: 071, acc1: 74.520%, acc5: 92.670%, test_loss: 1.0417, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-05-31 02:39:44 - until epoch: 071, best_acc1: 75.440%
2023-05-31 02:39:44 - epoch 072 lr: 0.020000
2023-05-31 02:39:44 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 1.8679
2023-05-31 02:39:44 - train: epoch 077, train_loss: 0.8498
2023-05-31 02:39:46 - eval: epoch: 077, acc1: 72.260%, acc5: 92.850%, test_loss: 1.0370, per_image_load_time: 0.083ms, per_image_inference_time: 0.052ms
2023-05-31 02:39:46 - until epoch: 077, best_acc1: 72.920%
2023-05-31 02:39:46 - epoch 078 lr: 0.020000
2023-05-31 02:39:46 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.9895
2023-05-31 02:39:47 - train: epoch 0072, iter [00050, 00390], lr: 0.020000, loss: 0.9525
2023-05-31 02:39:49 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.2566
2023-05-31 02:39:50 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 2.4447
2023-05-31 02:39:51 - train: epoch 0072, iter [00100, 00390], lr: 0.020000, loss: 0.9708
2023-05-31 02:39:53 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.5519
2023-05-31 02:39:54 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 0.3825
2023-05-31 02:39:54 - train: epoch 0072, iter [00150, 00390], lr: 0.020000, loss: 0.9311
2023-05-31 02:39:56 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 0.3233
2023-05-31 02:39:57 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 0.4436
2023-05-31 02:39:57 - train: epoch 0072, iter [00200, 00390], lr: 0.020000, loss: 0.9283
2023-05-31 02:39:59 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 0.2421
2023-05-31 02:40:00 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 1.1301
2023-05-31 02:40:00 - train: epoch 0072, iter [00250, 00390], lr: 0.020000, loss: 0.9298
2023-05-31 02:40:02 - train: epoch 127, train_loss: 1.2449
2023-05-31 02:40:03 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 2.0032
2023-05-31 02:40:03 - train: epoch 0072, iter [00300, 00390], lr: 0.020000, loss: 0.9579
2023-05-31 02:40:04 - eval: epoch: 127, acc1: 78.820%, acc5: 94.550%, test_loss: 0.8188, per_image_load_time: 0.087ms, per_image_inference_time: 0.052ms
2023-05-31 02:40:04 - until epoch: 127, best_acc1: 79.020%
2023-05-31 02:40:04 - epoch 128 lr: 0.004000
2023-05-31 02:40:06 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 1.4993
2023-05-31 02:40:06 - train: epoch 0072, iter [00350, 00390], lr: 0.020000, loss: 0.9993
2023-05-31 02:40:08 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 1.9303
2023-05-31 02:40:09 - train: epoch 072, train_loss: 0.9434
2023-05-31 02:40:09 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 0.3013
2023-05-31 02:40:11 - eval: epoch: 072, acc1: 74.190%, acc5: 92.350%, test_loss: 1.0565, per_image_load_time: 0.067ms, per_image_inference_time: 0.055ms
2023-05-31 02:40:11 - until epoch: 072, best_acc1: 75.440%
2023-05-31 02:40:11 - epoch 073 lr: 0.020000
2023-05-31 02:40:11 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.7173
2023-05-31 02:40:12 - train: epoch 078, train_loss: 0.8782
2023-05-31 02:40:13 - eval: epoch: 078, acc1: 71.150%, acc5: 92.320%, test_loss: 1.1018, per_image_load_time: 0.075ms, per_image_inference_time: 0.054ms
2023-05-31 02:40:13 - until epoch: 078, best_acc1: 72.920%
2023-05-31 02:40:13 - epoch 079 lr: 0.020000
2023-05-31 02:40:14 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 1.7535
2023-05-31 02:40:15 - train: epoch 0073, iter [00050, 00390], lr: 0.020000, loss: 0.9743
2023-05-31 02:40:17 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.9778
2023-05-31 02:40:17 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 0.3455
2023-05-31 02:40:18 - train: epoch 0073, iter [00100, 00390], lr: 0.020000, loss: 0.9279
2023-05-31 02:40:20 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 1.8908
2023-05-31 02:40:21 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 0.3353
2023-05-31 02:40:21 - train: epoch 0073, iter [00150, 00390], lr: 0.020000, loss: 0.9445
2023-05-31 02:40:23 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 1.9604
2023-05-31 02:40:24 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 0.7710
2023-05-31 02:40:24 - train: epoch 0073, iter [00200, 00390], lr: 0.020000, loss: 0.9926
2023-05-31 02:40:27 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 1.2431
2023-05-31 02:40:27 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 0.9871
2023-05-31 02:40:28 - train: epoch 0073, iter [00250, 00390], lr: 0.020000, loss: 0.9349
2023-05-31 02:40:29 - train: epoch 128, train_loss: 1.2570
2023-05-31 02:40:30 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 0.8296
2023-05-31 02:40:31 - train: epoch 0073, iter [00300, 00390], lr: 0.020000, loss: 0.9419
2023-05-31 02:40:31 - eval: epoch: 128, acc1: 78.590%, acc5: 94.940%, test_loss: 0.8101, per_image_load_time: 0.081ms, per_image_inference_time: 0.055ms
2023-05-31 02:40:31 - until epoch: 128, best_acc1: 79.020%
2023-05-31 02:40:31 - epoch 129 lr: 0.004000
2023-05-31 02:40:33 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 2.6262
2023-05-31 02:40:34 - train: epoch 0073, iter [00350, 00390], lr: 0.020000, loss: 0.9410
2023-05-31 02:40:35 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 1.2181
2023-05-31 02:40:36 - train: epoch 073, train_loss: 0.9476
2023-05-31 02:40:36 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 0.6492
2023-05-31 02:40:38 - eval: epoch: 073, acc1: 73.970%, acc5: 92.370%, test_loss: 1.0630, per_image_load_time: 0.065ms, per_image_inference_time: 0.052ms
2023-05-31 02:40:38 - until epoch: 073, best_acc1: 75.440%
2023-05-31 02:40:38 - epoch 074 lr: 0.020000
2023-05-31 02:40:38 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 1.7370
2023-05-31 02:40:39 - train: epoch 079, train_loss: 0.8543
2023-05-31 02:40:40 - eval: epoch: 079, acc1: 71.840%, acc5: 92.780%, test_loss: 1.0544, per_image_load_time: 0.084ms, per_image_inference_time: 0.054ms
2023-05-31 02:40:41 - until epoch: 079, best_acc1: 72.920%
2023-05-31 02:40:41 - epoch 080 lr: 0.020000
2023-05-31 02:40:41 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 1.8389
2023-05-31 02:40:42 - train: epoch 0074, iter [00050, 00390], lr: 0.020000, loss: 0.9502
2023-05-31 02:40:44 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 1.6563
2023-05-31 02:40:45 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 0.6439
2023-05-31 02:40:45 - train: epoch 0074, iter [00100, 00390], lr: 0.020000, loss: 0.9347
2023-05-31 02:40:47 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 1.5307
2023-05-31 02:40:48 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 0.7877
2023-05-31 02:40:48 - train: epoch 0074, iter [00150, 00390], lr: 0.020000, loss: 0.9764
2023-05-31 02:40:50 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 1.9804
2023-05-31 02:40:51 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 0.3214
2023-05-31 02:40:51 - train: epoch 0074, iter [00200, 00390], lr: 0.020000, loss: 0.9429
2023-05-31 02:40:54 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.2198
2023-05-31 02:40:55 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 1.6554
2023-05-31 02:40:55 - train: epoch 0074, iter [00250, 00390], lr: 0.020000, loss: 0.9142
2023-05-31 02:40:56 - train: epoch 129, train_loss: 1.2768
2023-05-31 02:40:58 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 0.6296
2023-05-31 02:40:58 - train: epoch 0074, iter [00300, 00390], lr: 0.020000, loss: 0.9950
2023-05-31 02:40:58 - eval: epoch: 129, acc1: 79.030%, acc5: 94.740%, test_loss: 0.8024, per_image_load_time: 0.080ms, per_image_inference_time: 0.052ms
2023-05-31 02:40:58 - until epoch: 129, best_acc1: 79.030%
2023-05-31 02:40:58 - epoch 130 lr: 0.004000
2023-05-31 02:41:00 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 0.4810
2023-05-31 02:41:01 - train: epoch 0074, iter [00350, 00390], lr: 0.020000, loss: 0.9761
2023-05-31 02:41:03 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 1.5240
2023-05-31 02:41:03 - train: epoch 074, train_loss: 0.9483
2023-05-31 02:41:04 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 1.7266
2023-05-31 02:41:05 - eval: epoch: 074, acc1: 74.070%, acc5: 92.540%, test_loss: 1.0694, per_image_load_time: 0.068ms, per_image_inference_time: 0.055ms
2023-05-31 02:41:05 - until epoch: 074, best_acc1: 75.440%
2023-05-31 02:41:05 - epoch 075 lr: 0.020000
2023-05-31 02:41:05 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 1.5268
2023-05-31 02:41:06 - train: epoch 080, train_loss: 0.8540
2023-05-31 02:41:08 - eval: epoch: 080, acc1: 71.310%, acc5: 92.350%, test_loss: 1.1058, per_image_load_time: 0.076ms, per_image_inference_time: 0.054ms
2023-05-31 02:41:08 - until epoch: 080, best_acc1: 72.920%
2023-05-31 02:41:08 - epoch 081 lr: 0.020000
2023-05-31 02:41:08 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 1.8188
2023-05-31 02:41:09 - train: epoch 0075, iter [00050, 00390], lr: 0.020000, loss: 0.9493
2023-05-31 02:41:11 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 1.1406
2023-05-31 02:41:12 - train: epoch 0075, iter [00100, 00390], lr: 0.020000, loss: 0.9565
2023-05-31 02:41:12 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 0.8022
2023-05-31 02:41:14 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.8244
2023-05-31 02:41:15 - train: epoch 0075, iter [00150, 00390], lr: 0.020000, loss: 0.9081
2023-05-31 02:41:15 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 0.4839
2023-05-31 02:41:18 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 1.5726
2023-05-31 02:41:18 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 2.1870
2023-05-31 02:41:19 - train: epoch 0075, iter [00200, 00390], lr: 0.020000, loss: 0.9810
2023-05-31 02:41:21 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 1.6622
2023-05-31 02:41:22 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 0.4453
2023-05-31 02:41:22 - train: epoch 0075, iter [00250, 00390], lr: 0.020000, loss: 0.9074
2023-05-31 02:41:24 - train: epoch 130, train_loss: 1.2383
2023-05-31 02:41:25 - train: epoch 0075, iter [00300, 00390], lr: 0.020000, loss: 0.9587
2023-05-31 02:41:25 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 0.5554
2023-05-31 02:41:25 - eval: epoch: 130, acc1: 78.870%, acc5: 94.810%, test_loss: 0.8121, per_image_load_time: 0.075ms, per_image_inference_time: 0.055ms
2023-05-31 02:41:26 - until epoch: 130, best_acc1: 79.030%
2023-05-31 02:41:26 - epoch 131 lr: 0.004000
2023-05-31 02:41:27 - train: epoch 0075, iter [00350, 00390], lr: 0.020000, loss: 0.9630
2023-05-31 02:41:28 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 0.5684
2023-05-31 02:41:30 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 1.8242
2023-05-31 02:41:30 - train: epoch 075, train_loss: 0.9507
2023-05-31 02:41:31 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 0.4933
2023-05-31 02:41:32 - eval: epoch: 075, acc1: 72.970%, acc5: 91.910%, test_loss: 1.1110, per_image_load_time: 0.084ms, per_image_inference_time: 0.054ms
2023-05-31 02:41:32 - until epoch: 075, best_acc1: 75.440%
2023-05-31 02:41:32 - epoch 076 lr: 0.020000
2023-05-31 02:41:33 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 1.8759
2023-05-31 02:41:33 - train: epoch 081, train_loss: 0.8838
2023-05-31 02:41:35 - eval: epoch: 081, acc1: 71.060%, acc5: 92.510%, test_loss: 1.0945, per_image_load_time: 0.074ms, per_image_inference_time: 0.056ms
2023-05-31 02:41:35 - until epoch: 081, best_acc1: 72.920%
2023-05-31 02:41:35 - epoch 082 lr: 0.020000
2023-05-31 02:41:35 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 1.6760
2023-05-31 02:41:36 - train: epoch 0076, iter [00050, 00390], lr: 0.020000, loss: 0.9099
2023-05-31 02:41:39 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 1.4787
2023-05-31 02:41:39 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 1.4767
2023-05-31 02:41:39 - train: epoch 0076, iter [00100, 00390], lr: 0.020000, loss: 0.9293
2023-05-31 02:41:42 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 1.8114
2023-05-31 02:41:42 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 0.3320
2023-05-31 02:41:42 - train: epoch 0076, iter [00150, 00390], lr: 0.020000, loss: 0.9081
2023-05-31 02:41:45 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 1.8039
2023-05-31 02:41:45 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 1.5518
2023-05-31 02:41:46 - train: epoch 0076, iter [00200, 00390], lr: 0.020000, loss: 0.9171
2023-05-31 02:41:48 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 1.6299
2023-05-31 02:41:49 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 1.1737
2023-05-31 02:41:49 - train: epoch 0076, iter [00250, 00390], lr: 0.020000, loss: 0.9844
2023-05-31 02:41:51 - train: epoch 131, train_loss: 1.2144
2023-05-31 02:41:52 - train: epoch 0076, iter [00300, 00390], lr: 0.020000, loss: 0.9921
2023-05-31 02:41:52 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 0.8777
2023-05-31 02:41:53 - eval: epoch: 131, acc1: 78.880%, acc5: 94.800%, test_loss: 0.8046, per_image_load_time: 0.077ms, per_image_inference_time: 0.053ms
2023-05-31 02:41:53 - until epoch: 131, best_acc1: 79.030%
2023-05-31 02:41:53 - epoch 132 lr: 0.004000
2023-05-31 02:41:55 - train: epoch 0076, iter [00350, 00390], lr: 0.020000, loss: 1.0436
2023-05-31 02:41:55 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 0.3955
2023-05-31 02:41:57 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.2336
2023-05-31 02:41:57 - train: epoch 076, train_loss: 0.9563
2023-05-31 02:41:58 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 0.3886
2023-05-31 02:41:59 - eval: epoch: 076, acc1: 73.580%, acc5: 91.910%, test_loss: 1.0956, per_image_load_time: 0.072ms, per_image_inference_time: 0.057ms
2023-05-31 02:41:59 - until epoch: 076, best_acc1: 75.440%
2023-05-31 02:41:59 - epoch 077 lr: 0.020000
2023-05-31 02:42:00 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 1.8094
2023-05-31 02:42:00 - train: epoch 082, train_loss: 0.8813
2023-05-31 02:42:02 - eval: epoch: 082, acc1: 69.120%, acc5: 91.390%, test_loss: 1.1645, per_image_load_time: 0.073ms, per_image_inference_time: 0.059ms
2023-05-31 02:42:02 - until epoch: 082, best_acc1: 72.920%
2023-05-31 02:42:02 - epoch 083 lr: 0.020000
2023-05-31 02:42:03 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 1.5609
2023-05-31 02:42:03 - train: epoch 0077, iter [00050, 00390], lr: 0.020000, loss: 0.9130
2023-05-31 02:42:06 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 1.6008
2023-05-31 02:42:06 - train: epoch 0077, iter [00100, 00390], lr: 0.020000, loss: 0.9224
2023-05-31 02:42:06 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 0.4175
2023-05-31 02:42:09 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 1.7796
2023-05-31 02:42:09 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 0.4707
2023-05-31 02:42:09 - train: epoch 0077, iter [00150, 00390], lr: 0.020000, loss: 0.9718
2023-05-31 02:42:12 - train: epoch 0077, iter [00200, 00390], lr: 0.020000, loss: 1.0239
2023-05-31 02:42:12 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 1.3155
2023-05-31 02:42:12 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 0.9890
2023-05-31 02:42:16 - train: epoch 0077, iter [00250, 00390], lr: 0.020000, loss: 0.9604
2023-05-31 02:42:16 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.0652
2023-05-31 02:42:16 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 0.2425
2023-05-31 02:42:18 - train: epoch 132, train_loss: 1.2395
2023-05-31 02:42:19 - train: epoch 0077, iter [00300, 00390], lr: 0.020000, loss: 0.9875
2023-05-31 02:42:19 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 0.4550
2023-05-31 02:42:20 - eval: epoch: 132, acc1: 78.650%, acc5: 94.980%, test_loss: 0.7965, per_image_load_time: 0.080ms, per_image_inference_time: 0.053ms
2023-05-31 02:42:20 - until epoch: 132, best_acc1: 79.030%
2023-05-31 02:42:20 - epoch 133 lr: 0.004000
2023-05-31 02:42:21 - train: epoch 0077, iter [00350, 00390], lr: 0.020000, loss: 0.9721
2023-05-31 02:42:22 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 0.3435
2023-05-31 02:42:24 - train: epoch 077, train_loss: 0.9618
2023-05-31 02:42:24 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.0906
2023-05-31 02:42:25 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 0.4219
2023-05-31 02:42:26 - eval: epoch: 077, acc1: 73.400%, acc5: 91.770%, test_loss: 1.1131, per_image_load_time: 0.067ms, per_image_inference_time: 0.056ms
2023-05-31 02:42:26 - until epoch: 077, best_acc1: 75.440%
2023-05-31 02:42:26 - epoch 078 lr: 0.020000
2023-05-31 02:42:27 - train: epoch 083, train_loss: 0.8740
2023-05-31 02:42:27 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.2868
2023-05-31 02:42:29 - eval: epoch: 083, acc1: 70.810%, acc5: 92.560%, test_loss: 1.1178, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-05-31 02:42:29 - until epoch: 083, best_acc1: 72.920%
2023-05-31 02:42:29 - epoch 084 lr: 0.020000
2023-05-31 02:42:29 - train: epoch 0078, iter [00050, 00390], lr: 0.020000, loss: 1.0248
2023-05-31 02:42:30 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.6866
2023-05-31 02:42:33 - train: epoch 0078, iter [00100, 00390], lr: 0.020000, loss: 0.8898
2023-05-31 02:42:33 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 1.6656
2023-05-31 02:42:33 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 0.4238
2023-05-31 02:42:36 - train: epoch 0078, iter [00150, 00390], lr: 0.020000, loss: 0.9556
2023-05-31 02:42:36 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 1.8078
2023-05-31 02:42:37 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 1.0743
2023-05-31 02:42:39 - train: epoch 0078, iter [00200, 00390], lr: 0.020000, loss: 0.9611
2023-05-31 02:42:40 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 1.2671
2023-05-31 02:42:40 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 0.4612
2023-05-31 02:42:42 - train: epoch 0078, iter [00250, 00390], lr: 0.020000, loss: 0.9905
2023-05-31 02:42:43 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.6117
2023-05-31 02:42:43 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 0.4669
2023-05-31 02:42:46 - train: epoch 0078, iter [00300, 00390], lr: 0.020000, loss: 1.0080
2023-05-31 02:42:46 - train: epoch 133, train_loss: 1.1629
2023-05-31 02:42:46 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 0.7388
2023-05-31 02:42:47 - eval: epoch: 133, acc1: 78.590%, acc5: 94.750%, test_loss: 0.8231, per_image_load_time: 0.080ms, per_image_inference_time: 0.051ms
2023-05-31 02:42:48 - until epoch: 133, best_acc1: 79.030%
2023-05-31 02:42:48 - epoch 134 lr: 0.004000
2023-05-31 02:42:48 - train: epoch 0078, iter [00350, 00390], lr: 0.020000, loss: 1.0089
2023-05-31 02:42:49 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 0.5025
2023-05-31 02:42:51 - train: epoch 078, train_loss: 0.9630
2023-05-31 02:42:52 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 1.7697
2023-05-31 02:42:52 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 1.4869
2023-05-31 02:42:53 - eval: epoch: 078, acc1: 72.190%, acc5: 91.710%, test_loss: 1.1453, per_image_load_time: 0.068ms, per_image_inference_time: 0.063ms
2023-05-31 02:42:53 - until epoch: 078, best_acc1: 75.440%
2023-05-31 02:42:53 - epoch 079 lr: 0.020000
2023-05-31 02:42:54 - train: epoch 084, train_loss: 0.7973
2023-05-31 02:42:54 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 1.3659
2023-05-31 02:42:56 - eval: epoch: 084, acc1: 69.960%, acc5: 92.220%, test_loss: 1.1519, per_image_load_time: 0.075ms, per_image_inference_time: 0.053ms
2023-05-31 02:42:56 - until epoch: 084, best_acc1: 72.920%
2023-05-31 02:42:56 - epoch 085 lr: 0.020000
2023-05-31 02:42:56 - train: epoch 0079, iter [00050, 00390], lr: 0.020000, loss: 0.8989
2023-05-31 02:42:57 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 1.6427
2023-05-31 02:43:00 - train: epoch 0079, iter [00100, 00390], lr: 0.020000, loss: 0.9229
2023-05-31 02:43:00 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 0.4365
2023-05-31 02:43:00 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.1391
2023-05-31 02:43:03 - train: epoch 0079, iter [00150, 00390], lr: 0.020000, loss: 0.9931
2023-05-31 02:43:03 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 1.9878
2023-05-31 02:43:04 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 1.6774
2023-05-31 02:43:06 - train: epoch 0079, iter [00200, 00390], lr: 0.020000, loss: 0.9684
2023-05-31 02:43:07 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 0.5337
2023-05-31 02:43:07 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.4168
2023-05-31 02:43:09 - train: epoch 0079, iter [00250, 00390], lr: 0.020000, loss: 1.0058
2023-05-31 02:43:10 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 0.2025
2023-05-31 02:43:10 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 1.6277
2023-05-31 02:43:13 - train: epoch 0079, iter [00300, 00390], lr: 0.020000, loss: 0.8997
2023-05-31 02:43:13 - train: epoch 134, train_loss: 1.2542
2023-05-31 02:43:13 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 0.6326
2023-05-31 02:43:15 - eval: epoch: 134, acc1: 78.760%, acc5: 94.450%, test_loss: 0.8522, per_image_load_time: 0.081ms, per_image_inference_time: 0.054ms
2023-05-31 02:43:15 - until epoch: 134, best_acc1: 79.030%
2023-05-31 02:43:15 - epoch 135 lr: 0.004000
2023-05-31 02:43:15 - train: epoch 0079, iter [00350, 00390], lr: 0.020000, loss: 1.0074
2023-05-31 02:43:16 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 0.3239
2023-05-31 02:43:18 - train: epoch 079, train_loss: 0.9734
2023-05-31 02:43:19 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 2.3314
2023-05-31 02:43:19 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 1.4520
2023-05-31 02:43:20 - eval: epoch: 079, acc1: 73.170%, acc5: 91.610%, test_loss: 1.1105, per_image_load_time: 0.065ms, per_image_inference_time: 0.052ms
2023-05-31 02:43:20 - until epoch: 079, best_acc1: 75.440%
2023-05-31 02:43:20 - epoch 080 lr: 0.020000
2023-05-31 02:43:21 - train: epoch 085, train_loss: 0.8580
2023-05-31 02:43:21 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.0750
2023-05-31 02:43:22 - eval: epoch: 085, acc1: 70.500%, acc5: 91.730%, test_loss: 1.1620, per_image_load_time: 0.071ms, per_image_inference_time: 0.052ms
2023-05-31 02:43:23 - until epoch: 085, best_acc1: 72.920%
2023-05-31 02:43:23 - epoch 086 lr: 0.020000
2023-05-31 02:43:23 - train: epoch 0080, iter [00050, 00390], lr: 0.020000, loss: 0.9971
2023-05-31 02:43:25 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 1.1620
2023-05-31 02:43:27 - train: epoch 0080, iter [00100, 00390], lr: 0.020000, loss: 1.0078
2023-05-31 02:43:27 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 0.2477
2023-05-31 02:43:28 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 1.6476
2023-05-31 02:43:30 - train: epoch 0080, iter [00150, 00390], lr: 0.020000, loss: 0.9627
2023-05-31 02:43:30 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 0.2408
2023-05-31 02:43:31 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 1.5975
2023-05-31 02:43:33 - train: epoch 0080, iter [00200, 00390], lr: 0.020000, loss: 0.9725
2023-05-31 02:43:33 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 0.3716
2023-05-31 02:43:34 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 0.6856
2023-05-31 02:43:36 - train: epoch 0080, iter [00250, 00390], lr: 0.020000, loss: 0.9412
2023-05-31 02:43:37 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 0.4440
2023-05-31 02:43:38 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 1.7092
2023-05-31 02:43:39 - train: epoch 0080, iter [00300, 00390], lr: 0.020000, loss: 0.9901
2023-05-31 02:43:40 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 0.2624
2023-05-31 02:43:40 - train: epoch 135, train_loss: 1.2564
2023-05-31 02:43:42 - eval: epoch: 135, acc1: 78.280%, acc5: 94.740%, test_loss: 0.8233, per_image_load_time: 0.081ms, per_image_inference_time: 0.052ms
2023-05-31 02:43:42 - until epoch: 135, best_acc1: 79.030%
2023-05-31 02:43:42 - epoch 136 lr: 0.004000
2023-05-31 02:43:42 - train: epoch 0080, iter [00350, 00390], lr: 0.020000, loss: 0.9809
2023-05-31 02:43:43 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 1.3085
2023-05-31 02:43:45 - train: epoch 080, train_loss: 0.9789
2023-05-31 02:43:45 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 0.4644
2023-05-31 02:43:46 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.0555
2023-05-31 02:43:46 - eval: epoch: 080, acc1: 72.720%, acc5: 91.610%, test_loss: 1.1302, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-05-31 02:43:47 - until epoch: 080, best_acc1: 75.440%
2023-05-31 02:43:47 - epoch 081 lr: 0.020000
2023-05-31 02:43:48 - train: epoch 086, train_loss: 0.8374
2023-05-31 02:43:49 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.2275
2023-05-31 02:43:49 - eval: epoch: 086, acc1: 71.480%, acc5: 92.450%, test_loss: 1.1318, per_image_load_time: 0.068ms, per_image_inference_time: 0.056ms
2023-05-31 02:43:50 - until epoch: 086, best_acc1: 72.920%
2023-05-31 02:43:50 - epoch 087 lr: 0.020000
2023-05-31 02:43:50 - train: epoch 0081, iter [00050, 00390], lr: 0.020000, loss: 0.9513
2023-05-31 02:43:52 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.6721
2023-05-31 02:43:53 - train: epoch 0081, iter [00100, 00390], lr: 0.020000, loss: 0.9674
2023-05-31 02:43:54 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 0.5068
2023-05-31 02:43:55 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 1.2217
2023-05-31 02:43:57 - train: epoch 0081, iter [00150, 00390], lr: 0.020000, loss: 1.0100
2023-05-31 02:43:57 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 0.2855
2023-05-31 02:43:58 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.1426
2023-05-31 02:44:00 - train: epoch 0081, iter [00200, 00390], lr: 0.020000, loss: 0.9942
2023-05-31 02:44:00 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 0.8021
2023-05-31 02:44:01 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 1.7886
2023-05-31 02:44:03 - train: epoch 0081, iter [00250, 00390], lr: 0.020000, loss: 0.9792
2023-05-31 02:44:04 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 1.3497
2023-05-31 02:44:05 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 1.7999
2023-05-31 02:44:07 - train: epoch 0081, iter [00300, 00390], lr: 0.020000, loss: 1.0105
2023-05-31 02:44:07 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 0.4571
2023-05-31 02:44:07 - train: epoch 136, train_loss: 1.2149
2023-05-31 02:44:09 - eval: epoch: 136, acc1: 78.560%, acc5: 94.570%, test_loss: 0.8237, per_image_load_time: 0.082ms, per_image_inference_time: 0.055ms
2023-05-31 02:44:09 - until epoch: 136, best_acc1: 79.030%
2023-05-31 02:44:09 - epoch 137 lr: 0.004000
2023-05-31 02:44:09 - train: epoch 0081, iter [00350, 00390], lr: 0.020000, loss: 1.0634
2023-05-31 02:44:09 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 0.9288
2023-05-31 02:44:12 - train: epoch 081, train_loss: 0.9827
2023-05-31 02:44:12 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 0.5332
2023-05-31 02:44:13 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 1.6142
2023-05-31 02:44:13 - eval: epoch: 081, acc1: 72.810%, acc5: 91.680%, test_loss: 1.1232, per_image_load_time: 0.069ms, per_image_inference_time: 0.055ms
2023-05-31 02:44:14 - until epoch: 081, best_acc1: 75.440%
2023-05-31 02:44:14 - epoch 082 lr: 0.020000
2023-05-31 02:44:15 - train: epoch 087, train_loss: 0.8192
2023-05-31 02:44:16 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 1.4622
2023-05-31 02:44:16 - eval: epoch: 087, acc1: 69.990%, acc5: 92.280%, test_loss: 1.1724, per_image_load_time: 0.080ms, per_image_inference_time: 0.052ms
2023-05-31 02:44:17 - until epoch: 087, best_acc1: 72.920%
2023-05-31 02:44:17 - epoch 088 lr: 0.020000
2023-05-31 02:44:18 - train: epoch 0082, iter [00050, 00390], lr: 0.020000, loss: 0.9867
2023-05-31 02:44:19 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.9022
2023-05-31 02:44:21 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 0.3520
2023-05-31 02:44:21 - train: epoch 0082, iter [00100, 00390], lr: 0.020000, loss: 0.9987
2023-05-31 02:44:22 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 1.3451
2023-05-31 02:44:24 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 0.4836
2023-05-31 02:44:24 - train: epoch 0082, iter [00150, 00390], lr: 0.020000, loss: 0.9724
2023-05-31 02:44:25 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 1.4261
2023-05-31 02:44:27 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 2.2652
2023-05-31 02:44:27 - train: epoch 0082, iter [00200, 00390], lr: 0.020000, loss: 0.9598
2023-05-31 02:44:28 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 1.2695
2023-05-31 02:44:31 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 0.3100
2023-05-31 02:44:31 - train: epoch 0082, iter [00250, 00390], lr: 0.020000, loss: 1.0195
2023-05-31 02:44:32 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.1255
2023-05-31 02:44:34 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 1.0404
2023-05-31 02:44:34 - train: epoch 0082, iter [00300, 00390], lr: 0.020000, loss: 1.0052
2023-05-31 02:44:34 - train: epoch 137, train_loss: 1.2147
2023-05-31 02:44:36 - eval: epoch: 137, acc1: 78.650%, acc5: 94.720%, test_loss: 0.8298, per_image_load_time: 0.088ms, per_image_inference_time: 0.053ms
2023-05-31 02:44:36 - until epoch: 137, best_acc1: 79.030%
2023-05-31 02:44:36 - epoch 138 lr: 0.004000
2023-05-31 02:44:37 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 2.0750
2023-05-31 02:44:37 - train: epoch 0082, iter [00350, 00390], lr: 0.020000, loss: 1.0266
2023-05-31 02:44:39 - train: epoch 082, train_loss: 0.9851
2023-05-31 02:44:40 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 1.0699
2023-05-31 02:44:40 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 1.3867
2023-05-31 02:44:41 - eval: epoch: 082, acc1: 72.310%, acc5: 91.230%, test_loss: 1.1368, per_image_load_time: 0.089ms, per_image_inference_time: 0.054ms
2023-05-31 02:44:41 - until epoch: 082, best_acc1: 75.440%
2023-05-31 02:44:41 - epoch 083 lr: 0.020000
2023-05-31 02:44:42 - train: epoch 088, train_loss: 0.8452
2023-05-31 02:44:43 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 1.5401
2023-05-31 02:44:44 - eval: epoch: 088, acc1: 71.800%, acc5: 92.250%, test_loss: 1.1001, per_image_load_time: 0.076ms, per_image_inference_time: 0.053ms
2023-05-31 02:44:44 - until epoch: 088, best_acc1: 72.920%
2023-05-31 02:44:44 - epoch 089 lr: 0.020000
2023-05-31 02:44:45 - train: epoch 0083, iter [00050, 00390], lr: 0.020000, loss: 1.0029
2023-05-31 02:44:46 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 1.5284
2023-05-31 02:44:48 - train: epoch 0083, iter [00100, 00390], lr: 0.020000, loss: 1.0108
2023-05-31 02:44:48 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 0.5880
2023-05-31 02:44:49 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 2.0115
2023-05-31 02:44:51 - train: epoch 0083, iter [00150, 00390], lr: 0.020000, loss: 0.9854
2023-05-31 02:44:51 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 0.3205
2023-05-31 02:44:52 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.8272
2023-05-31 02:44:54 - train: epoch 0083, iter [00200, 00390], lr: 0.020000, loss: 1.0235
2023-05-31 02:44:55 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 0.8265
2023-05-31 02:44:55 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.8965
2023-05-31 02:44:57 - train: epoch 0083, iter [00250, 00390], lr: 0.020000, loss: 1.0061
2023-05-31 02:44:58 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 0.7771
2023-05-31 02:44:59 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 1.5919
2023-05-31 02:45:01 - train: epoch 0083, iter [00300, 00390], lr: 0.020000, loss: 1.0270
2023-05-31 02:45:01 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 2.3549
2023-05-31 02:45:01 - train: epoch 138, train_loss: 1.1879
2023-05-31 02:45:03 - eval: epoch: 138, acc1: 78.690%, acc5: 94.540%, test_loss: 0.8353, per_image_load_time: 0.091ms, per_image_inference_time: 0.056ms
2023-05-31 02:45:04 - train: epoch 0083, iter [00350, 00390], lr: 0.020000, loss: 0.9826
2023-05-31 02:45:04 - until epoch: 138, best_acc1: 79.030%
2023-05-31 02:45:04 - epoch 139 lr: 0.004000
2023-05-31 02:45:04 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 0.8492
2023-05-31 02:45:06 - train: epoch 083, train_loss: 0.9925
2023-05-31 02:45:07 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 0.2538
2023-05-31 02:45:07 - eval: epoch: 083, acc1: 71.480%, acc5: 91.180%, test_loss: 1.1711, per_image_load_time: 0.071ms, per_image_inference_time: 0.056ms
2023-05-31 02:45:07 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 1.0496
2023-05-31 02:45:08 - until epoch: 083, best_acc1: 75.440%
2023-05-31 02:45:08 - epoch 084 lr: 0.020000
2023-05-31 02:45:09 - train: epoch 089, train_loss: 0.8121
2023-05-31 02:45:10 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 1.4695
2023-05-31 02:45:11 - eval: epoch: 089, acc1: 70.520%, acc5: 92.210%, test_loss: 1.1691, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-05-31 02:45:11 - train: epoch 0084, iter [00050, 00390], lr: 0.020000, loss: 0.9676
2023-05-31 02:45:11 - until epoch: 089, best_acc1: 72.920%
2023-05-31 02:45:11 - epoch 090 lr: 0.020000
2023-05-31 02:45:13 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 1.6690
2023-05-31 02:45:14 - train: epoch 0084, iter [00100, 00390], lr: 0.020000, loss: 1.0068
2023-05-31 02:45:16 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 0.2223
2023-05-31 02:45:16 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.6190
2023-05-31 02:45:17 - train: epoch 0084, iter [00150, 00390], lr: 0.020000, loss: 0.9921
2023-05-31 02:45:19 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 0.3414
2023-05-31 02:45:20 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 1.5107
2023-05-31 02:45:21 - train: epoch 0084, iter [00200, 00390], lr: 0.020000, loss: 0.9581
2023-05-31 02:45:22 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 0.5066
2023-05-31 02:45:23 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 1.5871
2023-05-31 02:45:24 - train: epoch 0084, iter [00250, 00390], lr: 0.020000, loss: 0.9920
2023-05-31 02:45:25 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 0.7420
2023-05-31 02:45:26 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 1.6890
2023-05-31 02:45:27 - train: epoch 0084, iter [00300, 00390], lr: 0.020000, loss: 1.0816
2023-05-31 02:45:29 - train: epoch 139, train_loss: 1.2888
2023-05-31 02:45:29 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 0.3556
2023-05-31 02:45:30 - train: epoch 0084, iter [00350, 00390], lr: 0.020000, loss: 0.9872
2023-05-31 02:45:30 - eval: epoch: 139, acc1: 78.510%, acc5: 94.480%, test_loss: 0.8420, per_image_load_time: 0.084ms, per_image_inference_time: 0.056ms
2023-05-31 02:45:31 - until epoch: 139, best_acc1: 79.030%
2023-05-31 02:45:31 - epoch 140 lr: 0.004000
2023-05-31 02:45:31 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 0.4455
2023-05-31 02:45:32 - train: epoch 084, train_loss: 0.9889
2023-05-31 02:45:34 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 0.5119
2023-05-31 02:45:34 - eval: epoch: 084, acc1: 71.570%, acc5: 91.110%, test_loss: 1.1633, per_image_load_time: 0.075ms, per_image_inference_time: 0.055ms
2023-05-31 02:45:35 - until epoch: 084, best_acc1: 75.440%
2023-05-31 02:45:35 - epoch 085 lr: 0.020000
2023-05-31 02:45:35 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 1.3774
2023-05-31 02:45:36 - train: epoch 090, train_loss: 0.8077
2023-05-31 02:45:38 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 1.6265
2023-05-31 02:45:38 - eval: epoch: 090, acc1: 70.540%, acc5: 91.910%, test_loss: 1.1614, per_image_load_time: 0.077ms, per_image_inference_time: 0.055ms
2023-05-31 02:45:38 - train: epoch 0085, iter [00050, 00390], lr: 0.020000, loss: 0.9601
2023-05-31 02:45:38 - until epoch: 090, best_acc1: 72.920%
2023-05-31 02:45:38 - epoch 091 lr: 0.020000
2023-05-31 02:45:40 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 1.3792
2023-05-31 02:45:41 - train: epoch 0085, iter [00100, 00390], lr: 0.020000, loss: 1.0147
2023-05-31 02:45:42 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 0.2489
2023-05-31 02:45:44 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.3936
2023-05-31 02:45:45 - train: epoch 0085, iter [00150, 00390], lr: 0.020000, loss: 1.0232
2023-05-31 02:45:46 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 0.6712
2023-05-31 02:45:47 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 1.7843
2023-05-31 02:45:48 - train: epoch 0085, iter [00200, 00390], lr: 0.020000, loss: 0.9405
2023-05-31 02:45:49 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 0.2818
2023-05-31 02:45:50 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.3236
2023-05-31 02:45:51 - train: epoch 0085, iter [00250, 00390], lr: 0.020000, loss: 0.9337
2023-05-31 02:45:52 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 0.2823
2023-05-31 02:45:53 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 1.8279
2023-05-31 02:45:54 - train: epoch 0085, iter [00300, 00390], lr: 0.020000, loss: 0.9996
2023-05-31 02:45:56 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 1.3120
2023-05-31 02:45:56 - train: epoch 140, train_loss: 1.1959
2023-05-31 02:45:57 - train: epoch 0085, iter [00350, 00390], lr: 0.020000, loss: 0.9837
2023-05-31 02:45:58 - eval: epoch: 140, acc1: 78.730%, acc5: 94.660%, test_loss: 0.8128, per_image_load_time: 0.083ms, per_image_inference_time: 0.053ms
2023-05-31 02:45:58 - until epoch: 140, best_acc1: 79.030%
2023-05-31 02:45:58 - epoch 141 lr: 0.004000
2023-05-31 02:45:58 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 0.3220
2023-05-31 02:45:59 - train: epoch 085, train_loss: 0.9872
2023-05-31 02:46:01 - eval: epoch: 085, acc1: 71.170%, acc5: 90.560%, test_loss: 1.1848, per_image_load_time: 0.064ms, per_image_inference_time: 0.054ms
2023-05-31 02:46:01 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 1.5530
2023-05-31 02:46:01 - until epoch: 085, best_acc1: 75.440%
2023-05-31 02:46:01 - epoch 086 lr: 0.020000
2023-05-31 02:46:02 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.9835
2023-05-31 02:46:04 - train: epoch 091, train_loss: 0.8291
2023-05-31 02:46:05 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 1.5747
2023-05-31 02:46:05 - eval: epoch: 091, acc1: 71.580%, acc5: 92.930%, test_loss: 1.0825, per_image_load_time: 0.070ms, per_image_inference_time: 0.053ms
2023-05-31 02:46:05 - train: epoch 0086, iter [00050, 00390], lr: 0.020000, loss: 0.9308
2023-05-31 02:46:05 - until epoch: 091, best_acc1: 72.920%
2023-05-31 02:46:05 - epoch 092 lr: 0.020000
2023-05-31 02:46:08 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.0590
2023-05-31 02:46:08 - train: epoch 0086, iter [00100, 00390], lr: 0.020000, loss: 0.9570
2023-05-31 02:46:09 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 0.4239
2023-05-31 02:46:11 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 1.6020
2023-05-31 02:46:11 - train: epoch 0086, iter [00150, 00390], lr: 0.020000, loss: 0.9770
2023-05-31 02:46:13 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 3.2666
2023-05-31 02:46:14 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 1.6355
2023-05-31 02:46:15 - train: epoch 0086, iter [00200, 00390], lr: 0.020000, loss: 0.9802
2023-05-31 02:46:16 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 0.8552
2023-05-31 02:46:17 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 1.6342
2023-05-31 02:46:18 - train: epoch 0086, iter [00250, 00390], lr: 0.020000, loss: 0.9859
2023-05-31 02:46:19 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 2.1305
2023-05-31 02:46:21 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.9882
2023-05-31 02:46:21 - train: epoch 0086, iter [00300, 00390], lr: 0.020000, loss: 1.0066
2023-05-31 02:46:23 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 0.5714
2023-05-31 02:46:23 - train: epoch 141, train_loss: 1.1645
2023-05-31 02:46:24 - train: epoch 0086, iter [00350, 00390], lr: 0.020000, loss: 1.0141
2023-05-31 02:46:25 - eval: epoch: 141, acc1: 78.810%, acc5: 94.590%, test_loss: 0.8284, per_image_load_time: 0.081ms, per_image_inference_time: 0.053ms
2023-05-31 02:46:25 - until epoch: 141, best_acc1: 79.030%
2023-05-31 02:46:25 - epoch 142 lr: 0.004000
2023-05-31 02:46:25 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 0.5234
2023-05-31 02:46:26 - train: epoch 086, train_loss: 0.9853
2023-05-31 02:46:28 - eval: epoch: 086, acc1: 72.750%, acc5: 91.940%, test_loss: 1.1126, per_image_load_time: 0.072ms, per_image_inference_time: 0.055ms
2023-05-31 02:46:28 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 1.3425
2023-05-31 02:46:28 - until epoch: 086, best_acc1: 75.440%
2023-05-31 02:46:28 - epoch 087 lr: 0.020000
2023-05-31 02:46:29 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 1.3015
2023-05-31 02:46:31 - train: epoch 092, train_loss: 0.8479
2023-05-31 02:46:32 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.0482
2023-05-31 02:46:32 - eval: epoch: 092, acc1: 72.200%, acc5: 92.350%, test_loss: 1.0853, per_image_load_time: 0.066ms, per_image_inference_time: 0.055ms
2023-05-31 02:46:32 - train: epoch 0087, iter [00050, 00390], lr: 0.020000, loss: 0.9406
2023-05-31 02:46:32 - until epoch: 092, best_acc1: 72.920%
2023-05-31 02:46:32 - epoch 093 lr: 0.020000
2023-05-31 02:46:35 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.2230
2023-05-31 02:46:35 - train: epoch 0087, iter [00100, 00390], lr: 0.020000, loss: 0.9784
2023-05-31 02:46:37 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 0.6261
2023-05-31 02:46:38 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 1.7089
2023-05-31 02:46:38 - train: epoch 0087, iter [00150, 00390], lr: 0.020000, loss: 0.9461
2023-05-31 02:46:40 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 0.2998
2023-05-31 02:46:41 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 1.3331
2023-05-31 02:46:42 - train: epoch 0087, iter [00200, 00390], lr: 0.020000, loss: 1.0010
2023-05-31 02:46:43 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 0.4373
2023-05-31 02:46:44 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 1.7745
2023-05-31 02:46:45 - train: epoch 0087, iter [00250, 00390], lr: 0.020000, loss: 0.9875
2023-05-31 02:46:46 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 0.3070
2023-05-31 02:46:48 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 1.4519
2023-05-31 02:46:48 - train: epoch 0087, iter [00300, 00390], lr: 0.020000, loss: 1.0435
2023-05-31 02:46:50 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 1.2036
2023-05-31 02:46:50 - train: epoch 142, train_loss: 1.2236
2023-05-31 02:46:51 - train: epoch 0087, iter [00350, 00390], lr: 0.020000, loss: 0.9609
2023-05-31 02:46:52 - eval: epoch: 142, acc1: 78.480%, acc5: 94.750%, test_loss: 0.8246, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-05-31 02:46:52 - until epoch: 142, best_acc1: 79.030%
2023-05-31 02:46:52 - epoch 143 lr: 0.004000
2023-05-31 02:46:52 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 1.0606
2023-05-31 02:46:53 - train: epoch 087, train_loss: 0.9856
2023-05-31 02:46:55 - eval: epoch: 087, acc1: 72.770%, acc5: 91.610%, test_loss: 1.1203, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-05-31 02:46:55 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 0.4649
2023-05-31 02:46:55 - until epoch: 087, best_acc1: 75.440%
2023-05-31 02:46:55 - epoch 088 lr: 0.020000
2023-05-31 02:46:56 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 2.0047
2023-05-31 02:46:58 - train: epoch 093, train_loss: 0.8154
2023-05-31 02:46:59 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 1.0360
2023-05-31 02:46:59 - train: epoch 0088, iter [00050, 00390], lr: 0.020000, loss: 0.9258
2023-05-31 02:46:59 - eval: epoch: 093, acc1: 71.460%, acc5: 92.020%, test_loss: 1.0963, per_image_load_time: 0.080ms, per_image_inference_time: 0.053ms
2023-05-31 02:47:00 - until epoch: 093, best_acc1: 72.920%
2023-05-31 02:47:00 - epoch 094 lr: 0.020000
2023-05-31 02:47:02 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 1.6153
2023-05-31 02:47:02 - train: epoch 0088, iter [00100, 00390], lr: 0.020000, loss: 1.0085
2023-05-31 02:47:04 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 0.1958
2023-05-31 02:47:05 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 1.3830
2023-05-31 02:47:05 - train: epoch 0088, iter [00150, 00390], lr: 0.020000, loss: 1.0327
2023-05-31 02:47:07 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 0.8441
2023-05-31 02:47:08 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 1.5221
2023-05-31 02:47:09 - train: epoch 0088, iter [00200, 00390], lr: 0.020000, loss: 0.9566
2023-05-31 02:47:10 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 0.2162
2023-05-31 02:47:12 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 1.6224
2023-05-31 02:47:12 - train: epoch 0088, iter [00250, 00390], lr: 0.020000, loss: 0.9381
2023-05-31 02:47:13 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 0.6151
2023-05-31 02:47:15 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.8891
2023-05-31 02:47:15 - train: epoch 0088, iter [00300, 00390], lr: 0.020000, loss: 0.9651
2023-05-31 02:47:17 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 0.2729
2023-05-31 02:47:18 - train: epoch 143, train_loss: 1.1946
2023-05-31 02:47:18 - train: epoch 0088, iter [00350, 00390], lr: 0.020000, loss: 1.0583
2023-05-31 02:47:19 - eval: epoch: 143, acc1: 78.830%, acc5: 94.750%, test_loss: 0.8203, per_image_load_time: 0.086ms, per_image_inference_time: 0.054ms
2023-05-31 02:47:20 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 0.9639
2023-05-31 02:47:20 - until epoch: 143, best_acc1: 79.030%
2023-05-31 02:47:20 - epoch 144 lr: 0.004000
2023-05-31 02:47:21 - train: epoch 088, train_loss: 0.9844
2023-05-31 02:47:22 - eval: epoch: 088, acc1: 70.690%, acc5: 90.520%, test_loss: 1.2101, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-05-31 02:47:22 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 0.7473
2023-05-31 02:47:22 - until epoch: 088, best_acc1: 75.440%
2023-05-31 02:47:22 - epoch 089 lr: 0.020000
2023-05-31 02:47:23 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.1766
2023-05-31 02:47:25 - train: epoch 094, train_loss: 0.8227
2023-05-31 02:47:26 - train: epoch 0089, iter [00050, 00390], lr: 0.020000, loss: 0.9672
2023-05-31 02:47:26 - eval: epoch: 094, acc1: 70.860%, acc5: 91.990%, test_loss: 1.1613, per_image_load_time: 0.071ms, per_image_inference_time: 0.052ms
2023-05-31 02:47:26 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 1.2105
2023-05-31 02:47:27 - until epoch: 094, best_acc1: 72.920%
2023-05-31 02:47:27 - epoch 095 lr: 0.020000
2023-05-31 02:47:29 - train: epoch 0089, iter [00100, 00390], lr: 0.020000, loss: 0.9370
2023-05-31 02:47:29 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 1.6550
2023-05-31 02:47:31 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 2.8095
2023-05-31 02:47:32 - train: epoch 0089, iter [00150, 00390], lr: 0.020000, loss: 0.9583
2023-05-31 02:47:32 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 1.9936
2023-05-31 02:47:34 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 0.2761
2023-05-31 02:47:36 - train: epoch 0089, iter [00200, 00390], lr: 0.020000, loss: 0.9444
2023-05-31 02:47:36 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 1.8038
2023-05-31 02:47:37 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 0.2770
2023-05-31 02:47:39 - train: epoch 0089, iter [00250, 00390], lr: 0.020000, loss: 1.0095
2023-05-31 02:47:39 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.2376
2023-05-31 02:47:40 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 0.7987
2023-05-31 02:47:42 - train: epoch 0089, iter [00300, 00390], lr: 0.020000, loss: 0.9659
2023-05-31 02:47:42 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 1.1215
2023-05-31 02:47:44 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 0.6035
2023-05-31 02:47:45 - train: epoch 144, train_loss: 1.2419
2023-05-31 02:47:45 - train: epoch 0089, iter [00350, 00390], lr: 0.020000, loss: 0.9455
2023-05-31 02:47:47 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 0.7568
2023-05-31 02:47:47 - eval: epoch: 144, acc1: 78.340%, acc5: 94.630%, test_loss: 0.8356, per_image_load_time: 0.088ms, per_image_inference_time: 0.058ms
2023-05-31 02:47:47 - until epoch: 144, best_acc1: 79.030%
2023-05-31 02:47:47 - epoch 145 lr: 0.004000
2023-05-31 02:47:48 - train: epoch 089, train_loss: 0.9848
2023-05-31 02:47:49 - eval: epoch: 089, acc1: 72.430%, acc5: 91.710%, test_loss: 1.1479, per_image_load_time: 0.081ms, per_image_inference_time: 0.056ms
2023-05-31 02:47:49 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 0.2335
2023-05-31 02:47:50 - until epoch: 089, best_acc1: 75.440%
2023-05-31 02:47:50 - epoch 090 lr: 0.020000
2023-05-31 02:47:51 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.3573
2023-05-31 02:47:52 - train: epoch 095, train_loss: 0.8399
2023-05-31 02:47:53 - eval: epoch: 095, acc1: 69.720%, acc5: 91.440%, test_loss: 1.2012, per_image_load_time: 0.076ms, per_image_inference_time: 0.059ms
2023-05-31 02:47:53 - train: epoch 0090, iter [00050, 00390], lr: 0.020000, loss: 0.9309
2023-05-31 02:47:54 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 1.0416
2023-05-31 02:47:54 - until epoch: 095, best_acc1: 72.920%
2023-05-31 02:47:54 - epoch 096 lr: 0.020000
2023-05-31 02:47:56 - train: epoch 0090, iter [00100, 00390], lr: 0.020000, loss: 0.9936
2023-05-31 02:47:57 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.8413
2023-05-31 02:47:58 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 0.3089
2023-05-31 02:48:00 - train: epoch 0090, iter [00150, 00390], lr: 0.020000, loss: 0.9433
2023-05-31 02:48:00 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 1.7774
2023-05-31 02:48:01 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 0.3039
2023-05-31 02:48:03 - train: epoch 0090, iter [00200, 00390], lr: 0.020000, loss: 0.9509
2023-05-31 02:48:03 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.3694
2023-05-31 02:48:05 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 0.4407
2023-05-31 02:48:06 - train: epoch 0090, iter [00250, 00390], lr: 0.020000, loss: 0.9802
2023-05-31 02:48:06 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.3912
2023-05-31 02:48:08 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 0.3751
2023-05-31 02:48:09 - train: epoch 0090, iter [00300, 00390], lr: 0.020000, loss: 1.0134
2023-05-31 02:48:10 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.5077
2023-05-31 02:48:11 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 0.7460
2023-05-31 02:48:12 - train: epoch 145, train_loss: 1.1552
2023-05-31 02:48:13 - train: epoch 0090, iter [00350, 00390], lr: 0.020000, loss: 1.0007
2023-05-31 02:48:14 - eval: epoch: 145, acc1: 78.750%, acc5: 94.540%, test_loss: 0.8203, per_image_load_time: 0.081ms, per_image_inference_time: 0.052ms
2023-05-31 02:48:14 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 0.5070
2023-05-31 02:48:14 - until epoch: 145, best_acc1: 79.030%
2023-05-31 02:48:14 - epoch 146 lr: 0.004000
2023-05-31 02:48:15 - train: epoch 090, train_loss: 0.9859
2023-05-31 02:48:17 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 0.4422
2023-05-31 02:48:17 - eval: epoch: 090, acc1: 71.800%, acc5: 91.480%, test_loss: 1.1504, per_image_load_time: 0.083ms, per_image_inference_time: 0.059ms
2023-05-31 02:48:17 - until epoch: 090, best_acc1: 75.440%
2023-05-31 02:48:17 - epoch 091 lr: 0.020000
2023-05-31 02:48:18 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.0855
2023-05-31 02:48:19 - train: epoch 096, train_loss: 0.8106
2023-05-31 02:48:21 - eval: epoch: 096, acc1: 71.160%, acc5: 92.050%, test_loss: 1.1121, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-05-31 02:48:21 - until epoch: 096, best_acc1: 72.920%
2023-05-31 02:48:21 - epoch 097 lr: 0.020000
2023-05-31 02:48:21 - train: epoch 0091, iter [00050, 00390], lr: 0.020000, loss: 0.9634
2023-05-31 02:48:21 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 1.6944
2023-05-31 02:48:24 - train: epoch 0091, iter [00100, 00390], lr: 0.020000, loss: 0.9764
2023-05-31 02:48:24 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 1.6230
2023-05-31 02:48:25 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 0.7539
2023-05-31 02:48:27 - train: epoch 0091, iter [00150, 00390], lr: 0.020000, loss: 0.9549
2023-05-31 02:48:27 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 1.5254
2023-05-31 02:48:28 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 0.1960
2023-05-31 02:48:30 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 1.8244
2023-05-31 02:48:31 - train: epoch 0091, iter [00200, 00390], lr: 0.020000, loss: 0.9248
2023-05-31 02:48:31 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 3.2481
2023-05-31 02:48:34 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 1.0637
2023-05-31 02:48:34 - train: epoch 0091, iter [00250, 00390], lr: 0.020000, loss: 0.9764
2023-05-31 02:48:35 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 0.5850
2023-05-31 02:48:37 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.0518
2023-05-31 02:48:37 - train: epoch 0091, iter [00300, 00390], lr: 0.020000, loss: 0.9945
2023-05-31 02:48:38 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 0.4569
2023-05-31 02:48:40 - train: epoch 146, train_loss: 1.1503
2023-05-31 02:48:40 - train: epoch 0091, iter [00350, 00390], lr: 0.020000, loss: 1.0246
2023-05-31 02:48:41 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 0.3553
2023-05-31 02:48:41 - eval: epoch: 146, acc1: 78.390%, acc5: 94.340%, test_loss: 0.8346, per_image_load_time: 0.085ms, per_image_inference_time: 0.054ms
2023-05-31 02:48:42 - until epoch: 146, best_acc1: 79.030%
2023-05-31 02:48:42 - epoch 147 lr: 0.004000
2023-05-31 02:48:42 - train: epoch 091, train_loss: 0.9801
2023-05-31 02:48:43 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 2.5773
2023-05-31 02:48:44 - eval: epoch: 091, acc1: 71.320%, acc5: 91.250%, test_loss: 1.1690, per_image_load_time: 0.084ms, per_image_inference_time: 0.055ms
2023-05-31 02:48:44 - until epoch: 091, best_acc1: 75.440%
2023-05-31 02:48:44 - epoch 092 lr: 0.020000
2023-05-31 02:48:45 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 1.5826
2023-05-31 02:48:46 - train: epoch 097, train_loss: 0.7482
2023-05-31 02:48:48 - eval: epoch: 097, acc1: 71.050%, acc5: 92.200%, test_loss: 1.1492, per_image_load_time: 0.073ms, per_image_inference_time: 0.057ms
2023-05-31 02:48:48 - until epoch: 097, best_acc1: 72.920%
2023-05-31 02:48:48 - epoch 098 lr: 0.020000
2023-05-31 02:48:48 - train: epoch 0092, iter [00050, 00390], lr: 0.020000, loss: 0.9942
2023-05-31 02:48:48 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 1.7360
2023-05-31 02:48:51 - train: epoch 0092, iter [00100, 00390], lr: 0.020000, loss: 0.9479
2023-05-31 02:48:51 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 1.3066
2023-05-31 02:48:52 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 0.2390
2023-05-31 02:48:54 - train: epoch 0092, iter [00150, 00390], lr: 0.020000, loss: 0.9170
2023-05-31 02:48:55 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 1.5976
2023-05-31 02:48:55 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 0.4908
2023-05-31 02:48:58 - train: epoch 0092, iter [00200, 00390], lr: 0.020000, loss: 0.9815
2023-05-31 02:48:58 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 1.6369
2023-05-31 02:48:58 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 0.3373
2023-05-31 02:49:01 - train: epoch 0092, iter [00250, 00390], lr: 0.020000, loss: 0.9913
2023-05-31 02:49:01 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 1.7023
2023-05-31 02:49:02 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 0.3009
2023-05-31 02:49:04 - train: epoch 0092, iter [00300, 00390], lr: 0.020000, loss: 1.0092
2023-05-31 02:49:04 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 1.6606
2023-05-31 02:49:05 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 0.6223
2023-05-31 02:49:07 - train: epoch 147, train_loss: 1.2011
2023-05-31 02:49:07 - train: epoch 0092, iter [00350, 00390], lr: 0.020000, loss: 1.0148
2023-05-31 02:49:08 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 0.9032
2023-05-31 02:49:09 - eval: epoch: 147, acc1: 78.210%, acc5: 94.260%, test_loss: 0.8344, per_image_load_time: 0.082ms, per_image_inference_time: 0.054ms
2023-05-31 02:49:09 - until epoch: 147, best_acc1: 79.030%
2023-05-31 02:49:09 - epoch 148 lr: 0.004000
2023-05-31 02:49:09 - train: epoch 092, train_loss: 0.9850
2023-05-31 02:49:10 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 0.5086
2023-05-31 02:49:11 - eval: epoch: 092, acc1: 71.110%, acc5: 90.990%, test_loss: 1.1991, per_image_load_time: 0.078ms, per_image_inference_time: 0.055ms
2023-05-31 02:49:11 - until epoch: 092, best_acc1: 75.440%
2023-05-31 02:49:11 - epoch 093 lr: 0.020000
2023-05-31 02:49:12 - train: epoch 098, train_loss: 0.7596
2023-05-31 02:49:13 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 1.6132
2023-05-31 02:49:14 - eval: epoch: 098, acc1: 70.100%, acc5: 91.920%, test_loss: 1.2063, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-05-31 02:49:14 - until epoch: 098, best_acc1: 72.920%
2023-05-31 02:49:14 - epoch 099 lr: 0.020000
2023-05-31 02:49:15 - train: epoch 0093, iter [00050, 00390], lr: 0.020000, loss: 0.9351
2023-05-31 02:49:16 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 1.7409
2023-05-31 02:49:18 - train: epoch 0093, iter [00100, 00390], lr: 0.020000, loss: 0.9812
2023-05-31 02:49:18 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 1.4102
2023-05-31 02:49:19 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.0849
2023-05-31 02:49:21 - train: epoch 0093, iter [00150, 00390], lr: 0.020000, loss: 0.9923
2023-05-31 02:49:22 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 0.2400
2023-05-31 02:49:22 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 1.1795
2023-05-31 02:49:25 - train: epoch 0093, iter [00200, 00390], lr: 0.020000, loss: 0.9444
2023-05-31 02:49:25 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 0.7480
2023-05-31 02:49:25 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 1.7189
2023-05-31 02:49:28 - train: epoch 0093, iter [00250, 00390], lr: 0.020000, loss: 1.0117
2023-05-31 02:49:28 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 0.3261
2023-05-31 02:49:29 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 1.4171
2023-05-31 02:49:31 - train: epoch 0093, iter [00300, 00390], lr: 0.020000, loss: 1.0118
2023-05-31 02:49:31 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 1.1988
2023-05-31 02:49:32 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 1.2012
2023-05-31 02:49:34 - train: epoch 0093, iter [00350, 00390], lr: 0.020000, loss: 0.9560
2023-05-31 02:49:35 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 0.2561
2023-05-31 02:49:35 - train: epoch 148, train_loss: 1.1856
2023-05-31 02:49:36 - eval: epoch: 148, acc1: 78.600%, acc5: 94.550%, test_loss: 0.8296, per_image_load_time: 0.076ms, per_image_inference_time: 0.053ms
2023-05-31 02:49:37 - until epoch: 148, best_acc1: 79.030%
2023-05-31 02:49:37 - epoch 149 lr: 0.004000
2023-05-31 02:49:37 - train: epoch 093, train_loss: 0.9837
2023-05-31 02:49:37 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 1.4835
2023-05-31 02:49:38 - eval: epoch: 093, acc1: 70.310%, acc5: 90.650%, test_loss: 1.2312, per_image_load_time: 0.068ms, per_image_inference_time: 0.062ms
2023-05-31 02:49:39 - until epoch: 093, best_acc1: 75.440%
2023-05-31 02:49:39 - epoch 094 lr: 0.020000
2023-05-31 02:49:39 - train: epoch 099, train_loss: 0.7876
2023-05-31 02:49:40 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 1.4696
2023-05-31 02:49:41 - eval: epoch: 099, acc1: 70.190%, acc5: 91.760%, test_loss: 1.2127, per_image_load_time: 0.077ms, per_image_inference_time: 0.062ms
2023-05-31 02:49:41 - until epoch: 099, best_acc1: 72.920%
2023-05-31 02:49:41 - epoch 100 lr: 0.020000
2023-05-31 02:49:42 - train: epoch 0094, iter [00050, 00390], lr: 0.020000, loss: 0.9987
2023-05-31 02:49:43 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 1.7376
2023-05-31 02:49:45 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 0.3293
2023-05-31 02:49:46 - train: epoch 0094, iter [00100, 00390], lr: 0.020000, loss: 0.9823
2023-05-31 02:49:46 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.8742
2023-05-31 02:49:48 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 0.1804
2023-05-31 02:49:49 - train: epoch 0094, iter [00150, 00390], lr: 0.020000, loss: 0.9604
2023-05-31 02:49:50 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 1.4909
2023-05-31 02:49:52 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 1.6854
2023-05-31 02:49:52 - train: epoch 0094, iter [00200, 00390], lr: 0.020000, loss: 0.9719
2023-05-31 02:49:53 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.7169
2023-05-31 02:49:55 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 2.2994
2023-05-31 02:49:55 - train: epoch 0094, iter [00250, 00390], lr: 0.020000, loss: 0.9975
2023-05-31 02:49:56 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 1.1128
2023-05-31 02:49:58 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 0.8969
2023-05-31 02:49:59 - train: epoch 0094, iter [00300, 00390], lr: 0.020000, loss: 1.0061
2023-05-31 02:50:00 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 1.7672
2023-05-31 02:50:01 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 1.9062
2023-05-31 02:50:02 - train: epoch 0094, iter [00350, 00390], lr: 0.020000, loss: 0.9900
2023-05-31 02:50:02 - train: epoch 149, train_loss: 1.1689
2023-05-31 02:50:04 - eval: epoch: 149, acc1: 78.860%, acc5: 94.370%, test_loss: 0.8347, per_image_load_time: 0.083ms, per_image_inference_time: 0.054ms
2023-05-31 02:50:04 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 0.4071
2023-05-31 02:50:04 - until epoch: 149, best_acc1: 79.030%
2023-05-31 02:50:04 - epoch 150 lr: 0.004000
2023-05-31 02:50:04 - train: epoch 094, train_loss: 0.9825
2023-05-31 02:50:06 - train: epoch 100, train_loss: 0.8526
2023-05-31 02:50:06 - eval: epoch: 094, acc1: 72.080%, acc5: 91.070%, test_loss: 1.1755, per_image_load_time: 0.066ms, per_image_inference_time: 0.057ms
2023-05-31 02:50:06 - until epoch: 094, best_acc1: 75.440%
2023-05-31 02:50:06 - epoch 095 lr: 0.020000
2023-05-31 02:50:08 - eval: epoch: 100, acc1: 69.950%, acc5: 91.720%, test_loss: 1.1873, per_image_load_time: 0.071ms, per_image_inference_time: 0.057ms
2023-05-31 02:50:08 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.5625
2023-05-31 02:50:08 - until epoch: 100, best_acc1: 72.920%
2023-05-31 02:50:08 - epoch 101 lr: 0.020000
2023-05-31 02:50:10 - train: epoch 0095, iter [00050, 00390], lr: 0.020000, loss: 0.9165
2023-05-31 02:50:11 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.0750
2023-05-31 02:50:12 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 0.3725
2023-05-31 02:50:13 - train: epoch 0095, iter [00100, 00390], lr: 0.020000, loss: 0.9747
2023-05-31 02:50:14 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.5966
2023-05-31 02:50:15 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 1.6430
2023-05-31 02:50:16 - train: epoch 0095, iter [00150, 00390], lr: 0.020000, loss: 0.9554
2023-05-31 02:50:17 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 1.3745
2023-05-31 02:50:19 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 0.3331
2023-05-31 02:50:20 - train: epoch 0095, iter [00200, 00390], lr: 0.020000, loss: 1.0041
2023-05-31 02:50:20 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 1.7208
2023-05-31 02:50:22 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 0.6310
2023-05-31 02:50:23 - train: epoch 0095, iter [00250, 00390], lr: 0.020000, loss: 1.0324
2023-05-31 02:50:23 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 1.8871
2023-05-31 02:50:25 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 0.5328
2023-05-31 02:50:26 - train: epoch 0095, iter [00300, 00390], lr: 0.020000, loss: 0.9503
2023-05-31 02:50:27 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 1.4318
2023-05-31 02:50:29 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 0.5998
2023-05-31 02:50:29 - train: epoch 0095, iter [00350, 00390], lr: 0.020000, loss: 0.9967
2023-05-31 02:50:29 - train: epoch 150, train_loss: 1.1785
2023-05-31 02:50:31 - eval: epoch: 150, acc1: 78.770%, acc5: 94.330%, test_loss: 0.8327, per_image_load_time: 0.090ms, per_image_inference_time: 0.049ms
2023-05-31 02:50:31 - until epoch: 150, best_acc1: 79.030%
2023-05-31 02:50:31 - epoch 151 lr: 0.004000
2023-05-31 02:50:31 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 0.8344
2023-05-31 02:50:32 - train: epoch 095, train_loss: 0.9825
2023-05-31 02:50:33 - eval: epoch: 095, acc1: 71.380%, acc5: 90.870%, test_loss: 1.1839, per_image_load_time: 0.067ms, per_image_inference_time: 0.068ms
2023-05-31 02:50:33 - train: epoch 101, train_loss: 0.7893
2023-05-31 02:50:34 - until epoch: 095, best_acc1: 75.440%
2023-05-31 02:50:34 - epoch 096 lr: 0.020000
2023-05-31 02:50:35 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 1.3937
2023-05-31 02:50:35 - eval: epoch: 101, acc1: 69.710%, acc5: 92.030%, test_loss: 1.1770, per_image_load_time: 0.076ms, per_image_inference_time: 0.066ms
2023-05-31 02:50:35 - until epoch: 101, best_acc1: 72.920%
2023-05-31 02:50:35 - epoch 102 lr: 0.020000
2023-05-31 02:50:37 - train: epoch 0096, iter [00050, 00390], lr: 0.020000, loss: 0.9692
2023-05-31 02:50:38 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 1.5533
2023-05-31 02:50:39 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 0.6804
2023-05-31 02:50:41 - train: epoch 0096, iter [00100, 00390], lr: 0.020000, loss: 0.9536
2023-05-31 02:50:41 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 1.6045
2023-05-31 02:50:43 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 0.4421
2023-05-31 02:50:44 - train: epoch 0096, iter [00150, 00390], lr: 0.020000, loss: 0.9700
2023-05-31 02:50:44 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 1.6585
2023-05-31 02:50:46 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 0.5538
2023-05-31 02:50:47 - train: epoch 0096, iter [00200, 00390], lr: 0.020000, loss: 1.0057
2023-05-31 02:50:47 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 1.2275
2023-05-31 02:50:49 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 0.2084
2023-05-31 02:50:51 - train: epoch 0096, iter [00250, 00390], lr: 0.020000, loss: 0.9429
2023-05-31 02:50:51 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.1324
2023-05-31 02:50:52 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 0.9431
2023-05-31 02:50:54 - train: epoch 0096, iter [00300, 00390], lr: 0.020000, loss: 1.0032
2023-05-31 02:50:54 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.3633
2023-05-31 02:50:56 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 0.7975
2023-05-31 02:50:57 - train: epoch 151, train_loss: 1.2106
2023-05-31 02:50:57 - train: epoch 0096, iter [00350, 00390], lr: 0.020000, loss: 0.9903
2023-05-31 02:50:58 - eval: epoch: 151, acc1: 78.120%, acc5: 94.550%, test_loss: 0.8459, per_image_load_time: 0.080ms, per_image_inference_time: 0.054ms
2023-05-31 02:50:59 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 0.3700
2023-05-31 02:50:59 - until epoch: 151, best_acc1: 79.030%
2023-05-31 02:50:59 - epoch 152 lr: 0.004000
2023-05-31 02:50:59 - train: epoch 096, train_loss: 0.9785
2023-05-31 02:51:01 - train: epoch 102, train_loss: 0.8795
2023-05-31 02:51:01 - eval: epoch: 096, acc1: 71.310%, acc5: 91.020%, test_loss: 1.1790, per_image_load_time: 0.074ms, per_image_inference_time: 0.052ms
2023-05-31 02:51:01 - until epoch: 096, best_acc1: 75.440%
2023-05-31 02:51:01 - epoch 097 lr: 0.020000
2023-05-31 02:51:02 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 1.3275
2023-05-31 02:51:02 - eval: epoch: 102, acc1: 70.480%, acc5: 91.530%, test_loss: 1.1790, per_image_load_time: 0.073ms, per_image_inference_time: 0.061ms
2023-05-31 02:51:03 - until epoch: 102, best_acc1: 72.920%
2023-05-31 02:51:03 - epoch 103 lr: 0.020000
2023-05-31 02:51:05 - train: epoch 0097, iter [00050, 00390], lr: 0.020000, loss: 0.9525
2023-05-31 02:51:05 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.1083
2023-05-31 02:51:07 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 1.2335
2023-05-31 02:51:08 - train: epoch 0097, iter [00100, 00390], lr: 0.020000, loss: 0.8996
2023-05-31 02:51:08 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.0497
2023-05-31 02:51:10 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 0.6475
2023-05-31 02:51:11 - train: epoch 0097, iter [00150, 00390], lr: 0.020000, loss: 0.9283
2023-05-31 02:51:11 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.0573
2023-05-31 02:51:13 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 0.6700
2023-05-31 02:51:14 - train: epoch 0097, iter [00200, 00390], lr: 0.020000, loss: 0.9950
2023-05-31 02:51:15 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.0832
2023-05-31 02:51:17 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 0.8785
2023-05-31 02:51:17 - train: epoch 0097, iter [00250, 00390], lr: 0.020000, loss: 0.9358
2023-05-31 02:51:18 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 1.6927
2023-05-31 02:51:20 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 0.1940
2023-05-31 02:51:21 - train: epoch 0097, iter [00300, 00390], lr: 0.020000, loss: 0.9775
2023-05-31 02:51:21 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 1.3325
2023-05-31 02:51:23 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 1.4776
2023-05-31 02:51:24 - train: epoch 152, train_loss: 1.1622
2023-05-31 02:51:24 - train: epoch 0097, iter [00350, 00390], lr: 0.020000, loss: 1.0430
2023-05-31 02:51:26 - eval: epoch: 152, acc1: 78.580%, acc5: 94.280%, test_loss: 0.8444, per_image_load_time: 0.088ms, per_image_inference_time: 0.059ms
2023-05-31 02:51:26 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 0.3846
2023-05-31 02:51:26 - until epoch: 152, best_acc1: 79.030%
2023-05-31 02:51:26 - epoch 153 lr: 0.004000
2023-05-31 02:51:26 - train: epoch 097, train_loss: 0.9736
2023-05-31 02:51:28 - train: epoch 103, train_loss: 0.7234
2023-05-31 02:51:28 - eval: epoch: 097, acc1: 71.080%, acc5: 90.740%, test_loss: 1.1969, per_image_load_time: 0.073ms, per_image_inference_time: 0.059ms
2023-05-31 02:51:28 - until epoch: 097, best_acc1: 75.440%
2023-05-31 02:51:28 - epoch 098 lr: 0.020000
2023-05-31 02:51:29 - eval: epoch: 103, acc1: 71.350%, acc5: 92.350%, test_loss: 1.1340, per_image_load_time: 0.074ms, per_image_inference_time: 0.061ms
2023-05-31 02:51:29 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.4097
2023-05-31 02:51:29 - until epoch: 103, best_acc1: 72.920%
2023-05-31 02:51:29 - epoch 104 lr: 0.020000
2023-05-31 02:51:32 - train: epoch 0098, iter [00050, 00390], lr: 0.020000, loss: 0.9615
2023-05-31 02:51:33 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 1.6980
2023-05-31 02:51:34 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 0.3033
2023-05-31 02:51:35 - train: epoch 0098, iter [00100, 00390], lr: 0.020000, loss: 0.9818
2023-05-31 02:51:36 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 1.9071
2023-05-31 02:51:37 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 0.6124
2023-05-31 02:51:38 - train: epoch 0098, iter [00150, 00390], lr: 0.020000, loss: 0.8982
2023-05-31 02:51:39 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 1.6838
2023-05-31 02:51:40 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 2.3192
2023-05-31 02:51:41 - train: epoch 0098, iter [00200, 00390], lr: 0.020000, loss: 1.0783
2023-05-31 02:51:42 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 1.0825
2023-05-31 02:51:43 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 1.1167
2023-05-31 02:51:45 - train: epoch 0098, iter [00250, 00390], lr: 0.020000, loss: 0.9676
2023-05-31 02:51:46 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 1.6414
2023-05-31 02:51:47 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 0.1983
2023-05-31 02:51:48 - train: epoch 0098, iter [00300, 00390], lr: 0.020000, loss: 1.0460
2023-05-31 02:51:49 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 1.6114
2023-05-31 02:51:50 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 0.6123
2023-05-31 02:51:51 - train: epoch 0098, iter [00350, 00390], lr: 0.020000, loss: 0.9767
2023-05-31 02:51:52 - train: epoch 153, train_loss: 1.1806
2023-05-31 02:51:53 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 0.4826
2023-05-31 02:51:53 - eval: epoch: 153, acc1: 78.650%, acc5: 94.520%, test_loss: 0.8232, per_image_load_time: 0.090ms, per_image_inference_time: 0.056ms
2023-05-31 02:51:54 - train: epoch 098, train_loss: 0.9700
2023-05-31 02:51:54 - until epoch: 153, best_acc1: 79.030%
2023-05-31 02:51:54 - epoch 154 lr: 0.004000
2023-05-31 02:51:54 - train: epoch 104, train_loss: 0.7837
2023-05-31 02:51:55 - eval: epoch: 098, acc1: 71.680%, acc5: 90.780%, test_loss: 1.1824, per_image_load_time: 0.073ms, per_image_inference_time: 0.056ms
2023-05-31 02:51:55 - until epoch: 098, best_acc1: 75.440%
2023-05-31 02:51:55 - epoch 099 lr: 0.020000
2023-05-31 02:51:56 - eval: epoch: 104, acc1: 68.920%, acc5: 91.090%, test_loss: 1.2524, per_image_load_time: 0.086ms, per_image_inference_time: 0.049ms
2023-05-31 02:51:56 - until epoch: 104, best_acc1: 72.920%
2023-05-31 02:51:56 - epoch 105 lr: 0.020000
2023-05-31 02:51:57 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 1.7417
2023-05-31 02:51:59 - train: epoch 0099, iter [00050, 00390], lr: 0.020000, loss: 0.9578
2023-05-31 02:52:00 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 1.6048
2023-05-31 02:52:00 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 0.5215
2023-05-31 02:52:03 - train: epoch 0099, iter [00100, 00390], lr: 0.020000, loss: 0.9346
2023-05-31 02:52:03 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 0.7769
2023-05-31 02:52:04 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 1.2452
2023-05-31 02:52:06 - train: epoch 0099, iter [00150, 00390], lr: 0.020000, loss: 0.9389
2023-05-31 02:52:07 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 0.2576
2023-05-31 02:52:07 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 1.0614
2023-05-31 02:52:09 - train: epoch 0099, iter [00200, 00390], lr: 0.020000, loss: 1.0276
2023-05-31 02:52:10 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 0.3088
2023-05-31 02:52:10 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 1.1403
2023-05-31 02:52:13 - train: epoch 0099, iter [00250, 00390], lr: 0.020000, loss: 0.9467
2023-05-31 02:52:13 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 0.2797
2023-05-31 02:52:13 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 1.1009
2023-05-31 02:52:16 - train: epoch 0099, iter [00300, 00390], lr: 0.020000, loss: 0.9575
2023-05-31 02:52:16 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 0.7112
2023-05-31 02:52:17 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.3487
2023-05-31 02:52:19 - train: epoch 0099, iter [00350, 00390], lr: 0.020000, loss: 0.9902
2023-05-31 02:52:19 - train: epoch 154, train_loss: 1.0606
2023-05-31 02:52:20 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 0.3955
2023-05-31 02:52:21 - eval: epoch: 154, acc1: 78.880%, acc5: 94.530%, test_loss: 0.8156, per_image_load_time: 0.079ms, per_image_inference_time: 0.051ms
2023-05-31 02:52:21 - until epoch: 154, best_acc1: 79.030%
2023-05-31 02:52:21 - epoch 155 lr: 0.004000
2023-05-31 02:52:21 - train: epoch 099, train_loss: 0.9728
2023-05-31 02:52:22 - train: epoch 105, train_loss: 0.7897
2023-05-31 02:52:23 - eval: epoch: 099, acc1: 72.020%, acc5: 91.170%, test_loss: 1.1805, per_image_load_time: 0.087ms, per_image_inference_time: 0.064ms
2023-05-31 02:52:23 - eval: epoch: 105, acc1: 69.830%, acc5: 91.000%, test_loss: 1.2483, per_image_load_time: 0.080ms, per_image_inference_time: 0.061ms
2023-05-31 02:52:24 - until epoch: 105, best_acc1: 72.920%
2023-05-31 02:52:24 - epoch 106 lr: 0.020000
2023-05-31 02:52:24 - until epoch: 099, best_acc1: 75.440%
2023-05-31 02:52:24 - epoch 100 lr: 0.020000
2023-05-31 02:52:24 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 1.8237
2023-05-31 02:52:27 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 1.5471
2023-05-31 02:52:28 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 1.3600
2023-05-31 02:52:28 - train: epoch 0100, iter [00050, 00390], lr: 0.020000, loss: 0.9458
2023-05-31 02:52:30 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 1.6493
2023-05-31 02:52:31 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 0.2138
2023-05-31 02:52:31 - train: epoch 0100, iter [00100, 00390], lr: 0.020000, loss: 0.9175
2023-05-31 02:52:34 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 1.4549
2023-05-31 02:52:34 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 1.9779
2023-05-31 02:52:35 - train: epoch 0100, iter [00150, 00390], lr: 0.020000, loss: 0.9471
2023-05-31 02:52:37 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 1.3613
2023-05-31 02:52:38 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 0.3895
2023-05-31 02:52:38 - train: epoch 0100, iter [00200, 00390], lr: 0.020000, loss: 1.0637
2023-05-31 02:52:40 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.5974
2023-05-31 02:52:41 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 0.5195
2023-05-31 02:52:41 - train: epoch 0100, iter [00250, 00390], lr: 0.020000, loss: 0.9313
2023-05-31 02:52:43 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 1.6425
2023-05-31 02:52:44 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 0.5954
2023-05-31 02:52:44 - train: epoch 0100, iter [00300, 00390], lr: 0.020000, loss: 0.9944
2023-05-31 02:52:46 - train: epoch 155, train_loss: 1.1634
2023-05-31 02:52:47 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 0.5499
2023-05-31 02:52:47 - train: epoch 0100, iter [00350, 00390], lr: 0.020000, loss: 1.0477
2023-05-31 02:52:48 - eval: epoch: 155, acc1: 78.220%, acc5: 94.410%, test_loss: 0.8467, per_image_load_time: 0.076ms, per_image_inference_time: 0.057ms
2023-05-31 02:52:48 - until epoch: 155, best_acc1: 79.030%
2023-05-31 02:52:48 - epoch 156 lr: 0.004000
2023-05-31 02:52:49 - train: epoch 106, train_loss: 0.8030
2023-05-31 02:52:49 - train: epoch 100, train_loss: 0.9714
2023-05-31 02:52:51 - eval: epoch: 106, acc1: 70.730%, acc5: 92.160%, test_loss: 1.1589, per_image_load_time: 0.069ms, per_image_inference_time: 0.069ms
2023-05-31 02:52:51 - eval: epoch: 100, acc1: 72.270%, acc5: 91.700%, test_loss: 1.1600, per_image_load_time: 0.075ms, per_image_inference_time: 0.063ms
2023-05-31 02:52:51 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 1.3295
2023-05-31 02:52:52 - until epoch: 100, best_acc1: 75.440%
2023-05-31 02:52:52 - epoch 101 lr: 0.020000
2023-05-31 02:52:52 - until epoch: 106, best_acc1: 72.920%
2023-05-31 02:52:52 - epoch 107 lr: 0.020000
2023-05-31 02:52:54 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 1.0918
2023-05-31 02:52:56 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 0.2468
2023-05-31 02:52:56 - train: epoch 0101, iter [00050, 00390], lr: 0.020000, loss: 0.9384
2023-05-31 02:52:57 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 1.3096
2023-05-31 02:52:59 - train: epoch 0101, iter [00100, 00390], lr: 0.020000, loss: 0.8938
2023-05-31 02:52:59 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 0.2438
2023-05-31 02:53:00 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.0514
2023-05-31 02:53:02 - train: epoch 0101, iter [00150, 00390], lr: 0.020000, loss: 1.0194
2023-05-31 02:53:03 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 0.3140
2023-05-31 02:53:03 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.2127
2023-05-31 02:53:06 - train: epoch 0101, iter [00200, 00390], lr: 0.020000, loss: 0.9890
2023-05-31 02:53:06 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 0.5534
2023-05-31 02:53:07 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 1.4818
2023-05-31 02:53:09 - train: epoch 0101, iter [00250, 00390], lr: 0.020000, loss: 0.9916
2023-05-31 02:53:09 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 0.3644
2023-05-31 02:53:10 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 1.4065
2023-05-31 02:53:12 - train: epoch 0101, iter [00300, 00390], lr: 0.020000, loss: 1.0631
2023-05-31 02:53:12 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 0.5529
2023-05-31 02:53:13 - train: epoch 156, train_loss: 1.1027
2023-05-31 02:53:14 - eval: epoch: 156, acc1: 78.810%, acc5: 94.560%, test_loss: 0.8221, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-05-31 02:53:15 - until epoch: 156, best_acc1: 79.030%
2023-05-31 02:53:15 - epoch 157 lr: 0.004000
2023-05-31 02:53:15 - train: epoch 0101, iter [00350, 00390], lr: 0.020000, loss: 0.9556
2023-05-31 02:53:15 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 3.0691
2023-05-31 02:53:17 - train: epoch 101, train_loss: 0.9765
2023-05-31 02:53:18 - train: epoch 107, train_loss: 0.7373
2023-05-31 02:53:18 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 1.6627
2023-05-31 02:53:19 - eval: epoch: 101, acc1: 71.860%, acc5: 91.130%, test_loss: 1.1707, per_image_load_time: 0.070ms, per_image_inference_time: 0.059ms
2023-05-31 02:53:19 - until epoch: 101, best_acc1: 75.440%
2023-05-31 02:53:19 - epoch 102 lr: 0.020000
2023-05-31 02:53:19 - eval: epoch: 107, acc1: 72.370%, acc5: 92.390%, test_loss: 1.1035, per_image_load_time: 0.076ms, per_image_inference_time: 0.054ms
2023-05-31 02:53:19 - until epoch: 107, best_acc1: 72.920%
2023-05-31 02:53:19 - epoch 108 lr: 0.020000
2023-05-31 02:53:21 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.0627
2023-05-31 02:53:23 - train: epoch 0102, iter [00050, 00390], lr: 0.020000, loss: 0.9373
2023-05-31 02:53:24 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 0.6615
2023-05-31 02:53:24 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 1.6761
2023-05-31 02:53:26 - train: epoch 0102, iter [00100, 00390], lr: 0.020000, loss: 0.9851
2023-05-31 02:53:27 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 0.7147
2023-05-31 02:53:27 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 1.6272
2023-05-31 02:53:30 - train: epoch 0102, iter [00150, 00390], lr: 0.020000, loss: 0.9839
2023-05-31 02:53:30 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 0.5966
2023-05-31 02:53:30 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 1.5447
2023-05-31 02:53:33 - train: epoch 0102, iter [00200, 00390], lr: 0.020000, loss: 0.9135
2023-05-31 02:53:33 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 0.4443
2023-05-31 02:53:34 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.4230
2023-05-31 02:53:36 - train: epoch 0102, iter [00250, 00390], lr: 0.020000, loss: 0.9054
2023-05-31 02:53:37 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 0.7409
2023-05-31 02:53:37 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 1.5411
2023-05-31 02:53:39 - train: epoch 0102, iter [00300, 00390], lr: 0.020000, loss: 0.9417
2023-05-31 02:53:40 - train: epoch 157, train_loss: 1.1419
2023-05-31 02:53:40 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 0.9672
2023-05-31 02:53:41 - eval: epoch: 157, acc1: 78.430%, acc5: 94.590%, test_loss: 0.8423, per_image_load_time: 0.083ms, per_image_inference_time: 0.053ms
2023-05-31 02:53:42 - until epoch: 157, best_acc1: 79.030%
2023-05-31 02:53:42 - epoch 158 lr: 0.004000
2023-05-31 02:53:42 - train: epoch 0102, iter [00350, 00390], lr: 0.020000, loss: 0.9554
2023-05-31 02:53:42 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 0.3343
2023-05-31 02:53:45 - train: epoch 102, train_loss: 0.9704
2023-05-31 02:53:45 - train: epoch 108, train_loss: 0.8079
2023-05-31 02:53:45 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.8964
2023-05-31 02:53:46 - eval: epoch: 102, acc1: 71.810%, acc5: 90.810%, test_loss: 1.1714, per_image_load_time: 0.070ms, per_image_inference_time: 0.059ms
2023-05-31 02:53:47 - eval: epoch: 108, acc1: 69.880%, acc5: 91.220%, test_loss: 1.2366, per_image_load_time: 0.076ms, per_image_inference_time: 0.058ms
2023-05-31 02:53:47 - until epoch: 102, best_acc1: 75.440%
2023-05-31 02:53:47 - epoch 103 lr: 0.020000
2023-05-31 02:53:47 - until epoch: 108, best_acc1: 72.920%
2023-05-31 02:53:47 - epoch 109 lr: 0.020000
2023-05-31 02:53:47 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 1.6561
2023-05-31 02:53:50 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 1.3176
2023-05-31 02:53:51 - train: epoch 0103, iter [00050, 00390], lr: 0.020000, loss: 0.9801
2023-05-31 02:53:51 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 0.6379
2023-05-31 02:53:54 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 1.8414
2023-05-31 02:53:54 - train: epoch 0103, iter [00100, 00390], lr: 0.020000, loss: 0.9778
2023-05-31 02:53:54 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 0.2070
2023-05-31 02:53:57 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 1.4449
2023-05-31 02:53:57 - train: epoch 0103, iter [00150, 00390], lr: 0.020000, loss: 0.9279
2023-05-31 02:53:57 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 0.6684
2023-05-31 02:54:00 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 1.2025
2023-05-31 02:54:01 - train: epoch 0103, iter [00200, 00390], lr: 0.020000, loss: 0.9785
2023-05-31 02:54:01 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 0.4860
2023-05-31 02:54:03 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 1.7953
2023-05-31 02:54:04 - train: epoch 0103, iter [00250, 00390], lr: 0.020000, loss: 1.0137
2023-05-31 02:54:04 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 1.0622
2023-05-31 02:54:06 - train: epoch 158, train_loss: 1.1903
2023-05-31 02:54:07 - train: epoch 0103, iter [00300, 00390], lr: 0.020000, loss: 1.0338
2023-05-31 02:54:07 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 0.2313
2023-05-31 02:54:08 - eval: epoch: 158, acc1: 78.170%, acc5: 94.250%, test_loss: 0.8470, per_image_load_time: 0.098ms, per_image_inference_time: 0.056ms
2023-05-31 02:54:08 - until epoch: 158, best_acc1: 79.030%
2023-05-31 02:54:08 - epoch 159 lr: 0.004000
2023-05-31 02:54:10 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 1.0561
2023-05-31 02:54:10 - train: epoch 0103, iter [00350, 00390], lr: 0.020000, loss: 0.9598
2023-05-31 02:54:12 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 1.4231
2023-05-31 02:54:12 - train: epoch 109, train_loss: 0.7448
2023-05-31 02:54:13 - train: epoch 103, train_loss: 0.9714
2023-05-31 02:54:14 - eval: epoch: 109, acc1: 70.680%, acc5: 91.690%, test_loss: 1.1757, per_image_load_time: 0.086ms, per_image_inference_time: 0.064ms
2023-05-31 02:54:14 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 1.7285
2023-05-31 02:54:14 - eval: epoch: 103, acc1: 72.180%, acc5: 91.150%, test_loss: 1.1488, per_image_load_time: 0.088ms, per_image_inference_time: 0.061ms
2023-05-31 02:54:15 - until epoch: 109, best_acc1: 72.920%
2023-05-31 02:54:15 - epoch 110 lr: 0.020000
2023-05-31 02:54:15 - until epoch: 103, best_acc1: 75.440%
2023-05-31 02:54:15 - epoch 104 lr: 0.020000
2023-05-31 02:54:16 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.4724
2023-05-31 02:54:18 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 0.3911
2023-05-31 02:54:19 - train: epoch 0104, iter [00050, 00390], lr: 0.020000, loss: 0.9467
2023-05-31 02:54:20 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.2177
2023-05-31 02:54:22 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 2.3412
2023-05-31 02:54:23 - train: epoch 0104, iter [00100, 00390], lr: 0.020000, loss: 0.9449
2023-05-31 02:54:23 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 1.7278
2023-05-31 02:54:25 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 0.8440
2023-05-31 02:54:26 - train: epoch 0104, iter [00150, 00390], lr: 0.020000, loss: 1.0065
2023-05-31 02:54:26 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 1.6184
2023-05-31 02:54:28 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 0.3045
2023-05-31 02:54:29 - train: epoch 0104, iter [00200, 00390], lr: 0.020000, loss: 0.9536
2023-05-31 02:54:29 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.9544
2023-05-31 02:54:31 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 1.3976
2023-05-31 02:54:32 - train: epoch 159, train_loss: 1.1543
2023-05-31 02:54:32 - train: epoch 0104, iter [00250, 00390], lr: 0.020000, loss: 0.9454
2023-05-31 02:54:34 - eval: epoch: 159, acc1: 78.440%, acc5: 94.290%, test_loss: 0.8418, per_image_load_time: 0.079ms, per_image_inference_time: 0.053ms
2023-05-31 02:54:34 - until epoch: 159, best_acc1: 79.030%
2023-05-31 02:54:34 - epoch 160 lr: 0.004000
2023-05-31 02:54:34 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 1.6548
2023-05-31 02:54:35 - train: epoch 0104, iter [00300, 00390], lr: 0.020000, loss: 1.0173
2023-05-31 02:54:37 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 0.4495
2023-05-31 02:54:38 - train: epoch 0104, iter [00350, 00390], lr: 0.020000, loss: 1.0238
2023-05-31 02:54:38 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 1.6631
2023-05-31 02:54:40 - train: epoch 110, train_loss: 0.7797
2023-05-31 02:54:41 - train: epoch 104, train_loss: 0.9705
2023-05-31 02:54:41 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 1.4315
2023-05-31 02:54:41 - eval: epoch: 110, acc1: 70.370%, acc5: 92.360%, test_loss: 1.1571, per_image_load_time: 0.068ms, per_image_inference_time: 0.053ms
2023-05-31 02:54:42 - until epoch: 110, best_acc1: 72.920%
2023-05-31 02:54:42 - epoch 111 lr: 0.020000
2023-05-31 02:54:42 - eval: epoch: 104, acc1: 71.170%, acc5: 90.800%, test_loss: 1.1947, per_image_load_time: 0.067ms, per_image_inference_time: 0.050ms
2023-05-31 02:54:43 - until epoch: 104, best_acc1: 75.440%
2023-05-31 02:54:43 - epoch 105 lr: 0.020000
2023-05-31 02:54:44 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 1.5070
2023-05-31 02:54:45 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 0.1969
2023-05-31 02:54:47 - train: epoch 0105, iter [00050, 00390], lr: 0.020000, loss: 0.9765
2023-05-31 02:54:47 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 1.4839
2023-05-31 02:54:49 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 0.2412
2023-05-31 02:54:50 - train: epoch 0105, iter [00100, 00390], lr: 0.020000, loss: 0.9421
2023-05-31 02:54:50 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 1.5180
2023-05-31 02:54:52 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 1.4580
2023-05-31 02:54:53 - train: epoch 0105, iter [00150, 00390], lr: 0.020000, loss: 0.9533
2023-05-31 02:54:53 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 1.2812
2023-05-31 02:54:55 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 0.2475
2023-05-31 02:54:56 - train: epoch 0105, iter [00200, 00390], lr: 0.020000, loss: 0.9484
2023-05-31 02:54:57 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.8515
2023-05-31 02:54:58 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 0.3582
2023-05-31 02:54:59 - train: epoch 160, train_loss: 1.1775
2023-05-31 02:55:00 - train: epoch 0105, iter [00250, 00390], lr: 0.020000, loss: 0.9669
2023-05-31 02:55:01 - eval: epoch: 160, acc1: 78.430%, acc5: 94.210%, test_loss: 0.8573, per_image_load_time: 0.090ms, per_image_inference_time: 0.054ms
2023-05-31 02:55:01 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 0.2696
2023-05-31 02:55:01 - until epoch: 160, best_acc1: 79.030%
2023-05-31 02:55:01 - epoch 161 lr: 0.000800
2023-05-31 02:55:02 - train: epoch 0105, iter [00300, 00390], lr: 0.020000, loss: 0.9189
2023-05-31 02:55:04 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 1.1631
2023-05-31 02:55:05 - train: epoch 0105, iter [00350, 00390], lr: 0.020000, loss: 1.0124
2023-05-31 02:55:06 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 1.4208
2023-05-31 02:55:07 - train: epoch 111, train_loss: 0.8348
2023-05-31 02:55:08 - train: epoch 105, train_loss: 0.9706
2023-05-31 02:55:08 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.0823
2023-05-31 02:55:08 - eval: epoch: 111, acc1: 70.570%, acc5: 91.820%, test_loss: 1.1468, per_image_load_time: 0.061ms, per_image_inference_time: 0.056ms
2023-05-31 02:55:09 - until epoch: 111, best_acc1: 72.920%
2023-05-31 02:55:09 - epoch 112 lr: 0.020000
2023-05-31 02:55:09 - eval: epoch: 105, acc1: 71.950%, acc5: 91.030%, test_loss: 1.1800, per_image_load_time: 0.070ms, per_image_inference_time: 0.047ms
2023-05-31 02:55:10 - until epoch: 105, best_acc1: 75.440%
2023-05-31 02:55:10 - epoch 106 lr: 0.020000
2023-05-31 02:55:11 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.3702
2023-05-31 02:55:13 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 0.7010
2023-05-31 02:55:14 - train: epoch 0106, iter [00050, 00390], lr: 0.020000, loss: 0.9287
2023-05-31 02:55:14 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 1.8205
2023-05-31 02:55:16 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 0.2691
2023-05-31 02:55:17 - train: epoch 0106, iter [00100, 00390], lr: 0.020000, loss: 0.9349
2023-05-31 02:55:17 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.5258
2023-05-31 02:55:19 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 0.7641
2023-05-31 02:55:20 - train: epoch 0106, iter [00150, 00390], lr: 0.020000, loss: 0.9568
2023-05-31 02:55:20 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 1.6048
2023-05-31 02:55:22 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 0.5578
2023-05-31 02:55:24 - train: epoch 0106, iter [00200, 00390], lr: 0.020000, loss: 0.9518
2023-05-31 02:55:24 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 1.3744
2023-05-31 02:55:26 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 0.4874
2023-05-31 02:55:26 - train: epoch 161, train_loss: 1.1194
2023-05-31 02:55:27 - train: epoch 0106, iter [00250, 00390], lr: 0.020000, loss: 1.0358
2023-05-31 02:55:28 - eval: epoch: 161, acc1: 79.000%, acc5: 94.650%, test_loss: 0.8235, per_image_load_time: 0.079ms, per_image_inference_time: 0.056ms
2023-05-31 02:55:28 - until epoch: 161, best_acc1: 79.030%
2023-05-31 02:55:28 - epoch 162 lr: 0.000800
2023-05-31 02:55:28 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 0.6844
2023-05-31 02:55:29 - train: epoch 0106, iter [00300, 00390], lr: 0.020000, loss: 1.0534
2023-05-31 02:55:32 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 0.2944
2023-05-31 02:55:33 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 1.5332
2023-05-31 02:55:33 - train: epoch 0106, iter [00350, 00390], lr: 0.020000, loss: 1.0104
2023-05-31 02:55:34 - train: epoch 112, train_loss: 0.7483
2023-05-31 02:55:35 - train: epoch 106, train_loss: 0.9711
2023-05-31 02:55:35 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 1.0527
2023-05-31 02:55:36 - eval: epoch: 112, acc1: 70.580%, acc5: 91.880%, test_loss: 1.1925, per_image_load_time: 0.069ms, per_image_inference_time: 0.050ms
2023-05-31 02:55:36 - until epoch: 112, best_acc1: 72.920%
2023-05-31 02:55:36 - epoch 113 lr: 0.020000
2023-05-31 02:55:37 - eval: epoch: 106, acc1: 71.850%, acc5: 91.180%, test_loss: 1.1690, per_image_load_time: 0.073ms, per_image_inference_time: 0.050ms
2023-05-31 02:55:37 - until epoch: 106, best_acc1: 75.440%
2023-05-31 02:55:37 - epoch 107 lr: 0.020000
2023-05-31 02:55:38 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 1.4196
2023-05-31 02:55:40 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 0.4290
2023-05-31 02:55:41 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 1.4239
2023-05-31 02:55:41 - train: epoch 0107, iter [00050, 00390], lr: 0.020000, loss: 0.9202
2023-05-31 02:55:43 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 0.5856
2023-05-31 02:55:44 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.1487
2023-05-31 02:55:44 - train: epoch 0107, iter [00100, 00390], lr: 0.020000, loss: 0.9931
2023-05-31 02:55:46 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 1.2315
2023-05-31 02:55:47 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 1.5641
2023-05-31 02:55:48 - train: epoch 0107, iter [00150, 00390], lr: 0.020000, loss: 0.9701
2023-05-31 02:55:50 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 0.5783
2023-05-31 02:55:51 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 1.3369
2023-05-31 02:55:51 - train: epoch 0107, iter [00200, 00390], lr: 0.020000, loss: 1.0073
2023-05-31 02:55:53 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 0.6548
2023-05-31 02:55:53 - train: epoch 162, train_loss: 1.1369
2023-05-31 02:55:54 - train: epoch 0107, iter [00250, 00390], lr: 0.020000, loss: 1.0433
2023-05-31 02:55:55 - eval: epoch: 162, acc1: 79.080%, acc5: 94.710%, test_loss: 0.8165, per_image_load_time: 0.080ms, per_image_inference_time: 0.052ms
2023-05-31 02:55:56 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 0.5617
2023-05-31 02:55:56 - until epoch: 162, best_acc1: 79.080%
2023-05-31 02:55:56 - epoch 163 lr: 0.000800
2023-05-31 02:55:57 - train: epoch 0107, iter [00300, 00390], lr: 0.020000, loss: 0.9222
2023-05-31 02:55:59 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 0.3840
2023-05-31 02:56:00 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 1.1461
2023-05-31 02:56:00 - train: epoch 0107, iter [00350, 00390], lr: 0.020000, loss: 0.9787
2023-05-31 02:56:01 - train: epoch 113, train_loss: 0.7649
2023-05-31 02:56:02 - train: epoch 107, train_loss: 0.9616
2023-05-31 02:56:03 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 1.2329
2023-05-31 02:56:03 - eval: epoch: 113, acc1: 70.930%, acc5: 91.930%, test_loss: 1.1279, per_image_load_time: 0.063ms, per_image_inference_time: 0.051ms
2023-05-31 02:56:03 - until epoch: 113, best_acc1: 72.920%
2023-05-31 02:56:03 - epoch 114 lr: 0.020000
2023-05-31 02:56:04 - eval: epoch: 107, acc1: 71.810%, acc5: 91.120%, test_loss: 1.1662, per_image_load_time: 0.075ms, per_image_inference_time: 0.060ms
2023-05-31 02:56:04 - until epoch: 107, best_acc1: 75.440%
2023-05-31 02:56:04 - epoch 108 lr: 0.020000
2023-05-31 02:56:05 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 1.1397
2023-05-31 02:56:07 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 0.4405
2023-05-31 02:56:08 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 1.3472
2023-05-31 02:56:08 - train: epoch 0108, iter [00050, 00390], lr: 0.020000, loss: 0.9551
2023-05-31 02:56:10 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 1.2007
2023-05-31 02:56:11 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 1.2501
2023-05-31 02:56:12 - train: epoch 0108, iter [00100, 00390], lr: 0.020000, loss: 0.9215
2023-05-31 02:56:13 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 0.2869
2023-05-31 02:56:15 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 1.6189
2023-05-31 02:56:15 - train: epoch 0108, iter [00150, 00390], lr: 0.020000, loss: 0.9836
2023-05-31 02:56:17 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 0.6847
2023-05-31 02:56:18 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 1.8611
2023-05-31 02:56:18 - train: epoch 0108, iter [00200, 00390], lr: 0.020000, loss: 0.9531
2023-05-31 02:56:20 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 0.6517
2023-05-31 02:56:21 - train: epoch 163, train_loss: 1.1052
2023-05-31 02:56:21 - train: epoch 0108, iter [00250, 00390], lr: 0.020000, loss: 1.0003
2023-05-31 02:56:22 - eval: epoch: 163, acc1: 79.140%, acc5: 94.750%, test_loss: 0.8089, per_image_load_time: 0.081ms, per_image_inference_time: 0.052ms
2023-05-31 02:56:23 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 0.4928
2023-05-31 02:56:23 - until epoch: 163, best_acc1: 79.140%
2023-05-31 02:56:23 - epoch 164 lr: 0.000800
2023-05-31 02:56:24 - train: epoch 0108, iter [00300, 00390], lr: 0.020000, loss: 1.0003
2023-05-31 02:56:26 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 1.5246
2023-05-31 02:56:27 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 1.1814
2023-05-31 02:56:27 - train: epoch 0108, iter [00350, 00390], lr: 0.020000, loss: 0.9863
2023-05-31 02:56:28 - train: epoch 114, train_loss: 0.7148
2023-05-31 02:56:30 - eval: epoch: 114, acc1: 71.720%, acc5: 92.150%, test_loss: 1.1371, per_image_load_time: 0.064ms, per_image_inference_time: 0.049ms
2023-05-31 02:56:30 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 1.6854
2023-05-31 02:56:30 - train: epoch 108, train_loss: 0.9666
2023-05-31 02:56:30 - until epoch: 114, best_acc1: 72.920%
2023-05-31 02:56:30 - epoch 115 lr: 0.020000
2023-05-31 02:56:32 - eval: epoch: 108, acc1: 71.780%, acc5: 90.860%, test_loss: 1.1712, per_image_load_time: 0.079ms, per_image_inference_time: 0.061ms
2023-05-31 02:56:32 - until epoch: 108, best_acc1: 75.440%
2023-05-31 02:56:32 - epoch 109 lr: 0.020000
2023-05-31 02:56:32 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 1.6068
2023-05-31 02:56:34 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 0.7929
2023-05-31 02:56:35 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 1.3170
2023-05-31 02:56:36 - train: epoch 0109, iter [00050, 00390], lr: 0.020000, loss: 1.0073
2023-05-31 02:56:37 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 0.5031
2023-05-31 02:56:38 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.3803
2023-05-31 02:56:40 - train: epoch 0109, iter [00100, 00390], lr: 0.020000, loss: 0.9298
2023-05-31 02:56:40 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 0.1826
2023-05-31 02:56:41 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.8345
2023-05-31 02:56:43 - train: epoch 0109, iter [00150, 00390], lr: 0.020000, loss: 0.9304
2023-05-31 02:56:44 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 0.8920
2023-05-31 02:56:45 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 1.5120
2023-05-31 02:56:46 - train: epoch 0109, iter [00200, 00390], lr: 0.020000, loss: 0.9135
2023-05-31 02:56:47 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 1.4874
2023-05-31 02:56:47 - train: epoch 164, train_loss: 1.1306
2023-05-31 02:56:49 - eval: epoch: 164, acc1: 79.060%, acc5: 94.510%, test_loss: 0.8148, per_image_load_time: 0.082ms, per_image_inference_time: 0.055ms
2023-05-31 02:56:49 - train: epoch 0109, iter [00250, 00390], lr: 0.020000, loss: 0.9357
2023-05-31 02:56:49 - until epoch: 164, best_acc1: 79.140%
2023-05-31 02:56:49 - epoch 165 lr: 0.000800
2023-05-31 02:56:49 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 1.2828
2023-05-31 02:56:52 - train: epoch 0109, iter [00300, 00390], lr: 0.020000, loss: 0.9279
2023-05-31 02:56:53 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 1.1515
2023-05-31 02:56:53 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.4000
2023-05-31 02:56:55 - train: epoch 115, train_loss: 0.8738
2023-05-31 02:56:55 - train: epoch 0109, iter [00350, 00390], lr: 0.020000, loss: 1.0045
2023-05-31 02:56:57 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.3024
2023-05-31 02:56:57 - eval: epoch: 115, acc1: 69.970%, acc5: 91.470%, test_loss: 1.2512, per_image_load_time: 0.064ms, per_image_inference_time: 0.051ms
2023-05-31 02:56:57 - until epoch: 115, best_acc1: 72.920%
2023-05-31 02:56:57 - epoch 116 lr: 0.020000
2023-05-31 02:56:57 - train: epoch 109, train_loss: 0.9700
2023-05-31 02:56:59 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 1.6321
2023-05-31 02:56:59 - eval: epoch: 109, acc1: 71.210%, acc5: 90.260%, test_loss: 1.2123, per_image_load_time: 0.082ms, per_image_inference_time: 0.053ms
2023-05-31 02:56:59 - until epoch: 109, best_acc1: 75.440%
2023-05-31 02:56:59 - epoch 110 lr: 0.020000
2023-05-31 02:57:01 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 1.9886
2023-05-31 02:57:02 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 1.2795
2023-05-31 02:57:03 - train: epoch 0110, iter [00050, 00390], lr: 0.020000, loss: 0.8944
2023-05-31 02:57:04 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 0.7143
2023-05-31 02:57:05 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 1.5460
2023-05-31 02:57:07 - train: epoch 0110, iter [00100, 00390], lr: 0.020000, loss: 0.9358
2023-05-31 02:57:07 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 0.2538
2023-05-31 02:57:08 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.0412
2023-05-31 02:57:10 - train: epoch 0110, iter [00150, 00390], lr: 0.020000, loss: 0.9028
2023-05-31 02:57:11 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 0.3499
2023-05-31 02:57:12 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.7338
2023-05-31 02:57:13 - train: epoch 0110, iter [00200, 00390], lr: 0.020000, loss: 0.9914
2023-05-31 02:57:14 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 2.1518
2023-05-31 02:57:14 - train: epoch 165, train_loss: 1.1219
2023-05-31 02:57:16 - eval: epoch: 165, acc1: 78.990%, acc5: 94.600%, test_loss: 0.8216, per_image_load_time: 0.081ms, per_image_inference_time: 0.053ms
2023-05-31 02:57:16 - until epoch: 165, best_acc1: 79.140%
2023-05-31 02:57:16 - epoch 166 lr: 0.000800
2023-05-31 02:57:16 - train: epoch 0110, iter [00250, 00390], lr: 0.020000, loss: 0.9708
2023-05-31 02:57:17 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 0.6564
2023-05-31 02:57:19 - train: epoch 0110, iter [00300, 00390], lr: 0.020000, loss: 0.9995
2023-05-31 02:57:20 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 0.7259
2023-05-31 02:57:20 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 1.3435
2023-05-31 02:57:22 - train: epoch 0110, iter [00350, 00390], lr: 0.020000, loss: 0.9749
2023-05-31 02:57:23 - train: epoch 116, train_loss: 0.8071
2023-05-31 02:57:24 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 1.5451
2023-05-31 02:57:24 - eval: epoch: 116, acc1: 70.720%, acc5: 91.960%, test_loss: 1.1857, per_image_load_time: 0.061ms, per_image_inference_time: 0.052ms
2023-05-31 02:57:24 - until epoch: 116, best_acc1: 72.920%
2023-05-31 02:57:24 - epoch 117 lr: 0.020000
2023-05-31 02:57:25 - train: epoch 110, train_loss: 0.9614
2023-05-31 02:57:26 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 1.5899
2023-05-31 02:57:26 - eval: epoch: 110, acc1: 72.240%, acc5: 90.880%, test_loss: 1.1627, per_image_load_time: 0.077ms, per_image_inference_time: 0.055ms
2023-05-31 02:57:27 - until epoch: 110, best_acc1: 75.440%
2023-05-31 02:57:27 - epoch 111 lr: 0.020000
2023-05-31 02:57:28 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 0.5256
2023-05-31 02:57:29 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 1.3395
2023-05-31 02:57:31 - train: epoch 0111, iter [00050, 00390], lr: 0.020000, loss: 0.9412
2023-05-31 02:57:31 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 0.2742
2023-05-31 02:57:32 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 1.5763
2023-05-31 02:57:34 - train: epoch 0111, iter [00100, 00390], lr: 0.020000, loss: 0.9352
2023-05-31 02:57:35 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 0.3453
2023-05-31 02:57:36 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 1.4351
2023-05-31 02:57:37 - train: epoch 0111, iter [00150, 00390], lr: 0.020000, loss: 0.9599
2023-05-31 02:57:38 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 0.6078
2023-05-31 02:57:39 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 1.5236
2023-05-31 02:57:41 - train: epoch 0111, iter [00200, 00390], lr: 0.020000, loss: 0.9875
2023-05-31 02:57:41 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 1.7139
2023-05-31 02:57:42 - train: epoch 166, train_loss: 1.0619
2023-05-31 02:57:43 - eval: epoch: 166, acc1: 79.260%, acc5: 94.520%, test_loss: 0.8151, per_image_load_time: 0.076ms, per_image_inference_time: 0.054ms
2023-05-31 02:57:44 - train: epoch 0111, iter [00250, 00390], lr: 0.020000, loss: 0.9943
2023-05-31 02:57:44 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 0.7186
2023-05-31 02:57:44 - until epoch: 166, best_acc1: 79.260%
2023-05-31 02:57:44 - epoch 167 lr: 0.000800
2023-05-31 02:57:46 - train: epoch 0111, iter [00300, 00390], lr: 0.020000, loss: 0.9794
2023-05-31 02:57:47 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 0.2823
2023-05-31 02:57:48 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.3587
2023-05-31 02:57:50 - train: epoch 117, train_loss: 0.7883
2023-05-31 02:57:50 - train: epoch 0111, iter [00350, 00390], lr: 0.020000, loss: 0.9784
2023-05-31 02:57:51 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 1.4534
2023-05-31 02:57:51 - eval: epoch: 117, acc1: 71.240%, acc5: 92.270%, test_loss: 1.1649, per_image_load_time: 0.075ms, per_image_inference_time: 0.051ms
2023-05-31 02:57:52 - until epoch: 117, best_acc1: 72.920%
2023-05-31 02:57:52 - epoch 118 lr: 0.020000
2023-05-31 02:57:52 - train: epoch 111, train_loss: 0.9642
2023-05-31 02:57:54 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 1.0289
2023-05-31 02:57:54 - eval: epoch: 111, acc1: 71.850%, acc5: 90.900%, test_loss: 1.1804, per_image_load_time: 0.080ms, per_image_inference_time: 0.054ms
2023-05-31 02:57:54 - until epoch: 111, best_acc1: 75.440%
2023-05-31 02:57:54 - epoch 112 lr: 0.020000
2023-05-31 02:57:55 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 0.3560
2023-05-31 02:57:56 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 1.2386
2023-05-31 02:57:58 - train: epoch 0112, iter [00050, 00390], lr: 0.020000, loss: 0.9426
2023-05-31 02:57:58 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 1.2620
2023-05-31 02:58:00 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 1.6070
2023-05-31 02:58:01 - train: epoch 0112, iter [00100, 00390], lr: 0.020000, loss: 0.9426
2023-05-31 02:58:02 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 0.6927
2023-05-31 02:58:03 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.1946
2023-05-31 02:58:05 - train: epoch 0112, iter [00150, 00390], lr: 0.020000, loss: 0.9119
2023-05-31 02:58:05 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 1.3937
2023-05-31 02:58:06 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.0770
2023-05-31 02:58:08 - train: epoch 0112, iter [00200, 00390], lr: 0.020000, loss: 1.0019
2023-05-31 02:58:08 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 0.4550
2023-05-31 02:58:09 - train: epoch 167, train_loss: 1.1134
2023-05-31 02:58:11 - eval: epoch: 167, acc1: 79.110%, acc5: 94.470%, test_loss: 0.8307, per_image_load_time: 0.082ms, per_image_inference_time: 0.054ms
2023-05-31 02:58:11 - until epoch: 167, best_acc1: 79.260%
2023-05-31 02:58:11 - epoch 168 lr: 0.000800
2023-05-31 02:58:11 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 1.0590
2023-05-31 02:58:11 - train: epoch 0112, iter [00250, 00390], lr: 0.020000, loss: 0.9165
2023-05-31 02:58:14 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 1.5140
2023-05-31 02:58:14 - train: epoch 0112, iter [00300, 00390], lr: 0.020000, loss: 1.0614
2023-05-31 02:58:15 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 1.5725
2023-05-31 02:58:17 - train: epoch 118, train_loss: 0.7755
2023-05-31 02:58:17 - train: epoch 0112, iter [00350, 00390], lr: 0.020000, loss: 0.9745
2023-05-31 02:58:18 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 1.6512
2023-05-31 02:58:18 - eval: epoch: 118, acc1: 71.790%, acc5: 92.450%, test_loss: 1.1207, per_image_load_time: 0.069ms, per_image_inference_time: 0.056ms
2023-05-31 02:58:18 - until epoch: 118, best_acc1: 72.920%
2023-05-31 02:58:18 - epoch 119 lr: 0.020000
2023-05-31 02:58:20 - train: epoch 112, train_loss: 0.9656
2023-05-31 02:58:21 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 1.7003
2023-05-31 02:58:21 - eval: epoch: 112, acc1: 72.130%, acc5: 90.840%, test_loss: 1.1813, per_image_load_time: 0.066ms, per_image_inference_time: 0.055ms
2023-05-31 02:58:21 - until epoch: 112, best_acc1: 75.440%
2023-05-31 02:58:21 - epoch 113 lr: 0.020000
2023-05-31 02:58:22 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 0.1833
2023-05-31 02:58:24 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 1.4789
2023-05-31 02:58:25 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 0.3062
2023-05-31 02:58:26 - train: epoch 0113, iter [00050, 00390], lr: 0.020000, loss: 0.9490
2023-05-31 02:58:27 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 1.3042
2023-05-31 02:58:28 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 0.3961
2023-05-31 02:58:29 - train: epoch 0113, iter [00100, 00390], lr: 0.020000, loss: 0.9044
2023-05-31 02:58:30 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.0608
2023-05-31 02:58:32 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 0.2670
2023-05-31 02:58:32 - train: epoch 0113, iter [00150, 00390], lr: 0.020000, loss: 0.8948
2023-05-31 02:58:33 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 1.4346
2023-05-31 02:58:35 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 0.3447
2023-05-31 02:58:35 - train: epoch 0113, iter [00200, 00390], lr: 0.020000, loss: 0.9458
2023-05-31 02:58:36 - train: epoch 168, train_loss: 1.0746
2023-05-31 02:58:38 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 0.4449
2023-05-31 02:58:38 - eval: epoch: 168, acc1: 79.420%, acc5: 94.710%, test_loss: 0.7993, per_image_load_time: 0.081ms, per_image_inference_time: 0.056ms
2023-05-31 02:58:38 - train: epoch 0113, iter [00250, 00390], lr: 0.020000, loss: 0.9680
2023-05-31 02:58:38 - until epoch: 168, best_acc1: 79.420%
2023-05-31 02:58:38 - epoch 169 lr: 0.000800
2023-05-31 02:58:40 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 1.1049
2023-05-31 02:58:41 - train: epoch 0113, iter [00300, 00390], lr: 0.020000, loss: 1.0226
2023-05-31 02:58:43 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.0230
2023-05-31 02:58:43 - train: epoch 119, train_loss: 0.7677
2023-05-31 02:58:44 - train: epoch 0113, iter [00350, 00390], lr: 0.020000, loss: 0.9676
2023-05-31 02:58:45 - eval: epoch: 119, acc1: 71.180%, acc5: 92.080%, test_loss: 1.1650, per_image_load_time: 0.065ms, per_image_inference_time: 0.055ms
2023-05-31 02:58:45 - until epoch: 119, best_acc1: 72.920%
2023-05-31 02:58:45 - epoch 120 lr: 0.020000
2023-05-31 02:58:45 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 1.4901
2023-05-31 02:58:47 - train: epoch 113, train_loss: 0.9640
2023-05-31 02:58:48 - eval: epoch: 113, acc1: 71.120%, acc5: 90.670%, test_loss: 1.2035, per_image_load_time: 0.071ms, per_image_inference_time: 0.054ms
2023-05-31 02:58:48 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 1.5192
2023-05-31 02:58:48 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 1.0493
2023-05-31 02:58:48 - until epoch: 113, best_acc1: 75.440%
2023-05-31 02:58:48 - epoch 114 lr: 0.020000
2023-05-31 02:58:51 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 1.4121
2023-05-31 02:58:51 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 0.4248
2023-05-31 02:58:53 - train: epoch 0114, iter [00050, 00390], lr: 0.020000, loss: 0.8663
2023-05-31 02:58:54 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.2505
2023-05-31 02:58:55 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 0.6491
2023-05-31 02:58:56 - train: epoch 0114, iter [00100, 00390], lr: 0.020000, loss: 0.9254
2023-05-31 02:58:58 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 1.6458
2023-05-31 02:58:58 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 0.3307
2023-05-31 02:58:59 - train: epoch 0114, iter [00150, 00390], lr: 0.020000, loss: 0.9721
2023-05-31 02:59:01 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.9875
2023-05-31 02:59:01 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 2.6296
2023-05-31 02:59:02 - train: epoch 0114, iter [00200, 00390], lr: 0.020000, loss: 0.9665
2023-05-31 02:59:04 - train: epoch 169, train_loss: 1.0905
2023-05-31 02:59:04 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 0.3381
2023-05-31 02:59:05 - train: epoch 0114, iter [00250, 00390], lr: 0.020000, loss: 1.0235
2023-05-31 02:59:06 - eval: epoch: 169, acc1: 79.200%, acc5: 94.560%, test_loss: 0.8210, per_image_load_time: 0.085ms, per_image_inference_time: 0.058ms
2023-05-31 02:59:06 - until epoch: 169, best_acc1: 79.420%
2023-05-31 02:59:06 - epoch 170 lr: 0.000800
2023-05-31 02:59:07 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 1.4099
2023-05-31 02:59:08 - train: epoch 0114, iter [00300, 00390], lr: 0.020000, loss: 0.9820
2023-05-31 02:59:10 - train: epoch 120, train_loss: 0.7345
2023-05-31 02:59:10 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 1.9670
2023-05-31 02:59:11 - train: epoch 0114, iter [00350, 00390], lr: 0.020000, loss: 0.9203
2023-05-31 02:59:12 - eval: epoch: 120, acc1: 69.990%, acc5: 91.340%, test_loss: 1.2467, per_image_load_time: 0.077ms, per_image_inference_time: 0.053ms
2023-05-31 02:59:12 - until epoch: 120, best_acc1: 72.920%
2023-05-31 02:59:12 - epoch 121 lr: 0.004000
2023-05-31 02:59:13 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 1.4785
2023-05-31 02:59:13 - train: epoch 114, train_loss: 0.9620
2023-05-31 02:59:15 - eval: epoch: 114, acc1: 71.980%, acc5: 90.890%, test_loss: 1.1856, per_image_load_time: 0.070ms, per_image_inference_time: 0.056ms
2023-05-31 02:59:15 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 1.2144
2023-05-31 02:59:15 - until epoch: 114, best_acc1: 75.440%
2023-05-31 02:59:15 - epoch 115 lr: 0.020000
2023-05-31 02:59:16 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 0.7123
2023-05-31 02:59:18 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.8452
2023-05-31 02:59:19 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 0.4962
2023-05-31 02:59:20 - train: epoch 0115, iter [00050, 00390], lr: 0.020000, loss: 0.9665
2023-05-31 02:59:22 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 1.3796
2023-05-31 02:59:22 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 0.2423
2023-05-31 02:59:23 - train: epoch 0115, iter [00100, 00390], lr: 0.020000, loss: 0.9371
2023-05-31 02:59:25 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 1.5857
2023-05-31 02:59:25 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 0.5799
2023-05-31 02:59:26 - train: epoch 0115, iter [00150, 00390], lr: 0.020000, loss: 1.0243
2023-05-31 02:59:28 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.9356
2023-05-31 02:59:28 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 0.2234
2023-05-31 02:59:29 - train: epoch 0115, iter [00200, 00390], lr: 0.020000, loss: 0.9380
2023-05-31 02:59:31 - train: epoch 170, train_loss: 1.0936
2023-05-31 02:59:31 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 0.1770
2023-05-31 02:59:32 - train: epoch 0115, iter [00250, 00390], lr: 0.020000, loss: 0.9221
2023-05-31 02:59:32 - eval: epoch: 170, acc1: 79.150%, acc5: 94.670%, test_loss: 0.8178, per_image_load_time: 0.074ms, per_image_inference_time: 0.052ms
2023-05-31 02:59:33 - until epoch: 170, best_acc1: 79.420%
2023-05-31 02:59:33 - epoch 171 lr: 0.000800
2023-05-31 02:59:34 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 0.1794
2023-05-31 02:59:35 - train: epoch 0115, iter [00300, 00390], lr: 0.020000, loss: 0.9281
2023-05-31 02:59:37 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.9094
2023-05-31 02:59:37 - train: epoch 121, train_loss: 0.5527
2023-05-31 02:59:38 - train: epoch 0115, iter [00350, 00390], lr: 0.020000, loss: 0.9434
2023-05-31 02:59:39 - eval: epoch: 121, acc1: 75.270%, acc5: 93.580%, test_loss: 1.0088, per_image_load_time: 0.078ms, per_image_inference_time: 0.056ms
2023-05-31 02:59:39 - until epoch: 121, best_acc1: 75.270%
2023-05-31 02:59:39 - epoch 122 lr: 0.004000
2023-05-31 02:59:39 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 1.3761
2023-05-31 02:59:41 - train: epoch 115, train_loss: 0.9617
2023-05-31 02:59:42 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.5604
2023-05-31 02:59:42 - eval: epoch: 115, acc1: 72.250%, acc5: 91.270%, test_loss: 1.1733, per_image_load_time: 0.083ms, per_image_inference_time: 0.055ms
2023-05-31 02:59:43 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 0.3953
2023-05-31 02:59:43 - until epoch: 115, best_acc1: 75.440%
2023-05-31 02:59:43 - epoch 116 lr: 0.020000
2023-05-31 02:59:45 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.8725
2023-05-31 02:59:46 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 0.3788
2023-05-31 02:59:47 - train: epoch 0116, iter [00050, 00390], lr: 0.020000, loss: 0.9107
2023-05-31 02:59:49 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.0684
2023-05-31 02:59:49 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 0.1242
2023-05-31 02:59:50 - train: epoch 0116, iter [00100, 00390], lr: 0.020000, loss: 0.9099
2023-05-31 02:59:52 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 1.4902
2023-05-31 02:59:52 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 0.8677
2023-05-31 02:59:53 - train: epoch 0116, iter [00150, 00390], lr: 0.020000, loss: 0.9582
2023-05-31 02:59:55 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 1.2332
2023-05-31 02:59:55 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 0.6344
2023-05-31 02:59:57 - train: epoch 0116, iter [00200, 00390], lr: 0.020000, loss: 1.0106
2023-05-31 02:59:58 - train: epoch 171, train_loss: 1.0765
2023-05-31 02:59:58 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 1.3704
2023-05-31 02:59:59 - eval: epoch: 171, acc1: 79.140%, acc5: 94.580%, test_loss: 0.8279, per_image_load_time: 0.079ms, per_image_inference_time: 0.055ms
2023-05-31 03:00:00 - train: epoch 0116, iter [00250, 00390], lr: 0.020000, loss: 0.9536
2023-05-31 03:00:00 - until epoch: 171, best_acc1: 79.420%
2023-05-31 03:00:00 - epoch 172 lr: 0.000800
2023-05-31 03:00:01 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 0.9503
2023-05-31 03:00:02 - train: epoch 0116, iter [00300, 00390], lr: 0.020000, loss: 0.9774
2023-05-31 03:00:04 - train: epoch 122, train_loss: 0.4418
2023-05-31 03:00:04 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 1.1704
2023-05-31 03:00:05 - eval: epoch: 122, acc1: 75.940%, acc5: 93.820%, test_loss: 0.9820, per_image_load_time: 0.068ms, per_image_inference_time: 0.051ms
2023-05-31 03:00:05 - train: epoch 0116, iter [00350, 00390], lr: 0.020000, loss: 0.9683
2023-05-31 03:00:06 - until epoch: 122, best_acc1: 75.940%
2023-05-31 03:00:06 - epoch 123 lr: 0.004000
2023-05-31 03:00:07 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.3663
2023-05-31 03:00:08 - train: epoch 116, train_loss: 0.9725
2023-05-31 03:00:09 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 0.5141
2023-05-31 03:00:09 - eval: epoch: 116, acc1: 72.170%, acc5: 90.590%, test_loss: 1.1697, per_image_load_time: 0.079ms, per_image_inference_time: 0.053ms
2023-05-31 03:00:10 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 1.4471
2023-05-31 03:00:10 - until epoch: 116, best_acc1: 75.440%
2023-05-31 03:00:10 - epoch 117 lr: 0.020000
2023-05-31 03:00:12 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 0.1467
2023-05-31 03:00:12 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 1.3932
2023-05-31 03:00:14 - train: epoch 0117, iter [00050, 00390], lr: 0.020000, loss: 0.9326
2023-05-31 03:00:15 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 0.2802
2023-05-31 03:00:16 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.7698
2023-05-31 03:00:17 - train: epoch 0117, iter [00100, 00390], lr: 0.020000, loss: 0.9918
2023-05-31 03:00:19 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 0.0775
2023-05-31 03:00:19 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 1.4970
2023-05-31 03:00:21 - train: epoch 0117, iter [00150, 00390], lr: 0.020000, loss: 0.9205
2023-05-31 03:00:22 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 0.0675
2023-05-31 03:00:22 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.3630
2023-05-31 03:00:24 - train: epoch 0117, iter [00200, 00390], lr: 0.020000, loss: 1.0710
2023-05-31 03:00:25 - train: epoch 172, train_loss: 1.0244
2023-05-31 03:00:25 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.0587
2023-05-31 03:00:27 - train: epoch 0117, iter [00250, 00390], lr: 0.020000, loss: 0.9694
2023-05-31 03:00:27 - eval: epoch: 172, acc1: 78.950%, acc5: 94.520%, test_loss: 0.8178, per_image_load_time: 0.093ms, per_image_inference_time: 0.053ms
2023-05-31 03:00:27 - until epoch: 172, best_acc1: 79.420%
2023-05-31 03:00:27 - epoch 173 lr: 0.000800
2023-05-31 03:00:28 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 0.4677
2023-05-31 03:00:30 - train: epoch 0117, iter [00300, 00390], lr: 0.020000, loss: 1.0189
2023-05-31 03:00:30 - train: epoch 123, train_loss: 0.4706
2023-05-31 03:00:31 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 1.3141
2023-05-31 03:00:32 - eval: epoch: 123, acc1: 75.480%, acc5: 93.650%, test_loss: 1.0164, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-05-31 03:00:32 - until epoch: 123, best_acc1: 75.940%
2023-05-31 03:00:32 - epoch 124 lr: 0.004000
2023-05-31 03:00:32 - train: epoch 0117, iter [00350, 00390], lr: 0.020000, loss: 0.9733
2023-05-31 03:00:34 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.3489
2023-05-31 03:00:35 - train: epoch 117, train_loss: 0.9758
2023-05-31 03:00:36 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.0441
2023-05-31 03:00:37 - eval: epoch: 117, acc1: 71.190%, acc5: 90.390%, test_loss: 1.2179, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-05-31 03:00:37 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 1.8711
2023-05-31 03:00:37 - until epoch: 117, best_acc1: 75.440%
2023-05-31 03:00:37 - epoch 118 lr: 0.020000
2023-05-31 03:00:39 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 0.1046
2023-05-31 03:00:40 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 1.1886
2023-05-31 03:00:41 - train: epoch 0118, iter [00050, 00390], lr: 0.020000, loss: 0.9975
2023-05-31 03:00:42 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 1.2173
2023-05-31 03:00:43 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 1.4247
2023-05-31 03:00:44 - train: epoch 0118, iter [00100, 00390], lr: 0.020000, loss: 0.9462
2023-05-31 03:00:45 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 0.4654
2023-05-31 03:00:46 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.5403
2023-05-31 03:00:48 - train: epoch 0118, iter [00150, 00390], lr: 0.020000, loss: 0.9379
2023-05-31 03:00:49 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 1.2043
2023-05-31 03:00:50 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 1.5140
2023-05-31 03:00:51 - train: epoch 0118, iter [00200, 00390], lr: 0.020000, loss: 1.0082
2023-05-31 03:00:52 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 0.5040
2023-05-31 03:00:52 - train: epoch 173, train_loss: 1.0373
2023-05-31 03:00:54 - train: epoch 0118, iter [00250, 00390], lr: 0.020000, loss: 0.9990
2023-05-31 03:00:54 - eval: epoch: 173, acc1: 79.150%, acc5: 94.570%, test_loss: 0.8238, per_image_load_time: 0.084ms, per_image_inference_time: 0.052ms
2023-05-31 03:00:54 - until epoch: 173, best_acc1: 79.420%
2023-05-31 03:00:54 - epoch 174 lr: 0.000800
2023-05-31 03:00:55 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 0.1457
2023-05-31 03:00:56 - train: epoch 0118, iter [00300, 00390], lr: 0.020000, loss: 0.9715
2023-05-31 03:00:57 - train: epoch 124, train_loss: 0.4018
2023-05-31 03:00:58 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 1.5743
2023-05-31 03:00:59 - eval: epoch: 124, acc1: 76.470%, acc5: 94.040%, test_loss: 0.9512, per_image_load_time: 0.081ms, per_image_inference_time: 0.054ms
2023-05-31 03:00:59 - train: epoch 0118, iter [00350, 00390], lr: 0.020000, loss: 0.9706
2023-05-31 03:00:59 - until epoch: 124, best_acc1: 76.470%
2023-05-31 03:00:59 - epoch 125 lr: 0.004000
2023-05-31 03:01:01 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 1.5061
2023-05-31 03:01:02 - train: epoch 118, train_loss: 0.9654
2023-05-31 03:01:03 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.0906
2023-05-31 03:01:03 - eval: epoch: 118, acc1: 71.560%, acc5: 90.880%, test_loss: 1.1736, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-05-31 03:01:04 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.6322
2023-05-31 03:01:04 - until epoch: 118, best_acc1: 75.440%
2023-05-31 03:01:04 - epoch 119 lr: 0.020000
2023-05-31 03:01:06 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.0523
2023-05-31 03:01:07 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.3573
2023-05-31 03:01:08 - train: epoch 0119, iter [00050, 00390], lr: 0.020000, loss: 0.9269
2023-05-31 03:01:09 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 0.0448
2023-05-31 03:01:10 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 1.1894
2023-05-31 03:01:11 - train: epoch 0119, iter [00100, 00390], lr: 0.020000, loss: 1.0073
2023-05-31 03:01:12 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 0.1358
2023-05-31 03:01:13 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.0241
2023-05-31 03:01:14 - train: epoch 0119, iter [00150, 00390], lr: 0.020000, loss: 1.0119
2023-05-31 03:01:16 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 0.8681
2023-05-31 03:01:17 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.0646
2023-05-31 03:01:18 - train: epoch 0119, iter [00200, 00390], lr: 0.020000, loss: 0.9464
2023-05-31 03:01:19 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 0.0984
2023-05-31 03:01:19 - train: epoch 174, train_loss: 1.0762
2023-05-31 03:01:21 - train: epoch 0119, iter [00250, 00390], lr: 0.020000, loss: 0.9023
2023-05-31 03:01:21 - eval: epoch: 174, acc1: 79.760%, acc5: 94.700%, test_loss: 0.7963, per_image_load_time: 0.090ms, per_image_inference_time: 0.053ms
2023-05-31 03:01:21 - until epoch: 174, best_acc1: 79.760%
2023-05-31 03:01:21 - epoch 175 lr: 0.000800
2023-05-31 03:01:22 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 0.3926
2023-05-31 03:01:23 - train: epoch 0119, iter [00300, 00390], lr: 0.020000, loss: 0.9650
2023-05-31 03:01:24 - train: epoch 125, train_loss: 0.4197
2023-05-31 03:01:25 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 1.6551
2023-05-31 03:01:26 - eval: epoch: 125, acc1: 75.640%, acc5: 93.920%, test_loss: 0.9956, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-05-31 03:01:26 - until epoch: 125, best_acc1: 76.470%
2023-05-31 03:01:26 - epoch 126 lr: 0.004000
2023-05-31 03:01:26 - train: epoch 0119, iter [00350, 00390], lr: 0.020000, loss: 0.9830
2023-05-31 03:01:28 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 1.5916
2023-05-31 03:01:29 - train: epoch 119, train_loss: 0.9662
2023-05-31 03:01:30 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.0459
2023-05-31 03:01:30 - eval: epoch: 119, acc1: 71.570%, acc5: 90.590%, test_loss: 1.2094, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-05-31 03:01:31 - until epoch: 119, best_acc1: 75.440%
2023-05-31 03:01:31 - epoch 120 lr: 0.020000
2023-05-31 03:01:31 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 1.4947
2023-05-31 03:01:33 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 0.1063
2023-05-31 03:01:34 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.6539
2023-05-31 03:01:35 - train: epoch 0120, iter [00050, 00390], lr: 0.020000, loss: 0.9555
2023-05-31 03:01:36 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 0.7914
2023-05-31 03:01:37 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 1.2013
2023-05-31 03:01:38 - train: epoch 0120, iter [00100, 00390], lr: 0.020000, loss: 0.9675
2023-05-31 03:01:39 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 0.1990
2023-05-31 03:01:41 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 1.3721
2023-05-31 03:01:42 - train: epoch 0120, iter [00150, 00390], lr: 0.020000, loss: 1.0353
2023-05-31 03:01:43 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 0.0877
2023-05-31 03:01:44 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.1887
2023-05-31 03:01:45 - train: epoch 0120, iter [00200, 00390], lr: 0.020000, loss: 0.9469
2023-05-31 03:01:46 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 1.3674
2023-05-31 03:01:47 - train: epoch 175, train_loss: 1.0995
2023-05-31 03:01:48 - train: epoch 0120, iter [00250, 00390], lr: 0.020000, loss: 1.0172
2023-05-31 03:01:48 - eval: epoch: 175, acc1: 79.390%, acc5: 94.580%, test_loss: 0.8142, per_image_load_time: 0.074ms, per_image_inference_time: 0.059ms
2023-05-31 03:01:49 - until epoch: 175, best_acc1: 79.760%
2023-05-31 03:01:49 - epoch 176 lr: 0.000800
2023-05-31 03:01:49 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 0.4496
2023-05-31 03:01:51 - train: epoch 0120, iter [00300, 00390], lr: 0.020000, loss: 1.0536
2023-05-31 03:01:51 - train: epoch 126, train_loss: 0.3983
2023-05-31 03:01:53 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 1.5684
2023-05-31 03:01:53 - eval: epoch: 126, acc1: 76.330%, acc5: 94.170%, test_loss: 0.9577, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-05-31 03:01:53 - until epoch: 126, best_acc1: 76.470%
2023-05-31 03:01:53 - epoch 127 lr: 0.004000
2023-05-31 03:01:53 - train: epoch 0120, iter [00350, 00390], lr: 0.020000, loss: 0.9081
2023-05-31 03:01:55 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 1.5577
2023-05-31 03:01:56 - train: epoch 120, train_loss: 0.9616
2023-05-31 03:01:57 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.0462
2023-05-31 03:01:58 - eval: epoch: 120, acc1: 71.930%, acc5: 91.010%, test_loss: 1.1707, per_image_load_time: 0.078ms, per_image_inference_time: 0.054ms
2023-05-31 03:01:58 - until epoch: 120, best_acc1: 75.440%
2023-05-31 03:01:58 - epoch 121 lr: 0.004000
2023-05-31 03:01:58 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 1.9515
2023-05-31 03:02:00 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 1.0052
2023-05-31 03:02:01 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.5484
2023-05-31 03:02:02 - train: epoch 0121, iter [00050, 00390], lr: 0.004000, loss: 0.8647
2023-05-31 03:02:03 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.0564
2023-05-31 03:02:04 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 1.5218
2023-05-31 03:02:05 - train: epoch 0121, iter [00100, 00390], lr: 0.004000, loss: 0.8634
2023-05-31 03:02:06 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.0333
2023-05-31 03:02:08 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 1.7401
2023-05-31 03:02:08 - train: epoch 0121, iter [00150, 00390], lr: 0.004000, loss: 0.9304
2023-05-31 03:02:10 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.0712
2023-05-31 03:02:11 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 1.2960
2023-05-31 03:02:12 - train: epoch 0121, iter [00200, 00390], lr: 0.004000, loss: 0.8619
2023-05-31 03:02:13 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 0.0545
2023-05-31 03:02:14 - train: epoch 176, train_loss: 1.0969
2023-05-31 03:02:15 - train: epoch 0121, iter [00250, 00390], lr: 0.004000, loss: 0.8725
2023-05-31 03:02:16 - eval: epoch: 176, acc1: 79.640%, acc5: 94.750%, test_loss: 0.7985, per_image_load_time: 0.081ms, per_image_inference_time: 0.056ms
2023-05-31 03:02:16 - until epoch: 176, best_acc1: 79.760%
2023-05-31 03:02:16 - epoch 177 lr: 0.000800
2023-05-31 03:02:16 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 0.0432
2023-05-31 03:02:18 - train: epoch 0121, iter [00300, 00390], lr: 0.004000, loss: 0.8842
2023-05-31 03:02:18 - train: epoch 127, train_loss: 0.4360
2023-05-31 03:02:20 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.9008
2023-05-31 03:02:20 - eval: epoch: 127, acc1: 75.690%, acc5: 94.000%, test_loss: 0.9957, per_image_load_time: 0.071ms, per_image_inference_time: 0.052ms
2023-05-31 03:02:20 - until epoch: 127, best_acc1: 76.470%
2023-05-31 03:02:20 - epoch 128 lr: 0.004000
2023-05-31 03:02:20 - train: epoch 0121, iter [00350, 00390], lr: 0.004000, loss: 0.8947
2023-05-31 03:02:23 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 1.0465
2023-05-31 03:02:23 - train: epoch 121, train_loss: 0.8890
2023-05-31 03:02:24 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 0.7529
2023-05-31 03:02:25 - eval: epoch: 121, acc1: 75.870%, acc5: 92.700%, test_loss: 1.0247, per_image_load_time: 0.066ms, per_image_inference_time: 0.059ms
2023-05-31 03:02:25 - until epoch: 121, best_acc1: 75.870%
2023-05-31 03:02:25 - epoch 122 lr: 0.004000
2023-05-31 03:02:26 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.4374
2023-05-31 03:02:27 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.0475
2023-05-31 03:02:29 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 1.2762
2023-05-31 03:02:29 - train: epoch 0122, iter [00050, 00390], lr: 0.004000, loss: 0.8327
2023-05-31 03:02:30 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 1.8435
2023-05-31 03:02:32 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.3546
2023-05-31 03:02:32 - train: epoch 0122, iter [00100, 00390], lr: 0.004000, loss: 0.8577
2023-05-31 03:02:33 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.1635
2023-05-31 03:02:35 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 1.2597
2023-05-31 03:02:36 - train: epoch 0122, iter [00150, 00390], lr: 0.004000, loss: 0.8616
2023-05-31 03:02:36 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 1.3680
2023-05-31 03:02:39 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.5951
2023-05-31 03:02:39 - train: epoch 0122, iter [00200, 00390], lr: 0.004000, loss: 0.8458
2023-05-31 03:02:40 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 0.5083
2023-05-31 03:02:41 - train: epoch 177, train_loss: 1.0522
2023-05-31 03:02:42 - train: epoch 0122, iter [00250, 00390], lr: 0.004000, loss: 0.8646
2023-05-31 03:02:43 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 0.0897
2023-05-31 03:02:43 - eval: epoch: 177, acc1: 79.530%, acc5: 94.710%, test_loss: 0.7936, per_image_load_time: 0.082ms, per_image_inference_time: 0.054ms
2023-05-31 03:02:43 - until epoch: 177, best_acc1: 79.760%
2023-05-31 03:02:43 - epoch 178 lr: 0.000800
2023-05-31 03:02:45 - train: epoch 0122, iter [00300, 00390], lr: 0.004000, loss: 0.8903
2023-05-31 03:02:45 - train: epoch 128, train_loss: 0.4034
2023-05-31 03:02:47 - eval: epoch: 128, acc1: 76.430%, acc5: 94.340%, test_loss: 0.9600, per_image_load_time: 0.069ms, per_image_inference_time: 0.053ms
2023-05-31 03:02:47 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.0290
2023-05-31 03:02:47 - until epoch: 128, best_acc1: 76.470%
2023-05-31 03:02:47 - epoch 129 lr: 0.004000
2023-05-31 03:02:47 - train: epoch 0122, iter [00350, 00390], lr: 0.004000, loss: 0.8833
2023-05-31 03:02:50 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 1.0330
2023-05-31 03:02:50 - train: epoch 122, train_loss: 0.8590
2023-05-31 03:02:51 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 0.0922
2023-05-31 03:02:52 - eval: epoch: 122, acc1: 76.140%, acc5: 92.700%, test_loss: 1.0224, per_image_load_time: 0.069ms, per_image_inference_time: 0.054ms
2023-05-31 03:02:52 - until epoch: 122, best_acc1: 76.140%
2023-05-31 03:02:52 - epoch 123 lr: 0.004000
2023-05-31 03:02:53 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 1.0958
2023-05-31 03:02:54 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 1.0118
2023-05-31 03:02:56 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.6777
2023-05-31 03:02:56 - train: epoch 0123, iter [00050, 00390], lr: 0.004000, loss: 0.8311
2023-05-31 03:02:57 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 0.8159
2023-05-31 03:02:59 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.0288
2023-05-31 03:02:59 - train: epoch 0123, iter [00100, 00390], lr: 0.004000, loss: 0.8548
2023-05-31 03:03:00 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 1.1957
2023-05-31 03:03:02 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 1.6057
2023-05-31 03:03:03 - train: epoch 0123, iter [00150, 00390], lr: 0.004000, loss: 0.8375
2023-05-31 03:03:04 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 0.2197
2023-05-31 03:03:06 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.0266
2023-05-31 03:03:06 - train: epoch 0123, iter [00200, 00390], lr: 0.004000, loss: 0.8526
2023-05-31 03:03:07 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 0.9598
2023-05-31 03:03:08 - train: epoch 178, train_loss: 1.0216
2023-05-31 03:03:09 - train: epoch 0123, iter [00250, 00390], lr: 0.004000, loss: 0.8317
2023-05-31 03:03:10 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.0283
2023-05-31 03:03:10 - eval: epoch: 178, acc1: 79.580%, acc5: 94.740%, test_loss: 0.8061, per_image_load_time: 0.078ms, per_image_inference_time: 0.056ms
2023-05-31 03:03:10 - until epoch: 178, best_acc1: 79.760%
2023-05-31 03:03:10 - epoch 179 lr: 0.000800
2023-05-31 03:03:12 - train: epoch 0123, iter [00300, 00390], lr: 0.004000, loss: 0.8511
2023-05-31 03:03:12 - train: epoch 129, train_loss: 0.3691
2023-05-31 03:03:14 - eval: epoch: 129, acc1: 75.990%, acc5: 93.880%, test_loss: 1.0159, per_image_load_time: 0.070ms, per_image_inference_time: 0.058ms
2023-05-31 03:03:14 - until epoch: 129, best_acc1: 76.470%
2023-05-31 03:03:14 - epoch 130 lr: 0.004000
2023-05-31 03:03:14 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 1.3512
2023-05-31 03:03:14 - train: epoch 0123, iter [00350, 00390], lr: 0.004000, loss: 0.8161
2023-05-31 03:03:17 - train: epoch 123, train_loss: 0.8470
2023-05-31 03:03:17 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.5274
2023-05-31 03:03:18 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 0.1331
2023-05-31 03:03:18 - eval: epoch: 123, acc1: 76.350%, acc5: 92.860%, test_loss: 1.0244, per_image_load_time: 0.068ms, per_image_inference_time: 0.052ms
2023-05-31 03:03:19 - until epoch: 123, best_acc1: 76.350%
2023-05-31 03:03:19 - epoch 124 lr: 0.004000
2023-05-31 03:03:20 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 1.6428
2023-05-31 03:03:21 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 0.1637
2023-05-31 03:03:23 - train: epoch 0124, iter [00050, 00390], lr: 0.004000, loss: 0.8337
2023-05-31 03:03:23 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 1.3310
2023-05-31 03:03:24 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 0.4834
2023-05-31 03:03:26 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 1.5435
2023-05-31 03:03:26 - train: epoch 0124, iter [00100, 00390], lr: 0.004000, loss: 0.8486
2023-05-31 03:03:27 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 0.0644
2023-05-31 03:03:29 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.0664
2023-05-31 03:03:29 - train: epoch 0124, iter [00150, 00390], lr: 0.004000, loss: 0.8585
2023-05-31 03:03:30 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.0549
2023-05-31 03:03:33 - train: epoch 0124, iter [00200, 00390], lr: 0.004000, loss: 0.8318
2023-05-31 03:03:33 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 1.2950
2023-05-31 03:03:34 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 0.2003
2023-05-31 03:03:35 - train: epoch 179, train_loss: 1.0957
2023-05-31 03:03:36 - train: epoch 0124, iter [00250, 00390], lr: 0.004000, loss: 0.8264
2023-05-31 03:03:37 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 0.2857
2023-05-31 03:03:37 - eval: epoch: 179, acc1: 79.640%, acc5: 94.780%, test_loss: 0.7986, per_image_load_time: 0.077ms, per_image_inference_time: 0.051ms
2023-05-31 03:03:37 - until epoch: 179, best_acc1: 79.760%
2023-05-31 03:03:37 - epoch 180 lr: 0.000800
2023-05-31 03:03:39 - train: epoch 0124, iter [00300, 00390], lr: 0.004000, loss: 0.8318
2023-05-31 03:03:39 - train: epoch 130, train_loss: 0.3648
2023-05-31 03:03:41 - eval: epoch: 130, acc1: 76.170%, acc5: 94.120%, test_loss: 0.9842, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-05-31 03:03:41 - until epoch: 130, best_acc1: 76.470%
2023-05-31 03:03:41 - epoch 131 lr: 0.004000
2023-05-31 03:03:41 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 1.4480
2023-05-31 03:03:41 - train: epoch 0124, iter [00350, 00390], lr: 0.004000, loss: 0.8272
2023-05-31 03:03:44 - train: epoch 124, train_loss: 0.8411
2023-05-31 03:03:44 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.9451
2023-05-31 03:03:45 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 1.4011
2023-05-31 03:03:46 - eval: epoch: 124, acc1: 76.970%, acc5: 92.680%, test_loss: 1.0311, per_image_load_time: 0.070ms, per_image_inference_time: 0.055ms
2023-05-31 03:03:46 - until epoch: 124, best_acc1: 76.970%
2023-05-31 03:03:46 - epoch 125 lr: 0.004000
2023-05-31 03:03:47 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.0330
2023-05-31 03:03:47 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 0.5554
2023-05-31 03:03:50 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.5420
2023-05-31 03:03:50 - train: epoch 0125, iter [00050, 00390], lr: 0.004000, loss: 0.8105
2023-05-31 03:03:51 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 0.2585
2023-05-31 03:03:53 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.0640
2023-05-31 03:03:54 - train: epoch 0125, iter [00100, 00390], lr: 0.004000, loss: 0.8515
2023-05-31 03:03:54 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 0.1630
2023-05-31 03:03:56 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 1.2472
2023-05-31 03:03:57 - train: epoch 0125, iter [00150, 00390], lr: 0.004000, loss: 0.8383
2023-05-31 03:03:57 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 0.4102
2023-05-31 03:04:00 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.4578
2023-05-31 03:04:00 - train: epoch 0125, iter [00200, 00390], lr: 0.004000, loss: 0.8504
2023-05-31 03:04:00 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 0.7115
2023-05-31 03:04:02 - train: epoch 180, train_loss: 1.0743
2023-05-31 03:04:03 - train: epoch 0125, iter [00250, 00390], lr: 0.004000, loss: 0.8156
2023-05-31 03:04:03 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 1.7531
2023-05-31 03:04:04 - eval: epoch: 180, acc1: 79.380%, acc5: 94.650%, test_loss: 0.8260, per_image_load_time: 0.088ms, per_image_inference_time: 0.051ms
2023-05-31 03:04:04 - until epoch: 180, best_acc1: 79.760%
2023-05-31 03:04:04 - epoch 181 lr: 0.000800
2023-05-31 03:04:06 - train: epoch 131, train_loss: 0.3992
2023-05-31 03:04:06 - train: epoch 0125, iter [00300, 00390], lr: 0.004000, loss: 0.8365
2023-05-31 03:04:07 - eval: epoch: 131, acc1: 76.410%, acc5: 93.830%, test_loss: 0.9803, per_image_load_time: 0.068ms, per_image_inference_time: 0.051ms
2023-05-31 03:04:07 - until epoch: 131, best_acc1: 76.470%
2023-05-31 03:04:07 - epoch 132 lr: 0.004000
2023-05-31 03:04:08 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 1.5050
2023-05-31 03:04:09 - train: epoch 0125, iter [00350, 00390], lr: 0.004000, loss: 0.8277
2023-05-31 03:04:11 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 1.4058
2023-05-31 03:04:11 - train: epoch 125, train_loss: 0.8374
2023-05-31 03:04:11 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.0496
2023-05-31 03:04:13 - eval: epoch: 125, acc1: 77.000%, acc5: 92.880%, test_loss: 1.0208, per_image_load_time: 0.073ms, per_image_inference_time: 0.054ms
2023-05-31 03:04:13 - until epoch: 125, best_acc1: 77.000%
2023-05-31 03:04:13 - epoch 126 lr: 0.004000
2023-05-31 03:04:14 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 1.2753
2023-05-31 03:04:14 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 0.8081
2023-05-31 03:04:17 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.5470
2023-05-31 03:04:17 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 0.1563
2023-05-31 03:04:17 - train: epoch 0126, iter [00050, 00390], lr: 0.004000, loss: 0.8346
2023-05-31 03:04:20 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.9094
2023-05-31 03:04:21 - train: epoch 0126, iter [00100, 00390], lr: 0.004000, loss: 0.8398
2023-05-31 03:04:21 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 0.2094
2023-05-31 03:04:24 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 1.5277
2023-05-31 03:04:24 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 1.1473
2023-05-31 03:04:24 - train: epoch 0126, iter [00150, 00390], lr: 0.004000, loss: 0.8281
2023-05-31 03:04:27 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.0673
2023-05-31 03:04:27 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 0.1036
2023-05-31 03:04:27 - train: epoch 0126, iter [00200, 00390], lr: 0.004000, loss: 0.8391
2023-05-31 03:04:30 - train: epoch 181, train_loss: 1.0496
2023-05-31 03:04:30 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.0205
2023-05-31 03:04:30 - train: epoch 0126, iter [00250, 00390], lr: 0.004000, loss: 0.8269
2023-05-31 03:04:31 - eval: epoch: 181, acc1: 79.300%, acc5: 94.540%, test_loss: 0.8157, per_image_load_time: 0.081ms, per_image_inference_time: 0.054ms
2023-05-31 03:04:32 - until epoch: 181, best_acc1: 79.760%
2023-05-31 03:04:32 - epoch 182 lr: 0.000800
2023-05-31 03:04:32 - train: epoch 132, train_loss: 0.4008
2023-05-31 03:04:33 - train: epoch 0126, iter [00300, 00390], lr: 0.004000, loss: 0.8397
2023-05-31 03:04:34 - eval: epoch: 132, acc1: 76.610%, acc5: 94.160%, test_loss: 0.9518, per_image_load_time: 0.073ms, per_image_inference_time: 0.053ms
2023-05-31 03:04:34 - until epoch: 132, best_acc1: 76.610%
2023-05-31 03:04:34 - epoch 133 lr: 0.004000
2023-05-31 03:04:35 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 1.1644
2023-05-31 03:04:36 - train: epoch 0126, iter [00350, 00390], lr: 0.004000, loss: 0.8379
2023-05-31 03:04:38 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.0401
2023-05-31 03:04:38 - train: epoch 126, train_loss: 0.8327
2023-05-31 03:04:39 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 1.2295
2023-05-31 03:04:40 - eval: epoch: 126, acc1: 76.920%, acc5: 93.070%, test_loss: 1.0241, per_image_load_time: 0.065ms, per_image_inference_time: 0.054ms
2023-05-31 03:04:40 - until epoch: 126, best_acc1: 77.000%
2023-05-31 03:04:40 - epoch 127 lr: 0.004000
2023-05-31 03:04:41 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.0314
2023-05-31 03:04:41 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 1.3862
2023-05-31 03:04:44 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.0372
2023-05-31 03:04:44 - train: epoch 0127, iter [00050, 00390], lr: 0.004000, loss: 0.8269
2023-05-31 03:04:45 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.8359
2023-05-31 03:04:48 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 0.2117
2023-05-31 03:04:48 - train: epoch 0127, iter [00100, 00390], lr: 0.004000, loss: 0.8080
2023-05-31 03:04:48 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 1.2667
2023-05-31 03:04:51 - train: epoch 0127, iter [00150, 00390], lr: 0.004000, loss: 0.8304
2023-05-31 03:04:51 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 0.3550
2023-05-31 03:04:51 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 1.1862
2023-05-31 03:04:54 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 0.0880
2023-05-31 03:04:54 - train: epoch 0127, iter [00200, 00390], lr: 0.004000, loss: 0.8253
2023-05-31 03:04:54 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 1.3869
2023-05-31 03:04:57 - train: epoch 182, train_loss: 1.1195
2023-05-31 03:04:57 - train: epoch 0127, iter [00250, 00390], lr: 0.004000, loss: 0.8474
2023-05-31 03:04:57 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.0511
2023-05-31 03:04:59 - eval: epoch: 182, acc1: 79.550%, acc5: 94.880%, test_loss: 0.8017, per_image_load_time: 0.092ms, per_image_inference_time: 0.056ms
2023-05-31 03:04:59 - until epoch: 182, best_acc1: 79.760%
2023-05-31 03:04:59 - epoch 183 lr: 0.000800
2023-05-31 03:05:00 - train: epoch 133, train_loss: 0.3162
2023-05-31 03:05:00 - train: epoch 0127, iter [00300, 00390], lr: 0.004000, loss: 0.8267
2023-05-31 03:05:01 - eval: epoch: 133, acc1: 76.000%, acc5: 94.290%, test_loss: 1.0004, per_image_load_time: 0.082ms, per_image_inference_time: 0.062ms
2023-05-31 03:05:02 - until epoch: 133, best_acc1: 76.610%
2023-05-31 03:05:02 - epoch 134 lr: 0.004000
2023-05-31 03:05:02 - train: epoch 0127, iter [00350, 00390], lr: 0.004000, loss: 0.8328
2023-05-31 03:05:03 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.0687
2023-05-31 03:05:05 - train: epoch 127, train_loss: 0.8301
2023-05-31 03:05:06 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 1.2335
2023-05-31 03:05:06 - eval: epoch: 127, acc1: 77.020%, acc5: 92.810%, test_loss: 1.0246, per_image_load_time: 0.067ms, per_image_inference_time: 0.052ms
2023-05-31 03:05:06 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.4720
2023-05-31 03:05:07 - until epoch: 127, best_acc1: 77.020%
2023-05-31 03:05:07 - epoch 128 lr: 0.004000
2023-05-31 03:05:09 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 0.1690
2023-05-31 03:05:09 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 1.2908
2023-05-31 03:05:11 - train: epoch 0128, iter [00050, 00390], lr: 0.004000, loss: 0.8241
2023-05-31 03:05:12 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 0.1811
2023-05-31 03:05:13 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 1.4092
2023-05-31 03:05:14 - train: epoch 0128, iter [00100, 00390], lr: 0.004000, loss: 0.8205
2023-05-31 03:05:15 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.0378
2023-05-31 03:05:16 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 1.6068
2023-05-31 03:05:17 - train: epoch 0128, iter [00150, 00390], lr: 0.004000, loss: 0.8405
2023-05-31 03:05:18 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 0.6117
2023-05-31 03:05:19 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 1.5598
2023-05-31 03:05:20 - train: epoch 0128, iter [00200, 00390], lr: 0.004000, loss: 0.8391
2023-05-31 03:05:22 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.0386
2023-05-31 03:05:22 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 1.4298
2023-05-31 03:05:24 - train: epoch 0128, iter [00250, 00390], lr: 0.004000, loss: 0.8224
2023-05-31 03:05:25 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 0.2557
2023-05-31 03:05:25 - train: epoch 183, train_loss: 1.0446
2023-05-31 03:05:27 - eval: epoch: 183, acc1: 79.490%, acc5: 94.650%, test_loss: 0.8017, per_image_load_time: 0.089ms, per_image_inference_time: 0.050ms
2023-05-31 03:05:27 - train: epoch 0128, iter [00300, 00390], lr: 0.004000, loss: 0.8374
2023-05-31 03:05:27 - until epoch: 183, best_acc1: 79.760%
2023-05-31 03:05:27 - epoch 184 lr: 0.000800
2023-05-31 03:05:27 - train: epoch 134, train_loss: 0.3920
2023-05-31 03:05:29 - eval: epoch: 134, acc1: 75.840%, acc5: 93.820%, test_loss: 1.0175, per_image_load_time: 0.083ms, per_image_inference_time: 0.075ms
2023-05-31 03:05:29 - train: epoch 0128, iter [00350, 00390], lr: 0.004000, loss: 0.8292
2023-05-31 03:05:29 - until epoch: 134, best_acc1: 76.610%
2023-05-31 03:05:29 - epoch 135 lr: 0.004000
2023-05-31 03:05:31 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 1.0232
2023-05-31 03:05:32 - train: epoch 128, train_loss: 0.8299
2023-05-31 03:05:33 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 0.1210
2023-05-31 03:05:33 - eval: epoch: 128, acc1: 77.200%, acc5: 93.010%, test_loss: 1.0251, per_image_load_time: 0.073ms, per_image_inference_time: 0.056ms
2023-05-31 03:05:34 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 1.3343
2023-05-31 03:05:34 - until epoch: 128, best_acc1: 77.200%
2023-05-31 03:05:34 - epoch 129 lr: 0.004000
2023-05-31 03:05:36 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.0487
2023-05-31 03:05:36 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.7767
2023-05-31 03:05:38 - train: epoch 0129, iter [00050, 00390], lr: 0.004000, loss: 0.8106
2023-05-31 03:05:39 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 2.8989
2023-05-31 03:05:40 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 1.1044
2023-05-31 03:05:41 - train: epoch 0129, iter [00100, 00390], lr: 0.004000, loss: 0.8333
2023-05-31 03:05:42 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 0.4183
2023-05-31 03:05:43 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.8477
2023-05-31 03:05:45 - train: epoch 0129, iter [00150, 00390], lr: 0.004000, loss: 0.8268
2023-05-31 03:05:46 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 0.3168
2023-05-31 03:05:46 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.3798
2023-05-31 03:05:48 - train: epoch 0129, iter [00200, 00390], lr: 0.004000, loss: 0.8166
2023-05-31 03:05:49 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 0.0524
2023-05-31 03:05:49 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 1.3030
2023-05-31 03:05:51 - train: epoch 0129, iter [00250, 00390], lr: 0.004000, loss: 0.8197
2023-05-31 03:05:52 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 0.3977
2023-05-31 03:05:52 - train: epoch 184, train_loss: 1.0214
2023-05-31 03:05:54 - eval: epoch: 184, acc1: 79.610%, acc5: 94.620%, test_loss: 0.8220, per_image_load_time: 0.080ms, per_image_inference_time: 0.052ms
2023-05-31 03:05:54 - train: epoch 0129, iter [00300, 00390], lr: 0.004000, loss: 0.8017
2023-05-31 03:05:54 - train: epoch 135, train_loss: 0.3749
2023-05-31 03:05:55 - until epoch: 184, best_acc1: 79.760%
2023-05-31 03:05:55 - epoch 185 lr: 0.000800
2023-05-31 03:05:56 - eval: epoch: 135, acc1: 76.590%, acc5: 94.220%, test_loss: 0.9742, per_image_load_time: 0.071ms, per_image_inference_time: 0.061ms
2023-05-31 03:05:56 - train: epoch 0129, iter [00350, 00390], lr: 0.004000, loss: 0.8289
2023-05-31 03:05:56 - until epoch: 135, best_acc1: 76.610%
2023-05-31 03:05:56 - epoch 136 lr: 0.004000
2023-05-31 03:05:58 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 1.1531
2023-05-31 03:05:58 - train: epoch 129, train_loss: 0.8249
2023-05-31 03:06:00 - eval: epoch: 129, acc1: 77.130%, acc5: 93.100%, test_loss: 1.0241, per_image_load_time: 0.068ms, per_image_inference_time: 0.055ms
2023-05-31 03:06:00 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.0184
2023-05-31 03:06:00 - until epoch: 129, best_acc1: 77.200%
2023-05-31 03:06:00 - epoch 130 lr: 0.004000
2023-05-31 03:06:01 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 1.3637
2023-05-31 03:06:03 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.0289
2023-05-31 03:06:04 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.6593
2023-05-31 03:06:04 - train: epoch 0130, iter [00050, 00390], lr: 0.004000, loss: 0.8281
2023-05-31 03:06:06 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.0340
2023-05-31 03:06:08 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.1780
2023-05-31 03:06:08 - train: epoch 0130, iter [00100, 00390], lr: 0.004000, loss: 0.8228
2023-05-31 03:06:10 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 0.0737
2023-05-31 03:06:11 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 1.0446
2023-05-31 03:06:11 - train: epoch 0130, iter [00150, 00390], lr: 0.004000, loss: 0.8330
2023-05-31 03:06:13 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.0524
2023-05-31 03:06:14 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.1912
2023-05-31 03:06:14 - train: epoch 0130, iter [00200, 00390], lr: 0.004000, loss: 0.8376
2023-05-31 03:06:16 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 0.5780
2023-05-31 03:06:17 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 1.0487
2023-05-31 03:06:18 - train: epoch 0130, iter [00250, 00390], lr: 0.004000, loss: 0.8061
2023-05-31 03:06:19 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 0.3773
2023-05-31 03:06:20 - train: epoch 185, train_loss: 1.0961
2023-05-31 03:06:20 - train: epoch 0130, iter [00300, 00390], lr: 0.004000, loss: 0.8217
2023-05-31 03:06:22 - eval: epoch: 185, acc1: 79.690%, acc5: 94.810%, test_loss: 0.7965, per_image_load_time: 0.085ms, per_image_inference_time: 0.051ms
2023-05-31 03:06:22 - train: epoch 136, train_loss: 0.3718
2023-05-31 03:06:22 - until epoch: 185, best_acc1: 79.760%
2023-05-31 03:06:22 - epoch 186 lr: 0.000800
2023-05-31 03:06:23 - train: epoch 0130, iter [00350, 00390], lr: 0.004000, loss: 0.8315
2023-05-31 03:06:23 - eval: epoch: 136, acc1: 76.170%, acc5: 94.030%, test_loss: 0.9831, per_image_load_time: 0.073ms, per_image_inference_time: 0.059ms
2023-05-31 03:06:24 - until epoch: 136, best_acc1: 76.610%
2023-05-31 03:06:24 - epoch 137 lr: 0.004000
2023-05-31 03:06:25 - train: epoch 130, train_loss: 0.8241
2023-05-31 03:06:25 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.5098
2023-05-31 03:06:27 - eval: epoch: 130, acc1: 77.260%, acc5: 92.830%, test_loss: 1.0287, per_image_load_time: 0.067ms, per_image_inference_time: 0.052ms
2023-05-31 03:06:27 - until epoch: 130, best_acc1: 77.260%
2023-05-31 03:06:27 - epoch 131 lr: 0.004000
2023-05-31 03:06:28 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 0.3097
2023-05-31 03:06:28 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.9502
2023-05-31 03:06:31 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 0.4416
2023-05-31 03:06:31 - train: epoch 0131, iter [00050, 00390], lr: 0.004000, loss: 0.8311
2023-05-31 03:06:32 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 1.3891
2023-05-31 03:06:34 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.0568
2023-05-31 03:06:34 - train: epoch 0131, iter [00100, 00390], lr: 0.004000, loss: 0.8357
2023-05-31 03:06:35 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.1828
2023-05-31 03:06:37 - train: epoch 0131, iter [00150, 00390], lr: 0.004000, loss: 0.8139
2023-05-31 03:06:37 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 0.1217
2023-05-31 03:06:38 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 1.5455
2023-05-31 03:06:41 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 0.1925
2023-05-31 03:06:41 - train: epoch 0131, iter [00200, 00390], lr: 0.004000, loss: 0.8096
2023-05-31 03:06:41 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 1.5291
2023-05-31 03:06:44 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 0.0368
2023-05-31 03:06:44 - train: epoch 0131, iter [00250, 00390], lr: 0.004000, loss: 0.8187
2023-05-31 03:06:45 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 1.0682
2023-05-31 03:06:47 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.0594
2023-05-31 03:06:47 - train: epoch 0131, iter [00300, 00390], lr: 0.004000, loss: 0.8248
2023-05-31 03:06:47 - train: epoch 186, train_loss: 1.0229
2023-05-31 03:06:49 - eval: epoch: 186, acc1: 79.730%, acc5: 94.890%, test_loss: 0.7926, per_image_load_time: 0.080ms, per_image_inference_time: 0.055ms
2023-05-31 03:06:49 - train: epoch 137, train_loss: 0.3620
2023-05-31 03:06:49 - until epoch: 186, best_acc1: 79.760%
2023-05-31 03:06:49 - epoch 187 lr: 0.000800
2023-05-31 03:06:50 - train: epoch 0131, iter [00350, 00390], lr: 0.004000, loss: 0.8261
2023-05-31 03:06:51 - eval: epoch: 137, acc1: 75.760%, acc5: 93.610%, test_loss: 1.0381, per_image_load_time: 0.070ms, per_image_inference_time: 0.065ms
2023-05-31 03:06:52 - until epoch: 137, best_acc1: 76.610%
2023-05-31 03:06:52 - epoch 138 lr: 0.004000
2023-05-31 03:06:52 - train: epoch 131, train_loss: 0.8221
2023-05-31 03:06:53 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 1.2574
2023-05-31 03:06:54 - eval: epoch: 131, acc1: 77.450%, acc5: 93.030%, test_loss: 1.0252, per_image_load_time: 0.078ms, per_image_inference_time: 0.052ms
2023-05-31 03:06:54 - until epoch: 131, best_acc1: 77.450%
2023-05-31 03:06:54 - epoch 132 lr: 0.004000
2023-05-31 03:06:55 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 0.1590
2023-05-31 03:06:56 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.9008
2023-05-31 03:06:58 - train: epoch 0132, iter [00050, 00390], lr: 0.004000, loss: 0.8219
2023-05-31 03:06:59 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 0.5459
2023-05-31 03:06:59 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 1.6036
2023-05-31 03:07:01 - train: epoch 0132, iter [00100, 00390], lr: 0.004000, loss: 0.8079
2023-05-31 03:07:02 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 0.2281
2023-05-31 03:07:02 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 1.2243
2023-05-31 03:07:05 - train: epoch 0132, iter [00150, 00390], lr: 0.004000, loss: 0.8245
2023-05-31 03:07:05 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 0.5215
2023-05-31 03:07:05 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.6526
2023-05-31 03:07:08 - train: epoch 0132, iter [00200, 00390], lr: 0.004000, loss: 0.8113
2023-05-31 03:07:08 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.0882
2023-05-31 03:07:09 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 1.4110
2023-05-31 03:07:11 - train: epoch 0132, iter [00250, 00390], lr: 0.004000, loss: 0.8093
2023-05-31 03:07:12 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.0487
2023-05-31 03:07:12 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.5083
2023-05-31 03:07:14 - train: epoch 0132, iter [00300, 00390], lr: 0.004000, loss: 0.8155
2023-05-31 03:07:15 - train: epoch 187, train_loss: 1.0935
2023-05-31 03:07:15 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 0.1684
2023-05-31 03:07:16 - eval: epoch: 187, acc1: 79.560%, acc5: 94.550%, test_loss: 0.8137, per_image_load_time: 0.080ms, per_image_inference_time: 0.054ms
2023-05-31 03:07:17 - until epoch: 187, best_acc1: 79.760%
2023-05-31 03:07:17 - epoch 188 lr: 0.000800
2023-05-31 03:07:17 - train: epoch 138, train_loss: 0.3123
2023-05-31 03:07:17 - train: epoch 0132, iter [00350, 00390], lr: 0.004000, loss: 0.7995
2023-05-31 03:07:19 - eval: epoch: 138, acc1: 75.700%, acc5: 93.580%, test_loss: 1.0546, per_image_load_time: 0.079ms, per_image_inference_time: 0.056ms
2023-05-31 03:07:19 - until epoch: 138, best_acc1: 76.610%
2023-05-31 03:07:19 - epoch 139 lr: 0.004000
2023-05-31 03:07:19 - train: epoch 132, train_loss: 0.8216
2023-05-31 03:07:20 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 1.5214
2023-05-31 03:07:21 - eval: epoch: 132, acc1: 77.450%, acc5: 92.900%, test_loss: 1.0273, per_image_load_time: 0.078ms, per_image_inference_time: 0.056ms
2023-05-31 03:07:21 - until epoch: 132, best_acc1: 77.450%
2023-05-31 03:07:21 - epoch 133 lr: 0.004000
2023-05-31 03:07:23 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 0.0957
2023-05-31 03:07:23 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 1.1641
2023-05-31 03:07:25 - train: epoch 0133, iter [00050, 00390], lr: 0.004000, loss: 0.8380
2023-05-31 03:07:26 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 0.4232
2023-05-31 03:07:26 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 1.3686
2023-05-31 03:07:28 - train: epoch 0133, iter [00100, 00390], lr: 0.004000, loss: 0.8088
2023-05-31 03:07:29 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 2.0649
2023-05-31 03:07:29 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 1.4913
2023-05-31 03:07:31 - train: epoch 0133, iter [00150, 00390], lr: 0.004000, loss: 0.8217
2023-05-31 03:07:33 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.0350
2023-05-31 03:07:33 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 1.4112
2023-05-31 03:07:35 - train: epoch 0133, iter [00200, 00390], lr: 0.004000, loss: 0.8177
2023-05-31 03:07:36 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 0.3277
2023-05-31 03:07:36 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 1.3024
2023-05-31 03:07:38 - train: epoch 0133, iter [00250, 00390], lr: 0.004000, loss: 0.8192
2023-05-31 03:07:39 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 1.5842
2023-05-31 03:07:39 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 1.2397
2023-05-31 03:07:41 - train: epoch 0133, iter [00300, 00390], lr: 0.004000, loss: 0.8342
2023-05-31 03:07:42 - train: epoch 188, train_loss: 1.0717
2023-05-31 03:07:42 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 1.1419
2023-05-31 03:07:44 - eval: epoch: 188, acc1: 79.440%, acc5: 94.680%, test_loss: 0.8018, per_image_load_time: 0.079ms, per_image_inference_time: 0.054ms
2023-05-31 03:07:44 - until epoch: 188, best_acc1: 79.760%
2023-05-31 03:07:44 - epoch 189 lr: 0.000800
2023-05-31 03:07:44 - train: epoch 0133, iter [00350, 00390], lr: 0.004000, loss: 0.8133
2023-05-31 03:07:44 - train: epoch 139, train_loss: 0.3640
2023-05-31 03:07:46 - eval: epoch: 139, acc1: 75.470%, acc5: 93.840%, test_loss: 1.0417, per_image_load_time: 0.074ms, per_image_inference_time: 0.054ms
2023-05-31 03:07:46 - train: epoch 133, train_loss: 0.8198
2023-05-31 03:07:46 - until epoch: 139, best_acc1: 76.610%
2023-05-31 03:07:46 - epoch 140 lr: 0.004000
2023-05-31 03:07:47 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.9776
2023-05-31 03:07:48 - eval: epoch: 133, acc1: 77.400%, acc5: 92.800%, test_loss: 1.0206, per_image_load_time: 0.074ms, per_image_inference_time: 0.070ms
2023-05-31 03:07:48 - until epoch: 133, best_acc1: 77.450%
2023-05-31 03:07:48 - epoch 134 lr: 0.004000
2023-05-31 03:07:50 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 1.2538
2023-05-31 03:07:50 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 0.0851
2023-05-31 03:07:52 - train: epoch 0134, iter [00050, 00390], lr: 0.004000, loss: 0.8138
2023-05-31 03:07:53 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 1.0326
2023-05-31 03:07:54 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 0.3440
2023-05-31 03:07:55 - train: epoch 0134, iter [00100, 00390], lr: 0.004000, loss: 0.8091
2023-05-31 03:07:56 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 1.4447
2023-05-31 03:07:57 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 0.2002
2023-05-31 03:07:59 - train: epoch 0134, iter [00150, 00390], lr: 0.004000, loss: 0.8226
2023-05-31 03:08:00 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 1.2368
2023-05-31 03:08:00 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.0380
2023-05-31 03:08:02 - train: epoch 0134, iter [00200, 00390], lr: 0.004000, loss: 0.8503
2023-05-31 03:08:03 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 1.3140
2023-05-31 03:08:03 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 0.4055
2023-05-31 03:08:05 - train: epoch 0134, iter [00250, 00390], lr: 0.004000, loss: 0.8009
2023-05-31 03:08:06 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 1.4987
2023-05-31 03:08:07 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.0183
2023-05-31 03:08:08 - train: epoch 0134, iter [00300, 00390], lr: 0.004000, loss: 0.8274
2023-05-31 03:08:09 - train: epoch 189, train_loss: 1.0379
2023-05-31 03:08:10 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 0.4726
2023-05-31 03:08:11 - eval: epoch: 189, acc1: 79.370%, acc5: 94.730%, test_loss: 0.8018, per_image_load_time: 0.088ms, per_image_inference_time: 0.049ms
2023-05-31 03:08:11 - until epoch: 189, best_acc1: 79.760%
2023-05-31 03:08:11 - epoch 190 lr: 0.000800
2023-05-31 03:08:11 - train: epoch 0134, iter [00350, 00390], lr: 0.004000, loss: 0.8257
2023-05-31 03:08:12 - train: epoch 140, train_loss: 0.3661
2023-05-31 03:08:13 - train: epoch 134, train_loss: 0.8177
2023-05-31 03:08:13 - eval: epoch: 140, acc1: 76.480%, acc5: 93.830%, test_loss: 0.9905, per_image_load_time: 0.072ms, per_image_inference_time: 0.054ms
2023-05-31 03:08:14 - until epoch: 140, best_acc1: 76.610%
2023-05-31 03:08:14 - epoch 141 lr: 0.004000
2023-05-31 03:08:14 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 1.5905
2023-05-31 03:08:15 - eval: epoch: 134, acc1: 77.240%, acc5: 92.950%, test_loss: 1.0226, per_image_load_time: 0.074ms, per_image_inference_time: 0.048ms
2023-05-31 03:08:15 - until epoch: 134, best_acc1: 77.450%
2023-05-31 03:08:15 - epoch 135 lr: 0.004000
2023-05-31 03:08:17 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 1.3346
2023-05-31 03:08:18 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.0847
2023-05-31 03:08:19 - train: epoch 0135, iter [00050, 00390], lr: 0.004000, loss: 0.8123
2023-05-31 03:08:20 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 1.3344
2023-05-31 03:08:21 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 0.3784
2023-05-31 03:08:22 - train: epoch 0135, iter [00100, 00390], lr: 0.004000, loss: 0.8214
2023-05-31 03:08:23 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.0240
2023-05-31 03:08:25 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.0181
2023-05-31 03:08:26 - train: epoch 0135, iter [00150, 00390], lr: 0.004000, loss: 0.8256
2023-05-31 03:08:27 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 1.0899
2023-05-31 03:08:28 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 2.2013
2023-05-31 03:08:29 - train: epoch 0135, iter [00200, 00390], lr: 0.004000, loss: 0.8289
2023-05-31 03:08:30 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 1.1279
2023-05-31 03:08:31 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 0.1697
2023-05-31 03:08:32 - train: epoch 0135, iter [00250, 00390], lr: 0.004000, loss: 0.8461
2023-05-31 03:08:33 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 1.6819
2023-05-31 03:08:34 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 1.4453
2023-05-31 03:08:35 - train: epoch 0135, iter [00300, 00390], lr: 0.004000, loss: 0.8047
2023-05-31 03:08:36 - train: epoch 190, train_loss: 1.0714
2023-05-31 03:08:37 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.0465
2023-05-31 03:08:38 - eval: epoch: 190, acc1: 79.290%, acc5: 94.570%, test_loss: 0.8194, per_image_load_time: 0.085ms, per_image_inference_time: 0.069ms
2023-05-31 03:08:38 - train: epoch 0135, iter [00350, 00390], lr: 0.004000, loss: 0.8145
2023-05-31 03:08:38 - until epoch: 190, best_acc1: 79.760%
2023-05-31 03:08:38 - epoch 191 lr: 0.000800
2023-05-31 03:08:40 - train: epoch 141, train_loss: 0.3347
2023-05-31 03:08:40 - train: epoch 135, train_loss: 0.8188
2023-05-31 03:08:41 - eval: epoch: 141, acc1: 75.970%, acc5: 93.680%, test_loss: 1.0315, per_image_load_time: 0.068ms, per_image_inference_time: 0.054ms
2023-05-31 03:08:41 - until epoch: 141, best_acc1: 76.610%
2023-05-31 03:08:41 - epoch 142 lr: 0.004000
2023-05-31 03:08:42 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.1777
2023-05-31 03:08:42 - eval: epoch: 135, acc1: 77.690%, acc5: 92.890%, test_loss: 1.0255, per_image_load_time: 0.083ms, per_image_inference_time: 0.056ms
2023-05-31 03:08:42 - until epoch: 135, best_acc1: 77.690%
2023-05-31 03:08:42 - epoch 136 lr: 0.004000
2023-05-31 03:08:44 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 1.2654
2023-05-31 03:08:45 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 0.1253
2023-05-31 03:08:46 - train: epoch 0136, iter [00050, 00390], lr: 0.004000, loss: 0.8207
2023-05-31 03:08:47 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.0792
2023-05-31 03:08:49 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.0219
2023-05-31 03:08:50 - train: epoch 0136, iter [00100, 00390], lr: 0.004000, loss: 0.8214
2023-05-31 03:08:51 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 1.3089
2023-05-31 03:08:52 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.0295
2023-05-31 03:08:53 - train: epoch 0136, iter [00150, 00390], lr: 0.004000, loss: 0.8038
2023-05-31 03:08:54 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.9803
2023-05-31 03:08:55 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 0.4085
2023-05-31 03:08:56 - train: epoch 0136, iter [00200, 00390], lr: 0.004000, loss: 0.8254
2023-05-31 03:08:57 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.0646
2023-05-31 03:08:58 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 0.1307
2023-05-31 03:09:00 - train: epoch 0136, iter [00250, 00390], lr: 0.004000, loss: 0.8226
2023-05-31 03:09:00 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 1.3104
2023-05-31 03:09:02 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 0.6792
2023-05-31 03:09:03 - train: epoch 0136, iter [00300, 00390], lr: 0.004000, loss: 0.8214
2023-05-31 03:09:03 - train: epoch 191, train_loss: 1.0137
2023-05-31 03:09:05 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 0.1631
2023-05-31 03:09:05 - eval: epoch: 191, acc1: 79.380%, acc5: 94.760%, test_loss: 0.7994, per_image_load_time: 0.087ms, per_image_inference_time: 0.055ms
2023-05-31 03:09:05 - until epoch: 191, best_acc1: 79.760%
2023-05-31 03:09:05 - epoch 192 lr: 0.000800
2023-05-31 03:09:06 - train: epoch 0136, iter [00350, 00390], lr: 0.004000, loss: 0.8248
2023-05-31 03:09:07 - train: epoch 142, train_loss: 0.3569
2023-05-31 03:09:08 - train: epoch 136, train_loss: 0.8169
2023-05-31 03:09:08 - eval: epoch: 142, acc1: 75.640%, acc5: 93.500%, test_loss: 1.0700, per_image_load_time: 0.070ms, per_image_inference_time: 0.054ms
2023-05-31 03:09:08 - until epoch: 142, best_acc1: 76.610%
2023-05-31 03:09:08 - epoch 143 lr: 0.004000
2023-05-31 03:09:09 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 1.3386
2023-05-31 03:09:09 - eval: epoch: 136, acc1: 77.600%, acc5: 92.770%, test_loss: 1.0307, per_image_load_time: 0.077ms, per_image_inference_time: 0.058ms
2023-05-31 03:09:10 - until epoch: 136, best_acc1: 77.690%
2023-05-31 03:09:10 - epoch 137 lr: 0.004000
2023-05-31 03:09:12 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 1.1188
2023-05-31 03:09:12 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 0.4278
2023-05-31 03:09:14 - train: epoch 0137, iter [00050, 00390], lr: 0.004000, loss: 0.8029
2023-05-31 03:09:15 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 1.0614
2023-05-31 03:09:15 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 0.0777
2023-05-31 03:09:17 - train: epoch 0137, iter [00100, 00390], lr: 0.004000, loss: 0.8297
2023-05-31 03:09:18 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 1.2674
2023-05-31 03:09:19 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 0.3547
2023-05-31 03:09:20 - train: epoch 0137, iter [00150, 00390], lr: 0.004000, loss: 0.8341
2023-05-31 03:09:21 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 1.2800
2023-05-31 03:09:22 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 0.1004
2023-05-31 03:09:24 - train: epoch 0137, iter [00200, 00390], lr: 0.004000, loss: 0.8244
2023-05-31 03:09:25 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 1.3060
2023-05-31 03:09:25 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 0.2638
2023-05-31 03:09:27 - train: epoch 0137, iter [00250, 00390], lr: 0.004000, loss: 0.8194
2023-05-31 03:09:28 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 1.2704
2023-05-31 03:09:29 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 0.2434
2023-05-31 03:09:30 - train: epoch 0137, iter [00300, 00390], lr: 0.004000, loss: 0.8267
2023-05-31 03:09:31 - train: epoch 192, train_loss: 1.0437
2023-05-31 03:09:31 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.0517
2023-05-31 03:09:33 - eval: epoch: 192, acc1: 79.330%, acc5: 94.590%, test_loss: 0.8087, per_image_load_time: 0.085ms, per_image_inference_time: 0.060ms
2023-05-31 03:09:33 - until epoch: 192, best_acc1: 79.760%
2023-05-31 03:09:33 - epoch 193 lr: 0.000800
2023-05-31 03:09:33 - train: epoch 0137, iter [00350, 00390], lr: 0.004000, loss: 0.8306
2023-05-31 03:09:34 - train: epoch 143, train_loss: 0.3631
2023-05-31 03:09:35 - train: epoch 137, train_loss: 0.8160
2023-05-31 03:09:36 - eval: epoch: 143, acc1: 75.930%, acc5: 93.770%, test_loss: 1.0242, per_image_load_time: 0.079ms, per_image_inference_time: 0.056ms
2023-05-31 03:09:36 - until epoch: 143, best_acc1: 76.610%
2023-05-31 03:09:36 - epoch 144 lr: 0.004000
2023-05-31 03:09:36 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 1.6634
2023-05-31 03:09:37 - eval: epoch: 137, acc1: 77.580%, acc5: 92.910%, test_loss: 1.0282, per_image_load_time: 0.080ms, per_image_inference_time: 0.068ms
2023-05-31 03:09:37 - until epoch: 137, best_acc1: 77.690%
2023-05-31 03:09:37 - epoch 138 lr: 0.004000
2023-05-31 03:09:39 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 1.5592
2023-05-31 03:09:40 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.0312
2023-05-31 03:09:41 - train: epoch 0138, iter [00050, 00390], lr: 0.004000, loss: 0.8168
2023-05-31 03:09:42 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.7461
2023-05-31 03:09:43 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 0.0551
2023-05-31 03:09:45 - train: epoch 0138, iter [00100, 00390], lr: 0.004000, loss: 0.8041
2023-05-31 03:09:45 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 1.5875
2023-05-31 03:09:46 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 0.3803
2023-05-31 03:09:48 - train: epoch 0138, iter [00150, 00390], lr: 0.004000, loss: 0.8181
2023-05-31 03:09:49 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.5146
2023-05-31 03:09:50 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 0.9785
2023-05-31 03:09:51 - train: epoch 0138, iter [00200, 00390], lr: 0.004000, loss: 0.8197
2023-05-31 03:09:52 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 1.1317
2023-05-31 03:09:53 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 0.2935
2023-05-31 03:09:54 - train: epoch 0138, iter [00250, 00390], lr: 0.004000, loss: 0.8078
2023-05-31 03:09:55 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 1.4904
2023-05-31 03:09:56 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.0278
2023-05-31 03:09:58 - train: epoch 0138, iter [00300, 00390], lr: 0.004000, loss: 0.8146
2023-05-31 03:09:58 - train: epoch 193, train_loss: 1.0553
2023-05-31 03:09:59 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 0.0829
2023-05-31 03:10:00 - eval: epoch: 193, acc1: 79.200%, acc5: 94.720%, test_loss: 0.8047, per_image_load_time: 0.087ms, per_image_inference_time: 0.060ms
2023-05-31 03:10:00 - until epoch: 193, best_acc1: 79.760%
2023-05-31 03:10:00 - epoch 194 lr: 0.000800
2023-05-31 03:10:00 - train: epoch 0138, iter [00350, 00390], lr: 0.004000, loss: 0.8041
2023-05-31 03:10:01 - train: epoch 144, train_loss: 0.3600
2023-05-31 03:10:03 - train: epoch 138, train_loss: 0.8151
2023-05-31 03:10:03 - eval: epoch: 144, acc1: 75.980%, acc5: 93.640%, test_loss: 1.0457, per_image_load_time: 0.065ms, per_image_inference_time: 0.049ms
2023-05-31 03:10:03 - until epoch: 144, best_acc1: 76.610%
2023-05-31 03:10:03 - epoch 145 lr: 0.004000
2023-05-31 03:10:03 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 1.2332
2023-05-31 03:10:04 - eval: epoch: 138, acc1: 77.870%, acc5: 93.090%, test_loss: 1.0248, per_image_load_time: 0.073ms, per_image_inference_time: 0.064ms
2023-05-31 03:10:05 - until epoch: 138, best_acc1: 77.870%
2023-05-31 03:10:05 - epoch 139 lr: 0.004000
2023-05-31 03:10:06 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 1.3911
2023-05-31 03:10:07 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.0264
2023-05-31 03:10:09 - train: epoch 0139, iter [00050, 00390], lr: 0.004000, loss: 0.7941
2023-05-31 03:10:09 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.1886
2023-05-31 03:10:10 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 0.0503
2023-05-31 03:10:12 - train: epoch 0139, iter [00100, 00390], lr: 0.004000, loss: 0.7995
2023-05-31 03:10:12 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 1.4965
2023-05-31 03:10:13 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.0326
2023-05-31 03:10:15 - train: epoch 0139, iter [00150, 00390], lr: 0.004000, loss: 0.8309
2023-05-31 03:10:16 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 1.3713
2023-05-31 03:10:16 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 0.9233
2023-05-31 03:10:19 - train: epoch 0139, iter [00200, 00390], lr: 0.004000, loss: 0.8252
2023-05-31 03:10:19 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.1342
2023-05-31 03:10:20 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.0322
2023-05-31 03:10:22 - train: epoch 0139, iter [00250, 00390], lr: 0.004000, loss: 0.8141
2023-05-31 03:10:22 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 1.4432
2023-05-31 03:10:23 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.0253
2023-05-31 03:10:25 - train: epoch 194, train_loss: 1.0419
2023-05-31 03:10:25 - train: epoch 0139, iter [00300, 00390], lr: 0.004000, loss: 0.8110
2023-05-31 03:10:26 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.0265
2023-05-31 03:10:27 - eval: epoch: 194, acc1: 79.300%, acc5: 94.550%, test_loss: 0.8079, per_image_load_time: 0.085ms, per_image_inference_time: 0.057ms
2023-05-31 03:10:27 - until epoch: 194, best_acc1: 79.760%
2023-05-31 03:10:27 - epoch 195 lr: 0.000800
2023-05-31 03:10:28 - train: epoch 0139, iter [00350, 00390], lr: 0.004000, loss: 0.8160
2023-05-31 03:10:28 - train: epoch 145, train_loss: 0.3250
2023-05-31 03:10:30 - eval: epoch: 145, acc1: 76.450%, acc5: 93.830%, test_loss: 1.0054, per_image_load_time: 0.077ms, per_image_inference_time: 0.052ms
2023-05-31 03:10:30 - train: epoch 139, train_loss: 0.8146
2023-05-31 03:10:30 - until epoch: 145, best_acc1: 76.610%
2023-05-31 03:10:30 - epoch 146 lr: 0.004000
2023-05-31 03:10:30 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 1.3348
2023-05-31 03:10:32 - eval: epoch: 139, acc1: 77.770%, acc5: 92.890%, test_loss: 1.0280, per_image_load_time: 0.084ms, per_image_inference_time: 0.061ms
2023-05-31 03:10:32 - until epoch: 139, best_acc1: 77.870%
2023-05-31 03:10:32 - epoch 140 lr: 0.004000
2023-05-31 03:10:33 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 1.1417
2023-05-31 03:10:34 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.0397
2023-05-31 03:10:36 - train: epoch 0140, iter [00050, 00390], lr: 0.004000, loss: 0.8190
2023-05-31 03:10:37 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.5767
2023-05-31 03:10:37 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 0.7088
2023-05-31 03:10:39 - train: epoch 0140, iter [00100, 00390], lr: 0.004000, loss: 0.8081
2023-05-31 03:10:40 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 1.2033
2023-05-31 03:10:40 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 0.5712
2023-05-31 03:10:43 - train: epoch 0140, iter [00150, 00390], lr: 0.004000, loss: 0.8511
2023-05-31 03:10:43 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 1.5701
2023-05-31 03:10:44 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 0.2654
2023-05-31 03:10:46 - train: epoch 0140, iter [00200, 00390], lr: 0.004000, loss: 0.8205
2023-05-31 03:10:46 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.0621
2023-05-31 03:10:47 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 1.0230
2023-05-31 03:10:49 - train: epoch 0140, iter [00250, 00390], lr: 0.004000, loss: 0.8208
2023-05-31 03:10:50 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.0694
2023-05-31 03:10:50 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 0.0455
2023-05-31 03:10:52 - train: epoch 195, train_loss: 1.0466
2023-05-31 03:10:52 - train: epoch 0140, iter [00300, 00390], lr: 0.004000, loss: 0.8241
2023-05-31 03:10:53 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.0219
2023-05-31 03:10:54 - eval: epoch: 195, acc1: 79.260%, acc5: 94.590%, test_loss: 0.8096, per_image_load_time: 0.084ms, per_image_inference_time: 0.055ms
2023-05-31 03:10:54 - until epoch: 195, best_acc1: 79.760%
2023-05-31 03:10:54 - epoch 196 lr: 0.000800
2023-05-31 03:10:55 - train: epoch 0140, iter [00350, 00390], lr: 0.004000, loss: 0.8143
2023-05-31 03:10:55 - train: epoch 146, train_loss: 0.2871
2023-05-31 03:10:57 - eval: epoch: 146, acc1: 76.010%, acc5: 93.590%, test_loss: 1.0341, per_image_load_time: 0.080ms, per_image_inference_time: 0.054ms
2023-05-31 03:10:57 - train: epoch 140, train_loss: 0.8142
2023-05-31 03:10:57 - until epoch: 146, best_acc1: 76.610%
2023-05-31 03:10:57 - epoch 147 lr: 0.004000
2023-05-31 03:10:58 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 1.4828
2023-05-31 03:10:59 - eval: epoch: 140, acc1: 77.570%, acc5: 93.000%, test_loss: 1.0279, per_image_load_time: 0.072ms, per_image_inference_time: 0.065ms
2023-05-31 03:11:00 - until epoch: 140, best_acc1: 77.870%
2023-05-31 03:11:00 - epoch 141 lr: 0.004000
2023-05-31 03:11:00 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.1817
2023-05-31 03:11:01 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 1.4838
2023-05-31 03:11:03 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 1.4458
2023-05-31 03:11:04 - train: epoch 0141, iter [00050, 00390], lr: 0.004000, loss: 0.8143
2023-05-31 03:11:04 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 0.7354
2023-05-31 03:11:07 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.6819
2023-05-31 03:11:07 - train: epoch 0141, iter [00100, 00390], lr: 0.004000, loss: 0.8096
2023-05-31 03:11:07 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 0.0487
2023-05-31 03:11:10 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.0239
2023-05-31 03:11:10 - train: epoch 0141, iter [00150, 00390], lr: 0.004000, loss: 0.7962
2023-05-31 03:11:11 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 0.2615
2023-05-31 03:11:13 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.6352
2023-05-31 03:11:14 - train: epoch 0141, iter [00200, 00390], lr: 0.004000, loss: 0.8209
2023-05-31 03:11:14 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 0.3767
2023-05-31 03:11:16 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 1.1133
2023-05-31 03:11:17 - train: epoch 0141, iter [00250, 00390], lr: 0.004000, loss: 0.7917
2023-05-31 03:11:17 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 0.2658
2023-05-31 03:11:19 - train: epoch 196, train_loss: 1.0576
2023-05-31 03:11:20 - train: epoch 0141, iter [00300, 00390], lr: 0.004000, loss: 0.8072
2023-05-31 03:11:20 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 0.4166
2023-05-31 03:11:21 - eval: epoch: 196, acc1: 79.250%, acc5: 94.600%, test_loss: 0.8083, per_image_load_time: 0.086ms, per_image_inference_time: 0.054ms
2023-05-31 03:11:21 - until epoch: 196, best_acc1: 79.760%
2023-05-31 03:11:21 - epoch 197 lr: 0.000800
2023-05-31 03:11:22 - train: epoch 147, train_loss: 0.3806
2023-05-31 03:11:23 - train: epoch 0141, iter [00350, 00390], lr: 0.004000, loss: 0.7990
2023-05-31 03:11:24 - eval: epoch: 147, acc1: 75.770%, acc5: 93.550%, test_loss: 1.0372, per_image_load_time: 0.069ms, per_image_inference_time: 0.057ms
2023-05-31 03:11:24 - until epoch: 147, best_acc1: 76.610%
2023-05-31 03:11:24 - epoch 148 lr: 0.004000
2023-05-31 03:11:25 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.7201
2023-05-31 03:11:25 - train: epoch 141, train_loss: 0.8122
2023-05-31 03:11:27 - eval: epoch: 141, acc1: 77.780%, acc5: 93.020%, test_loss: 1.0312, per_image_load_time: 0.092ms, per_image_inference_time: 0.055ms
2023-05-31 03:11:27 - until epoch: 141, best_acc1: 77.870%
2023-05-31 03:11:27 - epoch 142 lr: 0.004000
2023-05-31 03:11:27 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 1.2676
2023-05-31 03:11:28 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 1.8343
2023-05-31 03:11:30 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 1.2248
2023-05-31 03:11:31 - train: epoch 0142, iter [00050, 00390], lr: 0.004000, loss: 0.8042
2023-05-31 03:11:31 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 0.8799
2023-05-31 03:11:33 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 1.6538
2023-05-31 03:11:34 - train: epoch 0142, iter [00100, 00390], lr: 0.004000, loss: 0.8085
2023-05-31 03:11:35 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.0274
2023-05-31 03:11:37 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.0240
2023-05-31 03:11:37 - train: epoch 0142, iter [00150, 00390], lr: 0.004000, loss: 0.7998
2023-05-31 03:11:38 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 0.0458
2023-05-31 03:11:40 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 1.4558
2023-05-31 03:11:41 - train: epoch 0142, iter [00200, 00390], lr: 0.004000, loss: 0.8039
2023-05-31 03:11:41 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 0.2485
2023-05-31 03:11:43 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 1.4850
2023-05-31 03:11:44 - train: epoch 0142, iter [00250, 00390], lr: 0.004000, loss: 0.8080
2023-05-31 03:11:44 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 0.1717
2023-05-31 03:11:46 - train: epoch 197, train_loss: 1.0597
2023-05-31 03:11:47 - train: epoch 0142, iter [00300, 00390], lr: 0.004000, loss: 0.8092
2023-05-31 03:11:47 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 0.0897
2023-05-31 03:11:48 - eval: epoch: 197, acc1: 79.170%, acc5: 94.510%, test_loss: 0.8047, per_image_load_time: 0.085ms, per_image_inference_time: 0.055ms
2023-05-31 03:11:48 - until epoch: 197, best_acc1: 79.760%
2023-05-31 03:11:48 - epoch 198 lr: 0.000800
2023-05-31 03:11:49 - train: epoch 148, train_loss: 0.3403
2023-05-31 03:11:50 - train: epoch 0142, iter [00350, 00390], lr: 0.004000, loss: 0.8335
2023-05-31 03:11:51 - eval: epoch: 148, acc1: 75.860%, acc5: 93.600%, test_loss: 1.0377, per_image_load_time: 0.071ms, per_image_inference_time: 0.052ms
2023-05-31 03:11:51 - until epoch: 148, best_acc1: 76.610%
2023-05-31 03:11:51 - epoch 149 lr: 0.004000
2023-05-31 03:11:52 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 1.0260
2023-05-31 03:11:52 - train: epoch 142, train_loss: 0.8121
2023-05-31 03:11:54 - eval: epoch: 142, acc1: 77.650%, acc5: 93.030%, test_loss: 1.0245, per_image_load_time: 0.082ms, per_image_inference_time: 0.058ms
2023-05-31 03:11:54 - until epoch: 142, best_acc1: 77.870%
2023-05-31 03:11:54 - epoch 143 lr: 0.004000
2023-05-31 03:11:54 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.3069
2023-05-31 03:11:55 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 0.8841
2023-05-31 03:11:57 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.1900
2023-05-31 03:11:58 - train: epoch 0143, iter [00050, 00390], lr: 0.004000, loss: 0.8179
2023-05-31 03:11:58 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 1.1261
2023-05-31 03:12:01 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 1.4047
2023-05-31 03:12:01 - train: epoch 0143, iter [00100, 00390], lr: 0.004000, loss: 0.8094
2023-05-31 03:12:02 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.0549
2023-05-31 03:12:04 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 1.0420
2023-05-31 03:12:04 - train: epoch 0143, iter [00150, 00390], lr: 0.004000, loss: 0.8164
2023-05-31 03:12:05 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 0.2819
2023-05-31 03:12:07 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 1.3103
2023-05-31 03:12:08 - train: epoch 0143, iter [00200, 00390], lr: 0.004000, loss: 0.8159
2023-05-31 03:12:08 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.0235
2023-05-31 03:12:10 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.8149
2023-05-31 03:12:11 - train: epoch 0143, iter [00250, 00390], lr: 0.004000, loss: 0.8077
2023-05-31 03:12:11 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 0.0419
2023-05-31 03:12:13 - train: epoch 198, train_loss: 1.0557
2023-05-31 03:12:14 - train: epoch 0143, iter [00300, 00390], lr: 0.004000, loss: 0.8087
2023-05-31 03:12:14 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 1.1315
2023-05-31 03:12:15 - eval: epoch: 198, acc1: 79.340%, acc5: 94.540%, test_loss: 0.8088, per_image_load_time: 0.080ms, per_image_inference_time: 0.054ms
2023-05-31 03:12:15 - until epoch: 198, best_acc1: 79.760%
2023-05-31 03:12:15 - epoch 199 lr: 0.000800
2023-05-31 03:12:16 - train: epoch 149, train_loss: 0.3459
2023-05-31 03:12:17 - train: epoch 0143, iter [00350, 00390], lr: 0.004000, loss: 0.8251
2023-05-31 03:12:18 - eval: epoch: 149, acc1: 75.780%, acc5: 93.660%, test_loss: 1.0304, per_image_load_time: 0.072ms, per_image_inference_time: 0.055ms
2023-05-31 03:12:18 - until epoch: 149, best_acc1: 76.610%
2023-05-31 03:12:18 - epoch 150 lr: 0.004000
2023-05-31 03:12:19 - train: epoch 143, train_loss: 0.8108
2023-05-31 03:12:19 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.5433
2023-05-31 03:12:20 - eval: epoch: 143, acc1: 77.840%, acc5: 93.000%, test_loss: 1.0295, per_image_load_time: 0.077ms, per_image_inference_time: 0.052ms
2023-05-31 03:12:21 - until epoch: 143, best_acc1: 77.870%
2023-05-31 03:12:21 - epoch 144 lr: 0.004000
2023-05-31 03:12:21 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.0547
2023-05-31 03:12:22 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.0263
2023-05-31 03:12:25 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 1.5135
2023-05-31 03:12:25 - train: epoch 0144, iter [00050, 00390], lr: 0.004000, loss: 0.8012
2023-05-31 03:12:25 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.0346
2023-05-31 03:12:28 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.6885
2023-05-31 03:12:28 - train: epoch 0144, iter [00100, 00390], lr: 0.004000, loss: 0.8112
2023-05-31 03:12:29 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.0533
2023-05-31 03:12:31 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 1.0773
2023-05-31 03:12:31 - train: epoch 0144, iter [00150, 00390], lr: 0.004000, loss: 0.8250
2023-05-31 03:12:32 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 0.0781
2023-05-31 03:12:34 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 1.1657
2023-05-31 03:12:34 - train: epoch 0144, iter [00200, 00390], lr: 0.004000, loss: 0.8282
2023-05-31 03:12:35 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 1.4447
2023-05-31 03:12:38 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.0735
2023-05-31 03:12:38 - train: epoch 0144, iter [00250, 00390], lr: 0.004000, loss: 0.7918
2023-05-31 03:12:38 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 1.2944
2023-05-31 03:12:40 - train: epoch 199, train_loss: 1.0475
2023-05-31 03:12:41 - train: epoch 0144, iter [00300, 00390], lr: 0.004000, loss: 0.8197
2023-05-31 03:12:41 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 0.0782
2023-05-31 03:12:42 - eval: epoch: 199, acc1: 79.170%, acc5: 94.540%, test_loss: 0.8143, per_image_load_time: 0.078ms, per_image_inference_time: 0.050ms
2023-05-31 03:12:42 - until epoch: 199, best_acc1: 79.760%
2023-05-31 03:12:42 - epoch 200 lr: 0.000800
2023-05-31 03:12:44 - train: epoch 150, train_loss: 0.3432
2023-05-31 03:12:44 - train: epoch 0144, iter [00350, 00390], lr: 0.004000, loss: 0.8124
2023-05-31 03:12:45 - eval: epoch: 150, acc1: 75.600%, acc5: 93.790%, test_loss: 1.0548, per_image_load_time: 0.068ms, per_image_inference_time: 0.055ms
2023-05-31 03:12:45 - until epoch: 150, best_acc1: 76.610%
2023-05-31 03:12:45 - epoch 151 lr: 0.004000
2023-05-31 03:12:46 - train: epoch 144, train_loss: 0.8114
2023-05-31 03:12:46 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 1.6102
2023-05-31 03:12:47 - eval: epoch: 144, acc1: 77.930%, acc5: 93.080%, test_loss: 1.0239, per_image_load_time: 0.082ms, per_image_inference_time: 0.054ms
2023-05-31 03:12:48 - until epoch: 144, best_acc1: 77.930%
2023-05-31 03:12:48 - epoch 145 lr: 0.004000
2023-05-31 03:12:48 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.7612
2023-05-31 03:12:49 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 0.1234
2023-05-31 03:12:52 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 1.3479
2023-05-31 03:12:52 - train: epoch 0145, iter [00050, 00390], lr: 0.004000, loss: 0.8118
2023-05-31 03:12:52 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 0.2793
2023-05-31 03:12:55 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.1796
2023-05-31 03:12:55 - train: epoch 0145, iter [00100, 00390], lr: 0.004000, loss: 0.8224
2023-05-31 03:12:56 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 0.7286
2023-05-31 03:12:58 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 1.3249
2023-05-31 03:12:59 - train: epoch 0145, iter [00150, 00390], lr: 0.004000, loss: 0.8175
2023-05-31 03:12:59 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 0.3475
2023-05-31 03:13:01 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 1.4676
2023-05-31 03:13:02 - train: epoch 0145, iter [00200, 00390], lr: 0.004000, loss: 0.8144
2023-05-31 03:13:02 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 0.0949
2023-05-31 03:13:05 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 1.4848
2023-05-31 03:13:05 - train: epoch 0145, iter [00250, 00390], lr: 0.004000, loss: 0.8057
2023-05-31 03:13:05 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.0131
2023-05-31 03:13:07 - train: epoch 200, train_loss: 1.0094
2023-05-31 03:13:08 - train: epoch 0145, iter [00300, 00390], lr: 0.004000, loss: 0.8030
2023-05-31 03:13:08 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.0235
2023-05-31 03:13:09 - eval: epoch: 200, acc1: 79.320%, acc5: 94.600%, test_loss: 0.8038, per_image_load_time: 0.088ms, per_image_inference_time: 0.055ms
2023-05-31 03:13:10 - until epoch: 200, best_acc1: 79.760%
2023-05-31 03:13:10 - train done. model: resnet18cifar, train time: 1.284 hours, best_acc1: 79.760%
2023-05-31 03:13:10 - train: epoch 151, train_loss: 0.3377
2023-05-31 03:13:10 - train: epoch 0145, iter [00350, 00390], lr: 0.004000, loss: 0.8125
2023-05-31 03:13:12 - eval: epoch: 151, acc1: 75.680%, acc5: 93.660%, test_loss: 1.0535, per_image_load_time: 0.064ms, per_image_inference_time: 0.049ms
2023-05-31 03:13:12 - until epoch: 151, best_acc1: 76.610%
2023-05-31 03:13:12 - epoch 152 lr: 0.004000
2023-05-31 03:13:12 - train: epoch 145, train_loss: 0.8107
2023-05-31 03:13:14 - eval: epoch: 145, acc1: 77.910%, acc5: 93.030%, test_loss: 1.0269, per_image_load_time: 0.067ms, per_image_inference_time: 0.059ms
2023-05-31 03:13:14 - until epoch: 145, best_acc1: 77.930%
2023-05-31 03:13:14 - epoch 146 lr: 0.004000
2023-05-31 03:13:14 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 0.0800
2023-05-31 03:13:17 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.0300
2023-05-31 03:13:17 - train: epoch 0146, iter [00050, 00390], lr: 0.004000, loss: 0.8174
2023-05-31 03:13:19 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.0215
2023-05-31 03:13:19 - train: epoch 0146, iter [00100, 00390], lr: 0.004000, loss: 0.8271
2023-05-31 03:13:21 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.0357
2023-05-31 03:13:22 - train: epoch 0146, iter [00150, 00390], lr: 0.004000, loss: 0.8408
2023-05-31 03:13:23 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.0156
2023-05-31 03:13:24 - train: epoch 0146, iter [00200, 00390], lr: 0.004000, loss: 0.8152
2023-05-31 03:13:25 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 0.2433
2023-05-31 03:13:26 - train: epoch 0146, iter [00250, 00390], lr: 0.004000, loss: 0.8041
2023-05-31 03:13:28 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 0.1320
2023-05-31 03:13:28 - train: epoch 0146, iter [00300, 00390], lr: 0.004000, loss: 0.8114
2023-05-31 03:13:29 - train: epoch 152, train_loss: 0.3071
2023-05-31 03:13:30 - train: epoch 0146, iter [00350, 00390], lr: 0.004000, loss: 0.8114
2023-05-31 03:13:31 - eval: epoch: 152, acc1: 75.670%, acc5: 93.360%, test_loss: 1.0686, per_image_load_time: 0.066ms, per_image_inference_time: 0.049ms
2023-05-31 03:13:31 - until epoch: 152, best_acc1: 76.610%
2023-05-31 03:13:31 - epoch 153 lr: 0.004000
2023-05-31 03:13:32 - train: epoch 146, train_loss: 0.8099
2023-05-31 03:13:33 - eval: epoch: 146, acc1: 78.230%, acc5: 93.010%, test_loss: 1.0268, per_image_load_time: 0.071ms, per_image_inference_time: 0.048ms
2023-05-31 03:13:33 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.0418
2023-05-31 03:13:34 - until epoch: 146, best_acc1: 78.230%
2023-05-31 03:13:34 - epoch 147 lr: 0.004000
2023-05-31 03:13:35 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 0.2540
2023-05-31 03:13:37 - train: epoch 0147, iter [00050, 00390], lr: 0.004000, loss: 0.8089
2023-05-31 03:13:37 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 0.5378
2023-05-31 03:13:39 - train: epoch 0147, iter [00100, 00390], lr: 0.004000, loss: 0.8068
2023-05-31 03:13:40 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 0.3196
2023-05-31 03:13:41 - train: epoch 0147, iter [00150, 00390], lr: 0.004000, loss: 0.8209
2023-05-31 03:13:42 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 0.0519
2023-05-31 03:13:44 - train: epoch 0147, iter [00200, 00390], lr: 0.004000, loss: 0.8253
2023-05-31 03:13:44 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 0.6897
2023-05-31 03:13:46 - train: epoch 0147, iter [00250, 00390], lr: 0.004000, loss: 0.8127
2023-05-31 03:13:46 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 0.2770
2023-05-31 03:13:48 - train: epoch 0147, iter [00300, 00390], lr: 0.004000, loss: 0.8210
2023-05-31 03:13:48 - train: epoch 153, train_loss: 0.3663
2023-05-31 03:13:50 - eval: epoch: 153, acc1: 75.510%, acc5: 93.660%, test_loss: 1.0376, per_image_load_time: 0.064ms, per_image_inference_time: 0.051ms
2023-05-31 03:13:50 - train: epoch 0147, iter [00350, 00390], lr: 0.004000, loss: 0.8143
2023-05-31 03:13:50 - until epoch: 153, best_acc1: 76.610%
2023-05-31 03:13:50 - epoch 154 lr: 0.004000
2023-05-31 03:13:51 - train: epoch 147, train_loss: 0.8100
2023-05-31 03:13:52 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 1.4862
2023-05-31 03:13:53 - eval: epoch: 147, acc1: 78.250%, acc5: 93.260%, test_loss: 1.0227, per_image_load_time: 0.064ms, per_image_inference_time: 0.050ms
2023-05-31 03:13:53 - until epoch: 147, best_acc1: 78.250%
2023-05-31 03:13:53 - epoch 148 lr: 0.004000
2023-05-31 03:13:54 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 0.3741
2023-05-31 03:13:56 - train: epoch 0148, iter [00050, 00390], lr: 0.004000, loss: 0.8135
2023-05-31 03:13:56 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 0.0358
2023-05-31 03:13:58 - train: epoch 0148, iter [00100, 00390], lr: 0.004000, loss: 0.8047
2023-05-31 03:13:58 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 0.0719
2023-05-31 03:14:00 - train: epoch 0148, iter [00150, 00390], lr: 0.004000, loss: 0.7906
2023-05-31 03:14:01 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 0.0401
2023-05-31 03:14:03 - train: epoch 0148, iter [00200, 00390], lr: 0.004000, loss: 0.8025
2023-05-31 03:14:03 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 0.1101
2023-05-31 03:14:05 - train: epoch 0148, iter [00250, 00390], lr: 0.004000, loss: 0.8265
2023-05-31 03:14:05 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.0213
2023-05-31 03:14:07 - train: epoch 154, train_loss: 0.3066
2023-05-31 03:14:07 - train: epoch 0148, iter [00300, 00390], lr: 0.004000, loss: 0.7895
2023-05-31 03:14:08 - eval: epoch: 154, acc1: 75.560%, acc5: 93.840%, test_loss: 1.0222, per_image_load_time: 0.065ms, per_image_inference_time: 0.047ms
2023-05-31 03:14:09 - until epoch: 154, best_acc1: 76.610%
2023-05-31 03:14:09 - epoch 155 lr: 0.004000
2023-05-31 03:14:09 - train: epoch 0148, iter [00350, 00390], lr: 0.004000, loss: 0.7960
2023-05-31 03:14:10 - train: epoch 148, train_loss: 0.8085
2023-05-31 03:14:11 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 0.1780
2023-05-31 03:14:12 - eval: epoch: 148, acc1: 78.110%, acc5: 92.990%, test_loss: 1.0285, per_image_load_time: 0.068ms, per_image_inference_time: 0.051ms
2023-05-31 03:14:12 - until epoch: 148, best_acc1: 78.250%
2023-05-31 03:14:12 - epoch 149 lr: 0.004000
2023-05-31 03:14:13 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 0.2166
2023-05-31 03:14:15 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 0.5962
2023-05-31 03:14:15 - train: epoch 0149, iter [00050, 00390], lr: 0.004000, loss: 0.7963
2023-05-31 03:14:17 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 0.2214
2023-05-31 03:14:17 - train: epoch 0149, iter [00100, 00390], lr: 0.004000, loss: 0.8063
2023-05-31 03:14:19 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 0.1503
2023-05-31 03:14:20 - train: epoch 0149, iter [00150, 00390], lr: 0.004000, loss: 0.8067
2023-05-31 03:14:22 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.0479
2023-05-31 03:14:22 - train: epoch 0149, iter [00200, 00390], lr: 0.004000, loss: 0.7998
2023-05-31 03:14:24 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 0.8266
2023-05-31 03:14:24 - train: epoch 0149, iter [00250, 00390], lr: 0.004000, loss: 0.8236
2023-05-31 03:14:26 - train: epoch 155, train_loss: 0.3108
2023-05-31 03:14:26 - train: epoch 0149, iter [00300, 00390], lr: 0.004000, loss: 0.8051
2023-05-31 03:14:27 - eval: epoch: 155, acc1: 75.610%, acc5: 93.410%, test_loss: 1.0596, per_image_load_time: 0.062ms, per_image_inference_time: 0.051ms
2023-05-31 03:14:27 - until epoch: 155, best_acc1: 76.610%
2023-05-31 03:14:27 - epoch 156 lr: 0.004000
2023-05-31 03:14:28 - train: epoch 0149, iter [00350, 00390], lr: 0.004000, loss: 0.7940
2023-05-31 03:14:30 - train: epoch 149, train_loss: 0.8080
2023-05-31 03:14:30 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 0.1124
2023-05-31 03:14:31 - eval: epoch: 149, acc1: 77.680%, acc5: 93.120%, test_loss: 1.0337, per_image_load_time: 0.071ms, per_image_inference_time: 0.047ms
2023-05-31 03:14:31 - until epoch: 149, best_acc1: 78.250%
2023-05-31 03:14:31 - epoch 150 lr: 0.004000
2023-05-31 03:14:32 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 0.0541
2023-05-31 03:14:34 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 0.0659
2023-05-31 03:14:34 - train: epoch 0150, iter [00050, 00390], lr: 0.004000, loss: 0.8325
2023-05-31 03:14:36 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.0058
2023-05-31 03:14:37 - train: epoch 0150, iter [00100, 00390], lr: 0.004000, loss: 0.8066
2023-05-31 03:14:38 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.0190
2023-05-31 03:14:39 - train: epoch 0150, iter [00150, 00390], lr: 0.004000, loss: 0.7994
2023-05-31 03:14:40 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 0.1267
2023-05-31 03:14:41 - train: epoch 0150, iter [00200, 00390], lr: 0.004000, loss: 0.8096
2023-05-31 03:14:43 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 0.4679
2023-05-31 03:14:43 - train: epoch 0150, iter [00250, 00390], lr: 0.004000, loss: 0.8242
2023-05-31 03:14:45 - train: epoch 156, train_loss: 0.3083
2023-05-31 03:14:45 - train: epoch 0150, iter [00300, 00390], lr: 0.004000, loss: 0.7954
2023-05-31 03:14:46 - eval: epoch: 156, acc1: 75.950%, acc5: 93.540%, test_loss: 1.0205, per_image_load_time: 0.066ms, per_image_inference_time: 0.049ms
2023-05-31 03:14:46 - until epoch: 156, best_acc1: 76.610%
2023-05-31 03:14:46 - epoch 157 lr: 0.004000
2023-05-31 03:14:47 - train: epoch 0150, iter [00350, 00390], lr: 0.004000, loss: 0.8222
2023-05-31 03:14:49 - train: epoch 150, train_loss: 0.8080
2023-05-31 03:14:49 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 1.5701
2023-05-31 03:14:50 - eval: epoch: 150, acc1: 77.690%, acc5: 93.310%, test_loss: 1.0279, per_image_load_time: 0.068ms, per_image_inference_time: 0.057ms
2023-05-31 03:14:50 - until epoch: 150, best_acc1: 78.250%
2023-05-31 03:14:50 - epoch 151 lr: 0.004000
2023-05-31 03:14:51 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.0240
2023-05-31 03:14:53 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 0.1506
2023-05-31 03:14:54 - train: epoch 0151, iter [00050, 00390], lr: 0.004000, loss: 0.8091
2023-05-31 03:14:55 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 0.4849
2023-05-31 03:14:56 - train: epoch 0151, iter [00100, 00390], lr: 0.004000, loss: 0.8071
2023-05-31 03:14:57 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 0.1901
2023-05-31 03:14:58 - train: epoch 0151, iter [00150, 00390], lr: 0.004000, loss: 0.8436
2023-05-31 03:14:59 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.0323
2023-05-31 03:15:00 - train: epoch 0151, iter [00200, 00390], lr: 0.004000, loss: 0.8228
2023-05-31 03:15:02 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 0.1921
2023-05-31 03:15:03 - train: epoch 0151, iter [00250, 00390], lr: 0.004000, loss: 0.7960
2023-05-31 03:15:03 - train: epoch 157, train_loss: 0.3163
2023-05-31 03:15:04 - train: epoch 0151, iter [00300, 00390], lr: 0.004000, loss: 0.8168
2023-05-31 03:15:05 - eval: epoch: 157, acc1: 75.820%, acc5: 93.570%, test_loss: 1.0392, per_image_load_time: 0.066ms, per_image_inference_time: 0.055ms
2023-05-31 03:15:05 - until epoch: 157, best_acc1: 76.610%
2023-05-31 03:15:05 - epoch 158 lr: 0.004000
2023-05-31 03:15:06 - train: epoch 0151, iter [00350, 00390], lr: 0.004000, loss: 0.7872
2023-05-31 03:15:08 - train: epoch 151, train_loss: 0.8085
2023-05-31 03:15:08 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.0657
2023-05-31 03:15:09 - eval: epoch: 151, acc1: 78.000%, acc5: 93.320%, test_loss: 1.0289, per_image_load_time: 0.064ms, per_image_inference_time: 0.049ms
2023-05-31 03:15:09 - until epoch: 151, best_acc1: 78.250%
2023-05-31 03:15:09 - epoch 152 lr: 0.004000
2023-05-31 03:15:10 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 0.6832
2023-05-31 03:15:12 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 0.1574
2023-05-31 03:15:12 - train: epoch 0152, iter [00050, 00390], lr: 0.004000, loss: 0.8094
2023-05-31 03:15:14 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 0.3132
2023-05-31 03:15:15 - train: epoch 0152, iter [00100, 00390], lr: 0.004000, loss: 0.8130
2023-05-31 03:15:16 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 0.1133
2023-05-31 03:15:17 - train: epoch 0152, iter [00150, 00390], lr: 0.004000, loss: 0.7881
2023-05-31 03:15:18 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 0.0939
2023-05-31 03:15:19 - train: epoch 0152, iter [00200, 00390], lr: 0.004000, loss: 0.7987
2023-05-31 03:15:21 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 0.5140
2023-05-31 03:15:21 - train: epoch 0152, iter [00250, 00390], lr: 0.004000, loss: 0.8028
2023-05-31 03:15:23 - train: epoch 158, train_loss: 0.3335
2023-05-31 03:15:23 - train: epoch 0152, iter [00300, 00390], lr: 0.004000, loss: 0.7959
2023-05-31 03:15:24 - eval: epoch: 158, acc1: 75.760%, acc5: 93.660%, test_loss: 1.0337, per_image_load_time: 0.068ms, per_image_inference_time: 0.049ms
2023-05-31 03:15:25 - until epoch: 158, best_acc1: 76.610%
2023-05-31 03:15:25 - epoch 159 lr: 0.004000
2023-05-31 03:15:25 - train: epoch 0152, iter [00350, 00390], lr: 0.004000, loss: 0.8182
2023-05-31 03:15:26 - train: epoch 152, train_loss: 0.8074
2023-05-31 03:15:27 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 0.7813
2023-05-31 03:15:28 - eval: epoch: 152, acc1: 77.950%, acc5: 93.180%, test_loss: 1.0318, per_image_load_time: 0.066ms, per_image_inference_time: 0.050ms
2023-05-31 03:15:28 - until epoch: 152, best_acc1: 78.250%
2023-05-31 03:15:28 - epoch 153 lr: 0.004000
2023-05-31 03:15:29 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 0.6076
2023-05-31 03:15:31 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.0296
2023-05-31 03:15:31 - train: epoch 0153, iter [00050, 00390], lr: 0.004000, loss: 0.8105
2023-05-31 03:15:33 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.0205
2023-05-31 03:15:34 - train: epoch 0153, iter [00100, 00390], lr: 0.004000, loss: 0.8073
2023-05-31 03:15:36 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 0.2424
2023-05-31 03:15:36 - train: epoch 0153, iter [00150, 00390], lr: 0.004000, loss: 0.8194
2023-05-31 03:15:38 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 0.4257
2023-05-31 03:15:38 - train: epoch 0153, iter [00200, 00390], lr: 0.004000, loss: 0.8085
2023-05-31 03:15:40 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.0568
2023-05-31 03:15:40 - train: epoch 0153, iter [00250, 00390], lr: 0.004000, loss: 0.8164
2023-05-31 03:15:42 - train: epoch 159, train_loss: 0.3516
2023-05-31 03:15:42 - train: epoch 0153, iter [00300, 00390], lr: 0.004000, loss: 0.8051
2023-05-31 03:15:43 - eval: epoch: 159, acc1: 75.460%, acc5: 93.880%, test_loss: 1.0475, per_image_load_time: 0.071ms, per_image_inference_time: 0.049ms
2023-05-31 03:15:44 - until epoch: 159, best_acc1: 76.610%
2023-05-31 03:15:44 - epoch 160 lr: 0.004000
2023-05-31 03:15:44 - train: epoch 0153, iter [00350, 00390], lr: 0.004000, loss: 0.7881
2023-05-31 03:15:46 - train: epoch 153, train_loss: 0.8070
2023-05-31 03:15:46 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 0.2502
2023-05-31 03:15:47 - eval: epoch: 153, acc1: 77.880%, acc5: 93.120%, test_loss: 1.0309, per_image_load_time: 0.064ms, per_image_inference_time: 0.050ms
2023-05-31 03:15:48 - until epoch: 153, best_acc1: 78.250%
2023-05-31 03:15:48 - epoch 154 lr: 0.004000
2023-05-31 03:15:48 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 0.2975
2023-05-31 03:15:50 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 0.2078
2023-05-31 03:15:51 - train: epoch 0154, iter [00050, 00390], lr: 0.004000, loss: 0.8265
2023-05-31 03:15:52 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 0.2128
2023-05-31 03:15:53 - train: epoch 0154, iter [00100, 00390], lr: 0.004000, loss: 0.8066
2023-05-31 03:15:54 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 0.5564
2023-05-31 03:15:55 - train: epoch 0154, iter [00150, 00390], lr: 0.004000, loss: 0.8255
2023-05-31 03:15:57 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 0.0979
2023-05-31 03:15:58 - train: epoch 0154, iter [00200, 00390], lr: 0.004000, loss: 0.7982
2023-05-31 03:15:59 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.0450
2023-05-31 03:16:00 - train: epoch 0154, iter [00250, 00390], lr: 0.004000, loss: 0.8161
2023-05-31 03:16:01 - train: epoch 160, train_loss: 0.3659
2023-05-31 03:16:02 - train: epoch 0154, iter [00300, 00390], lr: 0.004000, loss: 0.8120
2023-05-31 03:16:02 - eval: epoch: 160, acc1: 74.500%, acc5: 93.090%, test_loss: 1.1141, per_image_load_time: 0.068ms, per_image_inference_time: 0.047ms
2023-05-31 03:16:03 - until epoch: 160, best_acc1: 76.610%
2023-05-31 03:16:03 - epoch 161 lr: 0.000800
2023-05-31 03:16:03 - train: epoch 0154, iter [00350, 00390], lr: 0.004000, loss: 0.8018
2023-05-31 03:16:05 - train: epoch 154, train_loss: 0.8071
2023-05-31 03:16:05 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 0.1815
2023-05-31 03:16:06 - eval: epoch: 154, acc1: 77.860%, acc5: 93.110%, test_loss: 1.0327, per_image_load_time: 0.067ms, per_image_inference_time: 0.049ms
2023-05-31 03:16:07 - until epoch: 154, best_acc1: 78.250%
2023-05-31 03:16:07 - epoch 155 lr: 0.004000
2023-05-31 03:16:07 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.0084
2023-05-31 03:16:09 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.0076
2023-05-31 03:16:10 - train: epoch 0155, iter [00050, 00390], lr: 0.004000, loss: 0.7971
2023-05-31 03:16:12 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 0.7330
2023-05-31 03:16:12 - train: epoch 0155, iter [00100, 00390], lr: 0.004000, loss: 0.8085
2023-05-31 03:16:14 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.0259
2023-05-31 03:16:14 - train: epoch 0155, iter [00150, 00390], lr: 0.004000, loss: 0.8009
2023-05-31 03:16:16 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 0.4787
2023-05-31 03:16:17 - train: epoch 0155, iter [00200, 00390], lr: 0.004000, loss: 0.8063
2023-05-31 03:16:19 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 0.1221
2023-05-31 03:16:19 - train: epoch 0155, iter [00250, 00390], lr: 0.004000, loss: 0.7972
2023-05-31 03:16:20 - train: epoch 161, train_loss: 0.2706
2023-05-31 03:16:21 - train: epoch 0155, iter [00300, 00390], lr: 0.004000, loss: 0.8175
2023-05-31 03:16:22 - eval: epoch: 161, acc1: 76.400%, acc5: 93.840%, test_loss: 1.0117, per_image_load_time: 0.067ms, per_image_inference_time: 0.047ms
2023-05-31 03:16:22 - until epoch: 161, best_acc1: 76.610%
2023-05-31 03:16:22 - epoch 162 lr: 0.000800
2023-05-31 03:16:22 - train: epoch 0155, iter [00350, 00390], lr: 0.004000, loss: 0.7903
2023-05-31 03:16:24 - train: epoch 155, train_loss: 0.8060
2023-05-31 03:16:25 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 0.3101
2023-05-31 03:16:26 - eval: epoch: 155, acc1: 77.890%, acc5: 93.260%, test_loss: 1.0326, per_image_load_time: 0.071ms, per_image_inference_time: 0.053ms
2023-05-31 03:16:26 - until epoch: 155, best_acc1: 78.250%
2023-05-31 03:16:26 - epoch 156 lr: 0.004000
2023-05-31 03:16:26 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 0.0305
2023-05-31 03:16:29 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 0.2052
2023-05-31 03:16:29 - train: epoch 0156, iter [00050, 00390], lr: 0.004000, loss: 0.8055
2023-05-31 03:16:31 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 0.2017
2023-05-31 03:16:31 - train: epoch 0156, iter [00100, 00390], lr: 0.004000, loss: 0.7949
2023-05-31 03:16:33 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.0245
2023-05-31 03:16:33 - train: epoch 0156, iter [00150, 00390], lr: 0.004000, loss: 0.8212
2023-05-31 03:16:35 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 0.6190
2023-05-31 03:16:36 - train: epoch 0156, iter [00200, 00390], lr: 0.004000, loss: 0.7921
2023-05-31 03:16:38 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 0.1872
2023-05-31 03:16:38 - train: epoch 0156, iter [00250, 00390], lr: 0.004000, loss: 0.8194
2023-05-31 03:16:39 - train: epoch 162, train_loss: 0.2774
2023-05-31 03:16:40 - train: epoch 0156, iter [00300, 00390], lr: 0.004000, loss: 0.8089
2023-05-31 03:16:41 - eval: epoch: 162, acc1: 76.690%, acc5: 93.880%, test_loss: 0.9855, per_image_load_time: 0.071ms, per_image_inference_time: 0.046ms
2023-05-31 03:16:41 - until epoch: 162, best_acc1: 76.690%
2023-05-31 03:16:41 - epoch 163 lr: 0.000800
2023-05-31 03:16:42 - train: epoch 0156, iter [00350, 00390], lr: 0.004000, loss: 0.8071
2023-05-31 03:16:43 - train: epoch 156, train_loss: 0.8054
2023-05-31 03:16:44 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 0.0994
2023-05-31 03:16:45 - eval: epoch: 156, acc1: 77.870%, acc5: 93.150%, test_loss: 1.0342, per_image_load_time: 0.066ms, per_image_inference_time: 0.049ms
2023-05-31 03:16:45 - until epoch: 156, best_acc1: 78.250%
2023-05-31 03:16:45 - epoch 157 lr: 0.004000
2023-05-31 03:16:45 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 2.6330
2023-05-31 03:16:48 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 0.0313
2023-05-31 03:16:48 - train: epoch 0157, iter [00050, 00390], lr: 0.004000, loss: 0.8255
2023-05-31 03:16:50 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 0.0993
2023-05-31 03:16:50 - train: epoch 0157, iter [00100, 00390], lr: 0.004000, loss: 0.7924
2023-05-31 03:16:52 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 0.0274
2023-05-31 03:16:53 - train: epoch 0157, iter [00150, 00390], lr: 0.004000, loss: 0.8138
2023-05-31 03:16:54 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 0.8734
2023-05-31 03:16:55 - train: epoch 0157, iter [00200, 00390], lr: 0.004000, loss: 0.7948
2023-05-31 03:16:56 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 0.8862
2023-05-31 03:16:57 - train: epoch 0157, iter [00250, 00390], lr: 0.004000, loss: 0.8157
2023-05-31 03:16:58 - train: epoch 163, train_loss: 0.2602
2023-05-31 03:16:59 - train: epoch 0157, iter [00300, 00390], lr: 0.004000, loss: 0.7949
2023-05-31 03:17:00 - eval: epoch: 163, acc1: 76.460%, acc5: 94.030%, test_loss: 0.9818, per_image_load_time: 0.065ms, per_image_inference_time: 0.049ms
2023-05-31 03:17:00 - until epoch: 163, best_acc1: 76.690%
2023-05-31 03:17:00 - epoch 164 lr: 0.000800
2023-05-31 03:17:01 - train: epoch 0157, iter [00350, 00390], lr: 0.004000, loss: 0.8050
2023-05-31 03:17:03 - train: epoch 157, train_loss: 0.8063
2023-05-31 03:17:03 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 0.0494
2023-05-31 03:17:04 - eval: epoch: 157, acc1: 77.740%, acc5: 93.140%, test_loss: 1.0353, per_image_load_time: 0.071ms, per_image_inference_time: 0.048ms
2023-05-31 03:17:04 - until epoch: 157, best_acc1: 78.250%
2023-05-31 03:17:04 - epoch 158 lr: 0.004000
2023-05-31 03:17:05 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 0.8171
2023-05-31 03:17:06 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 0.3858
2023-05-31 03:17:07 - train: epoch 0158, iter [00050, 00390], lr: 0.004000, loss: 0.8039
2023-05-31 03:17:09 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 0.0966
2023-05-31 03:17:10 - train: epoch 0158, iter [00100, 00390], lr: 0.004000, loss: 0.7954
2023-05-31 03:17:11 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.0173
2023-05-31 03:17:12 - train: epoch 0158, iter [00150, 00390], lr: 0.004000, loss: 0.7991
2023-05-31 03:17:13 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.0370
2023-05-31 03:17:14 - train: epoch 0158, iter [00200, 00390], lr: 0.004000, loss: 0.8183
2023-05-31 03:17:15 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 0.3598
2023-05-31 03:17:16 - train: epoch 0158, iter [00250, 00390], lr: 0.004000, loss: 0.8139
2023-05-31 03:17:17 - train: epoch 164, train_loss: 0.2872
2023-05-31 03:17:18 - train: epoch 0158, iter [00300, 00390], lr: 0.004000, loss: 0.7968
2023-05-31 03:17:19 - eval: epoch: 164, acc1: 76.460%, acc5: 93.880%, test_loss: 1.0117, per_image_load_time: 0.066ms, per_image_inference_time: 0.049ms
2023-05-31 03:17:19 - until epoch: 164, best_acc1: 76.690%
2023-05-31 03:17:19 - epoch 165 lr: 0.000800
2023-05-31 03:17:20 - train: epoch 0158, iter [00350, 00390], lr: 0.004000, loss: 0.8227
2023-05-31 03:17:22 - train: epoch 158, train_loss: 0.8061
2023-05-31 03:17:22 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.0121
2023-05-31 03:17:23 - eval: epoch: 158, acc1: 77.800%, acc5: 93.190%, test_loss: 1.0339, per_image_load_time: 0.080ms, per_image_inference_time: 0.052ms
2023-05-31 03:17:24 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.0051
2023-05-31 03:17:24 - until epoch: 158, best_acc1: 78.250%
2023-05-31 03:17:24 - epoch 159 lr: 0.004000
2023-05-31 03:17:25 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 0.4877
2023-05-31 03:17:27 - train: epoch 0159, iter [00050, 00390], lr: 0.004000, loss: 0.8029
2023-05-31 03:17:28 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 0.1301
2023-05-31 03:17:29 - train: epoch 0159, iter [00100, 00390], lr: 0.004000, loss: 0.8156
2023-05-31 03:17:30 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 0.2325
2023-05-31 03:17:31 - train: epoch 0159, iter [00150, 00390], lr: 0.004000, loss: 0.7980
2023-05-31 03:17:32 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.0069
2023-05-31 03:17:33 - train: epoch 0159, iter [00200, 00390], lr: 0.004000, loss: 0.7933
2023-05-31 03:17:34 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.0165
2023-05-31 03:17:36 - train: epoch 0159, iter [00250, 00390], lr: 0.004000, loss: 0.8064
2023-05-31 03:17:36 - train: epoch 165, train_loss: 0.2903
2023-05-31 03:17:37 - train: epoch 0159, iter [00300, 00390], lr: 0.004000, loss: 0.8135
2023-05-31 03:17:38 - eval: epoch: 165, acc1: 76.310%, acc5: 93.880%, test_loss: 1.0195, per_image_load_time: 0.073ms, per_image_inference_time: 0.046ms
2023-05-31 03:17:38 - until epoch: 165, best_acc1: 76.690%
2023-05-31 03:17:38 - epoch 166 lr: 0.000800
2023-05-31 03:17:39 - train: epoch 0159, iter [00350, 00390], lr: 0.004000, loss: 0.8066
2023-05-31 03:17:41 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 0.0938
2023-05-31 03:17:41 - train: epoch 159, train_loss: 0.8054
2023-05-31 03:17:42 - eval: epoch: 159, acc1: 77.890%, acc5: 93.130%, test_loss: 1.0425, per_image_load_time: 0.067ms, per_image_inference_time: 0.048ms
2023-05-31 03:17:43 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 1.1459
2023-05-31 03:17:43 - until epoch: 159, best_acc1: 78.250%
2023-05-31 03:17:43 - epoch 160 lr: 0.004000
2023-05-31 03:17:44 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 0.1353
2023-05-31 03:17:46 - train: epoch 0160, iter [00050, 00390], lr: 0.004000, loss: 0.8360
2023-05-31 03:17:46 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 0.1180
2023-05-31 03:17:48 - train: epoch 0160, iter [00100, 00390], lr: 0.004000, loss: 0.7940
2023-05-31 03:17:49 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 0.2996
2023-05-31 03:17:50 - train: epoch 0160, iter [00150, 00390], lr: 0.004000, loss: 0.8136
2023-05-31 03:17:51 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 0.1864
2023-05-31 03:17:53 - train: epoch 0160, iter [00200, 00390], lr: 0.004000, loss: 0.8076
2023-05-31 03:17:53 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 0.9198
2023-05-31 03:17:55 - train: epoch 0160, iter [00250, 00390], lr: 0.004000, loss: 0.7921
2023-05-31 03:17:55 - train: epoch 166, train_loss: 0.2350
2023-05-31 03:17:57 - train: epoch 0160, iter [00300, 00390], lr: 0.004000, loss: 0.8062
2023-05-31 03:17:57 - eval: epoch: 166, acc1: 76.650%, acc5: 93.970%, test_loss: 0.9884, per_image_load_time: 0.074ms, per_image_inference_time: 0.048ms
2023-05-31 03:17:57 - until epoch: 166, best_acc1: 76.690%
2023-05-31 03:17:57 - epoch 167 lr: 0.000800
2023-05-31 03:17:58 - train: epoch 0160, iter [00350, 00390], lr: 0.004000, loss: 0.8026
2023-05-31 03:18:00 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.0125
2023-05-31 03:18:00 - train: epoch 160, train_loss: 0.8054
2023-05-31 03:18:01 - eval: epoch: 160, acc1: 78.320%, acc5: 93.150%, test_loss: 1.0328, per_image_load_time: 0.067ms, per_image_inference_time: 0.049ms
2023-05-31 03:18:02 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 0.2971
2023-05-31 03:18:02 - until epoch: 160, best_acc1: 78.320%
2023-05-31 03:18:02 - epoch 161 lr: 0.000800
2023-05-31 03:18:03 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 0.0171
2023-05-31 03:18:05 - train: epoch 0161, iter [00050, 00390], lr: 0.000800, loss: 0.8105
2023-05-31 03:18:05 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 0.0566
2023-05-31 03:18:07 - train: epoch 0161, iter [00100, 00390], lr: 0.000800, loss: 0.8058
2023-05-31 03:18:08 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 1.2930
2023-05-31 03:18:10 - train: epoch 0161, iter [00150, 00390], lr: 0.000800, loss: 0.8117
2023-05-31 03:18:10 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.0090
2023-05-31 03:18:12 - train: epoch 0161, iter [00200, 00390], lr: 0.000800, loss: 0.8056
2023-05-31 03:18:12 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.0160
2023-05-31 03:18:14 - train: epoch 167, train_loss: 0.2725
2023-05-31 03:18:14 - train: epoch 0161, iter [00250, 00390], lr: 0.000800, loss: 0.8113
2023-05-31 03:18:15 - eval: epoch: 167, acc1: 76.390%, acc5: 93.860%, test_loss: 1.0242, per_image_load_time: 0.061ms, per_image_inference_time: 0.048ms
2023-05-31 03:18:15 - until epoch: 167, best_acc1: 76.690%
2023-05-31 03:18:15 - epoch 168 lr: 0.000800
2023-05-31 03:18:16 - train: epoch 0161, iter [00300, 00390], lr: 0.000800, loss: 0.8054
2023-05-31 03:18:18 - train: epoch 0161, iter [00350, 00390], lr: 0.000800, loss: 0.8017
2023-05-31 03:18:18 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 0.5055
2023-05-31 03:18:19 - train: epoch 161, train_loss: 0.8038
2023-05-31 03:18:20 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 0.9795
2023-05-31 03:18:21 - eval: epoch: 161, acc1: 78.150%, acc5: 93.230%, test_loss: 1.0326, per_image_load_time: 0.066ms, per_image_inference_time: 0.048ms
2023-05-31 03:18:21 - until epoch: 161, best_acc1: 78.320%
2023-05-31 03:18:21 - epoch 162 lr: 0.000800
2023-05-31 03:18:22 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 1.0551
2023-05-31 03:18:24 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 0.5483
2023-05-31 03:18:24 - train: epoch 0162, iter [00050, 00390], lr: 0.000800, loss: 0.7988
2023-05-31 03:18:26 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 0.0988
2023-05-31 03:18:26 - train: epoch 0162, iter [00100, 00390], lr: 0.000800, loss: 0.8086
2023-05-31 03:18:29 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.0072
2023-05-31 03:18:29 - train: epoch 0162, iter [00150, 00390], lr: 0.000800, loss: 0.8097
2023-05-31 03:18:31 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 0.1236
2023-05-31 03:18:31 - train: epoch 0162, iter [00200, 00390], lr: 0.000800, loss: 0.7952
2023-05-31 03:18:33 - train: epoch 168, train_loss: 0.2772
2023-05-31 03:18:33 - train: epoch 0162, iter [00250, 00390], lr: 0.000800, loss: 0.8010
2023-05-31 03:18:34 - eval: epoch: 168, acc1: 76.530%, acc5: 93.870%, test_loss: 1.0128, per_image_load_time: 0.072ms, per_image_inference_time: 0.047ms
2023-05-31 03:18:34 - until epoch: 168, best_acc1: 76.690%
2023-05-31 03:18:34 - epoch 169 lr: 0.000800
2023-05-31 03:18:35 - train: epoch 0162, iter [00300, 00390], lr: 0.000800, loss: 0.8036
2023-05-31 03:18:37 - train: epoch 0162, iter [00350, 00390], lr: 0.000800, loss: 0.7928
2023-05-31 03:18:37 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.0043
2023-05-31 03:18:39 - train: epoch 162, train_loss: 0.8025
2023-05-31 03:18:39 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 0.2001
2023-05-31 03:18:40 - eval: epoch: 162, acc1: 78.240%, acc5: 93.230%, test_loss: 1.0301, per_image_load_time: 0.068ms, per_image_inference_time: 0.049ms
2023-05-31 03:18:41 - until epoch: 162, best_acc1: 78.320%
2023-05-31 03:18:41 - epoch 163 lr: 0.000800
2023-05-31 03:18:41 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 0.1798
2023-05-31 03:18:43 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 1.0580
2023-05-31 03:18:44 - train: epoch 0163, iter [00050, 00390], lr: 0.000800, loss: 0.8115
2023-05-31 03:18:45 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.0079
2023-05-31 03:18:46 - train: epoch 0163, iter [00100, 00390], lr: 0.000800, loss: 0.8067
2023-05-31 03:18:48 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 0.4765
2023-05-31 03:18:48 - train: epoch 0163, iter [00150, 00390], lr: 0.000800, loss: 0.8006
2023-05-31 03:18:50 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.0181
2023-05-31 03:18:50 - train: epoch 0163, iter [00200, 00390], lr: 0.000800, loss: 0.7943
2023-05-31 03:18:52 - train: epoch 169, train_loss: 0.2564
2023-05-31 03:18:52 - train: epoch 0163, iter [00250, 00390], lr: 0.000800, loss: 0.8013
2023-05-31 03:18:53 - eval: epoch: 169, acc1: 76.540%, acc5: 93.920%, test_loss: 1.0004, per_image_load_time: 0.071ms, per_image_inference_time: 0.048ms
2023-05-31 03:18:53 - until epoch: 169, best_acc1: 76.690%
2023-05-31 03:18:53 - epoch 170 lr: 0.000800
2023-05-31 03:18:54 - train: epoch 0163, iter [00300, 00390], lr: 0.000800, loss: 0.8046
2023-05-31 03:18:56 - train: epoch 0163, iter [00350, 00390], lr: 0.000800, loss: 0.8192
2023-05-31 03:18:56 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 0.9897
2023-05-31 03:18:58 - train: epoch 163, train_loss: 0.8033
2023-05-31 03:18:58 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 0.3380
2023-05-31 03:19:00 - eval: epoch: 163, acc1: 78.510%, acc5: 93.210%, test_loss: 1.0278, per_image_load_time: 0.077ms, per_image_inference_time: 0.046ms
2023-05-31 03:19:00 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 0.1100
2023-05-31 03:19:00 - until epoch: 163, best_acc1: 78.510%
2023-05-31 03:19:00 - epoch 164 lr: 0.000800
2023-05-31 03:19:02 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.0168
2023-05-31 03:19:03 - train: epoch 0164, iter [00050, 00390], lr: 0.000800, loss: 0.7847
2023-05-31 03:19:04 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 0.1766
2023-05-31 03:19:06 - train: epoch 0164, iter [00100, 00390], lr: 0.000800, loss: 0.8060
2023-05-31 03:19:06 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 0.4169
2023-05-31 03:19:08 - train: epoch 0164, iter [00150, 00390], lr: 0.000800, loss: 0.8093
2023-05-31 03:19:08 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.0298
2023-05-31 03:19:10 - train: epoch 0164, iter [00200, 00390], lr: 0.000800, loss: 0.8030
2023-05-31 03:19:10 - train: epoch 170, train_loss: 0.2527
2023-05-31 03:19:12 - train: epoch 0164, iter [00250, 00390], lr: 0.000800, loss: 0.8008
2023-05-31 03:19:12 - eval: epoch: 170, acc1: 76.540%, acc5: 93.880%, test_loss: 1.0183, per_image_load_time: 0.068ms, per_image_inference_time: 0.052ms
2023-05-31 03:19:12 - until epoch: 170, best_acc1: 76.690%
2023-05-31 03:19:12 - epoch 171 lr: 0.000800
2023-05-31 03:19:13 - train: epoch 0164, iter [00300, 00390], lr: 0.000800, loss: 0.7961
2023-05-31 03:19:15 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.0194
2023-05-31 03:19:16 - train: epoch 0164, iter [00350, 00390], lr: 0.000800, loss: 0.7944
2023-05-31 03:19:17 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 0.1992
2023-05-31 03:19:18 - train: epoch 164, train_loss: 0.8016
2023-05-31 03:19:19 - eval: epoch: 164, acc1: 78.530%, acc5: 93.340%, test_loss: 1.0301, per_image_load_time: 0.069ms, per_image_inference_time: 0.048ms
2023-05-31 03:19:19 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.0095
2023-05-31 03:19:20 - until epoch: 164, best_acc1: 78.530%
2023-05-31 03:19:20 - epoch 165 lr: 0.000800
2023-05-31 03:19:21 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.0143
2023-05-31 03:19:23 - train: epoch 0165, iter [00050, 00390], lr: 0.000800, loss: 0.8065
2023-05-31 03:19:23 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.0064
2023-05-31 03:19:25 - train: epoch 0165, iter [00100, 00390], lr: 0.000800, loss: 0.7836
2023-05-31 03:19:25 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 1.8593
2023-05-31 03:19:27 - train: epoch 0165, iter [00150, 00390], lr: 0.000800, loss: 0.8124
2023-05-31 03:19:27 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 0.0550
2023-05-31 03:19:29 - train: epoch 171, train_loss: 0.2313
2023-05-31 03:19:29 - train: epoch 0165, iter [00200, 00390], lr: 0.000800, loss: 0.7939
2023-05-31 03:19:31 - eval: epoch: 171, acc1: 76.650%, acc5: 93.900%, test_loss: 1.0274, per_image_load_time: 0.063ms, per_image_inference_time: 0.046ms
2023-05-31 03:19:31 - until epoch: 171, best_acc1: 76.690%
2023-05-31 03:19:31 - epoch 172 lr: 0.000800
2023-05-31 03:19:31 - train: epoch 0165, iter [00250, 00390], lr: 0.000800, loss: 0.7986
2023-05-31 03:19:33 - train: epoch 0165, iter [00300, 00390], lr: 0.000800, loss: 0.7761
2023-05-31 03:19:34 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 2.0354
2023-05-31 03:19:35 - train: epoch 0165, iter [00350, 00390], lr: 0.000800, loss: 0.7998
2023-05-31 03:19:36 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.0124
2023-05-31 03:19:37 - train: epoch 165, train_loss: 0.8007
2023-05-31 03:19:38 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 1.5310
2023-05-31 03:19:39 - eval: epoch: 165, acc1: 78.390%, acc5: 93.290%, test_loss: 1.0285, per_image_load_time: 0.072ms, per_image_inference_time: 0.050ms
2023-05-31 03:19:39 - until epoch: 165, best_acc1: 78.530%
2023-05-31 03:19:39 - epoch 166 lr: 0.000800
2023-05-31 03:19:40 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 0.0923
2023-05-31 03:19:42 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.0175
2023-05-31 03:19:42 - train: epoch 0166, iter [00050, 00390], lr: 0.000800, loss: 0.7955
2023-05-31 03:19:44 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 0.2579
2023-05-31 03:19:44 - train: epoch 0166, iter [00100, 00390], lr: 0.000800, loss: 0.8161
2023-05-31 03:19:46 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.0124
2023-05-31 03:19:46 - train: epoch 0166, iter [00150, 00390], lr: 0.000800, loss: 0.8011
2023-05-31 03:19:48 - train: epoch 172, train_loss: 0.2302
2023-05-31 03:19:48 - train: epoch 0166, iter [00200, 00390], lr: 0.000800, loss: 0.7949
2023-05-31 03:19:49 - eval: epoch: 172, acc1: 76.790%, acc5: 94.030%, test_loss: 1.0032, per_image_load_time: 0.064ms, per_image_inference_time: 0.048ms
2023-05-31 03:19:50 - train: epoch 0166, iter [00250, 00390], lr: 0.000800, loss: 0.8066
2023-05-31 03:19:50 - until epoch: 172, best_acc1: 76.790%
2023-05-31 03:19:50 - epoch 173 lr: 0.000800
2023-05-31 03:19:52 - train: epoch 0166, iter [00300, 00390], lr: 0.000800, loss: 0.8038
2023-05-31 03:19:53 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 0.0720
2023-05-31 03:19:54 - train: epoch 0166, iter [00350, 00390], lr: 0.000800, loss: 0.8101
2023-05-31 03:19:55 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.0111
2023-05-31 03:19:56 - train: epoch 166, train_loss: 0.8007
2023-05-31 03:19:57 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 0.6776
2023-05-31 03:19:58 - eval: epoch: 166, acc1: 78.470%, acc5: 93.290%, test_loss: 1.0330, per_image_load_time: 0.073ms, per_image_inference_time: 0.052ms
2023-05-31 03:19:58 - until epoch: 166, best_acc1: 78.530%
2023-05-31 03:19:58 - epoch 167 lr: 0.000800
2023-05-31 03:19:59 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 0.0569
2023-05-31 03:20:01 - train: epoch 0167, iter [00050, 00390], lr: 0.000800, loss: 0.7997
2023-05-31 03:20:01 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 1.9096
2023-05-31 03:20:03 - train: epoch 0167, iter [00100, 00390], lr: 0.000800, loss: 0.7860
2023-05-31 03:20:03 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.0062
2023-05-31 03:20:05 - train: epoch 0167, iter [00150, 00390], lr: 0.000800, loss: 0.7984
2023-05-31 03:20:06 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 1.2399
2023-05-31 03:20:07 - train: epoch 0167, iter [00200, 00390], lr: 0.000800, loss: 0.7945
2023-05-31 03:20:07 - train: epoch 173, train_loss: 0.2467
2023-05-31 03:20:09 - eval: epoch: 173, acc1: 76.500%, acc5: 94.090%, test_loss: 1.0204, per_image_load_time: 0.065ms, per_image_inference_time: 0.049ms
2023-05-31 03:20:09 - train: epoch 0167, iter [00250, 00390], lr: 0.000800, loss: 0.8016
2023-05-31 03:20:09 - until epoch: 173, best_acc1: 76.790%
2023-05-31 03:20:10 - epoch 174 lr: 0.000800
2023-05-31 03:20:11 - train: epoch 0167, iter [00300, 00390], lr: 0.000800, loss: 0.8030
2023-05-31 03:20:13 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 0.2607
2023-05-31 03:20:13 - train: epoch 0167, iter [00350, 00390], lr: 0.000800, loss: 0.8171
2023-05-31 03:20:15 - train: epoch 167, train_loss: 0.8013
2023-05-31 03:20:15 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 1.2478
2023-05-31 03:20:16 - eval: epoch: 167, acc1: 78.430%, acc5: 93.300%, test_loss: 1.0387, per_image_load_time: 0.071ms, per_image_inference_time: 0.048ms
2023-05-31 03:20:16 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.0133
2023-05-31 03:20:16 - until epoch: 167, best_acc1: 78.530%
2023-05-31 03:20:16 - epoch 168 lr: 0.000800
2023-05-31 03:20:18 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.0105
2023-05-31 03:20:19 - train: epoch 0168, iter [00050, 00390], lr: 0.000800, loss: 0.8001
2023-05-31 03:20:20 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 0.0237
2023-05-31 03:20:22 - train: epoch 0168, iter [00100, 00390], lr: 0.000800, loss: 0.7984
2023-05-31 03:20:23 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.0060
2023-05-31 03:20:24 - train: epoch 0168, iter [00150, 00390], lr: 0.000800, loss: 0.7938
2023-05-31 03:20:25 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.0132
2023-05-31 03:20:26 - train: epoch 0168, iter [00200, 00390], lr: 0.000800, loss: 0.7884
2023-05-31 03:20:27 - train: epoch 174, train_loss: 0.2445
2023-05-31 03:20:28 - train: epoch 0168, iter [00250, 00390], lr: 0.000800, loss: 0.8060
2023-05-31 03:20:28 - eval: epoch: 174, acc1: 76.880%, acc5: 94.040%, test_loss: 0.9827, per_image_load_time: 0.064ms, per_image_inference_time: 0.049ms
2023-05-31 03:20:29 - until epoch: 174, best_acc1: 76.880%
2023-05-31 03:20:29 - epoch 175 lr: 0.000800
2023-05-31 03:20:29 - train: epoch 0168, iter [00300, 00390], lr: 0.000800, loss: 0.7977
2023-05-31 03:20:32 - train: epoch 0168, iter [00350, 00390], lr: 0.000800, loss: 0.7961
2023-05-31 03:20:32 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 0.6297
2023-05-31 03:20:34 - train: epoch 168, train_loss: 0.8008
2023-05-31 03:20:34 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 0.8823
2023-05-31 03:20:35 - eval: epoch: 168, acc1: 78.320%, acc5: 93.210%, test_loss: 1.0296, per_image_load_time: 0.070ms, per_image_inference_time: 0.047ms
2023-05-31 03:20:35 - until epoch: 168, best_acc1: 78.530%
2023-05-31 03:20:35 - epoch 169 lr: 0.000800
2023-05-31 03:20:36 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 0.3133
2023-05-31 03:20:38 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.0181
2023-05-31 03:20:38 - train: epoch 0169, iter [00050, 00390], lr: 0.000800, loss: 0.8109
2023-05-31 03:20:40 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 0.1068
2023-05-31 03:20:41 - train: epoch 0169, iter [00100, 00390], lr: 0.000800, loss: 0.7816
2023-05-31 03:20:42 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 0.0864
2023-05-31 03:20:43 - train: epoch 0169, iter [00150, 00390], lr: 0.000800, loss: 0.8091
2023-05-31 03:20:44 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.0133
2023-05-31 03:20:45 - train: epoch 0169, iter [00200, 00390], lr: 0.000800, loss: 0.7997
2023-05-31 03:20:46 - train: epoch 175, train_loss: 0.2495
2023-05-31 03:20:47 - train: epoch 0169, iter [00250, 00390], lr: 0.000800, loss: 0.8038
2023-05-31 03:20:48 - eval: epoch: 175, acc1: 76.610%, acc5: 94.010%, test_loss: 1.0349, per_image_load_time: 0.064ms, per_image_inference_time: 0.048ms
2023-05-31 03:20:48 - until epoch: 175, best_acc1: 76.880%
2023-05-31 03:20:48 - epoch 176 lr: 0.000800
2023-05-31 03:20:48 - train: epoch 0169, iter [00300, 00390], lr: 0.000800, loss: 0.8143
2023-05-31 03:20:51 - train: epoch 0169, iter [00350, 00390], lr: 0.000800, loss: 0.8036
2023-05-31 03:20:51 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 0.4484
2023-05-31 03:20:53 - train: epoch 169, train_loss: 0.8002
2023-05-31 03:20:53 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 0.3516
2023-05-31 03:20:54 - eval: epoch: 169, acc1: 78.490%, acc5: 93.190%, test_loss: 1.0233, per_image_load_time: 0.071ms, per_image_inference_time: 0.049ms
2023-05-31 03:20:54 - until epoch: 169, best_acc1: 78.530%
2023-05-31 03:20:54 - epoch 170 lr: 0.000800
2023-05-31 03:20:55 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 0.6542
2023-05-31 03:20:56 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.0072
2023-05-31 03:20:57 - train: epoch 0170, iter [00050, 00390], lr: 0.000800, loss: 0.8027
2023-05-31 03:20:59 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 1.0280
2023-05-31 03:21:00 - train: epoch 0170, iter [00100, 00390], lr: 0.000800, loss: 0.8126
2023-05-31 03:21:01 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 0.6619
2023-05-31 03:21:02 - train: epoch 0170, iter [00150, 00390], lr: 0.000800, loss: 0.8087
2023-05-31 03:21:03 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 0.0824
2023-05-31 03:21:04 - train: epoch 0170, iter [00200, 00390], lr: 0.000800, loss: 0.8032
2023-05-31 03:21:05 - train: epoch 176, train_loss: 0.2639
2023-05-31 03:21:06 - train: epoch 0170, iter [00250, 00390], lr: 0.000800, loss: 0.7885
2023-05-31 03:21:06 - eval: epoch: 176, acc1: 76.850%, acc5: 94.020%, test_loss: 1.0030, per_image_load_time: 0.068ms, per_image_inference_time: 0.047ms
2023-05-31 03:21:07 - until epoch: 176, best_acc1: 76.880%
2023-05-31 03:21:07 - epoch 177 lr: 0.000800
2023-05-31 03:21:08 - train: epoch 0170, iter [00300, 00390], lr: 0.000800, loss: 0.8087
2023-05-31 03:21:10 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.0165
2023-05-31 03:21:10 - train: epoch 0170, iter [00350, 00390], lr: 0.000800, loss: 0.8036
2023-05-31 03:21:12 - train: epoch 170, train_loss: 0.8005
2023-05-31 03:21:12 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 0.0210
2023-05-31 03:21:13 - eval: epoch: 170, acc1: 78.370%, acc5: 93.220%, test_loss: 1.0287, per_image_load_time: 0.067ms, per_image_inference_time: 0.048ms
2023-05-31 03:21:14 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.0079
2023-05-31 03:21:14 - until epoch: 170, best_acc1: 78.530%
2023-05-31 03:21:14 - epoch 171 lr: 0.000800
2023-05-31 03:21:15 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 0.1182
2023-05-31 03:21:17 - train: epoch 0171, iter [00050, 00390], lr: 0.000800, loss: 0.7956
2023-05-31 03:21:18 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.0144
2023-05-31 03:21:19 - train: epoch 0171, iter [00100, 00390], lr: 0.000800, loss: 0.8024
2023-05-31 03:21:20 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 0.0981
2023-05-31 03:21:21 - train: epoch 0171, iter [00150, 00390], lr: 0.000800, loss: 0.8057
2023-05-31 03:21:22 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.0147
2023-05-31 03:21:23 - train: epoch 0171, iter [00200, 00390], lr: 0.000800, loss: 0.7883
2023-05-31 03:21:24 - train: epoch 177, train_loss: 0.2138
2023-05-31 03:21:25 - train: epoch 0171, iter [00250, 00390], lr: 0.000800, loss: 0.8022
2023-05-31 03:21:25 - eval: epoch: 177, acc1: 77.230%, acc5: 94.190%, test_loss: 0.9846, per_image_load_time: 0.072ms, per_image_inference_time: 0.048ms
2023-05-31 03:21:26 - until epoch: 177, best_acc1: 77.230%
2023-05-31 03:21:26 - epoch 178 lr: 0.000800
2023-05-31 03:21:27 - train: epoch 0171, iter [00300, 00390], lr: 0.000800, loss: 0.8073
2023-05-31 03:21:29 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.0064
2023-05-31 03:21:29 - train: epoch 0171, iter [00350, 00390], lr: 0.000800, loss: 0.7940
2023-05-31 03:21:31 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 0.0277
2023-05-31 03:21:31 - train: epoch 171, train_loss: 0.8005
2023-05-31 03:21:33 - eval: epoch: 171, acc1: 78.310%, acc5: 93.150%, test_loss: 1.0322, per_image_load_time: 0.066ms, per_image_inference_time: 0.052ms
2023-05-31 03:21:33 - until epoch: 171, best_acc1: 78.530%
2023-05-31 03:21:33 - epoch 172 lr: 0.000800
2023-05-31 03:21:33 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 0.0140
2023-05-31 03:21:35 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.0084
2023-05-31 03:21:36 - train: epoch 0172, iter [00050, 00390], lr: 0.000800, loss: 0.7992
2023-05-31 03:21:37 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.0148
2023-05-31 03:21:38 - train: epoch 0172, iter [00100, 00390], lr: 0.000800, loss: 0.8265
2023-05-31 03:21:39 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 0.3868
2023-05-31 03:21:40 - train: epoch 0172, iter [00150, 00390], lr: 0.000800, loss: 0.8044
2023-05-31 03:21:41 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.0096
2023-05-31 03:21:42 - train: epoch 0172, iter [00200, 00390], lr: 0.000800, loss: 0.8009
2023-05-31 03:21:43 - train: epoch 178, train_loss: 0.2166
2023-05-31 03:21:44 - train: epoch 0172, iter [00250, 00390], lr: 0.000800, loss: 0.8110
2023-05-31 03:21:45 - eval: epoch: 178, acc1: 77.020%, acc5: 94.010%, test_loss: 1.0102, per_image_load_time: 0.073ms, per_image_inference_time: 0.051ms
2023-05-31 03:21:45 - until epoch: 178, best_acc1: 77.230%
2023-05-31 03:21:45 - epoch 179 lr: 0.000800
2023-05-31 03:21:46 - train: epoch 0172, iter [00300, 00390], lr: 0.000800, loss: 0.8133
2023-05-31 03:21:48 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 0.0490
2023-05-31 03:21:48 - train: epoch 0172, iter [00350, 00390], lr: 0.000800, loss: 0.7981
2023-05-31 03:21:50 - train: epoch 172, train_loss: 0.8003
2023-05-31 03:21:50 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.0065
2023-05-31 03:21:52 - eval: epoch: 172, acc1: 78.260%, acc5: 93.080%, test_loss: 1.0364, per_image_load_time: 0.063ms, per_image_inference_time: 0.050ms
2023-05-31 03:21:52 - until epoch: 172, best_acc1: 78.530%
2023-05-31 03:21:52 - epoch 173 lr: 0.000800
2023-05-31 03:21:52 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 0.8224
2023-05-31 03:21:54 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 0.0852
2023-05-31 03:21:55 - train: epoch 0173, iter [00050, 00390], lr: 0.000800, loss: 0.7995
2023-05-31 03:21:56 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 0.2649
2023-05-31 03:21:57 - train: epoch 0173, iter [00100, 00390], lr: 0.000800, loss: 0.7718
2023-05-31 03:21:58 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.0066
2023-05-31 03:21:59 - train: epoch 0173, iter [00150, 00390], lr: 0.000800, loss: 0.8084
2023-05-31 03:22:00 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 0.0633
2023-05-31 03:22:02 - train: epoch 0173, iter [00200, 00390], lr: 0.000800, loss: 0.8056
2023-05-31 03:22:02 - train: epoch 179, train_loss: 0.2391
2023-05-31 03:22:03 - train: epoch 0173, iter [00250, 00390], lr: 0.000800, loss: 0.7807
2023-05-31 03:22:04 - eval: epoch: 179, acc1: 76.760%, acc5: 94.000%, test_loss: 0.9917, per_image_load_time: 0.069ms, per_image_inference_time: 0.048ms
2023-05-31 03:22:04 - until epoch: 179, best_acc1: 77.230%
2023-05-31 03:22:04 - epoch 180 lr: 0.000800
2023-05-31 03:22:05 - train: epoch 0173, iter [00300, 00390], lr: 0.000800, loss: 0.7989
2023-05-31 03:22:07 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 0.2534
2023-05-31 03:22:07 - train: epoch 0173, iter [00350, 00390], lr: 0.000800, loss: 0.7920
2023-05-31 03:22:09 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.0336
2023-05-31 03:22:09 - train: epoch 173, train_loss: 0.8011
2023-05-31 03:22:11 - eval: epoch: 173, acc1: 78.250%, acc5: 93.110%, test_loss: 1.0369, per_image_load_time: 0.065ms, per_image_inference_time: 0.046ms
2023-05-31 03:22:11 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.0084
2023-05-31 03:22:11 - until epoch: 173, best_acc1: 78.530%
2023-05-31 03:22:11 - epoch 174 lr: 0.000800
2023-05-31 03:22:13 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.0110
2023-05-31 03:22:14 - train: epoch 0174, iter [00050, 00390], lr: 0.000800, loss: 0.8066
2023-05-31 03:22:15 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.0160
2023-05-31 03:22:16 - train: epoch 0174, iter [00100, 00390], lr: 0.000800, loss: 0.8005
2023-05-31 03:22:17 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 0.0618
2023-05-31 03:22:18 - train: epoch 0174, iter [00150, 00390], lr: 0.000800, loss: 0.8135
2023-05-31 03:22:20 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.0082
2023-05-31 03:22:21 - train: epoch 0174, iter [00200, 00390], lr: 0.000800, loss: 0.7974
2023-05-31 03:22:21 - train: epoch 180, train_loss: 0.2321
2023-05-31 03:22:22 - train: epoch 0174, iter [00250, 00390], lr: 0.000800, loss: 0.7921
2023-05-31 03:22:23 - eval: epoch: 180, acc1: 76.390%, acc5: 93.870%, test_loss: 1.0536, per_image_load_time: 0.074ms, per_image_inference_time: 0.053ms
2023-05-31 03:22:23 - until epoch: 180, best_acc1: 77.230%
2023-05-31 03:22:23 - epoch 181 lr: 0.000800
2023-05-31 03:22:24 - train: epoch 0174, iter [00300, 00390], lr: 0.000800, loss: 0.7881
2023-05-31 03:22:26 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 0.2875
2023-05-31 03:22:27 - train: epoch 0174, iter [00350, 00390], lr: 0.000800, loss: 0.8012
2023-05-31 03:22:28 - train: epoch 174, train_loss: 0.7998
2023-05-31 03:22:28 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 0.1463
2023-05-31 03:22:30 - eval: epoch: 174, acc1: 78.410%, acc5: 93.100%, test_loss: 1.0287, per_image_load_time: 0.069ms, per_image_inference_time: 0.049ms
2023-05-31 03:22:30 - until epoch: 174, best_acc1: 78.530%
2023-05-31 03:22:30 - epoch 175 lr: 0.000800
2023-05-31 03:22:30 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 0.2673
2023-05-31 03:22:32 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.0151
2023-05-31 03:22:33 - train: epoch 0175, iter [00050, 00390], lr: 0.000800, loss: 0.8104
2023-05-31 03:22:34 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.0147
2023-05-31 03:22:35 - train: epoch 0175, iter [00100, 00390], lr: 0.000800, loss: 0.8175
2023-05-31 03:22:36 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 0.1645
2023-05-31 03:22:38 - train: epoch 0175, iter [00150, 00390], lr: 0.000800, loss: 0.7938
2023-05-31 03:22:39 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.0103
2023-05-31 03:22:40 - train: epoch 0175, iter [00200, 00390], lr: 0.000800, loss: 0.7909
2023-05-31 03:22:40 - train: epoch 181, train_loss: 0.2297
2023-05-31 03:22:42 - train: epoch 0175, iter [00250, 00390], lr: 0.000800, loss: 0.8007
2023-05-31 03:22:42 - eval: epoch: 181, acc1: 76.770%, acc5: 93.790%, test_loss: 1.0223, per_image_load_time: 0.066ms, per_image_inference_time: 0.051ms
2023-05-31 03:22:42 - until epoch: 181, best_acc1: 77.230%
2023-05-31 03:22:42 - epoch 182 lr: 0.000800
2023-05-31 03:22:43 - train: epoch 0175, iter [00300, 00390], lr: 0.000800, loss: 0.8134
2023-05-31 03:22:45 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 0.0730
2023-05-31 03:22:46 - train: epoch 0175, iter [00350, 00390], lr: 0.000800, loss: 0.7854
2023-05-31 03:22:47 - train: epoch 175, train_loss: 0.7997
2023-05-31 03:22:47 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 0.0434
2023-05-31 03:22:49 - eval: epoch: 175, acc1: 78.380%, acc5: 93.190%, test_loss: 1.0294, per_image_load_time: 0.068ms, per_image_inference_time: 0.051ms
2023-05-31 03:22:49 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 0.1955
2023-05-31 03:22:49 - until epoch: 175, best_acc1: 78.530%
2023-05-31 03:22:49 - epoch 176 lr: 0.000800
2023-05-31 03:22:51 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.0065
2023-05-31 03:22:52 - train: epoch 0176, iter [00050, 00390], lr: 0.000800, loss: 0.7978
2023-05-31 03:22:53 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 0.0720
2023-05-31 03:22:55 - train: epoch 0176, iter [00100, 00390], lr: 0.000800, loss: 0.7986
2023-05-31 03:22:55 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 0.0466
2023-05-31 03:22:57 - train: epoch 0176, iter [00150, 00390], lr: 0.000800, loss: 0.7896
2023-05-31 03:22:57 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 0.6257
2023-05-31 03:22:59 - train: epoch 0176, iter [00200, 00390], lr: 0.000800, loss: 0.8115
2023-05-31 03:22:59 - train: epoch 182, train_loss: 0.2637
2023-05-31 03:23:01 - eval: epoch: 182, acc1: 76.560%, acc5: 93.860%, test_loss: 1.0157, per_image_load_time: 0.073ms, per_image_inference_time: 0.048ms
2023-05-31 03:23:01 - train: epoch 0176, iter [00250, 00390], lr: 0.000800, loss: 0.7942
2023-05-31 03:23:01 - until epoch: 182, best_acc1: 77.230%
2023-05-31 03:23:01 - epoch 183 lr: 0.000800
2023-05-31 03:23:03 - train: epoch 0176, iter [00300, 00390], lr: 0.000800, loss: 0.7987
2023-05-31 03:23:04 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.0055
2023-05-31 03:23:05 - train: epoch 0176, iter [00350, 00390], lr: 0.000800, loss: 0.8028
2023-05-31 03:23:06 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.0045
2023-05-31 03:23:07 - train: epoch 176, train_loss: 0.7997
2023-05-31 03:23:08 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 0.0561
2023-05-31 03:23:09 - eval: epoch: 176, acc1: 78.330%, acc5: 93.460%, test_loss: 1.0292, per_image_load_time: 0.078ms, per_image_inference_time: 0.049ms
2023-05-31 03:23:09 - until epoch: 176, best_acc1: 78.530%
2023-05-31 03:23:09 - epoch 177 lr: 0.000800
2023-05-31 03:23:10 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 0.1087
2023-05-31 03:23:12 - train: epoch 0177, iter [00050, 00390], lr: 0.000800, loss: 0.7949
2023-05-31 03:23:12 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 0.4447
2023-05-31 03:23:14 - train: epoch 0177, iter [00100, 00390], lr: 0.000800, loss: 0.7829
2023-05-31 03:23:14 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 1.7486
2023-05-31 03:23:16 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 1.7347
2023-05-31 03:23:16 - train: epoch 0177, iter [00150, 00390], lr: 0.000800, loss: 0.8050
2023-05-31 03:23:18 - train: epoch 183, train_loss: 0.2503
2023-05-31 03:23:19 - train: epoch 0177, iter [00200, 00390], lr: 0.000800, loss: 0.7986
2023-05-31 03:23:20 - eval: epoch: 183, acc1: 76.810%, acc5: 94.090%, test_loss: 0.9822, per_image_load_time: 0.067ms, per_image_inference_time: 0.050ms
2023-05-31 03:23:20 - until epoch: 183, best_acc1: 77.230%
2023-05-31 03:23:20 - epoch 184 lr: 0.000800
2023-05-31 03:23:20 - train: epoch 0177, iter [00250, 00390], lr: 0.000800, loss: 0.7988
2023-05-31 03:23:22 - train: epoch 0177, iter [00300, 00390], lr: 0.000800, loss: 0.8011
2023-05-31 03:23:23 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 0.0353
2023-05-31 03:23:24 - train: epoch 0177, iter [00350, 00390], lr: 0.000800, loss: 0.7975
2023-05-31 03:23:25 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 0.1621
2023-05-31 03:23:26 - train: epoch 177, train_loss: 0.7995
2023-05-31 03:23:27 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.0309
2023-05-31 03:23:28 - eval: epoch: 177, acc1: 78.460%, acc5: 93.270%, test_loss: 1.0292, per_image_load_time: 0.066ms, per_image_inference_time: 0.046ms
2023-05-31 03:23:28 - until epoch: 177, best_acc1: 78.530%
2023-05-31 03:23:28 - epoch 178 lr: 0.000800
2023-05-31 03:23:29 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 0.0336
2023-05-31 03:23:31 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.0092
2023-05-31 03:23:31 - train: epoch 0178, iter [00050, 00390], lr: 0.000800, loss: 0.7929
2023-05-31 03:23:33 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.0063
2023-05-31 03:23:33 - train: epoch 0178, iter [00100, 00390], lr: 0.000800, loss: 0.7897
2023-05-31 03:23:35 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 0.0986
2023-05-31 03:23:36 - train: epoch 0178, iter [00150, 00390], lr: 0.000800, loss: 0.7932
2023-05-31 03:23:37 - train: epoch 184, train_loss: 0.2269
2023-05-31 03:23:38 - train: epoch 0178, iter [00200, 00390], lr: 0.000800, loss: 0.7864
2023-05-31 03:23:39 - eval: epoch: 184, acc1: 76.690%, acc5: 93.990%, test_loss: 1.0189, per_image_load_time: 0.064ms, per_image_inference_time: 0.049ms
2023-05-31 03:23:39 - until epoch: 184, best_acc1: 77.230%
2023-05-31 03:23:39 - epoch 185 lr: 0.000800
2023-05-31 03:23:39 - train: epoch 0178, iter [00250, 00390], lr: 0.000800, loss: 0.7840
2023-05-31 03:23:41 - train: epoch 0178, iter [00300, 00390], lr: 0.000800, loss: 0.7875
2023-05-31 03:23:42 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 0.0368
2023-05-31 03:23:44 - train: epoch 0178, iter [00350, 00390], lr: 0.000800, loss: 0.7997
2023-05-31 03:23:44 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 0.1459
2023-05-31 03:23:45 - train: epoch 178, train_loss: 0.7999
2023-05-31 03:23:46 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.0065
2023-05-31 03:23:47 - eval: epoch: 178, acc1: 78.340%, acc5: 93.170%, test_loss: 1.0294, per_image_load_time: 0.074ms, per_image_inference_time: 0.048ms
2023-05-31 03:23:47 - until epoch: 178, best_acc1: 78.530%
2023-05-31 03:23:47 - epoch 179 lr: 0.000800
2023-05-31 03:23:48 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.0117
2023-05-31 03:23:50 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 0.0230
2023-05-31 03:23:50 - train: epoch 0179, iter [00050, 00390], lr: 0.000800, loss: 0.8009
2023-05-31 03:23:52 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.0065
2023-05-31 03:23:53 - train: epoch 0179, iter [00100, 00390], lr: 0.000800, loss: 0.7975
2023-05-31 03:23:54 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 0.0233
2023-05-31 03:23:55 - train: epoch 0179, iter [00150, 00390], lr: 0.000800, loss: 0.8039
2023-05-31 03:23:56 - train: epoch 185, train_loss: 0.2545
2023-05-31 03:23:57 - train: epoch 0179, iter [00200, 00390], lr: 0.000800, loss: 0.7924
2023-05-31 03:23:58 - eval: epoch: 185, acc1: 76.730%, acc5: 93.960%, test_loss: 0.9828, per_image_load_time: 0.063ms, per_image_inference_time: 0.049ms
2023-05-31 03:23:58 - until epoch: 185, best_acc1: 77.230%
2023-05-31 03:23:58 - epoch 186 lr: 0.000800
2023-05-31 03:23:58 - train: epoch 0179, iter [00250, 00390], lr: 0.000800, loss: 0.7998
2023-05-31 03:24:00 - train: epoch 0179, iter [00300, 00390], lr: 0.000800, loss: 0.8026
2023-05-31 03:24:01 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.0057
2023-05-31 03:24:03 - train: epoch 0179, iter [00350, 00390], lr: 0.000800, loss: 0.7929
2023-05-31 03:24:04 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.0103
2023-05-31 03:24:05 - train: epoch 179, train_loss: 0.7986
2023-05-31 03:24:05 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 0.1857
2023-05-31 03:24:06 - eval: epoch: 179, acc1: 78.130%, acc5: 93.200%, test_loss: 1.0326, per_image_load_time: 0.075ms, per_image_inference_time: 0.048ms
2023-05-31 03:24:06 - until epoch: 179, best_acc1: 78.530%
2023-05-31 03:24:06 - epoch 180 lr: 0.000800
2023-05-31 03:24:07 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.0051
2023-05-31 03:24:09 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 0.1858
2023-05-31 03:24:09 - train: epoch 0180, iter [00050, 00390], lr: 0.000800, loss: 0.7903
2023-05-31 03:24:11 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 0.2167
2023-05-31 03:24:12 - train: epoch 0180, iter [00100, 00390], lr: 0.000800, loss: 0.7930
2023-05-31 03:24:13 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 0.0359
2023-05-31 03:24:14 - train: epoch 0180, iter [00150, 00390], lr: 0.000800, loss: 0.7895
2023-05-31 03:24:15 - train: epoch 186, train_loss: 0.2027
2023-05-31 03:24:16 - train: epoch 0180, iter [00200, 00390], lr: 0.000800, loss: 0.8100
2023-05-31 03:24:17 - eval: epoch: 186, acc1: 76.420%, acc5: 94.000%, test_loss: 0.9960, per_image_load_time: 0.069ms, per_image_inference_time: 0.049ms
2023-05-31 03:24:17 - until epoch: 186, best_acc1: 77.230%
2023-05-31 03:24:17 - epoch 187 lr: 0.000800
2023-05-31 03:24:18 - train: epoch 0180, iter [00250, 00390], lr: 0.000800, loss: 0.8113
2023-05-31 03:24:20 - train: epoch 0180, iter [00300, 00390], lr: 0.000800, loss: 0.7966
2023-05-31 03:24:20 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 0.1403
2023-05-31 03:24:22 - train: epoch 0180, iter [00350, 00390], lr: 0.000800, loss: 0.7833
2023-05-31 03:24:22 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.0146
2023-05-31 03:24:24 - train: epoch 180, train_loss: 0.7997
2023-05-31 03:24:24 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 0.6612
2023-05-31 03:24:25 - eval: epoch: 180, acc1: 78.210%, acc5: 93.240%, test_loss: 1.0368, per_image_load_time: 0.064ms, per_image_inference_time: 0.049ms
2023-05-31 03:24:26 - until epoch: 180, best_acc1: 78.530%
2023-05-31 03:24:26 - epoch 181 lr: 0.000800
2023-05-31 03:24:26 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 0.0610
2023-05-31 03:24:28 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.0128
2023-05-31 03:24:29 - train: epoch 0181, iter [00050, 00390], lr: 0.000800, loss: 0.8037
2023-05-31 03:24:30 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 0.3197
2023-05-31 03:24:31 - train: epoch 0181, iter [00100, 00390], lr: 0.000800, loss: 0.7942
2023-05-31 03:24:32 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.0105
2023-05-31 03:24:33 - train: epoch 0181, iter [00150, 00390], lr: 0.000800, loss: 0.7984
2023-05-31 03:24:34 - train: epoch 187, train_loss: 0.2431
2023-05-31 03:24:35 - train: epoch 0181, iter [00200, 00390], lr: 0.000800, loss: 0.7853
2023-05-31 03:24:36 - eval: epoch: 187, acc1: 76.720%, acc5: 94.080%, test_loss: 1.0037, per_image_load_time: 0.064ms, per_image_inference_time: 0.050ms
2023-05-31 03:24:36 - until epoch: 187, best_acc1: 77.230%
2023-05-31 03:24:36 - epoch 188 lr: 0.000800
2023-05-31 03:24:37 - train: epoch 0181, iter [00250, 00390], lr: 0.000800, loss: 0.8076
2023-05-31 03:24:39 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 0.1970
2023-05-31 03:24:39 - train: epoch 0181, iter [00300, 00390], lr: 0.000800, loss: 0.8005
2023-05-31 03:24:41 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 0.0785
2023-05-31 03:24:41 - train: epoch 0181, iter [00350, 00390], lr: 0.000800, loss: 0.7993
2023-05-31 03:24:43 - train: epoch 181, train_loss: 0.7982
2023-05-31 03:24:43 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 0.1489
2023-05-31 03:24:45 - eval: epoch: 181, acc1: 78.260%, acc5: 93.260%, test_loss: 1.0393, per_image_load_time: 0.069ms, per_image_inference_time: 0.049ms
2023-05-31 03:24:45 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 0.9076
2023-05-31 03:24:45 - until epoch: 181, best_acc1: 78.530%
2023-05-31 03:24:45 - epoch 182 lr: 0.000800
2023-05-31 03:24:47 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 0.1930
2023-05-31 03:24:48 - train: epoch 0182, iter [00050, 00390], lr: 0.000800, loss: 0.7843
2023-05-31 03:24:49 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 0.1081
2023-05-31 03:24:50 - train: epoch 0182, iter [00100, 00390], lr: 0.000800, loss: 0.8129
2023-05-31 03:24:51 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 0.0867
2023-05-31 03:24:53 - train: epoch 0182, iter [00150, 00390], lr: 0.000800, loss: 0.7961
2023-05-31 03:24:53 - train: epoch 188, train_loss: 0.2196
2023-05-31 03:24:55 - train: epoch 0182, iter [00200, 00390], lr: 0.000800, loss: 0.7821
2023-05-31 03:24:55 - eval: epoch: 188, acc1: 76.710%, acc5: 94.020%, test_loss: 0.9937, per_image_load_time: 0.072ms, per_image_inference_time: 0.048ms
2023-05-31 03:24:55 - until epoch: 188, best_acc1: 77.230%
2023-05-31 03:24:55 - epoch 189 lr: 0.000800
2023-05-31 03:24:56 - train: epoch 0182, iter [00250, 00390], lr: 0.000800, loss: 0.7977
2023-05-31 03:24:58 - train: epoch 0182, iter [00300, 00390], lr: 0.000800, loss: 0.8323
2023-05-31 03:24:58 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.0160
2023-05-31 03:25:00 - train: epoch 0182, iter [00350, 00390], lr: 0.000800, loss: 0.7933
2023-05-31 03:25:01 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 0.0491
2023-05-31 03:25:02 - train: epoch 182, train_loss: 0.7997
2023-05-31 03:25:03 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 0.0452
2023-05-31 03:25:04 - eval: epoch: 182, acc1: 78.250%, acc5: 93.120%, test_loss: 1.0306, per_image_load_time: 0.062ms, per_image_inference_time: 0.051ms
2023-05-31 03:25:04 - until epoch: 182, best_acc1: 78.530%
2023-05-31 03:25:04 - epoch 183 lr: 0.000800
2023-05-31 03:25:04 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 0.3682
2023-05-31 03:25:06 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 0.1249
2023-05-31 03:25:07 - train: epoch 0183, iter [00050, 00390], lr: 0.000800, loss: 0.7938
2023-05-31 03:25:09 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 0.0749
2023-05-31 03:25:09 - train: epoch 0183, iter [00100, 00390], lr: 0.000800, loss: 0.7671
2023-05-31 03:25:11 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 0.2432
2023-05-31 03:25:12 - train: epoch 0183, iter [00150, 00390], lr: 0.000800, loss: 0.8032
2023-05-31 03:25:13 - train: epoch 189, train_loss: 0.2084
2023-05-31 03:25:13 - train: epoch 0183, iter [00200, 00390], lr: 0.000800, loss: 0.7902
2023-05-31 03:25:14 - eval: epoch: 189, acc1: 76.650%, acc5: 94.240%, test_loss: 0.9889, per_image_load_time: 0.071ms, per_image_inference_time: 0.047ms
2023-05-31 03:25:14 - until epoch: 189, best_acc1: 77.230%
2023-05-31 03:25:14 - epoch 190 lr: 0.000800
2023-05-31 03:25:15 - train: epoch 0183, iter [00250, 00390], lr: 0.000800, loss: 0.7879
2023-05-31 03:25:17 - train: epoch 0183, iter [00300, 00390], lr: 0.000800, loss: 0.8105
2023-05-31 03:25:18 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 0.9765
2023-05-31 03:25:20 - train: epoch 0183, iter [00350, 00390], lr: 0.000800, loss: 0.7986
2023-05-31 03:25:20 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 0.0690
2023-05-31 03:25:21 - train: epoch 183, train_loss: 0.7998
2023-05-31 03:25:22 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 0.1160
2023-05-31 03:25:23 - eval: epoch: 183, acc1: 78.270%, acc5: 93.330%, test_loss: 1.0330, per_image_load_time: 0.067ms, per_image_inference_time: 0.052ms
2023-05-31 03:25:23 - until epoch: 183, best_acc1: 78.530%
2023-05-31 03:25:23 - epoch 184 lr: 0.000800
2023-05-31 03:25:23 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.0062
2023-05-31 03:25:25 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 0.0139
2023-05-31 03:25:26 - train: epoch 0184, iter [00050, 00390], lr: 0.000800, loss: 0.7974
2023-05-31 03:25:28 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 0.0885
2023-05-31 03:25:28 - train: epoch 0184, iter [00100, 00390], lr: 0.000800, loss: 0.7982
2023-05-31 03:25:30 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 0.7599
2023-05-31 03:25:31 - train: epoch 0184, iter [00150, 00390], lr: 0.000800, loss: 0.7882
2023-05-31 03:25:32 - train: epoch 190, train_loss: 0.2595
2023-05-31 03:25:32 - train: epoch 0184, iter [00200, 00390], lr: 0.000800, loss: 0.7971
2023-05-31 03:25:33 - eval: epoch: 190, acc1: 76.820%, acc5: 93.980%, test_loss: 1.0119, per_image_load_time: 0.070ms, per_image_inference_time: 0.048ms
2023-05-31 03:25:33 - until epoch: 190, best_acc1: 77.230%
2023-05-31 03:25:33 - epoch 191 lr: 0.000800
2023-05-31 03:25:34 - train: epoch 0184, iter [00250, 00390], lr: 0.000800, loss: 0.8047
2023-05-31 03:25:36 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.0049
2023-05-31 03:25:37 - train: epoch 0184, iter [00300, 00390], lr: 0.000800, loss: 0.7977
2023-05-31 03:25:39 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 0.1919
2023-05-31 03:25:39 - train: epoch 0184, iter [00350, 00390], lr: 0.000800, loss: 0.8088
2023-05-31 03:25:41 - train: epoch 184, train_loss: 0.7993
2023-05-31 03:25:41 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.0059
2023-05-31 03:25:42 - eval: epoch: 184, acc1: 78.240%, acc5: 93.170%, test_loss: 1.0326, per_image_load_time: 0.072ms, per_image_inference_time: 0.046ms
2023-05-31 03:25:42 - until epoch: 184, best_acc1: 78.530%
2023-05-31 03:25:42 - epoch 185 lr: 0.000800
2023-05-31 03:25:42 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 0.0732
2023-05-31 03:25:44 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.0173
2023-05-31 03:25:45 - train: epoch 0185, iter [00050, 00390], lr: 0.000800, loss: 0.7950
2023-05-31 03:25:46 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.0053
2023-05-31 03:25:48 - train: epoch 0185, iter [00100, 00390], lr: 0.000800, loss: 0.8108
2023-05-31 03:25:49 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 0.0748
2023-05-31 03:25:50 - train: epoch 0185, iter [00150, 00390], lr: 0.000800, loss: 0.7956
2023-05-31 03:25:51 - train: epoch 191, train_loss: 0.2175
2023-05-31 03:25:52 - train: epoch 0185, iter [00200, 00390], lr: 0.000800, loss: 0.8171
2023-05-31 03:25:52 - eval: epoch: 191, acc1: 76.910%, acc5: 94.030%, test_loss: 0.9950, per_image_load_time: 0.069ms, per_image_inference_time: 0.047ms
2023-05-31 03:25:52 - until epoch: 191, best_acc1: 77.230%
2023-05-31 03:25:52 - epoch 192 lr: 0.000800
2023-05-31 03:25:53 - train: epoch 0185, iter [00250, 00390], lr: 0.000800, loss: 0.7925
2023-05-31 03:25:55 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 1.3058
2023-05-31 03:25:56 - train: epoch 0185, iter [00300, 00390], lr: 0.000800, loss: 0.8061
2023-05-31 03:25:57 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 0.0271
2023-05-31 03:25:58 - train: epoch 0185, iter [00350, 00390], lr: 0.000800, loss: 0.7925
2023-05-31 03:26:00 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 0.0202
2023-05-31 03:26:00 - train: epoch 185, train_loss: 0.7996
2023-05-31 03:26:01 - eval: epoch: 185, acc1: 78.270%, acc5: 93.290%, test_loss: 1.0350, per_image_load_time: 0.070ms, per_image_inference_time: 0.049ms
2023-05-31 03:26:01 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 1.6852
2023-05-31 03:26:01 - until epoch: 185, best_acc1: 78.530%
2023-05-31 03:26:01 - epoch 186 lr: 0.000800
2023-05-31 03:26:03 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 0.1370
2023-05-31 03:26:05 - train: epoch 0186, iter [00050, 00390], lr: 0.000800, loss: 0.8015
2023-05-31 03:26:05 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 0.1544
2023-05-31 03:26:07 - train: epoch 0186, iter [00100, 00390], lr: 0.000800, loss: 0.7946
2023-05-31 03:26:08 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 0.0591
2023-05-31 03:26:09 - train: epoch 0186, iter [00150, 00390], lr: 0.000800, loss: 0.8078
2023-05-31 03:26:10 - train: epoch 192, train_loss: 0.2203
2023-05-31 03:26:11 - train: epoch 0186, iter [00200, 00390], lr: 0.000800, loss: 0.8016
2023-05-31 03:26:11 - eval: epoch: 192, acc1: 76.610%, acc5: 93.900%, test_loss: 1.0136, per_image_load_time: 0.074ms, per_image_inference_time: 0.054ms
2023-05-31 03:26:11 - until epoch: 192, best_acc1: 77.230%
2023-05-31 03:26:11 - epoch 193 lr: 0.000800
2023-05-31 03:26:13 - train: epoch 0186, iter [00250, 00390], lr: 0.000800, loss: 0.7960
2023-05-31 03:26:14 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 0.5026
2023-05-31 03:26:15 - train: epoch 0186, iter [00300, 00390], lr: 0.000800, loss: 0.8002
2023-05-31 03:26:17 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 0.3611
2023-05-31 03:26:17 - train: epoch 0186, iter [00350, 00390], lr: 0.000800, loss: 0.8105
2023-05-31 03:26:19 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.0062
2023-05-31 03:26:19 - train: epoch 186, train_loss: 0.7997
2023-05-31 03:26:20 - eval: epoch: 186, acc1: 78.340%, acc5: 93.290%, test_loss: 1.0307, per_image_load_time: 0.069ms, per_image_inference_time: 0.048ms
2023-05-31 03:26:20 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 0.3578
2023-05-31 03:26:21 - until epoch: 186, best_acc1: 78.530%
2023-05-31 03:26:21 - epoch 187 lr: 0.000800
2023-05-31 03:26:22 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.0070
2023-05-31 03:26:24 - train: epoch 0187, iter [00050, 00390], lr: 0.000800, loss: 0.7832
2023-05-31 03:26:25 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 0.0583
2023-05-31 03:26:26 - train: epoch 0187, iter [00100, 00390], lr: 0.000800, loss: 0.8090
2023-05-31 03:26:27 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 0.2509
2023-05-31 03:26:28 - train: epoch 0187, iter [00150, 00390], lr: 0.000800, loss: 0.7717
2023-05-31 03:26:29 - train: epoch 193, train_loss: 0.2380
2023-05-31 03:26:30 - train: epoch 0187, iter [00200, 00390], lr: 0.000800, loss: 0.8079
2023-05-31 03:26:30 - eval: epoch: 193, acc1: 76.670%, acc5: 93.940%, test_loss: 1.0133, per_image_load_time: 0.066ms, per_image_inference_time: 0.050ms
2023-05-31 03:26:30 - until epoch: 193, best_acc1: 77.230%
2023-05-31 03:26:30 - epoch 194 lr: 0.000800
2023-05-31 03:26:32 - train: epoch 0187, iter [00250, 00390], lr: 0.000800, loss: 0.7921
2023-05-31 03:26:33 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 0.0383
2023-05-31 03:26:34 - train: epoch 0187, iter [00300, 00390], lr: 0.000800, loss: 0.8014
2023-05-31 03:26:36 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 0.1881
2023-05-31 03:26:36 - train: epoch 0187, iter [00350, 00390], lr: 0.000800, loss: 0.8017
2023-05-31 03:26:38 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.0136
2023-05-31 03:26:38 - train: epoch 187, train_loss: 0.7989
2023-05-31 03:26:39 - eval: epoch: 187, acc1: 78.250%, acc5: 93.150%, test_loss: 1.0318, per_image_load_time: 0.066ms, per_image_inference_time: 0.048ms
2023-05-31 03:26:39 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 0.2153
2023-05-31 03:26:40 - until epoch: 187, best_acc1: 78.530%
2023-05-31 03:26:40 - epoch 188 lr: 0.000800
2023-05-31 03:26:41 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 0.1576
2023-05-31 03:26:43 - train: epoch 0188, iter [00050, 00390], lr: 0.000800, loss: 0.8268
2023-05-31 03:26:43 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.0111
2023-05-31 03:26:45 - train: epoch 0188, iter [00100, 00390], lr: 0.000800, loss: 0.7900
2023-05-31 03:26:46 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 0.1677
2023-05-31 03:26:47 - train: epoch 194, train_loss: 0.2231
2023-05-31 03:26:47 - train: epoch 0188, iter [00150, 00390], lr: 0.000800, loss: 0.7957
2023-05-31 03:26:49 - eval: epoch: 194, acc1: 76.470%, acc5: 93.810%, test_loss: 1.0209, per_image_load_time: 0.076ms, per_image_inference_time: 0.047ms
2023-05-31 03:26:49 - train: epoch 0188, iter [00200, 00390], lr: 0.000800, loss: 0.7871
2023-05-31 03:26:49 - until epoch: 194, best_acc1: 77.230%
2023-05-31 03:26:49 - epoch 195 lr: 0.000800
2023-05-31 03:26:51 - train: epoch 0188, iter [00250, 00390], lr: 0.000800, loss: 0.7984
2023-05-31 03:26:52 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 0.6343
2023-05-31 03:26:53 - train: epoch 0188, iter [00300, 00390], lr: 0.000800, loss: 0.8049
2023-05-31 03:26:54 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 0.0283
2023-05-31 03:26:55 - train: epoch 0188, iter [00350, 00390], lr: 0.000800, loss: 0.8090
2023-05-31 03:26:57 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.0101
2023-05-31 03:26:57 - train: epoch 188, train_loss: 0.7987
2023-05-31 03:26:58 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 0.0558
2023-05-31 03:26:59 - eval: epoch: 188, acc1: 78.460%, acc5: 93.300%, test_loss: 1.0334, per_image_load_time: 0.069ms, per_image_inference_time: 0.049ms
2023-05-31 03:26:59 - until epoch: 188, best_acc1: 78.530%
2023-05-31 03:26:59 - epoch 189 lr: 0.000800
2023-05-31 03:27:00 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 0.3877
2023-05-31 03:27:02 - train: epoch 0189, iter [00050, 00390], lr: 0.000800, loss: 0.7955
2023-05-31 03:27:02 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.0065
2023-05-31 03:27:05 - train: epoch 0189, iter [00100, 00390], lr: 0.000800, loss: 0.8005
2023-05-31 03:27:05 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.0121
2023-05-31 03:27:06 - train: epoch 195, train_loss: 0.2302
2023-05-31 03:27:07 - train: epoch 0189, iter [00150, 00390], lr: 0.000800, loss: 0.8012
2023-05-31 03:27:08 - eval: epoch: 195, acc1: 76.810%, acc5: 93.880%, test_loss: 1.0141, per_image_load_time: 0.064ms, per_image_inference_time: 0.050ms
2023-05-31 03:27:08 - until epoch: 195, best_acc1: 77.230%
2023-05-31 03:27:08 - epoch 196 lr: 0.000800
2023-05-31 03:27:08 - train: epoch 0189, iter [00200, 00390], lr: 0.000800, loss: 0.8040
2023-05-31 03:27:10 - train: epoch 0189, iter [00250, 00390], lr: 0.000800, loss: 0.7976
2023-05-31 03:27:11 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 0.1291
2023-05-31 03:27:13 - train: epoch 0189, iter [00300, 00390], lr: 0.000800, loss: 0.7888
2023-05-31 03:27:13 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.0083
2023-05-31 03:27:15 - train: epoch 0189, iter [00350, 00390], lr: 0.000800, loss: 0.7799
2023-05-31 03:27:16 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 0.2231
2023-05-31 03:27:17 - train: epoch 189, train_loss: 0.7984
2023-05-31 03:27:17 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.0120
2023-05-31 03:27:18 - eval: epoch: 189, acc1: 78.470%, acc5: 93.330%, test_loss: 1.0308, per_image_load_time: 0.063ms, per_image_inference_time: 0.047ms
2023-05-31 03:27:18 - until epoch: 189, best_acc1: 78.530%
2023-05-31 03:27:18 - epoch 190 lr: 0.000800
2023-05-31 03:27:19 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.0046
2023-05-31 03:27:21 - train: epoch 0190, iter [00050, 00390], lr: 0.000800, loss: 0.7981
2023-05-31 03:27:21 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.0120
2023-05-31 03:27:24 - train: epoch 0190, iter [00100, 00390], lr: 0.000800, loss: 0.7940
2023-05-31 03:27:24 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 0.0193
2023-05-31 03:27:25 - train: epoch 196, train_loss: 0.2119
2023-05-31 03:27:26 - train: epoch 0190, iter [00150, 00390], lr: 0.000800, loss: 0.8024
2023-05-31 03:27:27 - eval: epoch: 196, acc1: 76.910%, acc5: 93.900%, test_loss: 1.0228, per_image_load_time: 0.069ms, per_image_inference_time: 0.049ms
2023-05-31 03:27:27 - until epoch: 196, best_acc1: 77.230%
2023-05-31 03:27:27 - epoch 197 lr: 0.000800
2023-05-31 03:27:27 - train: epoch 0190, iter [00200, 00390], lr: 0.000800, loss: 0.7774
2023-05-31 03:27:29 - train: epoch 0190, iter [00250, 00390], lr: 0.000800, loss: 0.8062
2023-05-31 03:27:30 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.0106
2023-05-31 03:27:32 - train: epoch 0190, iter [00300, 00390], lr: 0.000800, loss: 0.8029
2023-05-31 03:27:32 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 0.0660
2023-05-31 03:27:34 - train: epoch 0190, iter [00350, 00390], lr: 0.000800, loss: 0.7736
2023-05-31 03:27:35 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 0.1105
2023-05-31 03:27:36 - train: epoch 190, train_loss: 0.7982
2023-05-31 03:27:37 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 0.3022
2023-05-31 03:27:37 - eval: epoch: 190, acc1: 78.200%, acc5: 93.140%, test_loss: 1.0406, per_image_load_time: 0.073ms, per_image_inference_time: 0.048ms
2023-05-31 03:27:38 - until epoch: 190, best_acc1: 78.530%
2023-05-31 03:27:38 - epoch 191 lr: 0.000800
2023-05-31 03:27:38 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.0075
2023-05-31 03:27:40 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 0.3720
2023-05-31 03:27:41 - train: epoch 0191, iter [00050, 00390], lr: 0.000800, loss: 0.8001
2023-05-31 03:27:42 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 1.3076
2023-05-31 03:27:43 - train: epoch 0191, iter [00100, 00390], lr: 0.000800, loss: 0.7954
2023-05-31 03:27:44 - train: epoch 197, train_loss: 0.2250
2023-05-31 03:27:45 - train: epoch 0191, iter [00150, 00390], lr: 0.000800, loss: 0.8050
2023-05-31 03:27:46 - eval: epoch: 197, acc1: 76.790%, acc5: 93.890%, test_loss: 0.9977, per_image_load_time: 0.073ms, per_image_inference_time: 0.048ms
2023-05-31 03:27:46 - until epoch: 197, best_acc1: 77.230%
2023-05-31 03:27:46 - epoch 198 lr: 0.000800
2023-05-31 03:27:47 - train: epoch 0191, iter [00200, 00390], lr: 0.000800, loss: 0.7958
2023-05-31 03:27:49 - train: epoch 0191, iter [00250, 00390], lr: 0.000800, loss: 0.7810
2023-05-31 03:27:49 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 0.0141
2023-05-31 03:27:51 - train: epoch 0191, iter [00300, 00390], lr: 0.000800, loss: 0.7940
2023-05-31 03:27:52 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.0129
2023-05-31 03:27:53 - train: epoch 0191, iter [00350, 00390], lr: 0.000800, loss: 0.7999
2023-05-31 03:27:54 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.0106
2023-05-31 03:27:55 - train: epoch 191, train_loss: 0.7986
2023-05-31 03:27:56 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 0.1120
2023-05-31 03:27:57 - eval: epoch: 191, acc1: 78.480%, acc5: 93.300%, test_loss: 1.0253, per_image_load_time: 0.070ms, per_image_inference_time: 0.047ms
2023-05-31 03:27:57 - until epoch: 191, best_acc1: 78.530%
2023-05-31 03:27:57 - epoch 192 lr: 0.000800
2023-05-31 03:27:57 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 0.0144
2023-05-31 03:28:00 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 0.1422
2023-05-31 03:28:00 - train: epoch 0192, iter [00050, 00390], lr: 0.000800, loss: 0.8046
2023-05-31 03:28:02 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.0081
2023-05-31 03:28:02 - train: epoch 0192, iter [00100, 00390], lr: 0.000800, loss: 0.8044
2023-05-31 03:28:04 - train: epoch 198, train_loss: 0.2063
2023-05-31 03:28:04 - train: epoch 0192, iter [00150, 00390], lr: 0.000800, loss: 0.8131
2023-05-31 03:28:05 - eval: epoch: 198, acc1: 76.730%, acc5: 93.620%, test_loss: 1.0199, per_image_load_time: 0.065ms, per_image_inference_time: 0.051ms
2023-05-31 03:28:06 - until epoch: 198, best_acc1: 77.230%
2023-05-31 03:28:06 - epoch 199 lr: 0.000800
2023-05-31 03:28:06 - train: epoch 0192, iter [00200, 00390], lr: 0.000800, loss: 0.7961
2023-05-31 03:28:08 - train: epoch 0192, iter [00250, 00390], lr: 0.000800, loss: 0.7921
2023-05-31 03:28:09 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.0072
2023-05-31 03:28:10 - train: epoch 0192, iter [00300, 00390], lr: 0.000800, loss: 0.7986
2023-05-31 03:28:11 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.0056
2023-05-31 03:28:12 - train: epoch 0192, iter [00350, 00390], lr: 0.000800, loss: 0.7997
2023-05-31 03:28:13 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 0.9782
2023-05-31 03:28:14 - train: epoch 192, train_loss: 0.7984
2023-05-31 03:28:15 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.0162
2023-05-31 03:28:16 - eval: epoch: 192, acc1: 78.430%, acc5: 93.250%, test_loss: 1.0349, per_image_load_time: 0.069ms, per_image_inference_time: 0.047ms
2023-05-31 03:28:16 - until epoch: 192, best_acc1: 78.530%
2023-05-31 03:28:16 - epoch 193 lr: 0.000800
2023-05-31 03:28:17 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 0.0179
2023-05-31 03:28:19 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 0.0304
2023-05-31 03:28:19 - train: epoch 0193, iter [00050, 00390], lr: 0.000800, loss: 0.7915
2023-05-31 03:28:21 - train: epoch 0193, iter [00100, 00390], lr: 0.000800, loss: 0.7956
2023-05-31 03:28:21 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.0239
2023-05-31 03:28:23 - train: epoch 199, train_loss: 0.2433
2023-05-31 03:28:23 - train: epoch 0193, iter [00150, 00390], lr: 0.000800, loss: 0.8083
2023-05-31 03:28:25 - eval: epoch: 199, acc1: 76.460%, acc5: 93.600%, test_loss: 1.0358, per_image_load_time: 0.068ms, per_image_inference_time: 0.049ms
2023-05-31 03:28:25 - until epoch: 199, best_acc1: 77.230%
2023-05-31 03:28:25 - epoch 200 lr: 0.000800
2023-05-31 03:28:25 - train: epoch 0193, iter [00200, 00390], lr: 0.000800, loss: 0.8037
2023-05-31 03:28:27 - train: epoch 0193, iter [00250, 00390], lr: 0.000800, loss: 0.7958
2023-05-31 03:28:28 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 0.7981
2023-05-31 03:28:29 - train: epoch 0193, iter [00300, 00390], lr: 0.000800, loss: 0.7849
2023-05-31 03:28:30 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.0117
2023-05-31 03:28:32 - train: epoch 0193, iter [00350, 00390], lr: 0.000800, loss: 0.8048
2023-05-31 03:28:32 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 0.2558
2023-05-31 03:28:34 - train: epoch 193, train_loss: 0.7983
2023-05-31 03:28:34 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.0046
2023-05-31 03:28:35 - eval: epoch: 193, acc1: 78.340%, acc5: 93.340%, test_loss: 1.0323, per_image_load_time: 0.065ms, per_image_inference_time: 0.047ms
2023-05-31 03:28:35 - until epoch: 193, best_acc1: 78.530%
2023-05-31 03:28:35 - epoch 194 lr: 0.000800
2023-05-31 03:28:36 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 0.2076
2023-05-31 03:28:38 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 0.2648
2023-05-31 03:28:38 - train: epoch 0194, iter [00050, 00390], lr: 0.000800, loss: 0.7857
2023-05-31 03:28:40 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 1.5967
2023-05-31 03:28:41 - train: epoch 0194, iter [00100, 00390], lr: 0.000800, loss: 0.7979
2023-05-31 03:28:42 - train: epoch 200, train_loss: 0.2308
2023-05-31 03:28:43 - train: epoch 0194, iter [00150, 00390], lr: 0.000800, loss: 0.7962
2023-05-31 03:28:44 - eval: epoch: 200, acc1: 76.350%, acc5: 93.840%, test_loss: 1.0361, per_image_load_time: 0.072ms, per_image_inference_time: 0.049ms
2023-05-31 03:28:44 - until epoch: 200, best_acc1: 77.230%
2023-05-31 03:28:44 - train done. model: resnet18cifar, train time: 1.368 hours, best_acc1: 77.230%
2023-05-31 03:28:44 - train: epoch 0194, iter [00200, 00390], lr: 0.000800, loss: 0.7883
2023-05-31 03:28:46 - train: epoch 0194, iter [00250, 00390], lr: 0.000800, loss: 0.7970
2023-05-31 03:28:47 - train: epoch 0194, iter [00300, 00390], lr: 0.000800, loss: 0.8017
2023-05-31 03:28:48 - train: epoch 0194, iter [00350, 00390], lr: 0.000800, loss: 0.8058
2023-05-31 03:28:49 - train: epoch 194, train_loss: 0.7980
2023-05-31 03:28:50 - eval: epoch: 194, acc1: 78.360%, acc5: 93.220%, test_loss: 1.0267, per_image_load_time: 0.066ms, per_image_inference_time: 0.046ms
2023-05-31 03:28:51 - until epoch: 194, best_acc1: 78.530%
2023-05-31 03:28:51 - epoch 195 lr: 0.000800
2023-05-31 03:28:53 - train: epoch 0195, iter [00050, 00390], lr: 0.000800, loss: 0.8120
2023-05-31 03:28:54 - train: epoch 0195, iter [00100, 00390], lr: 0.000800, loss: 0.8141
2023-05-31 03:28:56 - train: epoch 0195, iter [00150, 00390], lr: 0.000800, loss: 0.7982
2023-05-31 03:28:57 - train: epoch 0195, iter [00200, 00390], lr: 0.000800, loss: 0.8077
2023-05-31 03:28:58 - train: epoch 0195, iter [00250, 00390], lr: 0.000800, loss: 0.8048
2023-05-31 03:28:59 - train: epoch 0195, iter [00300, 00390], lr: 0.000800, loss: 0.7932
2023-05-31 03:29:01 - train: epoch 0195, iter [00350, 00390], lr: 0.000800, loss: 0.7876
2023-05-31 03:29:02 - train: epoch 195, train_loss: 0.7982
2023-05-31 03:29:03 - eval: epoch: 195, acc1: 78.220%, acc5: 93.200%, test_loss: 1.0378, per_image_load_time: 0.064ms, per_image_inference_time: 0.045ms
2023-05-31 03:29:04 - until epoch: 195, best_acc1: 78.530%
2023-05-31 03:29:04 - epoch 196 lr: 0.000800
2023-05-31 03:29:06 - train: epoch 0196, iter [00050, 00390], lr: 0.000800, loss: 0.7987
2023-05-31 03:29:07 - train: epoch 0196, iter [00100, 00390], lr: 0.000800, loss: 0.8155
2023-05-31 03:29:08 - train: epoch 0196, iter [00150, 00390], lr: 0.000800, loss: 0.8166
2023-05-31 03:29:10 - train: epoch 0196, iter [00200, 00390], lr: 0.000800, loss: 0.8064
2023-05-31 03:29:11 - train: epoch 0196, iter [00250, 00390], lr: 0.000800, loss: 0.8013
2023-05-31 03:29:12 - train: epoch 0196, iter [00300, 00390], lr: 0.000800, loss: 0.8005
2023-05-31 03:29:14 - train: epoch 0196, iter [00350, 00390], lr: 0.000800, loss: 0.7813
2023-05-31 03:29:15 - train: epoch 196, train_loss: 0.7984
2023-05-31 03:29:16 - eval: epoch: 196, acc1: 78.340%, acc5: 93.280%, test_loss: 1.0295, per_image_load_time: 0.073ms, per_image_inference_time: 0.045ms
2023-05-31 03:29:16 - until epoch: 196, best_acc1: 78.530%
2023-05-31 03:29:16 - epoch 197 lr: 0.000800
2023-05-31 03:29:18 - train: epoch 0197, iter [00050, 00390], lr: 0.000800, loss: 0.7971
2023-05-31 03:29:20 - train: epoch 0197, iter [00100, 00390], lr: 0.000800, loss: 0.7869
2023-05-31 03:29:21 - train: epoch 0197, iter [00150, 00390], lr: 0.000800, loss: 0.7761
2023-05-31 03:29:22 - train: epoch 0197, iter [00200, 00390], lr: 0.000800, loss: 0.8086
2023-05-31 03:29:24 - train: epoch 0197, iter [00250, 00390], lr: 0.000800, loss: 0.7953
2023-05-31 03:29:25 - train: epoch 0197, iter [00300, 00390], lr: 0.000800, loss: 0.8070
2023-05-31 03:29:26 - train: epoch 0197, iter [00350, 00390], lr: 0.000800, loss: 0.7736
2023-05-31 03:29:27 - train: epoch 197, train_loss: 0.7984
2023-05-31 03:29:29 - eval: epoch: 197, acc1: 78.230%, acc5: 93.340%, test_loss: 1.0339, per_image_load_time: 0.067ms, per_image_inference_time: 0.045ms
2023-05-31 03:29:29 - until epoch: 197, best_acc1: 78.530%
2023-05-31 03:29:29 - epoch 198 lr: 0.000800
2023-05-31 03:29:31 - train: epoch 0198, iter [00050, 00390], lr: 0.000800, loss: 0.8036
2023-05-31 03:29:33 - train: epoch 0198, iter [00100, 00390], lr: 0.000800, loss: 0.7984
2023-05-31 03:29:34 - train: epoch 0198, iter [00150, 00390], lr: 0.000800, loss: 0.7984
2023-05-31 03:29:35 - train: epoch 0198, iter [00200, 00390], lr: 0.000800, loss: 0.8060
2023-05-31 03:29:37 - train: epoch 0198, iter [00250, 00390], lr: 0.000800, loss: 0.7978
2023-05-31 03:29:38 - train: epoch 0198, iter [00300, 00390], lr: 0.000800, loss: 0.7939
2023-05-31 03:29:39 - train: epoch 0198, iter [00350, 00390], lr: 0.000800, loss: 0.7826
2023-05-31 03:29:41 - train: epoch 198, train_loss: 0.7978
2023-05-31 03:29:42 - eval: epoch: 198, acc1: 78.420%, acc5: 93.290%, test_loss: 1.0353, per_image_load_time: 0.081ms, per_image_inference_time: 0.044ms
2023-05-31 03:29:42 - until epoch: 198, best_acc1: 78.530%
2023-05-31 03:29:42 - epoch 199 lr: 0.000800
2023-05-31 03:29:45 - train: epoch 0199, iter [00050, 00390], lr: 0.000800, loss: 0.8033
2023-05-31 03:29:46 - train: epoch 0199, iter [00100, 00390], lr: 0.000800, loss: 0.8119
2023-05-31 03:29:47 - train: epoch 0199, iter [00150, 00390], lr: 0.000800, loss: 0.8004
2023-05-31 03:29:49 - train: epoch 0199, iter [00200, 00390], lr: 0.000800, loss: 0.7865
2023-05-31 03:29:50 - train: epoch 0199, iter [00250, 00390], lr: 0.000800, loss: 0.7999
2023-05-31 03:29:51 - train: epoch 0199, iter [00300, 00390], lr: 0.000800, loss: 0.8072
2023-05-31 03:29:53 - train: epoch 0199, iter [00350, 00390], lr: 0.000800, loss: 0.7995
2023-05-31 03:29:54 - train: epoch 199, train_loss: 0.7990
2023-05-31 03:29:55 - eval: epoch: 199, acc1: 78.230%, acc5: 93.270%, test_loss: 1.0281, per_image_load_time: 0.071ms, per_image_inference_time: 0.046ms
2023-05-31 03:29:55 - until epoch: 199, best_acc1: 78.530%
2023-05-31 03:29:55 - epoch 200 lr: 0.000800
2023-05-31 03:29:57 - train: epoch 0200, iter [00050, 00390], lr: 0.000800, loss: 0.8128
2023-05-31 03:29:59 - train: epoch 0200, iter [00100, 00390], lr: 0.000800, loss: 0.8039
2023-05-31 03:30:00 - train: epoch 0200, iter [00150, 00390], lr: 0.000800, loss: 0.7920
2023-05-31 03:30:01 - train: epoch 0200, iter [00200, 00390], lr: 0.000800, loss: 0.7974
2023-05-31 03:30:03 - train: epoch 0200, iter [00250, 00390], lr: 0.000800, loss: 0.7955
2023-05-31 03:30:04 - train: epoch 0200, iter [00300, 00390], lr: 0.000800, loss: 0.8079
2023-05-31 03:30:05 - train: epoch 0200, iter [00350, 00390], lr: 0.000800, loss: 0.8001
2023-05-31 03:30:07 - train: epoch 200, train_loss: 0.7983
2023-05-31 03:30:08 - eval: epoch: 200, acc1: 78.280%, acc5: 93.260%, test_loss: 1.0343, per_image_load_time: 0.077ms, per_image_inference_time: 0.049ms
2023-05-31 03:30:09 - until epoch: 200, best_acc1: 78.530%
2023-05-31 03:30:09 - train done. model: resnet18cifar, train time: 1.357 hours, best_acc1: 78.530%
2023-06-04 15:15:14 - network: resnet18cifar
2023-06-04 15:15:14 - num_classes: 100
2023-06-04 15:15:14 - input_image_size: 32
2023-06-04 15:15:14 - trained_model_path: 
2023-06-04 15:15:14 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-06-04 15:15:14 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-06-04 15:15:14 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fe278adff70>
2023-06-04 15:15:14 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7fe294b823a0>
2023-06-04 15:15:14 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fe2999c5580>
2023-06-04 15:15:14 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7fe2999c55e0>
2023-06-04 15:15:14 - seed: 0
2023-06-04 15:15:14 - batch_size: 128
2023-06-04 15:15:14 - num_workers: 16
2023-06-04 15:15:14 - accumulation_steps: 1
2023-06-04 15:15:14 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-06-04 15:15:14 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-06-04 15:15:14 - epochs: 200
2023-06-04 15:15:14 - print_interval: 50
2023-06-04 15:15:14 - sync_bn: False
2023-06-04 15:15:14 - apex: True
2023-06-04 15:15:14 - use_ema_model: False
2023-06-04 15:15:14 - ema_model_decay: 0.9999
2023-06-04 15:15:14 - gpus_type: NVIDIA GeForce RTX 3090
2023-06-04 15:15:14 - gpus_num: 1
2023-06-04 15:15:14 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7fe278c76b70>
2023-06-04 15:15:14 - --------------------parameters--------------------
2023-06-04 15:15:14 - name: conv1.layer.0.weight, grad: True
2023-06-04 15:15:14 - name: conv1.layer.1.weight, grad: True
2023-06-04 15:15:14 - name: conv1.layer.1.bias, grad: True
2023-06-04 15:15:14 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-06-04 15:15:14 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-06-04 15:15:14 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-06-04 15:15:14 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-06-04 15:15:14 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-06-04 15:15:14 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-06-04 15:15:14 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-06-04 15:15:14 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-06-04 15:15:14 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-06-04 15:15:14 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-06-04 15:15:15 - name: fc.weight, grad: True
2023-06-04 15:15:15 - name: fc.bias, grad: True
2023-06-04 15:15:15 - --------------------buffers--------------------
2023-06-04 15:15:15 - name: conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:15:15 - -----------no weight decay layers--------------
2023-06-04 15:15:15 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:15:15 - -------------weight decay layers---------------
2023-06-04 15:15:15 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:15 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:15:16 - resuming model from ./checkpoints/mixup/latest.pth. resume_epoch: 200, used_time: 1.357 hours, best_acc1: 78.530%, test_loss: 1.0343, lr: 0.000800
2023-06-04 15:15:16 - train done. model: resnet18cifar, train time: 1.357 hours, best_acc1: 78.530%
2023-06-04 15:28:44 - network: resnet18cifar
2023-06-04 15:28:44 - num_classes: 100
2023-06-04 15:28:44 - input_image_size: 32
2023-06-04 15:28:44 - trained_model_path: 
2023-06-04 15:28:44 - train_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-06-04 15:28:44 - test_criterion: CELoss(
  (loss): CrossEntropyLoss()
)
2023-06-04 15:28:44 - train_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f5c9c4bfeb0>
2023-06-04 15:28:44 - test_dataset: <simpleAICV.classification.datasets.cifar100dataset.CIFAR100Dataset object at 0x7f5c9c4a5a60>
2023-06-04 15:28:44 - train_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f5c9c4a5820>
2023-06-04 15:28:44 - test_collater: <simpleAICV.classification.common.ClassificationCollater object at 0x7f5c9c4a5910>
2023-06-04 15:28:44 - seed: 0
2023-06-04 15:28:44 - batch_size: 128
2023-06-04 15:28:44 - num_workers: 16
2023-06-04 15:28:44 - accumulation_steps: 1
2023-06-04 15:28:44 - optimizer: ('SGD', {'lr': 0.1, 'momentum': 0.9, 'global_weight_decay': False, 'weight_decay': 0.0005, 'no_weight_decay_layer_name_list': []})
2023-06-04 15:28:44 - scheduler: ('MultiStepLR', {'warm_up_epochs': 0, 'gamma': 0.2, 'milestones': [60, 120, 160]})
2023-06-04 15:28:44 - epochs: 200
2023-06-04 15:28:44 - print_interval: 50
2023-06-04 15:28:44 - sync_bn: False
2023-06-04 15:28:44 - apex: True
2023-06-04 15:28:44 - use_ema_model: False
2023-06-04 15:28:44 - ema_model_decay: 0.9999
2023-06-04 15:28:44 - AUG: none
2023-06-04 15:28:44 - gpus_type: NVIDIA GeForce RTX 3090
2023-06-04 15:28:44 - gpus_num: 1
2023-06-04 15:28:44 - group: <torch._C._distributed_c10d.ProcessGroupNCCL object at 0x7f5c9c4b3470>
2023-06-04 15:28:44 - --------------------parameters--------------------
2023-06-04 15:28:44 - name: conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.0.weight, grad: True
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.1.weight, grad: True
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.1.bias, grad: True
2023-06-04 15:28:44 - name: fc.weight, grad: True
2023-06-04 15:28:44 - name: fc.bias, grad: True
2023-06-04 15:28:44 - --------------------buffers--------------------
2023-06-04 15:28:44 - name: conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.1.running_mean, grad: False
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.1.running_var, grad: False
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.1.num_batches_tracked, grad: False
2023-06-04 15:28:44 - -----------no weight decay layers--------------
2023-06-04 15:28:44 - name: conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.1.weight, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.1.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - name: fc.bias, weight_decay: 0.0, lr_scale: not setting!
2023-06-04 15:28:44 - -------------weight decay layers---------------
2023-06-04 15:28:44 - name: conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer1.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer2.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer3.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.0.downsample_conv.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.1.conv1.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: layer4.1.conv2.layer.0.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - name: fc.weight, weight_decay: 0.0005, lr_scale: not setting!
2023-06-04 15:28:44 - epoch 001 lr: 0.100000
2023-06-04 15:28:51 - train: epoch 0001, iter [00050, 00390], lr: 0.100000, loss: 4.0623
2023-06-04 15:28:52 - train: epoch 0001, iter [00100, 00390], lr: 0.100000, loss: 4.1057
2023-06-04 15:28:53 - train: epoch 0001, iter [00150, 00390], lr: 0.100000, loss: 3.9887
2023-06-04 15:28:55 - train: epoch 0001, iter [00200, 00390], lr: 0.100000, loss: 3.7424
2023-06-04 15:28:56 - train: epoch 0001, iter [00250, 00390], lr: 0.100000, loss: 3.8073
2023-06-04 15:28:57 - train: epoch 0001, iter [00300, 00390], lr: 0.100000, loss: 3.5881
2023-06-04 15:28:58 - train: epoch 0001, iter [00350, 00390], lr: 0.100000, loss: 3.6378
2023-06-04 15:28:59 - train: epoch 001, train_loss: 3.8533
2023-06-04 15:29:01 - eval: epoch: 001, acc1: 17.510%, acc5: 43.270%, test_loss: 3.4598, per_image_load_time: 0.082ms, per_image_inference_time: 0.045ms
2023-06-04 15:29:01 - until epoch: 001, best_acc1: 17.510%
2023-06-04 15:29:01 - epoch 002 lr: 0.100000
